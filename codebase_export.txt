===== FILE: .dockerignore =====
node_modules
.next
.git
.gitignore
README.md
frontend-next/node_modules
frontend-next/.next
frontend-next/out
__pycache__
*.pyc
.env
.env.local
===== END FILE =====

===== FILE: .gcloudignore =====
# This file specifies files that are *not* uploaded to Google Cloud
# The rules in this file follow the same syntax as .gitignore

.git
.gitignore
README.md
.DS_Store
.vscode/
.pytest_cache/
__pycache__/
*.pyc
*.pyo
*.pyd
.Python
env/
venv/
.venv/
pip-log.txt
pip-delete-this-directory.txt
.tox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.log
.mypy_cache/
.dmypy.json
dmypy.json

# Railway specific files (not needed for Cloud Run)
railway.json
packages.txt
===== END FILE =====

===== FILE: .gitignore =====
.streamlit/
__pycache__/
.DS_Store

# Next.js
frontend-next/.next/
frontend-next/out/
frontend-next/node_modules/

# Environment variables
.env
.env.local
.env.production.local
.env.development.local

# Secrets (never commit these!)
users.json
*.secret
*.pem

# Logs
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# Refactor instructions (local only)
refactor-instructions/

# Dependencies
node_modules/

# ffmpeg.wasm core (generated from node_modules)
frontend-next/public/ffmpeg-core.*
===== END FILE =====

===== FILE: AGENTS.md =====
# AGENTS.md

Instructions for AI coding agents (Claude Code, Cursor, Copilot, etc.) working on this repository.

## Project Overview

**TranscribeAlpha** is a legal transcript generation web application that converts audio/video files into professionally formatted legal transcripts.

| Component | Technology |
|-----------|------------|
| Backend | FastAPI (Python 3.x) |
| Frontend | Next.js 14 + TypeScript + Tailwind CSS |
| Transcription | AssemblyAI (slam-1) or Gemini 3.0 Pro |
| Timestamp Alignment | Rev AI Forced Alignment API |
| Deployment | Google Cloud Run + Cloud Storage |
| HTTP Server | Hypercorn (HTTP/2 support) |

## App Variants

This codebase supports **two deployment variants** controlled by the `APP_VARIANT` environment variable:

| Variant | Value | Export Formats | Target Users |
|---------|-------|----------------|--------------|
| **OnCue** | `oncue` (default) | PDF + OnCue XML | Legal software integration |
| **Criminal** | `criminal` | PDF + HTML Viewer | DA/PD offices |

**What differs between variants:**
- `oncue`: Generates OnCue XML for proprietary legal software import
- `criminal`: Generates standalone HTML viewer with embedded media player

**What stays the same:**
- All features (transcription, editor, Gemini refinement, Rev AI resync, clips)
- PDF export formatting
- Branding ("TranscribeAlpha")
- Lines per page (25)

## Codebase Architecture

```
TranscribeAlpha/
├── backend/                    # Python backend (FastAPI)
│   ├── server.py              # FastAPI app wiring (routers, middleware, static files)
│   ├── config.py              # Env-driven constants (CORS, TTLs, APP_VARIANT)
│   ├── models.py              # Pydantic models (TranscriptTurn, WordTimestamp, Gemini structs)
│   ├── transcript_formatting.py # PDF/XML generation + line timing helpers
│   ├── transcript_utils.py    # Session serialization + viewer HTML generation
│   ├── word_legacy.py         # Deprecated Word/DOCX helpers (legacy import path)
│   ├── storage.py             # Cloud Storage ops + snapshots/sessions persistence
│   ├── media_processing.py    # ffmpeg helpers, clip extraction, audio prep
│   ├── gemini.py              # Gemini transcription + refine flow
│   ├── api/                   # FastAPI routers
│   │   ├── auth.py            # Auth endpoints
│   │   ├── transcripts.py     # Transcribe/import/save/resync endpoints
│   │   ├── media.py           # Media upload/streaming endpoints
│   │   ├── clips.py           # Clip creation/lookup endpoints
│   │   ├── cases.py           # Cases CRUD + transcript assignment
│   │   └── health.py          # Health + cleanup endpoints
│   ├── viewer/                # HTML viewer module (criminal variant)
│   │   ├── __init__.py        # render_viewer_html() function
│   │   └── template.html      # Standalone HTML viewer template
│   ├── transcriber.py         # AssemblyAI integration + media probing
│   ├── rev_ai_sync.py         # Rev AI forced alignment
│   ├── auth.py                # JWT authentication
│   ├── templates/             # Legacy Word templates (deprecated)
│   └── requirements.txt       # Python dependencies
│
├── frontend-next/             # Next.js frontend
│   ├── src/
│   │   ├── app/               # App Router
│   │   │   ├── layout.tsx           # Root layout (AuthProvider)
│   │   │   └── (dashboard)/         # Dashboard route group
│   │   │       ├── layout.tsx       # Dashboard layout with Sidebar
│   │   │       ├── page.tsx         # Dashboard home (quick-start)
│   │   │       ├── transcribe/      # Wizard transcription flow
│   │   │       ├── editor/          # Transcript editor (?key=)
│   │   │       ├── clip-creator/    # Clip extraction (?key=)
│   │   │       ├── cases/           # Cases list
│   │   │       ├── case-detail/     # Case detail page (?id=...)
│   │   │       └── settings/        # App settings
│   │   ├── components/        # React components
│   │   │   ├── TranscriptEditor.tsx  # Line-by-line editor
│   │   │   ├── ClipCreator.tsx       # Video clip extraction
│   │   │   ├── MediaMissingBanner.tsx # Media re-import banner
│   │   │   ├── AuthProvider.tsx      # Auth context
│   │   │   ├── LoginModal.tsx        # Login UI
│   │   │   └── layout/              # Layout components
│   │   │       └── Sidebar.tsx      # Dashboard sidebar navigation
│   │   ├── context/           # React contexts
│   │   │   └── DashboardContext.tsx # Shared dashboard state
│   │   └── utils/             # Utility functions
│   └── out/                   # Static export (production)
│
├── scripts/                   # Admin utility scripts
│   ├── add_user.sh           # Add user to Secret Manager
│   ├── list_users.sh         # List all users
│   └── remove_user.sh        # Remove user
│
├── main.py                    # Entry point (Hypercorn server)
├── Dockerfile                 # Multi-stage build (accepts APP_VARIANT build arg)
├── cloudbuild-oncue.yaml      # Cloud Build for oncue variant
├── cloudbuild-criminal.yaml   # Cloud Build for criminal variant
└── AGENTS.md                  # This file
```

## Key Design Decisions

### App Variant System

The variant is determined at both build-time and runtime:

**Dockerfile:**
```dockerfile
ARG APP_VARIANT=oncue
ENV APP_VARIANT=${APP_VARIANT}
```

**config.py:**
```python
APP_VARIANT = os.getenv("APP_VARIANT", "oncue")
```

**API conditional logic (transcripts.py):**
```python
if APP_VARIANT == "criminal":
    # Generate HTML viewer
    transcript_data["viewer_html_base64"] = ...
else:
    # Generate OnCue XML
    transcript_data["oncue_xml_base64"] = ...
```

**Frontend detection:**
- Frontend fetches `/api/config` on mount to determine variant
- Conditionally shows "Download OnCue XML" vs "Download HTML Viewer" button

### HTML Viewer (Criminal Variant)

The HTML viewer (`backend/viewer/template.html`) is designed to match PDF transcript formatting:
- Font: Courier New 12pt
- Line spacing: 2.0 (double-spaced)
- First-line indent: 1 inch for speaker lines
- 25 lines per page
- Line-level timestamp highlighting (no word-level - edited transcripts only have line timestamps)

### Router-first HTTP layer
The HTTP layer is organized around routers under `backend/api/`, with `backend/server.py`
kept intentionally thin to wire middleware, include routers, and mount the static frontend.

### Module Responsibilities

| Module | Responsibility | Should Contain |
|--------|----------------|----------------|
| `server.py` | HTTP app wiring | Router inclusion, middleware, startup cleanup, static mount |
| `backend/api/*.py` | HTTP layer | Endpoints and request/response handling |
| `transcriber.py` | Core transcription logic | AssemblyAI integration, media probing, transcription flow |
| `transcript_formatting.py` | Transcript rendering | PDF/XML generation, line timing rules |
| `transcript_utils.py` | Transcript/session helpers | Line normalization, snapshot payloads, viewer HTML generation |
| `storage.py` | Persistence layer | GCS ops, snapshots, session storage |
| `media_processing.py` | Media utilities | ffmpeg conversion, clip extraction, audio prep |
| `gemini.py` | Gemini flows | ASR and refinement logic |
| `rev_ai_sync.py` | Forced alignment | Rev AI API calls, timestamp correction |
| `auth.py` | Authentication | JWT, Secret Manager, user verification |
| `viewer/` | HTML viewer | Template rendering for criminal variant |

### Transcription Pipeline

The transcription flow uses ASR timestamps first, with optional Rev AI alignment later:

```
Audio/Video → ASR (AssemblyAI or Gemini) → PDF + (OnCue XML or HTML Viewer)
                         ↘ Rev AI Alignment (re-sync + legacy DOCX import only)
```

1. **ASR Stage**: AssemblyAI or Gemini extracts text + word timestamps
2. **Artifact Generation**: PDF and OnCue XML (or HTML viewer) generated from shared line entries
3. **Alignment Stage (optional)**: Rev AI forced alignment re-syncs edited transcripts or aligns legacy DOCX imports

If `REV_AI_API_KEY` is not configured, re-sync and legacy DOCX import alignment are skipped.
The alignment step preserves original text (punctuation, capitalization) while only updating timestamps.

**Line timing rules**
- Generated line timestamps enforce a 1.25s minimum duration by expanding into adjacent gaps without overlap.
- User-edited line timings are preserved (minimum-duration enforcement is skipped during manual saves).

**Speaker label display**
- The editor shows a speaker label on every line for easy reassignment.
- PDF/XML outputs collapse consecutive identical speakers by omitting repeated labels (via `is_continuation`).

### Dashboard UI

The frontend uses a dashboard layout with a persistent sidebar:

**Route Structure:**
- `/` - Dashboard home (quick-start landing page)
- `/transcribe` - 3-step wizard flow (Upload → Configure → Transcribe)
- `/editor?key=` - Transcript editor (loads by media_key)
- `/clip-creator?key=` - Clip extraction tool
- `/cases` - Cases list
- `/case-detail/?id=` - Case detail with transcript list
- `/settings` - App settings

**Key UI Patterns:**
- Collapsible sidebar with recent transcripts and cases
- Settings/tools tucked away in collapsible panels
- Clean header toolbars with primary actions visible
- Media player embedded in sidebar for editor/clip pages

### Cases System

Cases are folders for organizing transcripts:

**Storage Structure:**
```
cases/
  {user_id}/
    index.json                    # Quick list of all user's cases
    {case_id}/
      meta.json                   # Case metadata (name, description)
      transcripts.json            # List of {media_key, added_at, title_label}
```

**TTL Rules:**
| Condition | Behavior |
|-----------|----------|
| Transcript in a case | No expiration (persistent) |
| Transcript uncategorized | 30-day TTL |
| Media files | Standard cleanup policy |

**Case-Wide Search:**
- Searches across all transcripts in a case
- Matches text content and speaker names
- Returns results grouped by transcript

### Import Pattern
The codebase uses a multi-context import pattern to work in different execution contexts:
```python
try:
    from .module import func  # Package import
except ImportError:
    try:
        from module import func  # Direct import
    except ImportError:
        import module
        func = module.func  # Fallback
```
**Do not simplify** this pattern - it's necessary for Cloud Run deployment.

## API Endpoints Reference

| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/api/config` | GET | Returns app variant and feature flags |
| `/api/transcribe` | POST | Main transcription (file → PDF + XML/HTML) |
| `/api/upload-preview` | POST | Upload media for preview |
| `/api/media/{file_id}` | GET | Stream media files |
| `/api/auth/login` | POST | User authentication |
| `/api/auth/refresh` | POST | Refresh access token |
| `/api/auth/logout` | POST | Logout (client deletes tokens) |
| `/api/auth/me` | GET | Current user info |
| `/api/transcripts` | GET | List transcripts for the current user |
| `/api/transcripts/by-key/{media_key}` | GET/PUT | Load/save transcript session |
| `/api/transcripts/by-key/{media_key}/history` | GET | List snapshots for a transcript |
| `/api/transcripts/by-key/{media_key}/restore/{snapshot_id}` | POST | Restore a snapshot |
| `/api/transcripts/import` | POST | Import XML/HTML or legacy DOCX with media |
| `/api/transcripts/by-key/{media_key}/gemini-refine` | POST | Gemini refine pass |
| `/api/transcripts/uncategorized` | GET | List transcripts not in any case |
| `/api/resync` | POST | Re-align transcript with audio (Rev AI) |
| `/api/clips/*` | Various | Clip creation/management |
| `/api/cases` | GET/POST | List user's cases / Create new case |
| `/api/cases/{case_id}` | GET/PUT/DELETE | Get/update/delete case |
| `/api/cases/{case_id}/transcripts` | POST | Assign transcript to case |
| `/api/cases/{case_id}/transcripts/{media_key}` | DELETE | Remove transcript from case |
| `/api/cases/{case_id}/search` | GET | Search text + speakers in case |
| `/health` | GET | Health check + cleanup trigger |

## Development Guidelines

### Before Making Changes
1. **Read relevant files first** - Understand the existing code before modifying
2. **Check for existing patterns** - Follow established conventions
3. **Avoid over-engineering** - Only add what's explicitly needed

### Code Style
- **Python**: Follow existing patterns (logging, error handling)
- **TypeScript**: Use existing component structure
- **No unnecessary abstractions** - Direct code is preferred
- **No premature optimization** - Working code first

### What to Avoid
- Creating new modules without explicit request
- Adding features beyond what was asked
- Refactoring unrelated code during a fix
- Adding extensive comments to existing code
- Creating documentation files unless requested

### Safe Refactoring Checklist
Before any refactor, verify:
- [ ] All existing tests pass (if any)
- [ ] `/health` endpoint responds correctly
- [ ] File upload → transcription flow works
- [ ] Editor save/load cycle works
- [ ] Media playback functions

## Environment Variables

| Variable | Required | Purpose |
|----------|----------|---------|
| `APP_VARIANT` | No | `oncue` (default) or `criminal` |
| `ASSEMBLYAI_API_KEY` | Yes* | AssemblyAI transcription |
| `GEMINI_API_KEY` | Yes* | Gemini transcription (alt: `GOOGLE_API_KEY`) |
| `REV_AI_API_KEY` | Recommended | Forced alignment for accurate timestamps |
| `JWT_SECRET_KEY` | For auth | Token signing |
| `GOOGLE_CLOUD_PROJECT` | For auth | Secret Manager access |
| `PORT` | No | Server port (default: 8080) |
| `ENVIRONMENT` | No | "production" for strict CORS |

*At least one transcription API key required (AssemblyAI or Gemini).

## Deployment

This app is designed for **Google Cloud Run** with two separate deployments from the same codebase.

### Two Cloud Build Triggers

Set up two triggers in Google Cloud Console, each pointing to a different cloudbuild file:

| Trigger | Cloudbuild File | Service Name | APP_VARIANT |
|---------|-----------------|--------------|-------------|
| OnCue | `cloudbuild-oncue.yaml` | `transcribealpha-assemblyai` | `oncue` |
| Criminal | `cloudbuild-criminal.yaml` | `transcribealpha-criminal` | `criminal` |

### Manual Deployment

```bash
# Deploy oncue variant
gcloud builds submit --config cloudbuild-oncue.yaml \
  --substitutions=_ASSEMBLYAI_API_KEY=your_key

# Deploy criminal variant
gcloud builds submit --config cloudbuild-criminal.yaml \
  --substitutions=_ASSEMBLYAI_API_KEY=your_key
```

### Local Testing with Docker

```bash
# Build oncue variant
docker build --build-arg APP_VARIANT=oncue -t transcribealpha-oncue .

# Build criminal variant
docker build --build-arg APP_VARIANT=criminal -t transcribealpha-criminal .

# Run locally
docker run -p 8080:8080 \
  -e APP_VARIANT=oncue \
  -e ASSEMBLYAI_API_KEY=xxx \
  transcribealpha-oncue
```

## Common Tasks

### Add New API Endpoint
1. Add the route handler in the appropriate `backend/api/*.py` router
2. Use existing patterns for error handling
3. Add authentication if needed: `current_user: dict = Depends(get_current_user)`
4. If you add a new router module, include it in `backend/server.py`

### Modify Transcript Formatting
- Edit `backend/transcript_formatting.py`
- Functions: `create_pdf()`, `generate_oncue_xml_from_line_entries()`, `compute_transcript_line_entries()`

### Legacy Word Path (Deprecated)
- Word/DOCX logic is isolated in `backend/word_legacy.py`
- Deprecated behavior notes live in `docs/word-export-deprecated.md`
- New export changes should target the PDF pipeline, not DOCX generation

### Modify HTML Viewer (Criminal Variant)
- Edit `backend/viewer/template.html`
- Viewer payload built in `backend/transcript_utils.py` → `build_viewer_payload()`

### Update Frontend Component
- Edit files in `frontend-next/src/components/`
- Run `npm run build` in `frontend-next/` to regenerate static output

### Add Variant-Specific Logic
```python
from config import APP_VARIANT

if APP_VARIANT == "criminal":
    # Criminal-specific code
else:
    # OnCue-specific code (default)
```

### Add User Management Script
- See existing scripts in `scripts/` for pattern
- Use `gcloud secrets` for Secret Manager operations

## Troubleshooting

| Issue | Solution |
|-------|----------|
| 502 errors | Check ffmpeg installation, memory limits |
| Import errors | Verify Python path setup in deployment |
| CORS errors | Check `ENVIRONMENT` variable |
| Auth failures | Verify `JWT_SECRET_KEY` and Secret Manager access |
| Large file upload fails | Ensure HTTP/2 is enabled |
| Wrong export format | Check `APP_VARIANT` env var |

## Testing Checklist

After any change, verify:
1. `curl https://your-app.run.app/health` returns 200
2. `curl https://your-app.run.app/api/config` returns correct variant
3. File upload completes without error
4. Transcript download works (PDF + XML for oncue, PDF + HTML for criminal)
5. Editor loads and saves correctly
6. Media playback functions
7. History modal shows snapshots after edits

---

*Last updated: 2026-02-05*
===== END FILE =====

===== FILE: Dockerfile =====
# Multi-stage build: Node.js for frontend, Python for backend
FROM node:18-alpine AS frontend-builder

# Build the Next.js frontend
WORKDIR /app/frontend-next
COPY frontend-next/package.json frontend-next/package-lock.json* ./
RUN npm install
COPY frontend-next/ .
RUN npm run build

# Python backend stage
FROM python:3.11-slim AS backend

# App variant: "oncue" (default) or "criminal"
ARG APP_VARIANT=oncue
ENV APP_VARIANT=${APP_VARIANT}

# Set working directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    ffmpeg \
    libsndfile1-dev \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements first for better caching
COPY requirements.txt .

# Install Python dependencies
RUN pip install --no-cache-dir -r requirements.txt

# Copy the application code
COPY . .

# Copy the built frontend from the frontend-builder stage
COPY --from=frontend-builder /app/frontend-next/out ./frontend

# Expose the port that Cloud Run expects
EXPOSE 8080

# Set environment variables for Cloud Run
ENV PORT=8080
ENV HOST=0.0.0.0

# Run the application
CMD ["python", "main.py"]
===== END FILE =====

===== FILE: README.md =====
# TranscribeAlpha

A simple transcript generator powered by AssemblyAI. The original Streamlit prototype has been replaced with a small FastAPI backend and a static HTML front-end.

## Running Locally

1. Install system packages listed in `packages.txt` (ffmpeg and libsndfile1).
2. Install Python dependencies:

```bash
pip install -r requirements.txt
```

3. Export your AssemblyAI API key:

```bash
export ASSEMBLYAI_API_KEY="YOUR_ASSEMBLYAI_KEY_HERE"
```

4. Start the server:

```bash
uvicorn backend.server:app --reload
```

5. Open [http://localhost:8000](http://localhost:8000) in your browser and interact with the app.

## Notes

The backend relies on the [AssemblyAI Python SDK](https://github.com/AssemblyAI/assemblyai-python-sdk) for transcription and formatting.
- Transcriptions run on AssemblyAI's `slam-1` model to take advantage of its speaker-and-language-aware accuracy.

## File Size & Duration Limits

- Maximum upload size enforced by the backend: **2 GB** (requests larger than this return HTTP 413).
- Files larger than **100 MB** are automatically stored in **Google Cloud Storage** (`transcribealpha-uploads-1750110926`) before processing; Cloud Storage itself supports multi‑terabyte objects, so it is not the limiting factor.
- Cloud Run's default 32 MB HTTP/1 request limit is bypassed via HTTP/2 and Cloud Storage, so the app-level 2 GB cap is the effective size limit.
- Maximum audio duration is effectively bounded by what AssemblyAI accepts for a single transcription job and by container resources; AssemblyAI supports multi‑hour recordings, but for current hard limits you should refer to their docs: https://www.assemblyai.com/docs.
===== END FILE =====

===== FILE: ToDo.md =====
# ToDo.md

This file provides a list, sorted by category and not in any particular order, of desired features or improvements to be added to the transcription app. 

## Fixes
- Fix thing where it gives you cached transcript automatically for files that aren't the same
- Clean up codebase
- Fix errors with large video files
- Speed up functions that turn .json into DOCX/XML (optimize formatting pipeline)
- ~~**URGENT**: Replace temporary even-distribution timestamp interpolation strategy with more robust solution~~
  - **COMPLETED**: Implemented AssemblyAI integration with word-level timestamps
  - AssemblyAI now provides accurate per-line timing using word-level data
  - Gemini integration has been removed from the codebase

### Additional Features/Capabilities, Generally
- Devise internal transcription benchmark using a human-generated transcript and audio file
- Provide other methods to transcribe besides u.i; e.g. Box, DropBox, Zapier, Email integrations/automations
- Create cache/persistent storage of past transcripts, "history" page
- Batch processing?
- Make the UI look more professional
- Optional AI Summary

### Changes to Core Transcribing Functionality
- Remove need for Gemini vs AssemblyAI comparison (AssemblyAI is the sole engine)
- Improve OnCue transcript formatting
- ~~Delete option to enter number of lines per page~~
  - **COMPLETED**: Backend uses fixed 25 lines per page for OnCue XML
  - Frontend control removed to avoid user confusion
### Logistics, Deployment, Etc.
- Setup login system w/api key management, etc. 
- Figure out cost tracking

## Transcript Editor
- Create a transcript editor for both synced and unsynced transcripts, or else integrate with external editor and allow re-importing/re-syncing of oncue transcripts

## Sync Mode
- Create sync mode using forced allignment to produce OnCue transcripts from human-generated pdfs/docx. Ensure persistent formatting accross different styles, line numbering schema

## FFMPEG Clip Creator
- Features:
 - Clip by timestamp
 - Clip by transcript
    - Page/line numbers
    - 'when X said Y'
    - Highlight/select interface
 - Convert between formats, mute audio/separate, compress/reduce size 
===== END FILE =====

===== FILE: __init__.py =====
# This file makes the directory a Python package
===== END FILE =====

===== FILE: backend/__init__.py =====
# This file makes the backend directory a Python package
===== END FILE =====

===== FILE: backend/access_control.py =====
import json
import logging
from typing import Optional

from fastapi import Request

try:
    from .auth import decode_token
except ImportError:
    try:
        from auth import decode_token
    except ImportError:
        import auth as auth_module
        decode_token = auth_module.decode_token

try:
    from .storage import load_current_transcript, storage_client, BUCKET_NAME
except ImportError:
    try:
        from storage import load_current_transcript, storage_client, BUCKET_NAME
    except ImportError:
        import storage as storage_module
        load_current_transcript = storage_module.load_current_transcript
        storage_client = storage_module.storage_client
        BUCKET_NAME = storage_module.BUCKET_NAME

logger = logging.getLogger(__name__)


def _extract_token_from_request(request: Request) -> Optional[str]:
    auth_header = request.headers.get("authorization") or request.headers.get("Authorization")
    if auth_header:
        parts = auth_header.split()
        if len(parts) == 2 and parts[0].lower() == "bearer":
            return parts[1]
    token_param = request.query_params.get("token")
    return token_param or None


def _get_user_from_request(request: Request) -> Optional[dict]:
    token = _extract_token_from_request(request)
    if not token:
        return None
    payload = decode_token(token)
    if not payload or payload.get("type") not in {"access", "media"}:
        return None
    username = payload.get("sub")
    if not username:
        return None
    return {
        "username": username,
        "role": payload.get("role", "user"),
        "user_id": username,
    }


def _user_can_access_media_blob(user_id: str, blob_name: str, metadata: Optional[dict]) -> bool:
    if metadata and metadata.get("user_id"):
        return metadata.get("user_id") == user_id
    logger.warning("Media blob missing user metadata: %s", blob_name)
    return False


def _user_owns_media_key(media_key: str, user_id: str) -> bool:
    current = load_current_transcript(media_key)
    if current and current.get("user_id") == user_id:
        return True

    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        prefix = f"transcripts/{media_key}/history/"
        for blob in bucket.list_blobs(prefix=prefix):
            try:
                snapshot_data = json.loads(blob.download_as_string())
            except Exception:
                continue
            if snapshot_data.get("user_id") == user_id:
                return True
        return False
    except Exception as exc:
        logger.warning("Failed to verify transcript ownership for %s: %s", media_key, exc)
        return False
===== END FILE =====

===== FILE: backend/api/__init__.py =====
# API router package
===== END FILE =====

===== FILE: backend/api/auth.py =====
import logging
from typing import Dict

from fastapi import APIRouter, Body, Depends, HTTPException

try:
    from ..auth import (
        authenticate_user,
        create_access_token,
        create_refresh_token,
        get_current_user,
        decode_token,
    )
except ImportError:
    try:
        from auth import (
            authenticate_user,
            create_access_token,
            create_refresh_token,
            get_current_user,
            decode_token,
        )
    except ImportError:
        import auth as auth_module
        authenticate_user = auth_module.authenticate_user
        create_access_token = auth_module.create_access_token
        create_refresh_token = auth_module.create_refresh_token
        get_current_user = auth_module.get_current_user
        decode_token = auth_module.decode_token

router = APIRouter()
logger = logging.getLogger(__name__)


@router.post("/api/auth/login")
async def login(credentials: Dict = Body(...)):
    """
    Authenticate user and return access and refresh tokens.

    Request body:
    {
        "username": "string",
        "password": "string"
    }
    """
    username = credentials.get("username")
    password = credentials.get("password")

    if not username or not password:
        raise HTTPException(
            status_code=400,
            detail="Username and password are required"
        )

    user = authenticate_user(username, password)
    if not user:
        raise HTTPException(
            status_code=401,
            detail="Incorrect username or password",
            headers={"WWW-Authenticate": "Bearer"},
        )

    # Create tokens
    access_token = create_access_token(
        data={"sub": username, "role": user.get("role", "user")}
    )
    refresh_token = create_refresh_token(
        data={"sub": username, "role": user.get("role", "user")}
    )

    logger.info("User '%s' logged in successfully", username)

    return {
        "access_token": access_token,
        "refresh_token": refresh_token,
        "token_type": "bearer",
        "user": {
            "username": username,
            "role": user.get("role", "user"),
        },
    }


@router.post("/api/auth/refresh")
async def refresh_token(token_data: Dict = Body(...)):
    """
    Refresh access token using refresh token.

    Request body:
    {
        "refresh_token": "string"
    }
    """
    refresh_token_value = token_data.get("refresh_token")

    if not refresh_token_value:
        raise HTTPException(
            status_code=400,
            detail="Refresh token is required"
        )

    # Decode and validate refresh token
    payload = decode_token(refresh_token_value)

    if not payload or payload.get("type") != "refresh":
        raise HTTPException(
            status_code=401,
            detail="Invalid refresh token",
            headers={"WWW-Authenticate": "Bearer"},
        )

    username = payload.get("sub")
    if not username:
        raise HTTPException(
            status_code=401,
            detail="Invalid refresh token",
            headers={"WWW-Authenticate": "Bearer"},
        )

    # Create new access token
    access_token = create_access_token(
        data={"sub": username, "role": payload.get("role", "user")}
    )

    return {
        "access_token": access_token,
        "token_type": "bearer",
    }


@router.post("/api/auth/logout")
async def logout(current_user: dict = Depends(get_current_user)):
    """
    Logout endpoint (client should delete tokens).
    """
    logger.info("User '%s' logged out", current_user["username"])
    return {"message": "Successfully logged out"}


@router.get("/api/auth/me")
async def get_current_user_info(current_user: dict = Depends(get_current_user)):
    """Get current user information from token."""
    return {
        "username": current_user["username"],
        "role": current_user.get("role", "user"),
        "user_id": current_user["user_id"],
    }
===== END FILE =====

===== FILE: backend/api/cases.py =====
"""
Cases API Router

Provides endpoints for managing case folders that organize transcripts.
"""

import logging
import uuid
from typing import Dict, Optional

from fastapi import APIRouter, Body, Depends, HTTPException, Query
from fastapi.responses import JSONResponse

# Multi-context imports for auth
try:
    from ..auth import get_current_user
except ImportError:
    try:
        from auth import get_current_user
    except ImportError:
        import auth as auth_module
        get_current_user = auth_module.get_current_user

# Multi-context imports for storage
try:
    from ..storage import (
        create_case,
        load_case_meta,
        update_case_meta,
        delete_case,
        list_user_cases,
        get_case_transcripts,
        add_transcript_to_case,
        remove_transcript_from_case,
        search_case_transcripts,
        list_uncategorized_transcripts,
        load_current_transcript,
    )
except ImportError:
    try:
        from storage import (
            create_case,
            load_case_meta,
            update_case_meta,
            delete_case,
            list_user_cases,
            get_case_transcripts,
            add_transcript_to_case,
            remove_transcript_from_case,
            search_case_transcripts,
            list_uncategorized_transcripts,
            load_current_transcript,
        )
    except ImportError:
        import storage as storage_module
        create_case = storage_module.create_case
        load_case_meta = storage_module.load_case_meta
        update_case_meta = storage_module.update_case_meta
        delete_case = storage_module.delete_case
        list_user_cases = storage_module.list_user_cases
        get_case_transcripts = storage_module.get_case_transcripts
        add_transcript_to_case = storage_module.add_transcript_to_case
        remove_transcript_from_case = storage_module.remove_transcript_from_case
        search_case_transcripts = storage_module.search_case_transcripts
        list_uncategorized_transcripts = storage_module.list_uncategorized_transcripts
        load_current_transcript = storage_module.load_current_transcript


router = APIRouter()
logger = logging.getLogger(__name__)


@router.get("/api/cases")
async def list_cases(current_user: dict = Depends(get_current_user)):
    """
    List all cases for the authenticated user.
    Also returns count of uncategorized transcripts.
    """
    try:
        user_id = current_user["user_id"]
        cases = list_user_cases(user_id)
        uncategorized = list_uncategorized_transcripts(user_id)

        return JSONResponse({
            "cases": cases,
            "uncategorized_count": len(uncategorized),
        })

    except Exception as e:
        logger.error("Failed to list cases: %s", e)
        raise HTTPException(status_code=500, detail="Failed to list cases")


@router.post("/api/cases")
async def create_new_case(
    payload: Dict = Body(...),
    current_user: dict = Depends(get_current_user),
):
    """
    Create a new case.

    Body:
        name: str (required) - Name of the case
        description: str (optional) - Description of the case
    """
    name = payload.get("name")
    if not name or not name.strip():
        raise HTTPException(status_code=400, detail="Case name is required")

    try:
        user_id = current_user["user_id"]
        case_id = uuid.uuid4().hex
        description = payload.get("description", "")

        case_meta = create_case(user_id, case_id, name.strip(), description)

        return JSONResponse({
            "case": case_meta,
            "message": "Case created successfully",
        })

    except Exception as e:
        logger.error("Failed to create case: %s", e)
        raise HTTPException(status_code=500, detail="Failed to create case")


@router.get("/api/cases/{case_id}")
async def get_case(
    case_id: str,
    current_user: dict = Depends(get_current_user),
):
    """
    Get case details with list of transcripts.
    """
    try:
        user_id = current_user["user_id"]
        case_meta = load_case_meta(user_id, case_id)

        if not case_meta:
            raise HTTPException(status_code=404, detail="Case not found")

        # Get transcript list with additional details
        transcripts = get_case_transcripts(user_id, case_id)
        enriched_transcripts = []

        for entry in transcripts:
            media_key = entry.get("media_key")
            transcript = load_current_transcript(media_key) if media_key else None

            enriched_transcripts.append({
                "media_key": media_key,
                "title_label": entry.get("title_label", media_key),
                "added_at": entry.get("added_at"),
                "updated_at": transcript.get("updated_at") if transcript else None,
                "line_count": len(transcript.get("lines", [])) if transcript else 0,
                "audio_duration": transcript.get("audio_duration", 0) if transcript else 0,
            })

        return JSONResponse({
            "case": case_meta,
            "transcripts": enriched_transcripts,
        })

    except HTTPException:
        raise
    except Exception as e:
        logger.error("Failed to get case %s: %s", case_id, e)
        raise HTTPException(status_code=500, detail="Failed to get case")


@router.put("/api/cases/{case_id}")
async def update_case(
    case_id: str,
    payload: Dict = Body(...),
    current_user: dict = Depends(get_current_user),
):
    """
    Update case metadata (name, description).

    Body:
        name: str (optional)
        description: str (optional)
    """
    try:
        user_id = current_user["user_id"]

        # Verify case exists
        case_meta = load_case_meta(user_id, case_id)
        if not case_meta:
            raise HTTPException(status_code=404, detail="Case not found")

        # Build updates
        updates = {}
        if "name" in payload:
            name = payload["name"]
            if not name or not name.strip():
                raise HTTPException(status_code=400, detail="Case name cannot be empty")
            updates["name"] = name.strip()
        if "description" in payload:
            updates["description"] = payload["description"] or ""

        if not updates:
            return JSONResponse({"case": case_meta, "message": "No changes made"})

        updated_meta = update_case_meta(user_id, case_id, updates)

        return JSONResponse({
            "case": updated_meta,
            "message": "Case updated successfully",
        })

    except HTTPException:
        raise
    except Exception as e:
        logger.error("Failed to update case %s: %s", case_id, e)
        raise HTTPException(status_code=500, detail="Failed to update case")


@router.delete("/api/cases/{case_id}")
async def delete_case_endpoint(
    case_id: str,
    delete_transcripts: bool = Query(default=False),
    current_user: dict = Depends(get_current_user),
):
    """
    Delete a case.

    Query params:
        delete_transcripts: bool (default False)
            - If True, permanently deletes all transcripts in the case
            - If False, moves transcripts to uncategorized (restores 30-day TTL)
    """
    try:
        user_id = current_user["user_id"]

        # Verify case exists
        case_meta = load_case_meta(user_id, case_id)
        if not case_meta:
            raise HTTPException(status_code=404, detail="Case not found")

        # Get transcript count for response
        transcripts = get_case_transcripts(user_id, case_id)
        transcript_count = len(transcripts)

        # Delete the case
        affected_keys = delete_case(user_id, case_id, delete_transcripts=delete_transcripts)

        action = "deleted" if delete_transcripts else "moved to uncategorized"
        return JSONResponse({
            "message": f"Case deleted successfully. {transcript_count} transcript(s) {action}.",
            "affected_transcript_count": transcript_count,
            "transcripts_deleted": delete_transcripts,
        })

    except HTTPException:
        raise
    except Exception as e:
        logger.error("Failed to delete case %s: %s", case_id, e)
        raise HTTPException(status_code=500, detail="Failed to delete case")


@router.post("/api/cases/{case_id}/transcripts")
async def add_transcript_to_case_endpoint(
    case_id: str,
    payload: Dict = Body(...),
    current_user: dict = Depends(get_current_user),
):
    """
    Add a transcript to a case.
    The transcript becomes persistent (no TTL expiration).

    Body:
        media_key: str (required) - The transcript's media_key
    """
    media_key = payload.get("media_key")
    if not media_key:
        raise HTTPException(status_code=400, detail="media_key is required")

    try:
        user_id = current_user["user_id"]

        # Verify case exists
        case_meta = load_case_meta(user_id, case_id)
        if not case_meta:
            raise HTTPException(status_code=404, detail="Case not found")

        # Verify transcript exists and belongs to user
        transcript = load_current_transcript(media_key)
        if not transcript:
            raise HTTPException(status_code=404, detail="Transcript not found")
        if transcript.get("user_id") != user_id:
            raise HTTPException(status_code=403, detail="Access denied to this transcript")

        # Get title label
        title_data = transcript.get("title_data", {})
        title_label = title_data.get("FILE_NAME") or title_data.get("CASE_NAME") or media_key

        # Add to case
        success = add_transcript_to_case(user_id, case_id, media_key, title_label)

        if not success:
            raise HTTPException(status_code=500, detail="Failed to add transcript to case")

        return JSONResponse({
            "message": "Transcript added to case successfully",
            "media_key": media_key,
            "case_id": case_id,
        })

    except HTTPException:
        raise
    except Exception as e:
        logger.error("Failed to add transcript %s to case %s: %s", media_key, case_id, e)
        raise HTTPException(status_code=500, detail="Failed to add transcript to case")


@router.delete("/api/cases/{case_id}/transcripts/{media_key}")
async def remove_transcript_from_case_endpoint(
    case_id: str,
    media_key: str,
    current_user: dict = Depends(get_current_user),
):
    """
    Remove a transcript from a case.
    The transcript moves to uncategorized and 30-day TTL is restored.
    """
    try:
        user_id = current_user["user_id"]

        # Verify case exists
        case_meta = load_case_meta(user_id, case_id)
        if not case_meta:
            raise HTTPException(status_code=404, detail="Case not found")

        # Remove from case
        success = remove_transcript_from_case(user_id, case_id, media_key)

        if not success:
            raise HTTPException(status_code=404, detail="Transcript not found in this case")

        return JSONResponse({
            "message": "Transcript removed from case. It will expire in 30 days if not added to another case.",
            "media_key": media_key,
        })

    except HTTPException:
        raise
    except Exception as e:
        logger.error("Failed to remove transcript %s from case %s: %s", media_key, case_id, e)
        raise HTTPException(status_code=500, detail="Failed to remove transcript from case")


@router.get("/api/cases/{case_id}/search")
async def search_case(
    case_id: str,
    q: str = Query(..., min_length=2),
    current_user: dict = Depends(get_current_user),
):
    """
    Search text and speaker names across all transcripts in a case.

    Query params:
        q: str (required, min 2 chars) - Search query
    """
    try:
        user_id = current_user["user_id"]

        # Verify case exists
        case_meta = load_case_meta(user_id, case_id)
        if not case_meta:
            raise HTTPException(status_code=404, detail="Case not found")

        results = search_case_transcripts(user_id, case_id, q)

        # Calculate totals
        total_matches = sum(len(r.get("matches", [])) for r in results)
        transcripts_with_matches = len(results)

        return JSONResponse({
            "query": q,
            "case_id": case_id,
            "results": results,
            "total_matches": total_matches,
            "transcripts_with_matches": transcripts_with_matches,
        })

    except HTTPException:
        raise
    except Exception as e:
        logger.error("Failed to search case %s: %s", case_id, e)
        raise HTTPException(status_code=500, detail="Failed to search case")


@router.get("/api/transcripts/uncategorized")
async def list_uncategorized(current_user: dict = Depends(get_current_user)):
    """
    List all transcripts not assigned to any case.
    These have 30-day TTL and will expire.
    """
    try:
        user_id = current_user["user_id"]
        transcripts = list_uncategorized_transcripts(user_id)

        return JSONResponse({
            "transcripts": transcripts,
            "count": len(transcripts),
        })

    except Exception as e:
        logger.error("Failed to list uncategorized transcripts: %s", e)
        raise HTTPException(status_code=500, detail="Failed to list transcripts")
===== END FILE =====

===== FILE: backend/api/clips.py =====
import base64
import uuid
from datetime import datetime, timedelta, timezone
from typing import Dict

from fastapi import APIRouter, Body, Depends, HTTPException
from fastapi.responses import JSONResponse

try:
    from ..auth import get_current_user
except ImportError:
    try:
        from auth import get_current_user
    except ImportError:
        import auth as auth_module
        get_current_user = auth_module.get_current_user

try:
    from ..config import CLIP_SESSION_TTL_DAYS, DEFAULT_LINES_PER_PAGE, APP_VARIANT
except ImportError:
    try:
        from config import CLIP_SESSION_TTL_DAYS, DEFAULT_LINES_PER_PAGE, APP_VARIANT
    except ImportError:
        import config as config_module
        CLIP_SESSION_TTL_DAYS = config_module.CLIP_SESSION_TTL_DAYS
        DEFAULT_LINES_PER_PAGE = config_module.DEFAULT_LINES_PER_PAGE
        APP_VARIANT = config_module.APP_VARIANT

try:
    from ..media_processing import clip_media_segment
except ImportError:
    try:
        from media_processing import clip_media_segment
    except ImportError:
        import media_processing as media_processing_module
        clip_media_segment = media_processing_module.clip_media_segment

try:
    from ..storage import (
        delete_clip_session,
        load_clip_session,
        load_current_transcript,
        save_clip_session,
        save_current_transcript,
    )
except ImportError:
    try:
        from storage import (
            delete_clip_session,
            load_clip_session,
            load_current_transcript,
            save_clip_session,
            save_current_transcript,
        )
    except ImportError:
        import storage as storage_module
        delete_clip_session = storage_module.delete_clip_session
        load_clip_session = storage_module.load_clip_session
        load_current_transcript = storage_module.load_current_transcript
        save_clip_session = storage_module.save_clip_session
        save_current_transcript = storage_module.save_current_transcript

try:
    from ..transcript_utils import (
        build_session_artifacts,
        build_variant_exports,
        construct_turns_from_lines,
        ensure_session_clip_list,
        normalize_line_payloads,
        parse_timecode_to_seconds,
        resolve_line_index,
        resolve_media_filename,
        sanitize_clip_label,
    )
except ImportError:
    try:
        from transcript_utils import (
            build_session_artifacts,
            build_variant_exports,
            construct_turns_from_lines,
            ensure_session_clip_list,
            normalize_line_payloads,
            parse_timecode_to_seconds,
            resolve_line_index,
            resolve_media_filename,
            sanitize_clip_label,
        )
    except ImportError:
        import transcript_utils as transcript_utils_module
        build_session_artifacts = transcript_utils_module.build_session_artifacts
        build_variant_exports = transcript_utils_module.build_variant_exports
        construct_turns_from_lines = transcript_utils_module.construct_turns_from_lines
        ensure_session_clip_list = transcript_utils_module.ensure_session_clip_list
        normalize_line_payloads = transcript_utils_module.normalize_line_payloads
        parse_timecode_to_seconds = transcript_utils_module.parse_timecode_to_seconds
        resolve_line_index = transcript_utils_module.resolve_line_index
        resolve_media_filename = transcript_utils_module.resolve_media_filename
        sanitize_clip_label = transcript_utils_module.sanitize_clip_label


router = APIRouter()


@router.post("/api/clips")
async def create_clip(payload: Dict = Body(...), current_user: dict = Depends(get_current_user)):
    media_key = payload.get("media_key")
    if not media_key:
        raise HTTPException(status_code=400, detail="media_key is required")

    session_data = load_current_transcript(media_key)
    if not session_data:
        raise HTTPException(status_code=404, detail="Transcript not found")
    if session_data.get("user_id") and session_data.get("user_id") != current_user["user_id"]:
        raise HTTPException(status_code=403, detail="Access denied to this transcript")

    lines = session_data.get("lines") or []
    if not lines:
        raise HTTPException(status_code=400, detail="Session does not contain transcript lines")

    # Resolve lines-per-page for the clip
    try:
        lines_per_page = int(payload.get("lines_per_page") or session_data.get("lines_per_page") or DEFAULT_LINES_PER_PAGE)
    except (TypeError, ValueError):
        lines_per_page = DEFAULT_LINES_PER_PAGE
    if lines_per_page <= 0:
        lines_per_page = DEFAULT_LINES_PER_PAGE

    # Accept page/line pairs if provided and derive pgln value for lookup
    start_pgln = payload.get("start_pgln")
    if start_pgln is None and payload.get("start_page") is not None and payload.get("start_line") is not None:
        try:
            start_pgln = int(payload["start_page"]) * 100 + int(payload["start_line"])
        except (TypeError, ValueError):
            start_pgln = None

    end_pgln = payload.get("end_pgln")
    if end_pgln is None and payload.get("end_page") is not None and payload.get("end_line") is not None:
        try:
            end_pgln = int(payload["end_page"]) * 100 + int(payload["end_line"])
        except (TypeError, ValueError):
            end_pgln = None

    start_time = parse_timecode_to_seconds(payload.get("start_time"))
    end_time = parse_timecode_to_seconds(payload.get("end_time"))

    start_index = resolve_line_index(
        lines,
        line_id=payload.get("start_line_id"),
        pgln=start_pgln,
        time_seconds=start_time,
        prefer_start=True,
    )
    if start_index is None:
        raise HTTPException(status_code=400, detail="Unable to resolve clip start line")

    end_index = resolve_line_index(
        lines,
        line_id=payload.get("end_line_id"),
        pgln=end_pgln,
        time_seconds=end_time,
        prefer_start=False,
    )
    if end_index is None:
        raise HTTPException(status_code=400, detail="Unable to resolve clip end line")

    if start_index > end_index:
        start_index, end_index = end_index, start_index

    selected_slice = lines[start_index : end_index + 1]
    if not selected_slice:
        raise HTTPException(status_code=400, detail="Selected clip range is empty")

    start_line = selected_slice[0]
    end_line = selected_slice[-1]

    start_absolute = float(start_line.get("start", 0.0) or 0.0)
    end_absolute = float(end_line.get("end", start_absolute) or start_absolute)

    if end_absolute <= start_absolute:
        end_absolute = start_absolute + 0.01

    rebased_lines = []
    for local_idx, original_line in enumerate(selected_slice):
        original_start = float(original_line.get("start", 0.0) or 0.0)
        original_end = float(original_line.get("end", original_start) or original_start)
        if original_end <= original_start:
            original_end = original_start + 0.01

        rebased_lines.append(
            {
                "id": f"clip-{local_idx}",
                "speaker": (str(original_line.get("speaker", "SPEAKER"))).strip().upper() or "SPEAKER",
                "text": str(original_line.get("text", "")),
                "start": max(original_start - start_absolute, 0.0),
                "end": max(original_end - start_absolute, 0.0),
                "is_continuation": False if local_idx == 0 else bool(original_line.get("is_continuation", False)),
            }
        )

    clip_duration_hint = max(end_absolute - start_absolute, 0.01)
    normalized_lines, normalized_duration = normalize_line_payloads(rebased_lines, clip_duration_hint)
    turns = construct_turns_from_lines(normalized_lines)
    if not turns:
        raise HTTPException(status_code=400, detail="Unable to construct transcript turns for clip")

    clip_count = len(ensure_session_clip_list(session_data))
    default_name = f"Clip {clip_count + 1}"
    clip_name = sanitize_clip_label(payload.get("clip_label"), default_name)

    clip_title_data = dict(session_data.get("title_data") or {})
    title_overrides = payload.get("title_overrides") if isinstance(payload.get("title_overrides"), dict) else {}
    for key, value in title_overrides.items():
        if value is not None:
            clip_title_data[key] = str(value)

    hours, remainder = divmod(normalized_duration, 3600)
    minutes, seconds = divmod(remainder, 60)
    clip_title_data["CLIP_DURATION"] = f"{int(hours):02d}:{int(minutes):02d}:{int(round(seconds)):02d}"
    clip_title_data["CLIP_TITLE"] = clip_name

    pdf_bytes, oncue_xml, transcript_text, clip_line_entries = build_session_artifacts(
        turns,
        clip_title_data,
        normalized_duration,
        lines_per_page,
        enforce_min_line_duration=False,
    )
    pdf_b64 = base64.b64encode(pdf_bytes).decode()

    clip_media_blob_name, clip_media_content_type = clip_media_segment(
        session_data.get("media_blob_name"),
        start_absolute,
        end_absolute,
        session_data.get("media_content_type"),
        clip_name,
        user_id=session_data.get("user_id"),
        parent_media_key=media_key,
    )

    media_filename = resolve_media_filename(
        clip_title_data,
        clip_media_blob_name or session_data.get("media_blob_name"),
        fallback="media.mp4",
    )
    export_payload = build_variant_exports(
        APP_VARIANT,
        clip_line_entries,
        clip_title_data,
        normalized_duration,
        lines_per_page,
        media_filename,
        clip_media_content_type or session_data.get("media_content_type"),
        oncue_xml=oncue_xml,
    )

    clip_id = uuid.uuid4().hex
    created_at = datetime.now(timezone.utc)
    clip_expires_at = created_at + timedelta(days=CLIP_SESSION_TTL_DAYS)

    clip_data = {
        "clip_id": clip_id,
        "parent_media_key": media_key,
        "user_id": session_data.get("user_id"),
        "name": clip_name,
        "created_at": created_at.isoformat(),
        "expires_at": clip_expires_at.isoformat(),
        "duration": float(normalized_duration),
        "start_time": float(start_absolute),
        "end_time": float(end_absolute),
        "start_line_id": start_line.get("id"),
        "end_line_id": end_line.get("id"),
        "start_pgln": start_line.get("pgln"),
        "end_pgln": end_line.get("pgln"),
        "start_page": start_line.get("page"),
        "start_line_number": start_line.get("line"),
        "end_page": end_line.get("page"),
        "end_line_number": end_line.get("line"),
        "pdf_base64": pdf_b64,
        "transcript_text": transcript_text,
        "lines": clip_line_entries,
        "title_data": clip_title_data,
        "lines_per_page": lines_per_page,
        "media_blob_name": clip_media_blob_name,
        "media_content_type": clip_media_content_type,
    }
    clip_data.update(export_payload)

    clip_summary = {
        "clip_id": clip_id,
        "parent_media_key": media_key,
        "name": clip_name,
        "created_at": created_at.isoformat(),
        "duration": float(normalized_duration),
        "start_time": float(start_absolute),
        "end_time": float(end_absolute),
        "start_pgln": start_line.get("pgln"),
        "end_pgln": end_line.get("pgln"),
        "start_page": start_line.get("page"),
        "start_line": start_line.get("line"),
        "end_page": end_line.get("page"),
        "end_line": end_line.get("line"),
        "media_blob_name": clip_media_blob_name,
        "media_content_type": clip_media_content_type,
        "file_name": clip_title_data.get("FILE_NAME"),
    }

    try:
        save_clip_session(clip_id, clip_data)
    except Exception as exc:
        raise HTTPException(status_code=500, detail="Unable to persist clip data") from exc

    clips_list = ensure_session_clip_list(session_data)
    clips_list.append(clip_summary)

    session_data["updated_at"] = created_at.isoformat()
    session_data["media_key"] = media_key

    try:
        save_current_transcript(media_key, session_data)
    except Exception as exc:
        clips_list.pop()
        delete_clip_session(clip_id)
        raise HTTPException(status_code=500, detail="Unable to update session with clip metadata") from exc

    clip_response = dict(clip_data)
    clip_response.pop("parent_media_key", None)
    clip_response.pop("user_id", None)
    clip_response["transcript"] = clip_response.pop("transcript_text", "")
    clip_response["summary"] = clip_summary

    return JSONResponse({
        "clip": clip_response,
        "transcript": session_data,
    })


@router.get("/api/clips/{clip_id}")
async def get_clip_session(clip_id: str, current_user: dict = Depends(get_current_user)):
    clip_data = load_clip_session(clip_id)
    if not clip_data:
        raise HTTPException(status_code=404, detail="Clip session not found")

    if clip_data.get("user_id") and clip_data.get("user_id") != current_user["user_id"]:
        raise HTTPException(status_code=403, detail="Access denied to this clip")

    expires_at = clip_data.get("expires_at")
    if expires_at:
        try:
            expires_dt = datetime.fromisoformat(expires_at)
        except ValueError:
            try:
                expires_dt = datetime.fromisoformat(expires_at.replace("Z", "+00:00"))
            except ValueError:
                expires_dt = None
        if expires_dt and expires_dt < datetime.now(timezone.utc):
            delete_clip_session(clip_id)
            raise HTTPException(status_code=404, detail="Clip session expired")

    response_payload = dict(clip_data)
    response_payload.pop("user_id", None)
    response_payload["transcript"] = response_payload.pop("transcript_text", "")
    return JSONResponse(response_payload)
===== END FILE =====

===== FILE: backend/api/health.py =====
import logging
import os
from datetime import datetime, timedelta

from fastapi import APIRouter

try:
    from ..config import APP_VARIANT
except ImportError:
    try:
        from config import APP_VARIANT
    except ImportError:
        import config as config_module
        APP_VARIANT = config_module.APP_VARIANT

try:
    from ..storage import cleanup_expired_clip_sessions, cleanup_old_files
except ImportError:
    try:
        from storage import cleanup_expired_clip_sessions, cleanup_old_files
    except ImportError:
        import storage as storage_module
        cleanup_expired_clip_sessions = storage_module.cleanup_expired_clip_sessions
        cleanup_old_files = storage_module.cleanup_old_files

router = APIRouter()
logger = logging.getLogger(__name__)

# Track last cleanup time for periodic cleanup
last_cleanup_time = datetime.now()


@router.get("/health")
async def health_check():
    """Health check endpoint for deployment platforms"""
    global last_cleanup_time

    # Skip cleanup for criminal variant (nothing stored in GCS)
    if APP_VARIANT != "criminal":
        # Run cleanup every 12 hours
        current_time = datetime.now()
        if current_time - last_cleanup_time > timedelta(hours=12):
            try:
                cleanup_old_files()
                cleanup_expired_clip_sessions()
                last_cleanup_time = current_time
                logger.info("Periodic cleanup completed via health check")
            except Exception as e:
                logger.error("Periodic cleanup failed: %s", str(e))

    return {
        "status": "healthy",
        "service": "TranscribeAlpha",
        "assemblyai_api_key_configured": bool(os.getenv("ASSEMBLYAI_API_KEY")),
        "last_cleanup": last_cleanup_time.isoformat(),
    }
===== END FILE =====

===== FILE: backend/api/media.py =====
import logging
import os
import mimetypes
import re
from datetime import datetime, timedelta, timezone
from typing import Optional

from fastapi import APIRouter, Depends, File, HTTPException, Request, UploadFile
from fastapi.responses import JSONResponse, StreamingResponse

try:
    from ..auth import get_current_user, create_media_token
except ImportError:
    try:
        from auth import get_current_user, create_media_token
    except ImportError:
        import auth as auth_module
        get_current_user = auth_module.get_current_user
        create_media_token = auth_module.create_media_token

try:
    from ..config import MEDIA_TOKEN_TTL_MINUTES
except ImportError:
    try:
        from config import MEDIA_TOKEN_TTL_MINUTES
    except ImportError:
        import config as config_module
        MEDIA_TOKEN_TTL_MINUTES = config_module.MEDIA_TOKEN_TTL_MINUTES

try:
    from ..access_control import _get_user_from_request, _user_can_access_media_blob
except ImportError:
    try:
        from access_control import _get_user_from_request, _user_can_access_media_blob
    except ImportError:
        import access_control as access_control_module
        _get_user_from_request = access_control_module._get_user_from_request
        _user_can_access_media_blob = access_control_module._user_can_access_media_blob

try:
    from ..storage import (
        get_blob_metadata,
        save_upload_to_tempfile,
        storage_client,
        BUCKET_NAME,
        upload_preview_file_to_cloud_storage_from_path,
    )
except ImportError:
    try:
        from storage import (
            get_blob_metadata,
            save_upload_to_tempfile,
            storage_client,
            BUCKET_NAME,
            upload_preview_file_to_cloud_storage_from_path,
        )
    except ImportError:
        import storage as storage_module
        get_blob_metadata = storage_module.get_blob_metadata
        save_upload_to_tempfile = storage_module.save_upload_to_tempfile
        storage_client = storage_module.storage_client
        BUCKET_NAME = storage_module.BUCKET_NAME
        upload_preview_file_to_cloud_storage_from_path = storage_module.upload_preview_file_to_cloud_storage_from_path

router = APIRouter()
logger = logging.getLogger(__name__)


@router.post("/api/upload-preview")
async def upload_media_preview(file: UploadFile = File(...), current_user: dict = Depends(get_current_user)):
    """Upload media file for preview purposes"""
    temp_path = None
    try:
        temp_path, file_size = await save_upload_to_tempfile(file)
        if not temp_path or file_size == 0:
            raise HTTPException(status_code=400, detail="Uploaded media file is empty")

        content_type = file.content_type or mimetypes.guess_type(file.filename)[0]

        blob_name = upload_preview_file_to_cloud_storage_from_path(
            temp_path,
            file.filename,
            content_type,
            user_id=current_user["user_id"],
        )

        logger.info("Uploaded media file for preview: %s (%d bytes)", file.filename, file_size)

        return JSONResponse({
            "file_id": blob_name,
            "filename": file.filename,
            "size": file_size,
            "content_type": content_type,
        })

    except HTTPException:
        raise
    except Exception as e:
        logger.error("Media preview upload failed: %s", str(e))
        raise HTTPException(status_code=500, detail=f"Upload failed: {str(e)}")
    finally:
        if temp_path:
            try:
                os.remove(temp_path)
            except OSError:
                pass


@router.post("/api/media-token")
async def create_media_token_endpoint(current_user: dict = Depends(get_current_user)):
    """Issue a short-lived token scoped for media playback."""
    ttl_minutes = max(int(MEDIA_TOKEN_TTL_MINUTES or 0), 1)
    expires_delta = timedelta(minutes=ttl_minutes)
    expires_at = datetime.now(timezone.utc) + expires_delta
    token = create_media_token(
        data={"sub": current_user["username"], "role": current_user.get("role", "user")},
        expires_delta=expires_delta,
    )
    return JSONResponse({
        "token": token,
        "expires_at": expires_at.isoformat(),
        "expires_in": ttl_minutes * 60,
    })


@router.get("/api/media/{file_id}")
async def serve_media_file(file_id: str, request: Request):
    """Serve media file for preview"""
    try:
        request_user = _get_user_from_request(request)
        if not request_user:
            raise HTTPException(status_code=401, detail="Authentication required")

        metadata = get_blob_metadata(file_id)
        if not metadata:
            raise HTTPException(status_code=404, detail="Media file not found")

        if not _user_can_access_media_blob(request_user["user_id"], file_id, metadata):
            raise HTTPException(status_code=403, detail="Access denied to media file")

        bucket = storage_client.bucket(BUCKET_NAME)
        blob = bucket.blob(file_id)
        if not blob.exists():
            raise HTTPException(status_code=404, detail="Media file not found")

        blob.reload()
        file_size = metadata.get("size") or blob.size or 0
        logger.info("Serving media %s: size=%s, content_type=%s", file_id, file_size, metadata.get("content_type"))
        content_type = metadata.get("content_type", "application/octet-stream")

        range_header = request.headers.get("range")
        start = 0
        end = file_size - 1 if file_size else None
        status_code = 200
        headers = {
            "Accept-Ranges": "bytes",
            "Cache-Control": "private, no-store",
        }

        if range_header and file_size:
            range_match = re.match(r"^bytes=(\d*)-(\d*)$", range_header.strip())
            if range_match:
                start_str = range_match.group(1)
                end_str = range_match.group(2)

                if start_str:
                    start = int(start_str)
                    end = int(end_str) if end_str else file_size - 1
                elif end_str:
                    suffix_size = int(end_str)
                    if suffix_size <= 0:
                        raise HTTPException(status_code=416, detail="Invalid range header")
                    start = max(file_size - suffix_size, 0)
                    end = file_size - 1
                else:
                    raise HTTPException(status_code=416, detail="Invalid range header")

                if end is None or end >= file_size:
                    end = file_size - 1
                if start >= file_size:
                    raise HTTPException(status_code=416, detail="Invalid range header")
                if start > end:
                    raise HTTPException(status_code=416, detail="Invalid range header")

                status_code = 206
                headers["Content-Range"] = f"bytes {start}-{end}/{file_size}"
                headers["Content-Length"] = str(end - start + 1)
            else:
                logger.warning("Invalid range header received: %s", range_header)

        elif file_size:
            headers["Content-Length"] = str(file_size)

        def iter_chunks(start_pos: int, end_pos: Optional[int]):
            chunk_size = 1024 * 1024  # 1MB chunks
            bytes_remaining = (end_pos - start_pos + 1) if end_pos is not None else None
            with blob.open("rb") as stream:
                if start_pos:
                    stream.seek(start_pos)
                while True:
                    read_size = chunk_size if bytes_remaining is None else min(chunk_size, bytes_remaining)
                    if read_size <= 0:
                        break
                    data = stream.read(read_size)
                    if not data:
                        break
                    yield data
                    if bytes_remaining is not None:
                        bytes_remaining -= len(data)
                        if bytes_remaining <= 0:
                            break

        return StreamingResponse(
            iter_chunks(start, end),
            media_type=content_type,
            status_code=status_code,
            headers=headers,
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error("Error serving media file %s: %s", file_id, str(e))
        raise HTTPException(status_code=500, detail="Error serving media file")
===== END FILE =====

===== FILE: backend/api/transcripts.py =====
import base64
import json
import logging
import mimetypes
import os
import tempfile
import time
import uuid
from datetime import datetime, timezone
from typing import Dict, List, Optional

import anyio
from fastapi import APIRouter, Body, Depends, File, Form, HTTPException, Request, UploadFile
from fastapi.responses import JSONResponse, Response

try:
    from ..access_control import _user_owns_media_key
except ImportError:
    try:
        from access_control import _user_owns_media_key
    except ImportError:
        import access_control as access_control_module
        _user_owns_media_key = access_control_module._user_owns_media_key

try:
    from ..auth import get_current_user
except ImportError:
    try:
        from auth import get_current_user
    except ImportError:
        import auth as auth_module
        get_current_user = auth_module.get_current_user

try:
    from ..config import DEFAULT_LINES_PER_PAGE, APP_VARIANT
except ImportError:
    try:
        from config import DEFAULT_LINES_PER_PAGE, APP_VARIANT
    except ImportError:
        import config as config_module
        DEFAULT_LINES_PER_PAGE = config_module.DEFAULT_LINES_PER_PAGE
        APP_VARIANT = config_module.APP_VARIANT

try:
    from ..gemini import run_gemini_edit, transcribe_with_gemini
except ImportError:
    try:
        from gemini import run_gemini_edit, transcribe_with_gemini
    except ImportError:
        import gemini as gemini_module
        run_gemini_edit = gemini_module.run_gemini_edit
        transcribe_with_gemini = gemini_module.transcribe_with_gemini

try:
    from ..media_processing import prepare_audio_for_gemini
except ImportError:
    try:
        from media_processing import prepare_audio_for_gemini
    except ImportError:
        import media_processing as media_processing_module
        prepare_audio_for_gemini = media_processing_module.prepare_audio_for_gemini

try:
    from ..models import TranscriptTurn
except ImportError:
    try:
        from models import TranscriptTurn
    except ImportError:
        import models as models_module
        TranscriptTurn = models_module.TranscriptTurn

try:
    from ..rev_ai_sync import RevAIAligner
except ImportError:
    try:
        from rev_ai_sync import RevAIAligner
    except ImportError:
        import rev_ai_sync as rev_ai_sync_module
        RevAIAligner = rev_ai_sync_module.RevAIAligner

try:
    from ..storage import (
        BUCKET_NAME,
        add_transcript_to_case,
        check_media_exists,
        delete_transcript_for_user,
        list_all_transcripts,
        load_current_transcript,
        prune_snapshots,
        save_current_transcript,
        save_upload_to_tempfile,
        storage_client,
        upload_preview_file_to_cloud_storage_from_path,
    )
except ImportError:
    try:
        from storage import (
            BUCKET_NAME,
            add_transcript_to_case,
            check_media_exists,
            delete_transcript_for_user,
            list_all_transcripts,
            load_current_transcript,
            prune_snapshots,
            save_current_transcript,
            save_upload_to_tempfile,
            storage_client,
            upload_preview_file_to_cloud_storage_from_path,
        )
    except ImportError:
        import storage as storage_module
        BUCKET_NAME = storage_module.BUCKET_NAME
        add_transcript_to_case = storage_module.add_transcript_to_case
        check_media_exists = storage_module.check_media_exists
        delete_transcript_for_user = storage_module.delete_transcript_for_user
        list_all_transcripts = storage_module.list_all_transcripts
        load_current_transcript = storage_module.load_current_transcript
        prune_snapshots = storage_module.prune_snapshots
        save_current_transcript = storage_module.save_current_transcript
        save_upload_to_tempfile = storage_module.save_upload_to_tempfile
        storage_client = storage_module.storage_client
        upload_preview_file_to_cloud_storage_from_path = storage_module.upload_preview_file_to_cloud_storage_from_path

try:
    from ..transcriber import (
        convert_video_to_audio,
        get_media_duration,
        process_transcription,
    )
except ImportError:
    try:
        from transcriber import (
            convert_video_to_audio,
            get_media_duration,
            process_transcription,
        )
    except ImportError:
        import transcriber as transcriber_module
        convert_video_to_audio = transcriber_module.convert_video_to_audio
        get_media_duration = transcriber_module.get_media_duration
        process_transcription = transcriber_module.process_transcription

try:
    from ..word_legacy import parse_docx_to_turns
except ImportError:
    try:
        from word_legacy import parse_docx_to_turns
    except ImportError:
        import word_legacy as word_legacy_module
        parse_docx_to_turns = word_legacy_module.parse_docx_to_turns

try:
    from ..transcript_formatting import create_pdf
except ImportError:
    try:
        from transcript_formatting import create_pdf
    except ImportError:
        import transcript_formatting as transcript_formatting_module
        create_pdf = transcript_formatting_module.create_pdf

try:
    from ..viewer import get_viewer_template
except ImportError:
    try:
        from viewer import get_viewer_template
    except ImportError:
        import viewer as viewer_module
        get_viewer_template = viewer_module.get_viewer_template

try:
    from ..transcript_utils import (
        build_session_artifacts,
        build_snapshot_payload,
        build_variant_exports,
        construct_turns_from_lines,
        normalize_speaker_label,
        normalize_line_payloads,
        parse_oncue_xml,
        parse_viewer_html,
        resolve_media_filename,
        serialize_transcript_turns,
    )
except ImportError:
    try:
        from transcript_utils import (
            build_session_artifacts,
            build_snapshot_payload,
            build_variant_exports,
            construct_turns_from_lines,
            normalize_speaker_label,
            normalize_line_payloads,
            parse_oncue_xml,
            parse_viewer_html,
            resolve_media_filename,
            serialize_transcript_turns,
        )
    except ImportError:
        import transcript_utils as transcript_utils_module
        build_session_artifacts = transcript_utils_module.build_session_artifacts
        build_snapshot_payload = transcript_utils_module.build_snapshot_payload
        build_variant_exports = transcript_utils_module.build_variant_exports
        construct_turns_from_lines = transcript_utils_module.construct_turns_from_lines
        normalize_speaker_label = transcript_utils_module.normalize_speaker_label
        normalize_line_payloads = transcript_utils_module.normalize_line_payloads
        parse_oncue_xml = transcript_utils_module.parse_oncue_xml
        parse_viewer_html = transcript_utils_module.parse_viewer_html
        resolve_media_filename = transcript_utils_module.resolve_media_filename
        serialize_transcript_turns = transcript_utils_module.serialize_transcript_turns

router = APIRouter()
logger = logging.getLogger(__name__)


@router.get("/api/config")
async def get_app_config():
    """Return app configuration including variant type."""
    return JSONResponse({
        "variant": APP_VARIANT,
        "features": {
            "oncue_xml": APP_VARIANT == "oncue",
            "viewer_html": APP_VARIANT == "criminal",
            "import_oncue": APP_VARIANT == "oncue",
            "import_viewer_html": APP_VARIANT == "criminal",
        }
    })


@router.get("/api/viewer-template")
async def get_viewer_template_endpoint(current_user: dict = Depends(get_current_user)):
    if APP_VARIANT != "criminal":
        raise HTTPException(status_code=400, detail="Viewer template is only available for criminal variant")
    template_html = get_viewer_template()
    return Response(content=template_html, media_type="text/html")


@router.post("/api/convert")
async def convert_media(
    file: UploadFile = File(...),
    current_user: dict = Depends(get_current_user),
):
    """Convert a proprietary audio/video file to a browser-playable format using server-side ffmpeg.

    Accepts any file that ffmpeg can decode (including G.729 WAV) and returns
    a PCM WAV (audio) or MP4 (video) suitable for browser playback.
    """
    import shutil
    import subprocess

    ffmpeg_path = shutil.which("ffmpeg")
    if not ffmpeg_path:
        raise HTTPException(status_code=500, detail="ffmpeg is not installed on the server")

    content_type = file.content_type or ""
    is_video = content_type.startswith("video/")
    out_ext = ".mp4" if is_video else ".wav"
    out_mime = "video/mp4" if is_video else "audio/wav"

    with tempfile.NamedTemporaryFile(suffix=os.path.splitext(file.filename or "input")[1] or ".wav", delete=False) as tmp_in:
        tmp_in_path = tmp_in.name
        chunk = await file.read(64 * 1024 * 1024)  # 64 MB max
        tmp_in.write(chunk)
        remainder = await file.read(1)
        if remainder:
            os.unlink(tmp_in_path)
            raise HTTPException(status_code=413, detail="File too large (max 64 MB)")

    tmp_out_path = tmp_in_path + out_ext
    try:
        if is_video:
            cmd = [ffmpeg_path, "-y", "-i", tmp_in_path, "-c:v", "libx264", "-preset", "fast",
                   "-crf", "18", "-c:a", "aac", "-b:a", "192k", "-movflags", "+faststart", tmp_out_path]
        else:
            cmd = [ffmpeg_path, "-y", "-i", tmp_in_path, "-acodec", "pcm_s16le", tmp_out_path]

        result = subprocess.run(cmd, capture_output=True, timeout=120)
        if result.returncode != 0:
            stderr_text = result.stderr.decode("utf-8", errors="replace")[-500:]
            raise HTTPException(status_code=422, detail=f"ffmpeg conversion failed: {stderr_text}")

        out_size = os.path.getsize(tmp_out_path)
        if out_size == 0:
            raise HTTPException(status_code=422, detail="ffmpeg produced an empty output file")

        orig_name = file.filename or "converted"
        dot = orig_name.rfind(".")
        base = orig_name[:dot] if dot != -1 else orig_name
        out_filename = f"{base}_converted{out_ext}"

        with open(tmp_out_path, "rb") as f:
            out_bytes = f.read()

        return Response(
            content=out_bytes,
            media_type=out_mime,
            headers={"Content-Disposition": f'attachment; filename="{out_filename}"'},
        )
    finally:
        for p in (tmp_in_path, tmp_out_path):
            try:
                os.unlink(p)
            except OSError:
                pass


@router.post("/api/format-pdf")
async def format_pdf_clip_excerpt(
    payload: dict = Body(...),
    current_user: dict = Depends(get_current_user),
):
    title_data = payload.get("title_data")
    line_entries = payload.get("line_entries")
    lines_per_page = payload.get("lines_per_page", DEFAULT_LINES_PER_PAGE)

    if not isinstance(title_data, dict):
        raise HTTPException(status_code=400, detail="title_data must be an object")
    if not isinstance(line_entries, list) or not line_entries:
        raise HTTPException(status_code=400, detail="line_entries must be a non-empty array")

    try:
        page_size = int(lines_per_page)
        if page_size <= 0:
            page_size = DEFAULT_LINES_PER_PAGE
    except (TypeError, ValueError):
        page_size = DEFAULT_LINES_PER_PAGE

    normalized_entries: List[dict] = []
    for idx, raw_entry in enumerate(line_entries):
        if not isinstance(raw_entry, dict):
            continue

        def _as_int(value, fallback):
            try:
                return int(value)
            except (TypeError, ValueError):
                return fallback

        def _as_float(value, fallback):
            try:
                return float(value)
            except (TypeError, ValueError):
                return fallback

        speaker = normalize_speaker_label(raw_entry.get("speaker") or "", fallback="SPEAKER")
        text = str(raw_entry.get("text") or "")
        rendered_text = str(raw_entry.get("rendered_text") or "")
        if not rendered_text:
            if speaker:
                rendered_text = f"          {speaker}:   {text}"
            else:
                rendered_text = text

        page = _as_int(raw_entry.get("page"), (idx // page_size) + 1)
        line = _as_int(raw_entry.get("line"), (idx % page_size) + 1)
        pgln = _as_int(raw_entry.get("pgln"), (page * 100) + line)
        start = _as_float(raw_entry.get("start"), 0.0)
        end = _as_float(raw_entry.get("end"), start)

        normalized_entries.append(
            {
                "id": str(raw_entry.get("id") or f"line-{idx}"),
                "speaker": speaker,
                "text": text,
                "rendered_text": rendered_text,
                "start": start,
                "end": end,
                "page": page,
                "line": line,
                "pgln": pgln,
                "is_continuation": bool(raw_entry.get("is_continuation", False)),
            }
        )

    if not normalized_entries:
        raise HTTPException(status_code=400, detail="No valid line_entries to format")

    try:
        pdf_bytes = create_pdf(title_data, normalized_entries, lines_per_page=page_size)
    except Exception as exc:
        logger.error("Failed to format PDF clip excerpt: %s", exc)
        raise HTTPException(status_code=500, detail="Failed to generate PDF") from exc

    return Response(
        content=pdf_bytes,
        media_type="application/pdf",
        headers={"Content-Disposition": "attachment; filename=clip-excerpt.pdf"},
    )


@router.post("/api/transcribe")
async def transcribe(
    file: UploadFile = File(...),
    case_name: str = Form(""),
    case_number: str = Form(""),
    firm_name: str = Form(""),
    input_date: str = Form(""),
    input_time: str = Form(""),
    location: str = Form(""),
    speakers_expected: Optional[int] = Form(None),
    transcription_model: str = Form("assemblyai"),
    case_id: Optional[str] = Form(None),
    source_filename: Optional[str] = Form(None),
    current_user: dict = Depends(get_current_user),
):
    logger.info("Received transcription request for file: %s using model: %s", file.filename, transcription_model)

    # Validate model selection
    valid_models = {"assemblyai", "gemini"}
    if transcription_model not in valid_models:
        raise HTTPException(
            status_code=400,
            detail=f"Invalid transcription model. Must be one of: {', '.join(valid_models)}",
        )

    # Check for required API key based on model
    if transcription_model == "assemblyai":
        if not os.getenv("ASSEMBLYAI_API_KEY"):
            logger.error("ASSEMBLYAI_API_KEY environment variable not set")
            raise HTTPException(
                status_code=500,
                detail="Server configuration error: AssemblyAI API key not configured",
            )
    elif transcription_model == "gemini":
        if not (os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_API_KEY")):
            logger.error("GEMINI_API_KEY/GOOGLE_API_KEY environment variable not set")
            raise HTTPException(
                status_code=500,
                detail="Server configuration error: Gemini API key not configured",
            )

    is_criminal = APP_VARIANT == "criminal"
    display_filename = (source_filename or "").strip() or file.filename or "media"
    temp_upload_path = None
    try:
        temp_upload_path, file_size = await save_upload_to_tempfile(file)
        logger.info("File size: %.2f MB", file_size / (1024 * 1024))

        # Increase limit to 2GB
        if file_size > 2 * 1024 * 1024 * 1024:
            raise HTTPException(status_code=413, detail="File too large. Maximum size is 2GB.")

        if not temp_upload_path:
            raise HTTPException(status_code=400, detail="Unable to read uploaded file")

        if speakers_expected is not None and speakers_expected <= 0:
            raise HTTPException(status_code=400, detail="speakers_expected must be a positive integer")

        # Generate stable MEDIA_ID for this transcript
        media_key = uuid.uuid4().hex
        title_data = {
            "CASE_NAME": case_name,
            "CASE_NUMBER": case_number,
            "FIRM_OR_ORGANIZATION_NAME": firm_name,
            "DATE": input_date,
            "TIME": input_time,
            "LOCATION": location,
            "FILE_NAME": display_filename,
            "FILE_DURATION": "Calculating...",
            "MEDIA_ID": media_key,
        }

        # Upload media for editor playback (skip for criminal - media stays local)
        media_blob_name = None
        media_content_type = file.content_type or mimetypes.guess_type(file.filename or display_filename)[0]
        if not is_criminal:
            try:
                media_blob_name = upload_preview_file_to_cloud_storage_from_path(
                    temp_upload_path,
                    file.filename,
                    media_content_type,
                    user_id=current_user["user_id"],
                    media_key=media_key,
                )
            except Exception as e:
                logger.warning("Failed to store media preview for editor session: %s", e)
                media_blob_name = None
                media_content_type = None

        duration_seconds = 0.0
        asr_start_time = time.time()

        if transcription_model == "assemblyai":
            logger.info("Starting AssemblyAI transcription...")
            try:
                turns, duration_seconds = process_transcription(
                    None,
                    file.filename,
                    speakers_expected,
                    title_data,
                    input_path=temp_upload_path,
                )
                asr_elapsed = time.time() - asr_start_time
                logger.info("AssemblyAI completed in %.1fs. Generated %d turns.", asr_elapsed, len(turns))
            except Exception as e:
                logger.exception("AssemblyAI transcription error")
                raise HTTPException(status_code=500, detail=f"AssemblyAI transcription failed: {str(e)}") from e

        elif transcription_model == "gemini":
            logger.info("Starting Gemini transcription...")
            try:
                with tempfile.TemporaryDirectory() as temp_dir:
                    input_path = temp_upload_path

                    ext = file.filename.split('.')[-1].lower()
                    audio_path = input_path
                    audio_mime = "audio/mpeg"

                    SUPPORTED_VIDEO_TYPES = ["mp4", "mov", "avi", "mkv"]
                    if ext in SUPPORTED_VIDEO_TYPES:
                        output_audio = os.path.join(
                            temp_dir,
                            f"{os.path.splitext(os.path.basename(file.filename))[0]}.mp3",
                        )
                        converted_audio = convert_video_to_audio(input_path, output_audio)
                        if converted_audio:
                            audio_path = converted_audio
                            audio_mime = "audio/mpeg"
                        else:
                            # Keep MIME aligned with the actual fallback input path.
                            video_mime_map = {
                                "mp4": "video/mp4",
                                "mov": "video/quicktime",
                                "avi": "video/x-msvideo",
                                "mkv": "video/x-matroska",
                            }
                            guessed_video_mime = (
                                file.content_type
                                or video_mime_map.get(ext)
                                or mimetypes.guess_type(file.filename)[0]
                                or "video/mp4"
                            )
                            audio_path = input_path
                            audio_mime = guessed_video_mime
                            logger.warning(
                                "FFmpeg conversion failed for %s; falling back to source media with MIME %s",
                                file.filename,
                                audio_mime,
                            )
                    else:
                        mime_map = {
                            "mp3": "audio/mpeg",
                            "wav": "audio/wav",
                            "m4a": "audio/mp4",
                            "flac": "audio/flac",
                            "ogg": "audio/ogg",
                            "aac": "audio/aac",
                            "aiff": "audio/aiff",
                        }
                        audio_mime = mime_map.get(ext, "audio/mpeg")

                    duration_seconds = get_media_duration(audio_path) or 0.0

                    hours, rem = divmod(duration_seconds, 3600)
                    minutes, seconds = divmod(rem, 60)
                    title_data["FILE_DURATION"] = "{:0>2}:{:0>2}:{:0>2}".format(
                        int(hours),
                        int(minutes),
                        int(round(seconds)),
                    )

                    gemini_lines = await anyio.to_thread.run_sync(
                        transcribe_with_gemini,
                        audio_path,
                        audio_mime,
                        duration_seconds,
                        None,
                    )

                    normalized_lines, normalized_duration = normalize_line_payloads(
                        gemini_lines,
                        duration_seconds,
                    )
                    turns = construct_turns_from_lines(normalized_lines)

                    if not turns:
                        raise HTTPException(status_code=400, detail="Gemini transcription returned no usable turns")

                    duration_seconds = normalized_duration
                    asr_elapsed = time.time() - asr_start_time
                    logger.info("Gemini completed in %.1fs. Generated %d turns.", asr_elapsed, len(turns))

            except HTTPException:
                raise
            except Exception as e:
                logger.exception("Gemini transcription error")
                raise HTTPException(status_code=500, detail=f"Gemini transcription failed: {str(e)}") from e

        logger.info("Preserving native ASR/Gemini word timestamps for initial transcription")

        pdf_bytes, oncue_xml, transcript_text, line_payloads = build_session_artifacts(
            turns,
            title_data,
            duration_seconds or 0,
            DEFAULT_LINES_PER_PAGE,
        )
        pdf_b64 = base64.b64encode(pdf_bytes).decode()

        created_at = datetime.now(timezone.utc)

        transcript_data = {
            "media_key": media_key,
            "created_at": created_at.isoformat(),
            "title_data": title_data,
            "audio_duration": float(duration_seconds or 0),
            "lines_per_page": DEFAULT_LINES_PER_PAGE,
            "turns": serialize_transcript_turns(turns),
            "source_turns": serialize_transcript_turns(turns),
            "lines": line_payloads,
            "pdf_base64": pdf_b64,
            "transcript_text": transcript_text,
            "transcript": transcript_text,
            "media_blob_name": media_blob_name,
            "media_content_type": media_content_type,
            "updated_at": created_at.isoformat(),
            "user_id": current_user["user_id"],
            "clips": [],
            "case_id": case_id if case_id else None,
            "is_persistent": bool(case_id),
        }

        media_filename = resolve_media_filename(title_data, media_blob_name, fallback=display_filename or "media.mp4")
        transcript_data.update(
            build_variant_exports(
                APP_VARIANT,
                line_payloads,
                title_data,
                duration_seconds or 0,
                DEFAULT_LINES_PER_PAGE,
                media_filename,
                media_content_type,
                oncue_xml=oncue_xml,
            )
        )

        if is_criminal:
            # Criminal variant: return full transcript data without persisting to GCS
            # The client saves it to the local workspace folder
            response_data = {
                **transcript_data,
                "transcript": transcript_text,
            }
            return JSONResponse(response_data)

        # Oncue variant: persist to GCS as before
        try:
            save_current_transcript(media_key, transcript_data)

            snapshot_id = uuid.uuid4().hex
            snapshot_payload = build_snapshot_payload(transcript_data, is_manual_save=True)
            bucket = storage_client.bucket(BUCKET_NAME)
            snapshot_blob = bucket.blob(f"transcripts/{media_key}/history/{snapshot_id}.json")
            snapshot_blob.upload_from_string(json.dumps(snapshot_payload), content_type="application/json")

            # If case_id provided, add transcript to case (makes it persistent)
            if case_id:
                try:
                    title_label = title_data.get("FILE_NAME") or title_data.get("CASE_NAME") or media_key
                    add_transcript_to_case(current_user["user_id"], case_id, media_key, title_label)
                    logger.info("Added transcript %s to case %s", media_key, case_id)
                except Exception as case_err:
                    logger.warning("Failed to add transcript to case %s: %s", case_id, case_err)

        except Exception as e:
            logger.error("Failed to store transcript: %s", e)
            raise HTTPException(status_code=500, detail="Unable to persist transcript") from e

        response_data = {
            **transcript_data,
            "transcript": transcript_text,
        }

        return JSONResponse(response_data)
    finally:
        if temp_upload_path and os.path.exists(temp_upload_path):
            try:
                os.remove(temp_upload_path)
            except OSError:
                pass


@router.get("/api/transcripts")
async def list_transcripts_endpoint(current_user: dict = Depends(get_current_user)):
    """List all transcripts for authenticated user."""
    if APP_VARIANT == "criminal":
        raise HTTPException(status_code=410, detail="Transcript listing is handled locally in this variant")
    try:
        transcripts = list_all_transcripts(current_user["user_id"])
        return JSONResponse(content={"transcripts": transcripts})
    except Exception as e:
        logger.error("Failed to list transcripts: %s", e)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/api/transcripts/by-key/{media_key}/history")
async def list_transcript_history_by_media_key(media_key: str, current_user: dict = Depends(get_current_user)):
    """List all snapshots for a media_key."""
    if APP_VARIANT == "criminal":
        raise HTTPException(status_code=410, detail="Snapshot history is handled locally in this variant")
    try:
        if not _user_owns_media_key(media_key, current_user["user_id"]):
            raise HTTPException(status_code=403, detail="Access denied to this transcript")

        logger.info("Fetching history for media_key: %s", media_key)
        bucket = storage_client.bucket(BUCKET_NAME)
        prefix = f"transcripts/{media_key}/history/"
        logger.info("Looking for snapshots at prefix: %s", prefix)

        snapshots = []
        blob_count = 0
        for blob in bucket.list_blobs(prefix=prefix):
            blob_count += 1
            try:
                data = json.loads(blob.download_as_string())
                is_manual = data.get("is_manual_save", data.get("saved", False))
                snapshots.append(
                    {
                        "snapshot_id": blob.name.split("/")[-1].replace(".json", ""),
                        "created_at": data.get("created_at"),
                        "is_manual_save": is_manual,
                        "line_count": data.get("line_count", 0),
                        "title_label": data.get("title_label", "Transcript"),
                    }
                )
            except Exception as e:
                logger.warning("Failed to parse snapshot blob %s: %s", blob.name, e)
                continue

        logger.info("Found %d blobs, %d valid snapshots", blob_count, len(snapshots))

        snapshots.sort(key=lambda x: x["created_at"] or "", reverse=True)

        return JSONResponse(content={"snapshots": snapshots})

    except HTTPException:
        raise
    except Exception as e:
        logger.error("Failed to list history for %s: %s", media_key, e)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/api/transcripts/by-key/{media_key}")
async def get_transcript_by_media_key(media_key: str, current_user: dict = Depends(get_current_user)):
    """Get current transcript state or latest snapshot by media_key."""
    if APP_VARIANT == "criminal":
        raise HTTPException(status_code=410, detail="Transcript retrieval is handled locally in this variant")
    try:
        data = load_current_transcript(media_key)
        if not data:
            raise HTTPException(status_code=404, detail="Transcript not found")

        if data.get("user_id") != current_user["user_id"]:
            raise HTTPException(status_code=403, detail="Access denied to this transcript")

        return JSONResponse(content=data)
    except HTTPException:
        raise
    except Exception as e:
        logger.error("Failed to load transcript %s: %s", media_key, e)
        raise HTTPException(status_code=500, detail=str(e))


@router.delete("/api/transcripts/by-key/{media_key}")
async def delete_transcript_by_media_key(media_key: str, current_user: dict = Depends(get_current_user)):
    """Permanently delete a transcript, snapshots, and linked media artifacts."""
    if APP_VARIANT == "criminal":
        raise HTTPException(status_code=410, detail="Transcript deletion is handled locally in this variant")
    try:
        deleted = delete_transcript_for_user(current_user["user_id"], media_key)
        if not deleted:
            raise HTTPException(status_code=404, detail="Transcript not found")

        return JSONResponse(
            {
                "message": "Transcript deleted successfully",
                "media_key": media_key,
            }
        )

    except PermissionError:
        raise HTTPException(status_code=403, detail="Access denied to this transcript")
    except HTTPException:
        raise
    except Exception as e:
        logger.error("Failed to delete transcript %s: %s", media_key, e)
        raise HTTPException(status_code=500, detail="Failed to delete transcript")


@router.put("/api/transcripts/by-key/{media_key}")
async def save_transcript_by_media_key(media_key: str, request: Request, current_user: dict = Depends(get_current_user)):
    """Save transcript changes (auto-save or manual save)."""
    if APP_VARIANT == "criminal":
        raise HTTPException(status_code=410, detail="Transcript saving is handled locally in this variant")
    try:
        payload = await request.json()

        lines = payload.get("lines", [])
        title_data = payload.get("title_data", {})
        is_manual_save = payload.get("is_manual_save", False)
        user_id = current_user["user_id"]

        existing = load_current_transcript(media_key) or {}
        if existing and existing.get("user_id") and existing.get("user_id") != user_id:
            raise HTTPException(status_code=403, detail="Access denied to this transcript")

        transcript_data = {
            **existing,
            "media_key": media_key,
            "lines": lines,
            "title_data": title_data,
            "user_id": user_id,
            "created_at": existing.get("created_at", datetime.now(timezone.utc).isoformat()),
            "updated_at": datetime.now(timezone.utc).isoformat(),
            "audio_duration": payload.get("audio_duration", existing.get("audio_duration", 0.0)),
            "lines_per_page": payload.get("lines_per_page", existing.get("lines_per_page", DEFAULT_LINES_PER_PAGE)),
            "media_blob_name": payload.get("media_blob_name", existing.get("media_blob_name")),
            "media_content_type": payload.get("media_content_type", existing.get("media_content_type")),
        }

        try:
            normalized_lines, normalized_duration = normalize_line_payloads(
                lines,
                float(transcript_data.get("audio_duration") or 0.0),
            )
            turns = construct_turns_from_lines(normalized_lines)
            pdf_bytes, oncue_xml, transcript_text, updated_lines = build_session_artifacts(
                turns,
                title_data,
                normalized_duration,
                transcript_data.get("lines_per_page", DEFAULT_LINES_PER_PAGE),
                enforce_min_line_duration=False,
            )
            transcript_data["lines"] = updated_lines
            transcript_data["audio_duration"] = normalized_duration
            transcript_data["pdf_base64"] = base64.b64encode(pdf_bytes).decode("ascii")
            transcript_data["transcript_text"] = transcript_text
            transcript_data["transcript"] = transcript_text

            media_filename = resolve_media_filename(
                title_data,
                transcript_data.get("media_blob_name"),
                fallback="media.mp4",
            )
            transcript_data.update(
                build_variant_exports(
                    APP_VARIANT,
                    updated_lines,
                    title_data,
                    normalized_duration,
                    transcript_data.get("lines_per_page", DEFAULT_LINES_PER_PAGE),
                    media_filename,
                    transcript_data.get("media_content_type"),
                    oncue_xml=oncue_xml,
                )
            )
        except Exception as e:
            logger.warning("Failed to regenerate documents: %s", e)

        save_current_transcript(media_key, transcript_data)

        snapshot_id = uuid.uuid4().hex
        snapshot_payload = build_snapshot_payload(transcript_data, is_manual_save=is_manual_save)
        bucket = storage_client.bucket(BUCKET_NAME)
        snapshot_blob = bucket.blob(f"transcripts/{media_key}/history/{snapshot_id}.json")
        snapshot_blob.upload_from_string(json.dumps(snapshot_payload), content_type="application/json")

        prune_snapshots(media_key)

        return JSONResponse(content=transcript_data)

    except HTTPException:
        raise
    except Exception as e:
        logger.error("Save failed for %s: %s", media_key, e)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/api/transcripts/by-key/{media_key}/restore/{snapshot_id}")
async def restore_snapshot_by_media_key(media_key: str, snapshot_id: str, current_user: dict = Depends(get_current_user)):
    """Restore a specific snapshot as current state."""
    if APP_VARIANT == "criminal":
        raise HTTPException(status_code=410, detail="Snapshot restore is handled locally in this variant")
    try:
        if not _user_owns_media_key(media_key, current_user["user_id"]):
            raise HTTPException(status_code=403, detail="Access denied to this transcript")

        bucket = storage_client.bucket(BUCKET_NAME)
        blob = bucket.blob(f"transcripts/{media_key}/history/{snapshot_id}.json")

        if not blob.exists():
            raise HTTPException(status_code=404, detail="Snapshot not found")

        snapshot_data = json.loads(blob.download_as_string())

        if not snapshot_data.get("media_key"):
            snapshot_data["media_key"] = media_key

        lines = snapshot_data.get("lines") or []
        if lines:
            title_data = snapshot_data.get("title_data") or {}
            lines_per_page = snapshot_data.get("lines_per_page", DEFAULT_LINES_PER_PAGE)
            audio_duration = float(snapshot_data.get("audio_duration") or 0.0)
            try:
                normalized_lines, normalized_duration = normalize_line_payloads(lines, audio_duration)
                turns = construct_turns_from_lines(normalized_lines)
                if turns:
                    pdf_bytes, oncue_xml, transcript_text, updated_lines = build_session_artifacts(
                        turns,
                        title_data,
                        normalized_duration,
                        lines_per_page,
                        enforce_min_line_duration=False,
                    )
                    snapshot_data["lines"] = updated_lines
                    snapshot_data["audio_duration"] = normalized_duration
                    snapshot_data["pdf_base64"] = base64.b64encode(pdf_bytes).decode("ascii")
                    snapshot_data["transcript_text"] = transcript_text
                    snapshot_data["transcript"] = transcript_text

                    media_filename = resolve_media_filename(
                        title_data,
                        snapshot_data.get("media_blob_name"),
                        fallback="media.mp4",
                    )
                    snapshot_data.update(
                        build_variant_exports(
                            APP_VARIANT,
                            updated_lines,
                            title_data,
                            normalized_duration,
                            lines_per_page,
                            media_filename,
                            snapshot_data.get("media_content_type"),
                            oncue_xml=oncue_xml,
                        )
                    )
            except Exception as exc:
                logger.warning("Failed to rebuild snapshot artifacts for %s: %s", media_key, exc)

        snapshot_data["updated_at"] = datetime.now(timezone.utc).isoformat()

        save_current_transcript(media_key, snapshot_data)

        return JSONResponse(content=snapshot_data)

    except HTTPException:
        raise
    except Exception as e:
        logger.error("Failed to restore snapshot %s for %s: %s", snapshot_id, media_key, e)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/api/transcripts/by-key/{media_key}/gemini-refine")
async def gemini_refine_transcript(media_key: str, current_user: dict = Depends(get_current_user)):
    if APP_VARIANT == "criminal":
        raise HTTPException(status_code=410, detail="Gemini refinement is handled via /api/gemini-refine in this variant")
    session_data = load_current_transcript(media_key)
    if not session_data:
        raise HTTPException(status_code=404, detail="Transcript not found")
    if session_data.get("user_id") and session_data.get("user_id") != current_user["user_id"]:
        raise HTTPException(status_code=403, detail="Access denied to this transcript")

    media_blob_name = session_data.get("media_blob_name")
    if not media_blob_name:
        raise HTTPException(status_code=400, detail="This session has no media attached for Gemini refinement")

    xml_b64 = session_data.get("oncue_xml_base64")
    if not xml_b64:
        raise HTTPException(status_code=400, detail="OnCue XML is missing for this session")

    try:
        xml_text = base64.b64decode(xml_b64).decode("utf-8", errors="replace")
    except Exception as e:
        raise HTTPException(status_code=400, detail="Unable to decode the session XML") from e

    audio_path = None
    media_path = None
    try:
        audio_path, audio_mime, duration_seconds, media_path = await anyio.to_thread.run_sync(
            prepare_audio_for_gemini,
            media_blob_name,
            session_data.get("media_content_type"),
        )
        duration_hint = duration_seconds or float(session_data.get("audio_duration") or 0)
        gemini_lines = await anyio.to_thread.run_sync(
            run_gemini_edit,
            xml_text,
            audio_path,
            audio_mime,
            duration_hint,
        )

        normalized_lines, normalized_duration = normalize_line_payloads(gemini_lines, duration_hint)
        turns = construct_turns_from_lines(normalized_lines)
        if not turns:
            raise HTTPException(status_code=400, detail="Gemini refinement returned no usable turns")

        lines_per_page = session_data.get("lines_per_page", DEFAULT_LINES_PER_PAGE)
        title_data = session_data.get("title_data") or {}

        pdf_bytes, oncue_xml, transcript_text, updated_lines_payload = build_session_artifacts(
            turns,
            title_data,
            normalized_duration,
            lines_per_page,
        )

        pdf_b64 = base64.b64encode(pdf_bytes).decode()

        hours, rem = divmod(normalized_duration, 3600)
        minutes, seconds = divmod(rem, 60)
        title_data["FILE_DURATION"] = "{:0>2}:{:0>2}:{:0>2}".format(
            int(hours),
            int(minutes),
            int(round(seconds)),
        )

        updated_at = datetime.now(timezone.utc)
        session_data["turns"] = serialize_transcript_turns(turns)
        session_data["lines"] = updated_lines_payload
        session_data["title_data"] = title_data
        session_data["audio_duration"] = normalized_duration
        session_data["pdf_base64"] = pdf_b64
        session_data["transcript_text"] = transcript_text
        session_data["transcript"] = transcript_text
        session_data["updated_at"] = updated_at.isoformat()

        media_filename = resolve_media_filename(
            title_data,
            session_data.get("media_blob_name"),
            fallback="media.mp4",
        )
        session_data.update(
            build_variant_exports(
                APP_VARIANT,
                updated_lines_payload,
                title_data,
                normalized_duration,
                lines_per_page,
                media_filename,
                session_data.get("media_content_type"),
                oncue_xml=oncue_xml,
            )
        )

        save_current_transcript(media_key, session_data)

        return JSONResponse(session_data)
    finally:
        for path in (audio_path, media_path):
            if path and os.path.exists(path):
                try:
                    os.remove(path)
                except Exception:
                    pass


@router.post("/api/transcripts/import")
async def import_transcript(
    transcript_file: UploadFile = File(...),
    media_file: UploadFile = File(...),
    case_name: str = Form(""),
    case_number: str = Form(""),
    firm_name: str = Form(""),
    input_date: str = Form(""),
    input_time: str = Form(""),
    location: str = Form(""),
    current_user: dict = Depends(get_current_user),
):
    """
    Import a transcript from OnCue XML, HTML viewer, or DOCX file (deprecated path).

    - XML: Parses OnCue format, uses embedded timestamps
    - HTML: Parses embedded viewer JSON payload for timestamps
    - DOCX (deprecated): Parses speaker/text, runs Rev AI alignment for timestamps

    Media file is required for both to enable playback and re-sync.
    """
    if APP_VARIANT == "criminal":
        raise HTTPException(status_code=410, detail="Transcript import is handled locally in this variant")

    filename = transcript_file.filename or ""
    file_ext = filename.lower().split('.')[-1] if '.' in filename else ''

    logger.info(
        "Import request: file=%s (type=%s), media=%s",
        filename,
        file_ext,
        media_file.filename if media_file else "None",
    )

    media_key = uuid.uuid4().hex
    transcript_path = None
    media_path = None
    try:
        transcript_path, transcript_size = await save_upload_to_tempfile(transcript_file)
        if not transcript_path or transcript_size == 0:
            raise HTTPException(status_code=400, detail="Uploaded transcript file is empty")

        if not media_file:
            raise HTTPException(status_code=400, detail="Media file is required for import")

        media_path, media_size = await save_upload_to_tempfile(media_file)
        if not media_path or media_size == 0:
            raise HTTPException(status_code=400, detail="Uploaded media file is empty")

        media_blob_name = None
        media_content_type = media_file.content_type or mimetypes.guess_type(media_file.filename)[0]
        duration_seconds = 0.0

        try:
            media_blob_name = upload_preview_file_to_cloud_storage_from_path(
                media_path,
                media_file.filename,
                media_content_type,
                user_id=current_user["user_id"],
                media_key=media_key,
            )
            logger.info("Import: uploaded media to blob %s", media_blob_name)

            audio_path, _, dur, original_media_path = await anyio.to_thread.run_sync(
                prepare_audio_for_gemini,
                media_blob_name,
                media_content_type,
            )
            duration_seconds = dur or 0.0
            for temp_path in (audio_path, original_media_path):
                if temp_path and os.path.exists(temp_path):
                    try:
                        os.remove(temp_path)
                    except OSError:
                        pass
        except Exception as e:
            logger.error("Failed to process media during import: %s", e)
            raise HTTPException(status_code=500, detail=f"Failed to process media file: {e}") from e

        with open(transcript_path, "rb") as transcript_stream:
            file_bytes = transcript_stream.read()
        if not file_bytes:
            raise HTTPException(status_code=400, detail="Uploaded transcript file is empty")

        lines_per_page = DEFAULT_LINES_PER_PAGE
        title_data: dict = {}

        if file_ext == 'xml':
            xml_text = file_bytes.decode("utf-8", errors="replace")
            parsed = parse_oncue_xml(xml_text)
            title_data = parsed["title_data"]
            xml_duration = float(parsed["audio_duration"] or 0)
            if xml_duration > 0:
                duration_seconds = xml_duration

            lines_payload = parsed["lines"]
            normalized_lines, duration_seconds = normalize_line_payloads(lines_payload, duration_seconds)
            turns = construct_turns_from_lines(normalized_lines)

            if not turns:
                raise HTTPException(status_code=400, detail="Unable to construct transcript turns from XML")

        elif file_ext in ('html', 'htm'):
            html_text = file_bytes.decode("utf-8", errors="replace")
            parsed = parse_viewer_html(html_text)
            title_data = parsed["title_data"]
            html_duration = float(parsed.get("audio_duration") or 0.0)
            if html_duration > 0:
                duration_seconds = html_duration
            lines_per_page = parsed.get("lines_per_page", DEFAULT_LINES_PER_PAGE)

            lines_payload = parsed["lines"]
            normalized_lines, duration_seconds = normalize_line_payloads(lines_payload, duration_seconds)
            turns = construct_turns_from_lines(normalized_lines)

            if not turns:
                raise HTTPException(status_code=400, detail="Unable to construct transcript turns from HTML viewer")

        elif file_ext == 'docx':
            docx_turns = parse_docx_to_turns(file_bytes)

            if not docx_turns:
                raise HTTPException(status_code=400, detail="Unable to parse transcript from DOCX")

            turns = [
                TranscriptTurn(
                    speaker=turn["speaker"],
                    text=turn["text"],
                    timestamp=None,
                    words=None,
                    is_continuation=bool(turn.get("is_continuation", False)),
                )
                for turn in docx_turns
            ]

            rev_api_key = os.getenv("REV_AI_API_KEY")
            if rev_api_key and media_blob_name:
                alignment_audio_path = None
                alignment_media_path = None
                alignment_start_time = time.time()
                try:
                    logger.info("Running Rev AI alignment for DOCX import...")

                    alignment_audio_path, _, _, alignment_media_path = await anyio.to_thread.run_sync(
                        prepare_audio_for_gemini,
                        media_blob_name,
                        media_content_type,
                    )

                    aligner = RevAIAligner(rev_api_key)
                    turns_payload = [turn.model_dump() for turn in turns]

                    aligned_turns_payload = await anyio.to_thread.run_sync(
                        aligner.align_transcript,
                        turns_payload,
                        alignment_audio_path,
                        None,
                    )

                    turns = [TranscriptTurn(**turn) for turn in aligned_turns_payload]
                    alignment_elapsed = time.time() - alignment_start_time
                    logger.info("Rev AI alignment completed in %.1fs for DOCX import", alignment_elapsed)

                except Exception as e:
                    logger.warning("Rev AI alignment failed for DOCX import: %s", e)
                finally:
                    for temp_path in (alignment_audio_path, alignment_media_path):
                        if temp_path and os.path.exists(temp_path):
                            try:
                                os.remove(temp_path)
                            except OSError:
                                pass
            else:
                logger.warning("REV_AI_API_KEY not configured, DOCX import will have no timestamps")

            title_data = {}
        else:
            raise HTTPException(
                status_code=400,
                detail=f"Unsupported file type: {file_ext}. Use .xml (OnCue), .html (viewer), or .docx (deprecated)",
            )

        overrides = {
            "CASE_NAME": case_name or title_data.get("CASE_NAME", ""),
            "CASE_NUMBER": case_number or title_data.get("CASE_NUMBER", ""),
            "FIRM_OR_ORGANIZATION_NAME": firm_name or title_data.get("FIRM_OR_ORGANIZATION_NAME", ""),
            "DATE": input_date or title_data.get("DATE", ""),
            "TIME": input_time or title_data.get("TIME", ""),
            "LOCATION": location or title_data.get("LOCATION", ""),
            "FILE_NAME": title_data.get("FILE_NAME") or media_file.filename or filename or "imported",
        }
        title_data.update(overrides)

        title_data["MEDIA_ID"] = media_key

        pdf_bytes_out, oncue_xml, transcript_text, line_payloads = build_session_artifacts(
            turns,
            title_data,
            duration_seconds,
            lines_per_page,
        )

        pdf_b64 = base64.b64encode(pdf_bytes_out).decode()

        created_at = datetime.now(timezone.utc)

        try:
            transcript_data = {
                "media_key": media_key,
                "created_at": created_at.isoformat(),
                "updated_at": created_at.isoformat(),
                "title_data": title_data,
                "audio_duration": duration_seconds,
                "lines_per_page": lines_per_page,
                "turns": serialize_transcript_turns(turns),
                "source_turns": serialize_transcript_turns(turns),
                "lines": line_payloads,
                "pdf_base64": pdf_b64,
                "transcript_text": transcript_text,
                "transcript": transcript_text,
                "media_blob_name": media_blob_name,
                "media_content_type": media_content_type,
                "user_id": current_user["user_id"],
                "clips": [],
            }

            media_filename = resolve_media_filename(
                title_data,
                media_blob_name,
                fallback=media_file.filename or filename or "media.mp4",
            )
            transcript_data.update(
                build_variant_exports(
                    APP_VARIANT,
                    line_payloads,
                    title_data,
                    duration_seconds,
                    lines_per_page,
                    media_filename,
                    media_content_type,
                    oncue_xml=oncue_xml,
                )
            )

            save_current_transcript(media_key, transcript_data)

            snapshot_id = uuid.uuid4().hex
            snapshot_payload = build_snapshot_payload(transcript_data, is_manual_save=True)
            bucket = storage_client.bucket(BUCKET_NAME)
            snapshot_blob = bucket.blob(f"transcripts/{media_key}/history/{snapshot_id}.json")
            snapshot_blob.upload_from_string(json.dumps(snapshot_payload), content_type="application/json")
            logger.info("Created initial snapshot for imported transcript: %s", media_key)

        except Exception as e:
            logger.error("Failed to save imported transcript: %s", e)
            raise HTTPException(status_code=500, detail="Unable to persist imported transcript") from e

        return JSONResponse(dict(transcript_data))
    finally:
        for temp_path in (transcript_path, media_path):
            if temp_path and os.path.exists(temp_path):
                try:
                    os.remove(temp_path)
                except OSError:
                    pass


@router.post("/api/resync")
async def resync_transcript(
    payload: dict = Body(...),
    current_user: dict = Depends(get_current_user),
):
    """
    Re-sync the transcript using Rev AI Forced Alignment (oncue variant).

    Payload:
      - media_key: string
      - api_key: string (optional, checks env if missing)
    """
    if APP_VARIANT == "criminal":
        raise HTTPException(status_code=410, detail="Use /api/resync-local for the criminal variant")

    media_key = payload.get("media_key")
    if not media_key:
        raise HTTPException(status_code=400, detail="Missing media_key")

    session_data = load_current_transcript(media_key)
    if not session_data:
        raise HTTPException(status_code=404, detail="Transcript not found")
    if session_data.get("user_id") and session_data.get("user_id") != current_user["user_id"]:
        raise HTTPException(status_code=403, detail="Access denied to this transcript")

    media_blob_name = session_data.get("media_blob_name")
    media_content_type = session_data.get("media_content_type")

    logger.info(
        "Resync: media_key=%s, media_blob_name=%s, media_content_type=%s",
        media_key,
        media_blob_name,
        media_content_type,
    )

    if not media_blob_name:
        raise HTTPException(status_code=400, detail="Audio file reference not found in session")

    audio_path = None
    try:
        audio_path, _, _, _ = await anyio.to_thread.run_sync(
            prepare_audio_for_gemini,
            media_blob_name,
            media_content_type,
        )
    except Exception as e:
        logger.error("Failed to prepare audio for re-sync: %s", e)
        raise HTTPException(status_code=500, detail=f"Failed to prepare audio: {e}") from e

    try:
        rev_api_key = payload.get("api_key") or os.getenv("REV_AI_API_KEY")
        if not rev_api_key:
            raise HTTPException(status_code=500, detail="Rev AI API Key not configured")

        aligner = RevAIAligner(rev_api_key)

        lines = session_data.get("lines", [])
        if not lines:
            raise HTTPException(status_code=400, detail="No transcript lines to align")

        audio_duration = session_data.get("audio_duration", 0.0)
        normalized_lines, _ = normalize_line_payloads(lines, audio_duration)
        turns = construct_turns_from_lines(normalized_lines)

        turns_payload = [turn.model_dump() for turn in turns]
        source_turns_payload = session_data.get("source_turns")

        updated_turns_payload = await anyio.to_thread.run_sync(
            aligner.align_transcript,
            turns_payload,
            audio_path,
            None,
            source_turns_payload,
        )

        updated_turns = [TranscriptTurn(**turn) for turn in updated_turns_payload]

        title_data = session_data.get("title_data", {})
        lines_per_page = session_data.get("lines_per_page", DEFAULT_LINES_PER_PAGE)

        pdf_bytes, oncue_xml, transcript_text, new_line_entries = build_session_artifacts(
            updated_turns,
            title_data,
            audio_duration,
            lines_per_page,
        )

        session_data["lines"] = new_line_entries
        session_data["turns"] = serialize_transcript_turns(updated_turns)
        session_data["pdf_base64"] = base64.b64encode(pdf_bytes).decode()
        session_data["transcript_text"] = transcript_text
        session_data["updated_at"] = datetime.now(timezone.utc).isoformat()

        # Conditionally generate OnCue XML or HTML viewer based on app variant
        response_data = {
            "status": "success",
            "lines": new_line_entries,
            "pdf_base64": session_data["pdf_base64"],
        }

        media_filename = resolve_media_filename(
            title_data,
            session_data.get("media_blob_name"),
            fallback="media.mp4",
        )
        exports = build_variant_exports(
            APP_VARIANT,
            new_line_entries,
            title_data,
            audio_duration,
            lines_per_page,
            media_filename,
            session_data.get("media_content_type"),
            oncue_xml=oncue_xml,
        )
        session_data.update(exports)
        response_data.update(exports)

        save_current_transcript(media_key, session_data)

        return response_data

    except HTTPException:
        raise
    except Exception as e:
        logger.error("Re-sync failed: %s", e)
        raise HTTPException(status_code=502, detail=f"Re-sync process failed: {e}") from e

    finally:
        if audio_path and os.path.exists(audio_path):
            try:
                os.remove(audio_path)
            except OSError:
                pass


@router.post("/api/resync-local")
async def resync_transcript_local(
    media_file: UploadFile = File(...),
    transcript_data: str = Form(...),
    current_user: dict = Depends(get_current_user),
):
    """
    Re-sync transcript using Rev AI Forced Alignment (criminal variant).
    Accepts media file and transcript data as multipart form.
    Returns re-synced lines without persisting.
    """
    temp_media_path = None
    try:
        session_data = json.loads(transcript_data)
    except (json.JSONDecodeError, TypeError) as e:
        raise HTTPException(status_code=400, detail=f"Invalid transcript_data JSON: {e}") from e

    try:
        temp_media_path, _ = await save_upload_to_tempfile(media_file)
        if not temp_media_path:
            raise HTTPException(status_code=400, detail="Unable to read uploaded media file")

        rev_api_key = os.getenv("REV_AI_API_KEY")
        if not rev_api_key:
            raise HTTPException(status_code=500, detail="Rev AI API Key not configured")

        aligner = RevAIAligner(rev_api_key)

        lines = session_data.get("lines", [])
        if not lines:
            raise HTTPException(status_code=400, detail="No transcript lines to align")

        audio_duration = float(session_data.get("audio_duration", 0.0))
        normalized_lines, _ = normalize_line_payloads(lines, audio_duration)
        turns = construct_turns_from_lines(normalized_lines)

        turns_payload = [turn.model_dump() for turn in turns]
        source_turns_payload = session_data.get("source_turns")

        updated_turns_payload = await anyio.to_thread.run_sync(
            aligner.align_transcript,
            turns_payload,
            temp_media_path,
            None,
            source_turns_payload,
        )

        updated_turns = [TranscriptTurn(**turn) for turn in updated_turns_payload]

        title_data = session_data.get("title_data", {})
        lines_per_page = session_data.get("lines_per_page", DEFAULT_LINES_PER_PAGE)

        pdf_bytes, oncue_xml, transcript_text, new_line_entries = build_session_artifacts(
            updated_turns,
            title_data,
            audio_duration,
            lines_per_page,
        )

        response_data = {
            "status": "success",
            "lines": new_line_entries,
            "turns": serialize_transcript_turns(updated_turns),
            "pdf_base64": base64.b64encode(pdf_bytes).decode(),
            "transcript_text": transcript_text,
        }

        media_filename = resolve_media_filename(
            title_data,
            None,
            fallback=media_file.filename or "media.mp4",
        )
        exports = build_variant_exports(
            APP_VARIANT,
            new_line_entries,
            title_data,
            audio_duration,
            lines_per_page,
            media_filename,
            media_file.content_type or mimetypes.guess_type(media_file.filename or "")[0],
            oncue_xml=oncue_xml,
        )
        response_data.update(exports)

        return response_data

    except HTTPException:
        raise
    except Exception as e:
        logger.error("Local re-sync failed: %s", e)
        raise HTTPException(status_code=502, detail=f"Re-sync process failed: {e}") from e
    finally:
        if temp_media_path and os.path.exists(temp_media_path):
            try:
                os.remove(temp_media_path)
            except OSError:
                pass


@router.post("/api/gemini-refine")
async def gemini_refine_local(
    media_file: UploadFile = File(...),
    transcript_data: str = Form(...),
    current_user: dict = Depends(get_current_user),
):
    """
    Gemini refinement for criminal variant.
    Accepts media file and transcript data as multipart form.
    Returns refined lines without persisting.
    """
    temp_media_path = None
    try:
        session_data = json.loads(transcript_data)
    except (json.JSONDecodeError, TypeError) as e:
        raise HTTPException(status_code=400, detail=f"Invalid transcript_data JSON: {e}") from e

    try:
        temp_media_path, _ = await save_upload_to_tempfile(media_file)
        if not temp_media_path:
            raise HTTPException(status_code=400, detail="Unable to read uploaded media file")

        # Get or build the XML from transcript data
        xml_b64 = session_data.get("oncue_xml_base64")
        if xml_b64:
            xml_text = base64.b64decode(xml_b64).decode("utf-8", errors="replace")
        else:
            # Build XML from lines
            lines = session_data.get("lines", [])
            title_data = session_data.get("title_data", {})
            audio_duration = float(session_data.get("audio_duration", 0.0))
            lines_per_page = session_data.get("lines_per_page", DEFAULT_LINES_PER_PAGE)

            normalized_lines, normalized_duration = normalize_line_payloads(lines, audio_duration)
            turns = construct_turns_from_lines(normalized_lines)
            if not turns:
                raise HTTPException(status_code=400, detail="No usable transcript turns found")

            _, oncue_xml_str, _, _ = build_session_artifacts(
                turns, title_data, normalized_duration, lines_per_page,
            )
            if not oncue_xml_str:
                raise HTTPException(status_code=400, detail="Unable to generate XML for Gemini refinement")
            xml_text = oncue_xml_str

        # Prepare audio for Gemini
        media_content_type = media_file.content_type or mimetypes.guess_type(media_file.filename or "")[0]
        ext = (media_file.filename or "").split(".")[-1].lower() if media_file.filename and "." in media_file.filename else ""
        audio_path = temp_media_path
        audio_mime = media_content_type or "audio/mpeg"

        SUPPORTED_VIDEO_TYPES = ["mp4", "mov", "avi", "mkv"]
        temp_audio_dir = None
        if ext in SUPPORTED_VIDEO_TYPES:
            temp_audio_dir = tempfile.mkdtemp()
            output_audio = os.path.join(temp_audio_dir, "converted.mp3")
            converted = convert_video_to_audio(temp_media_path, output_audio)
            if converted:
                audio_path = converted
                audio_mime = "audio/mpeg"
        else:
            mime_map = {
                "mp3": "audio/mpeg", "wav": "audio/wav", "m4a": "audio/mp4",
                "flac": "audio/flac", "ogg": "audio/ogg", "aac": "audio/aac",
            }
            audio_mime = mime_map.get(ext, audio_mime)

        duration_hint = float(session_data.get("audio_duration", 0.0))

        try:
            gemini_lines = await anyio.to_thread.run_sync(
                run_gemini_edit,
                xml_text,
                audio_path,
                audio_mime,
                duration_hint,
            )
        finally:
            if temp_audio_dir and os.path.exists(temp_audio_dir):
                import shutil
                shutil.rmtree(temp_audio_dir, ignore_errors=True)

        normalized_lines, normalized_duration = normalize_line_payloads(gemini_lines, duration_hint)
        turns = construct_turns_from_lines(normalized_lines)
        if not turns:
            raise HTTPException(status_code=400, detail="Gemini refinement returned no usable turns")

        title_data = session_data.get("title_data", {})
        lines_per_page = session_data.get("lines_per_page", DEFAULT_LINES_PER_PAGE)

        pdf_bytes, oncue_xml, transcript_text, updated_lines = build_session_artifacts(
            turns, title_data, normalized_duration, lines_per_page,
        )

        response_data = {
            "status": "success",
            "lines": updated_lines,
            "turns": serialize_transcript_turns(turns),
            "pdf_base64": base64.b64encode(pdf_bytes).decode(),
            "transcript_text": transcript_text,
            "audio_duration": normalized_duration,
        }

        media_filename = resolve_media_filename(
            title_data, None, fallback=media_file.filename or "media.mp4",
        )
        exports = build_variant_exports(
            APP_VARIANT,
            updated_lines,
            title_data,
            normalized_duration,
            lines_per_page,
            media_filename,
            media_content_type,
            oncue_xml=oncue_xml,
        )
        response_data.update(exports)

        return response_data

    except HTTPException:
        raise
    except Exception as e:
        logger.error("Local Gemini refinement failed: %s", e)
        raise HTTPException(status_code=500, detail=f"Gemini refinement failed: {e}") from e
    finally:
        if temp_media_path and os.path.exists(temp_media_path):
            try:
                os.remove(temp_media_path)
            except OSError:
                pass


@router.post("/api/transcripts/by-key/{media_key}/regenerate-viewer")
async def regenerate_viewer_html(media_key: str, current_user: dict = Depends(get_current_user)):
    """Rebuild HTML viewer export from current session state without creating a snapshot."""
    if APP_VARIANT == "criminal":
        raise HTTPException(status_code=410, detail="Viewer regeneration is handled locally in this variant")
    # Non-criminal variants don't support viewer HTML exports
    raise HTTPException(status_code=400, detail="HTML viewer exports are not enabled for this variant")
    try:
        transcript = load_current_transcript(media_key)
        if not transcript:
            raise HTTPException(status_code=404, detail="Transcript not found")
        if transcript.get("user_id") != current_user["user_id"]:
            raise HTTPException(status_code=403, detail="Access denied to this transcript")

        lines = transcript.get("lines") or []
        title_data = transcript.get("title_data") or {}
        audio_duration = float(transcript.get("audio_duration") or 0.0)
        lines_per_page = transcript.get("lines_per_page", DEFAULT_LINES_PER_PAGE)

        media_filename = resolve_media_filename(
            title_data,
            transcript.get("media_blob_name"),
            fallback=title_data.get("FILE_NAME") or "media.mp4",
        )

        oncue_xml = None
        oncue_b64 = transcript.get("oncue_xml_base64")
        if oncue_b64:
            try:
                oncue_xml = base64.b64decode(oncue_b64).decode("utf-8", errors="replace")
            except Exception:
                oncue_xml = None

        exports = build_variant_exports(
            APP_VARIANT,
            lines,
            title_data,
            audio_duration,
            lines_per_page,
            media_filename,
            transcript.get("media_content_type"),
            oncue_xml=oncue_xml,
        )
        transcript.update(exports)
        transcript["updated_at"] = datetime.now(timezone.utc).isoformat()
        save_current_transcript(media_key, transcript)

        return JSONResponse({
            "viewer_html_base64": transcript.get("viewer_html_base64"),
            "updated_at": transcript.get("updated_at"),
        })

    except HTTPException:
        raise
    except Exception as exc:
        logger.error("Failed to regenerate viewer HTML for %s: %s", media_key, exc)
        raise HTTPException(status_code=500, detail="Failed to regenerate viewer HTML") from exc


@router.get("/api/transcripts/by-key/{media_key}/media-status")
async def get_media_status(media_key: str, current_user: dict = Depends(get_current_user)):
    """
    Check if the media file for a transcript still exists.
    Returns availability status and blob info.
    """
    if APP_VARIANT == "criminal":
        raise HTTPException(status_code=410, detail="Media status is handled locally in this variant")
    try:
        # Load transcript and verify ownership
        transcript = load_current_transcript(media_key)
        if not transcript:
            raise HTTPException(status_code=404, detail="Transcript not found")
        if transcript.get("user_id") != current_user["user_id"]:
            raise HTTPException(status_code=403, detail="Access denied to this transcript")

        blob_name = transcript.get("media_blob_name")
        content_type = transcript.get("media_content_type")

        # Check if media exists
        available = check_media_exists(blob_name) if blob_name else False

        return JSONResponse({
            "media_available": available,
            "available": available,
            "blob_name": blob_name,
            "content_type": content_type,
            "media_key": media_key,
        })

    except HTTPException:
        raise
    except Exception as e:
        logger.error("Failed to check media status for %s: %s", media_key, e)
        raise HTTPException(status_code=500, detail="Failed to check media status")


@router.post("/api/transcripts/by-key/{media_key}/reattach-media")
async def reattach_media(
    media_key: str,
    file: UploadFile = File(...),
    current_user: dict = Depends(get_current_user),
):
    """
    Upload a new media file to attach to an existing transcript.
    Used when the original media has expired but the transcript is persistent.
    """
    if APP_VARIANT == "criminal":
        raise HTTPException(status_code=410, detail="Media reattachment is handled locally in this variant")
    try:
        # Load transcript and verify ownership
        transcript = load_current_transcript(media_key)
        if not transcript:
            raise HTTPException(status_code=404, detail="Transcript not found")
        if transcript.get("user_id") != current_user["user_id"]:
            raise HTTPException(status_code=403, detail="Access denied to this transcript")

        # Save uploaded file to temp
        temp_path, file_size = await save_upload_to_tempfile(file)

        try:
            # Upload to cloud storage
            content_type = file.content_type or mimetypes.guess_type(file.filename)[0]
            blob_name = upload_preview_file_to_cloud_storage_from_path(
                temp_path,
                file.filename,
                content_type,
                user_id=current_user["user_id"],
                media_key=media_key,
            )

            # Update transcript with new media reference
            title_data = transcript.get("title_data") or {}
            if file.filename:
                title_data["FILE_NAME"] = file.filename
            transcript["title_data"] = title_data
            transcript["media_blob_name"] = blob_name
            transcript["media_content_type"] = content_type
            transcript["updated_at"] = datetime.now(timezone.utc).isoformat()

            lines = transcript.get("lines") or []
            audio_duration = float(transcript.get("audio_duration") or 0.0)
            lines_per_page = transcript.get("lines_per_page", DEFAULT_LINES_PER_PAGE)
            oncue_xml = None
            oncue_b64 = transcript.get("oncue_xml_base64")
            if oncue_b64:
                try:
                    oncue_xml = base64.b64decode(oncue_b64).decode("utf-8", errors="replace")
                except Exception:
                    oncue_xml = None

            if APP_VARIANT == "oncue" and oncue_xml is None:
                normalized_lines, normalized_duration = normalize_line_payloads(lines, audio_duration)
                turns = construct_turns_from_lines(normalized_lines)
                if turns:
                    _pdf_bytes, oncue_xml, _transcript_text, updated_lines = build_session_artifacts(
                        turns,
                        title_data,
                        normalized_duration,
                        lines_per_page,
                        enforce_min_line_duration=False,
                    )
                    transcript["lines"] = updated_lines
                    transcript["audio_duration"] = normalized_duration

            media_filename = resolve_media_filename(
                title_data,
                blob_name,
                fallback=file.filename or "media.mp4",
            )
            transcript.update(
                build_variant_exports(
                    APP_VARIANT,
                    transcript.get("lines") or [],
                    title_data,
                    float(transcript.get("audio_duration") or 0.0),
                    lines_per_page,
                    media_filename,
                    content_type,
                    oncue_xml=oncue_xml,
                )
            )

            save_current_transcript(media_key, transcript)

            logger.info("Reattached media to transcript %s: %s", media_key, blob_name)

            return JSONResponse({
                "message": "Media file attached successfully",
                "media_key": media_key,
                "blob_name": blob_name,
                "content_type": content_type,
            })

        finally:
            if temp_path and os.path.exists(temp_path):
                try:
                    os.remove(temp_path)
                except OSError:
                    pass

    except HTTPException:
        raise
    except Exception as e:
        logger.error("Failed to reattach media for %s: %s", media_key, e)
        raise HTTPException(status_code=500, detail="Failed to attach media file")
===== END FILE =====

===== FILE: backend/auth.py =====
"""
Authentication module for TranscribeAlpha.
Handles JWT token generation, password verification, and Secret Manager integration.
"""

import os
import json
import logging
from datetime import datetime, timedelta, timezone
from typing import Optional, Dict, List

from jose import JWTError, jwt
import bcrypt
from google.cloud import secretmanager
from fastapi import HTTPException, status, Depends
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials

logger = logging.getLogger(__name__)

# JWT configuration
JWT_SECRET_KEY = os.getenv("JWT_SECRET_KEY", "dev-secret-key-change-in-production")
JWT_ALGORITHM = "HS256"
ACCESS_TOKEN_EXPIRE_DAYS = 365  # 1 year - effectively permanent
REFRESH_TOKEN_EXPIRE_DAYS = 3650  # 10 years - effectively permanent

# Secret Manager configuration
PROJECT_ID = os.getenv("GOOGLE_CLOUD_PROJECT", "")
SECRET_NAME = "transcribealpha-users"

# Security scheme
security = HTTPBearer()

# In-memory cache for users (refreshed periodically)
_users_cache: Optional[Dict[str, dict]] = None
_cache_timestamp: Optional[datetime] = None
CACHE_TTL_MINUTES = 5


def get_secret_manager_client():
    """Get Secret Manager client."""
    try:
        return secretmanager.SecretManagerServiceClient()
    except Exception as e:
        logger.error(f"Failed to create Secret Manager client: {e}")
        return None


def load_users_from_secret_manager() -> Dict[str, dict]:
    """
    Load users from Google Secret Manager.
    Returns a dictionary mapping username to user data.
    """
    global _users_cache, _cache_timestamp

    # Check cache first
    if _users_cache and _cache_timestamp:
        if datetime.now(timezone.utc) - _cache_timestamp < timedelta(minutes=CACHE_TTL_MINUTES):
            return _users_cache

    try:
        client = get_secret_manager_client()
        if not client:
            logger.warning("Secret Manager client not available, using fallback")
            return {}

        # Build the resource name
        if not PROJECT_ID:
            logger.warning("GOOGLE_CLOUD_PROJECT not set, cannot access Secret Manager")
            return {}

        name = f"projects/{PROJECT_ID}/secrets/{SECRET_NAME}/versions/latest"

        # Access the secret version
        response = client.access_secret_version(request={"name": name})
        secret_data = response.payload.data.decode("UTF-8")

        # Parse JSON
        users_data = json.loads(secret_data)

        # Convert to dictionary mapping username -> user data
        users_dict = {}
        for user in users_data.get("users", []):
            username = user.get("username")
            if username:
                users_dict[username] = user

        # Update cache
        _users_cache = users_dict
        _cache_timestamp = datetime.now(timezone.utc)

        logger.info(f"Loaded {len(users_dict)} users from Secret Manager")
        return users_dict

    except Exception as e:
        logger.error(f"Failed to load users from Secret Manager: {e}")
        # Return cached data if available
        if _users_cache:
            logger.info("Using cached user data due to Secret Manager error")
            return _users_cache
        return {}


def verify_password(plain_password: str, hashed_password: str) -> bool:
    """Verify a password against its hash."""
    try:
        return bcrypt.checkpw(plain_password.encode('utf-8'), hashed_password.encode('utf-8'))
    except Exception as e:
        logger.error(f"Password verification error: {e}")
        return False


def get_password_hash(password: str) -> str:
    """Generate password hash (for admin use)."""
    return bcrypt.hashpw(password.encode('utf-8'), bcrypt.gensalt()).decode('utf-8')


def authenticate_user(username: str, password: str) -> Optional[dict]:
    """
    Authenticate a user by username and password.
    Returns user data if successful, None otherwise.
    """
    users = load_users_from_secret_manager()
    user = users.get(username)

    if not user:
        logger.warning(f"Authentication failed: user '{username}' not found")
        return None

    if not verify_password(password, user.get("password_hash", "")):
        logger.warning(f"Authentication failed: invalid password for user '{username}'")
        return None

    logger.info(f"User '{username}' authenticated successfully")
    return user


def create_access_token(data: dict, expires_delta: Optional[timedelta] = None) -> str:
    """Create a JWT access token."""
    to_encode = data.copy()

    if expires_delta:
        expire = datetime.now(timezone.utc) + expires_delta
    else:
        expire = datetime.now(timezone.utc) + timedelta(days=ACCESS_TOKEN_EXPIRE_DAYS)

    to_encode.update({"exp": expire, "type": "access"})
    encoded_jwt = jwt.encode(to_encode, JWT_SECRET_KEY, algorithm=JWT_ALGORITHM)
    return encoded_jwt


def create_media_token(data: dict, expires_delta: Optional[timedelta] = None) -> str:
    """Create a short-lived JWT token scoped for media access."""
    to_encode = data.copy()

    if expires_delta:
        expire = datetime.now(timezone.utc) + expires_delta
    else:
        expire = datetime.now(timezone.utc) + timedelta(minutes=5)

    to_encode.update({"exp": expire, "type": "media"})
    encoded_jwt = jwt.encode(to_encode, JWT_SECRET_KEY, algorithm=JWT_ALGORITHM)
    return encoded_jwt


def create_refresh_token(data: dict) -> str:
    """Create a JWT refresh token."""
    to_encode = data.copy()
    expire = datetime.now(timezone.utc) + timedelta(days=REFRESH_TOKEN_EXPIRE_DAYS)
    to_encode.update({"exp": expire, "type": "refresh"})
    encoded_jwt = jwt.encode(to_encode, JWT_SECRET_KEY, algorithm=JWT_ALGORITHM)
    return encoded_jwt


def decode_token(token: str) -> Optional[dict]:
    """
    Decode and validate a JWT token.
    Returns the payload if valid, None otherwise.
    """
    try:
        payload = jwt.decode(token, JWT_SECRET_KEY, algorithms=[JWT_ALGORITHM])
        return payload
    except JWTError as e:
        logger.warning(f"Token decode error: {e}")
        return None


async def get_current_user(credentials: HTTPAuthorizationCredentials = Depends(security)) -> dict:
    """
    Dependency to get the current authenticated user from JWT token.
    Raises HTTPException if authentication fails.
    """
    credentials_exception = HTTPException(
        status_code=status.HTTP_401_UNAUTHORIZED,
        detail="Could not validate credentials",
        headers={"WWW-Authenticate": "Bearer"},
    )

    try:
        token = credentials.credentials
        payload = decode_token(token)

        if payload is None:
            raise credentials_exception

        # Check token type
        if payload.get("type") != "access":
            raise credentials_exception

        username: str = payload.get("sub")
        if username is None:
            raise credentials_exception

        # Return user info from token
        return {
            "username": username,
            "role": payload.get("role", "user"),
            "user_id": username  # Use username as user_id for simplicity
        }

    except Exception as e:
        logger.error(f"Authentication error: {e}")
        raise credentials_exception


async def get_current_user_optional(credentials: Optional[HTTPAuthorizationCredentials] = Depends(security)) -> Optional[dict]:
    """
    Optional authentication dependency.
    Returns user if authenticated, None if not.
    Useful for endpoints that work with or without auth.
    """
    if credentials is None:
        return None

    try:
        return await get_current_user(credentials)
    except HTTPException:
        return None


def generate_initial_password_hash(password: str) -> str:
    """
    Helper function to generate password hash for initial setup.
    This should be run locally, not in production code.
    """
    return get_password_hash(password)


# For development/testing: Generate a sample users JSON structure
def generate_sample_users_json(username: str, password: str) -> str:
    """
    Generate a sample users JSON for Secret Manager.
    Usage: python -c "from backend.auth import generate_sample_users_json; print(generate_sample_users_json('VerdictGroup', 'your_secure_password'))"
    """
    password_hash = get_password_hash(password)
    users_data = {
        "users": [
            {
                "username": username,
                "password_hash": password_hash,
                "role": "admin",
                "created_at": datetime.now(timezone.utc).isoformat()
            }
        ]
    }
    return json.dumps(users_data, indent=2)


if __name__ == "__main__":
    # Helper script to generate password hash
    import sys
    if len(sys.argv) > 1:
        password = sys.argv[1]
        print(f"Password hash: {get_password_hash(password)}")
    else:
        print("Usage: python auth.py <password>")
        print("Or: python -c \"from backend.auth import generate_sample_users_json; print(generate_sample_users_json('username', 'password'))\"")
===== END FILE =====

===== FILE: backend/config.py =====
import os

# App variant configuration
# "oncue" = OnCue XML + DOCX exports (default)
# "criminal" = HTML viewer + DOCX exports (for DA/PD offices)
APP_VARIANT = os.getenv("APP_VARIANT", "oncue")

# Environment-based CORS configuration
ENVIRONMENT = os.getenv("ENVIRONMENT", "development")
ALLOWED_ORIGINS = ["*"] if ENVIRONMENT == "development" else [
    "https://transcribealpha-*.cloudfunctions.net",
    "https://transcribealpha-*.appspot.com",
    "https://transcribealpha-*.run.app",
    # Add your production domains here
]

# Cloud Storage configuration
BUCKET_NAME = "transcribealpha-uploads-1750110926"

# Default transcript layout configuration
DEFAULT_LINES_PER_PAGE = 25

# Session / cleanup configuration
EDITOR_SESSION_TTL_DAYS = int(os.getenv("EDITOR_SESSION_TTL_DAYS", "7"))
CLIP_SESSION_PREFIX = "clip_sessions/"
CLIP_SESSION_TTL_DAYS = int(os.getenv("CLIP_SESSION_TTL_DAYS", str(EDITOR_SESSION_TTL_DAYS)))
SNAPSHOT_TTL_DAYS = int(os.getenv("SNAPSHOT_TTL_DAYS", "14"))
MEDIA_TTL_DAYS = int(os.getenv("MEDIA_TTL_DAYS", "1"))
MEDIA_CLEANUP_PREFIXES = ("preview_", "clip_", "raw_")
MEDIA_TOKEN_TTL_MINUTES = int(os.getenv("MEDIA_TOKEN_TTL_MINUTES", "5"))
===== END FILE =====

===== FILE: backend/gemini.py =====
import json
import logging
import os
import re
import time
from typing import Any, List, Optional

from fastapi import HTTPException

logger = logging.getLogger(__name__)
_SPEAKER_LETTER_RE = re.compile(r"^[A-Z]$")
_SPEAKER_NUMERIC_RE = re.compile(r"^[0-9]+$")


def _speaker_suffix_for_index(index: int) -> str:
    """Convert 0-based index to A, B, ..., Z, AA, AB, ..."""
    value = max(index, 0)
    chars: List[str] = []
    while True:
        value, remainder = divmod(value, 26)
        chars.append(chr(ord("A") + remainder))
        if value == 0:
            break
        value -= 1
    return "".join(reversed(chars))


def _normalize_speaker_label(raw_value: Any, fallback: str) -> str:
    fallback_value = str(fallback or "").strip().upper() or "SPEAKER A"
    candidate = str(raw_value or "").strip()
    candidate = re.sub(r":+$", "", candidate).strip().upper()

    if not candidate:
        candidate = fallback_value

    if candidate == "UNKNOWN":
        return fallback_value

    if candidate.startswith("SPEAKER"):
        suffix = candidate[len("SPEAKER"):].strip()
        return f"SPEAKER {suffix}" if suffix else "SPEAKER"

    if _SPEAKER_LETTER_RE.fullmatch(candidate) or _SPEAKER_NUMERIC_RE.fullmatch(candidate):
        return f"SPEAKER {candidate}"

    return candidate


def run_gemini_edit(xml_text: str, audio_path: str, audio_mime: str, duration_hint: float) -> List[dict]:
    api_key = os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_API_KEY")
    if api_key:
        api_key = api_key.strip()
        if (api_key.startswith('"') and api_key.endswith('"')) or (api_key.startswith("'") and api_key.endswith("'")):
            api_key = api_key[1:-1].strip()
        if api_key in {"your-gemini-key-here", "YOUR_GEMINI_KEY_HERE"}:
            raise HTTPException(
                status_code=500,
                detail="GEMINI_API_KEY is still set to the placeholder value; update your Cloud Run env var or Cloud Build trigger substitution _GEMINI_API_KEY.",
            )
    if not api_key:
        raise HTTPException(status_code=500, detail="GEMINI_API_KEY not configured")

    try:
        from google import genai
        from google.genai import types as genai_types
    except Exception as exc:
        logger.error("google-genai not available: %s", exc)
        raise HTTPException(status_code=500, detail="Gemini client library not installed") from exc

    model_name = os.getenv("GEMINI_MODEL_NAME", "gemini-3-pro-preview").strip()
    if not model_name:
        model_name = "gemini-3-pro-preview"

    instructions = (
        "You are improving an OnCue-style legal transcript. "
        "Use the provided XML transcript and the audio to correct ONLY: wording errors, punctuation, capitalization, and speaker labels. "
        "CRITICAL: You MUST preserve the EXACT start and end timestamps from the original - do NOT modify timing values. "
        "Keep the same number of lines and line order. Only fix text content and speaker names."
    )

    polish_schema = {
        "type": "array",
        "items": {
            "type": "object",
            "properties": {
                "speaker": {"type": "string"},
                "text": {"type": "string"},
                "start": {"type": "number"},
                "end": {"type": "number"},
            },
            "required": ["speaker", "text", "start", "end"],
        },
    }

    def wait_for_file_active(client: Any, file_name: str, *, timeout_seconds: int = 120) -> Any:
        deadline = time.time() + max(5, timeout_seconds)
        last_state = None
        while time.time() < deadline:
            fetched = client.files.get(name=file_name)
            state = getattr(fetched, "state", None)
            if state != last_state:
                logger.info("Gemini file %s state=%s", file_name, state)
                last_state = state
            if state == genai_types.FileState.ACTIVE:
                return fetched
            if state == genai_types.FileState.FAILED:
                err = getattr(fetched, "error", None)
                raise RuntimeError(f"Gemini file processing failed: {err}")
            time.sleep(2.0)
        raise TimeoutError("Timed out waiting for Gemini file to become ACTIVE")

    client = None
    uploaded = None
    try:
        client = genai.Client(
            api_key=api_key,
            http_options=genai_types.HttpOptions(timeout=600_000),
        )
        upload_config = genai_types.UploadFileConfig(
            mime_type=audio_mime,
            display_name=os.path.basename(audio_path),
        )
        try:
            uploaded = client.files.upload(file=audio_path, config=upload_config)
        except Exception as exc:
            logger.exception("Failed to upload media to Gemini")
            exc_text = str(exc)
            if "API_KEY_INVALID" in exc_text or "API key not valid" in exc_text:
                logger.error(
                    "Gemini rejected API key (len=%s). Check for quotes/whitespace and correct key source.",
                    len(api_key or ""),
                )
            raise HTTPException(
                status_code=502,
                detail=(
                    "Uploading media to Gemini failed. "
                    "If this is an API key error, ensure `GEMINI_API_KEY` (or `GOOGLE_API_KEY`) is set without quotes/whitespace "
                    "and is a valid Gemini Developer API key. "
                    f"({type(exc).__name__}: {exc})"
                ),
            ) from exc
        wait_timeout = int(os.getenv("GEMINI_FILE_ACTIVE_TIMEOUT_SECONDS", "120"))
        try:
            uploaded = wait_for_file_active(client, uploaded.name, timeout_seconds=wait_timeout)
        except Exception as exc:
            logger.exception("Uploaded file did not become ACTIVE")
            raise HTTPException(
                status_code=502,
                detail=f"Gemini file processing failed ({type(exc).__name__}: {exc})",
            ) from exc

        try:
            response = client.models.generate_content(
                model=model_name,
                contents=[
                    genai_types.Part.from_text(text=instructions),
                    genai_types.Part.from_text(
                        text=f"Total duration (seconds): {duration_hint:.2f}. Existing XML transcript follows:\n{xml_text}"
                    ),
                    genai_types.Part.from_uri(
                        file_uri=uploaded.uri,
                        mime_type=uploaded.mime_type or audio_mime,
                    ),
                ],
                config=genai_types.GenerateContentConfig(
                    temperature=0.15,
                    response_mime_type="application/json",
                    response_json_schema=polish_schema,
                    thinking_config=genai_types.ThinkingConfig(thinking_level="low"),
                ),
            )
        except Exception as exc:
            logger.exception("Gemini generation failed")
            raise HTTPException(
                status_code=502,
                detail=f"Gemini transcript refinement failed ({type(exc).__name__}: {exc})",
            ) from exc
    finally:
        if client and uploaded:
            try:
                client.files.delete(name=uploaded.name)
            except Exception:
                pass
        if client:
            try:
                client.close()
            except Exception:
                pass

    raw_text = getattr(response, "text", None) or getattr(response, "output_text", None)
    if not raw_text and getattr(response, "candidates", None):
        try:
            raw_text = response.candidates[0].content.parts[0].text
        except Exception:
            raw_text = None

    if not raw_text:
        logger.error("Gemini response missing text payload")
        raise HTTPException(status_code=502, detail="Gemini returned an empty response")

    try:
        parsed = json.loads(raw_text)
    except json.JSONDecodeError as exc:
        logger.error("Failed to parse Gemini JSON: %s", exc)
        raise HTTPException(status_code=502, detail="Gemini returned invalid JSON") from exc

    if not isinstance(parsed, list):
        raise HTTPException(status_code=502, detail="Gemini response must be a list of line objects")

    normalized = []
    for idx, item in enumerate(parsed):
        if not isinstance(item, dict):
            continue
        speaker = _normalize_speaker_label(
            item.get("speaker", ""),
            fallback=f"SPEAKER {_speaker_suffix_for_index(idx)}",
        )
        text = str(item.get("text", "")).strip()
        start_val = float(item.get("start", 0.0))
        end_val = float(item.get("end", start_val))
        normalized.append(
            {
                "id": item.get("id") or f"gem-{idx}",
                "speaker": speaker,
                "text": text,
                "start": max(start_val, 0.0),
                "end": max(end_val, start_val),
                "is_continuation": False,
            }
        )

    if not normalized:
        raise HTTPException(status_code=502, detail="Gemini did not return any transcript lines")

    logger.info("Gemini polish completed with %d lines", len(normalized))
    return normalized


def transcribe_with_gemini(
    audio_path: str,
    audio_mime: str,
    duration_hint: float,
    speaker_name_list: Optional[List[str]] = None,
) -> List[dict]:
    """
    Transcribe audio using Gemini 3.0 Pro with thinking_level="low".

    Args:
        audio_path: Path to the audio file
        audio_mime: MIME type of the audio
        duration_hint: Approximate duration in seconds
        speaker_name_list: Optional list of speaker names to use

    Returns:
        List of transcript line objects with speaker, text, start, end fields
    """
    api_key = os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_API_KEY")
    if api_key:
        api_key = api_key.strip()
        if (api_key.startswith('"') and api_key.endswith('"')) or (api_key.startswith("'") and api_key.endswith("'")):
            api_key = api_key[1:-1].strip()
        if api_key in {"your-gemini-key-here", "YOUR_GEMINI_KEY_HERE"}:
            raise HTTPException(
                status_code=500,
                detail="GEMINI_API_KEY is still set to the placeholder value; update your Cloud Run env var.",
            )
    if not api_key:
        raise HTTPException(status_code=500, detail="GEMINI_API_KEY not configured")

    try:
        from google import genai
        from google.genai import types as genai_types
    except Exception as exc:
        logger.error("google-genai not available: %s", exc)
        raise HTTPException(status_code=500, detail="Gemini client library not installed") from exc

    model_name = os.getenv("GEMINI_MODEL_NAME", "gemini-3-pro-preview").strip()
    if not model_name:
        model_name = "gemini-3-pro-preview"

    # Build speaker instructions
    speaker_instructions = ""
    if speaker_name_list and len(speaker_name_list) > 0:
        speaker_instructions = (
            f"Use these speaker names in order of appearance: {', '.join(speaker_name_list)}. "
            f"Expected number of speakers: {len(speaker_name_list)}. "
        )
    else:
        speaker_instructions = (
            "Identify and label distinct speakers as SPEAKER A, SPEAKER B, SPEAKER C, etc. "
        )

    instructions = (
        "You are a professional legal transcriptionist. "
        "Transcribe the provided audio file into a legal transcript format with precise WORD-LEVEL timestamps. "
        f"{speaker_instructions}"
        "Each utterance must include the 'words' array with timing for EVERY word in the text. "
        "Ensure proper punctuation and capitalization. "
        "All timestamps should be accurate in seconds, with start < end, entries non-overlapping and chronological."
    )

    def wait_for_file_active(client: Any, file_name: str, *, timeout_seconds: int = 120) -> Any:
        deadline = time.time() + max(5, timeout_seconds)
        last_state = None
        while time.time() < deadline:
            fetched = client.files.get(name=file_name)
            state = getattr(fetched, "state", None)
            if state != last_state:
                logger.info("Gemini file %s state=%s", file_name, state)
                last_state = state
            if state == genai_types.FileState.ACTIVE:
                return fetched
            if state == genai_types.FileState.FAILED:
                err = getattr(fetched, "error", None)
                raise RuntimeError(f"Gemini file processing failed: {err}")
            time.sleep(2.0)
        raise TimeoutError("Timed out waiting for Gemini file to become ACTIVE")

    client = None
    uploaded = None
    try:
        client = genai.Client(
            api_key=api_key,
            http_options=genai_types.HttpOptions(timeout=600_000),
        )
        upload_config = genai_types.UploadFileConfig(
            mime_type=audio_mime,
            display_name=os.path.basename(audio_path),
        )
        try:
            uploaded = client.files.upload(file=audio_path, config=upload_config)
        except Exception as exc:
            logger.exception("Failed to upload media to Gemini")
            exc_text = str(exc)
            if "API_KEY_INVALID" in exc_text or "API key not valid" in exc_text:
                logger.error("Gemini rejected API key (len=%s). Check for quotes/whitespace.", len(api_key or ""))
            raise HTTPException(
                status_code=502,
                detail=(
                    "Uploading media to Gemini failed. "
                    f"({type(exc).__name__}: {exc})"
                ),
            ) from exc

        wait_timeout = int(os.getenv("GEMINI_FILE_ACTIVE_TIMEOUT_SECONDS", "120"))
        try:
            uploaded = wait_for_file_active(client, uploaded.name, timeout_seconds=wait_timeout)
        except Exception as exc:
            logger.exception("Uploaded file did not become ACTIVE")
            raise HTTPException(
                status_code=502,
                detail=f"Gemini file processing failed ({type(exc).__name__}: {exc})",
            ) from exc

        # Build the JSON schema for structured output
        utterance_schema = {
            "type": "array",
            "items": {
                "type": "object",
                "properties": {
                    "speaker": {"type": "string"},
                    "text": {"type": "string"},
                    "start": {"type": "number"},
                    "end": {"type": "number"},
                    "words": {
                        "type": "array",
                        "items": {
                            "type": "object",
                            "properties": {
                                "word": {"type": "string"},
                                "start": {"type": "number"},
                                "end": {"type": "number"},
                            },
                            "required": ["word", "start", "end"],
                        },
                    },
                },
                "required": ["speaker", "text", "start", "end", "words"],
            },
        }

        try:
            response = client.models.generate_content(
                model=model_name,
                contents=[
                    genai_types.Part.from_text(text=instructions),
                    genai_types.Part.from_text(
                        text=f"Total audio duration (seconds): {duration_hint:.2f}. Please transcribe the following audio:"
                    ),
                    genai_types.Part.from_uri(
                        file_uri=uploaded.uri,
                        mime_type=uploaded.mime_type or audio_mime,
                    ),
                ],
                config=genai_types.GenerateContentConfig(
                    temperature=0.15,
                    response_mime_type="application/json",
                    response_json_schema=utterance_schema,
                    thinking_config=genai_types.ThinkingConfig(thinking_level="low"),
                ),
            )
        except Exception as exc:
            logger.exception("Gemini transcription failed")
            raise HTTPException(
                status_code=502,
                detail=f"Gemini transcription failed ({type(exc).__name__}: {exc})",
            ) from exc
    finally:
        if client and uploaded:
            try:
                client.files.delete(name=uploaded.name)
            except Exception:
                pass
        if client:
            try:
                client.close()
            except Exception:
                pass

    raw_text = getattr(response, "text", None) or getattr(response, "output_text", None)
    if not raw_text and getattr(response, "candidates", None):
        try:
            raw_text = response.candidates[0].content.parts[0].text
        except Exception:
            raw_text = None

    if not raw_text:
        logger.error("Gemini response missing text payload")
        raise HTTPException(status_code=502, detail="Gemini returned an empty response")

    try:
        parsed = json.loads(raw_text)
    except json.JSONDecodeError as exc:
        logger.error("Failed to parse Gemini JSON: %s", exc)
        raise HTTPException(status_code=502, detail="Gemini returned invalid JSON") from exc

    if not isinstance(parsed, list):
        raise HTTPException(status_code=502, detail="Gemini response must be a list of utterance objects")

    speaker_mapping = {}
    if speaker_name_list:
        for i, name in enumerate(speaker_name_list):
            suffix = _speaker_suffix_for_index(i)
            speaker_mapping[f"SPEAKER {suffix}"] = name.upper()
            speaker_mapping[suffix] = name.upper()

    normalized = []
    for idx, item in enumerate(parsed):
        if not isinstance(item, dict):
            logger.warning("Skipping non-dict item at index %d", idx)
            continue

        speaker = _normalize_speaker_label(
            item.get("speaker", ""),
            fallback=f"SPEAKER {_speaker_suffix_for_index(idx)}",
        )

        if speaker in speaker_mapping:
            speaker = speaker_mapping[speaker]

        text = str(item.get("text", "")).strip()
        start_val = float(item.get("start", 0.0))
        end_val = float(item.get("end", start_val))

        raw_words = item.get("words", [])
        if not raw_words:
            logger.warning("Utterance at index %d missing words array", idx)

        words_data = []
        for word_item in raw_words:
            word_text = str(word_item.get("word", "")).strip()
            if not word_text:
                continue
            word_start = float(word_item.get("start", 0.0))
            word_end = float(word_item.get("end", word_start))
            words_data.append({
                "text": word_text,
                "start": max(word_start, 0.0),
                "end": max(word_end, word_start),
                "speaker": speaker,
            })

        line_data = {
            "id": item.get("id") or f"gem-{idx}",
            "speaker": speaker,
            "text": text,
            "start": max(start_val, 0.0),
            "end": max(end_val, start_val),
            "is_continuation": False,
            "words": words_data,
        }

        normalized.append(line_data)

    if not normalized:
        raise HTTPException(status_code=502, detail="Gemini did not return any transcript lines")

    prev_speaker = None
    for item in normalized:
        current_speaker = item.get("speaker", "").strip().upper()
        if prev_speaker is not None and current_speaker == prev_speaker:
            item["is_continuation"] = True
        else:
            item["is_continuation"] = False
        prev_speaker = current_speaker

    logger.info("Gemini transcription completed with %d utterances", len(normalized))
    return normalized
===== END FILE =====

===== FILE: backend/media_processing.py =====
import logging
import mimetypes
import os
import shutil
import subprocess
import tempfile
from typing import Optional, Tuple

from fastapi import HTTPException

try:
    from .storage import download_blob_to_path, upload_clip_file_to_cloud_storage, storage_client, BUCKET_NAME
except ImportError:
    try:
        from storage import download_blob_to_path, upload_clip_file_to_cloud_storage, storage_client, BUCKET_NAME
    except ImportError:
        import storage as storage_module
        download_blob_to_path = storage_module.download_blob_to_path
        upload_clip_file_to_cloud_storage = storage_module.upload_clip_file_to_cloud_storage
        storage_client = storage_module.storage_client
        BUCKET_NAME = storage_module.BUCKET_NAME

try:
    from .transcript_utils import slugify_filename
except ImportError:
    try:
        from transcript_utils import slugify_filename
    except ImportError:
        import transcript_utils as transcript_utils_module
        slugify_filename = transcript_utils_module.slugify_filename

try:
    from .transcriber import ffmpeg_executable_path, get_media_duration
except ImportError:
    try:
        from transcriber import ffmpeg_executable_path, get_media_duration
    except ImportError:
        import transcriber as transcriber_module
        ffmpeg_executable_path = transcriber_module.ffmpeg_executable_path
        get_media_duration = transcriber_module.get_media_duration


def get_ffmpeg_binary() -> str:
    if ffmpeg_executable_path and shutil.which(ffmpeg_executable_path):
        return ffmpeg_executable_path
    fallback = shutil.which("ffmpeg")
    if fallback:
        return fallback
    raise HTTPException(status_code=500, detail="FFmpeg binary not available on server")


def prepare_audio_for_gemini(blob_name: str, content_type: Optional[str]) -> Tuple[str, str, float, str]:
    """Download media, convert to audio if needed, and return (audio_path, mime_type, duration, original_path)."""
    media_path, detected_type = download_blob_to_path(blob_name)
    try:
        if os.path.getsize(media_path) <= 0:
            raise HTTPException(status_code=400, detail="Downloaded media file is empty")
    except OSError:
        raise HTTPException(status_code=500, detail="Unable to access downloaded media file")
    audio_path = media_path
    source_mime = (detected_type or content_type or "").lower().strip()
    if not source_mime:
        source_mime = (mimetypes.guess_type(media_path)[0] or "").lower().strip()

    def canonicalize_audio_mime(mime_value: str, file_path: str) -> str:
        mime_value = (mime_value or "").lower().strip()
        if mime_value in {"audio/mp3", "audio/mpeg", "audio/x-mp3", "audio/mpeg3"}:
            return "audio/mpeg"
        if mime_value in {"audio/x-wav"}:
            return "audio/wav"
        guessed = (mimetypes.guess_type(file_path)[0] or "").lower().strip()
        if guessed in {"audio/mpeg", "audio/mp3", "audio/x-mp3", "audio/mpeg3"}:
            return "audio/mpeg"
        if guessed == "audio/x-wav":
            return "audio/wav"
        return mime_value or guessed or "application/octet-stream"

    supported_audio_mimes = {
        "audio/mpeg",
        "audio/wav",
        "audio/aac",
        "audio/ogg",
        "audio/flac",
        "audio/mp4",
        "audio/aiff",
    }

    audio_mime = canonicalize_audio_mime(source_mime, media_path)
    needs_conversion = (source_mime.startswith("video/") or audio_mime not in supported_audio_mimes)
    if needs_conversion:
        ffmpeg_bin = get_ffmpeg_binary()
        temp_audio = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
        temp_audio.close()
        command = [
            ffmpeg_bin,
            "-y",
            "-i",
            media_path,
            "-vn",
            "-ac",
            "1",
            "-ar",
            "16000",
            "-b:a",
            "96k",
            temp_audio.name,
        ]
        process = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        if process.returncode != 0 or not os.path.exists(temp_audio.name):
            stderr = process.stderr.decode("utf-8", errors="ignore")
            logger = logging.getLogger(__name__)
            logger.error("FFmpeg conversion failed: %s", stderr)
            raise HTTPException(status_code=500, detail="Failed to convert media to audio")
        audio_path = temp_audio.name
        audio_mime = "audio/mpeg"

    max_upload_bytes = int(os.getenv("GEMINI_MAX_UPLOAD_BYTES", str(1024 * 1024 * 1024)))  # 1 GiB default
    try:
        audio_size = os.path.getsize(audio_path)
    except OSError:
        audio_size = None
    if audio_size is not None and max_upload_bytes > 0 and audio_size > max_upload_bytes:
        raise HTTPException(
            status_code=413,
            detail=f"Audio is too large for Gemini refinement ({audio_size} bytes > {max_upload_bytes} bytes)",
        )

    duration_seconds = get_media_duration(audio_path) or 0.0
    return audio_path, audio_mime, duration_seconds, media_path


def clip_media_segment(
    source_blob_name: Optional[str],
    clip_start: float,
    clip_end: float,
    content_type: Optional[str],
    clip_label: str,
    user_id: Optional[str] = None,
    parent_media_key: Optional[str] = None,
) -> Tuple[Optional[str], Optional[str]]:
    if not source_blob_name:
        return None, None

    if clip_end <= clip_start:
        raise HTTPException(status_code=400, detail="Clip duration must be greater than zero")

    bucket = storage_client.bucket(BUCKET_NAME)
    source_blob = bucket.blob(source_blob_name)
    if not source_blob.exists():
        raise HTTPException(status_code=404, detail="Original media for session is unavailable")

    extension = os.path.splitext(source_blob_name)[1]
    if not extension and content_type:
        guessed = mimetypes.guess_extension(content_type)
        extension = guessed or extension
    extension = extension or ".mp4"

    ffmpeg_bin = get_ffmpeg_binary()
    start_time = max(clip_start, 0.0)
    duration = max(clip_end - clip_start, 0.01)

    source_temp = tempfile.NamedTemporaryFile(suffix=extension, delete=False)
    output_temp = tempfile.NamedTemporaryFile(suffix=extension, delete=False)
    try:
        source_temp.close()
        output_temp.close()
        source_blob.download_to_filename(source_temp.name)

        command = [
            ffmpeg_bin,
            "-y",
            "-i",
            source_temp.name,
            "-ss",
            f"{start_time:.3f}",
            "-t",
            f"{duration:.3f}",
            "-c:v",
            "libx264",
            "-preset",
            "fast",
            "-crf",
            "18",
            "-c:a",
            "aac",
            "-b:a",
            "192k",
            "-avoid_negative_ts",
            "make_zero",
            output_temp.name,
        ]

        process = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        if process.returncode != 0:
            stderr = process.stderr.decode("utf-8", errors="ignore")
            logger = logging.getLogger(__name__)
            logger.error("FFmpeg clip command failed: %s", stderr)
            raise HTTPException(status_code=500, detail="FFmpeg failed to produce clip")

        with open(output_temp.name, "rb") as output_file:
            clip_bytes = output_file.read()

        filename_slug = slugify_filename(clip_label or "clip")
        clip_filename = f"{filename_slug}{extension}"
        clip_blob_name = upload_clip_file_to_cloud_storage(
            clip_bytes,
            clip_filename,
            content_type,
            user_id=user_id,
            parent_media_key=parent_media_key,
        )
        return clip_blob_name, content_type
    finally:
        for temp_path in (source_temp.name, output_temp.name):
            try:
                os.remove(temp_path)
            except OSError:
                pass
===== END FILE =====

===== FILE: backend/models.py =====
from typing import List, Optional
from pydantic import BaseModel


class WordTimestamp(BaseModel):
    """Represents a single word with precise timing information."""
    text: str
    start: float  # Start time in milliseconds
    end: float    # End time in milliseconds
    confidence: Optional[float] = None
    speaker: Optional[str] = None


class TranscriptTurn(BaseModel):
    speaker: str
    text: str
    timestamp: Optional[str] = None
    words: Optional[List[WordTimestamp]] = None  # Word-level timestamps for accurate line timing
    is_continuation: bool = False  # True if same speaker as previous turn (no speaker label needed)


class GeminiWordTiming(BaseModel):
    """Word-level timing from Gemini transcription."""
    word: str
    start: float
    end: float


class GeminiUtterance(BaseModel):
    """A single speaker utterance from Gemini transcription."""
    speaker: str
    text: str
    start: float
    end: float
    words: List[GeminiWordTiming]


# ============================================================================
# Cases System Models
# ============================================================================


class CaseMeta(BaseModel):
    """Case metadata stored in cases/{user_id}/{case_id}/meta.json"""
    case_id: str
    user_id: str
    name: str
    description: Optional[str] = None
    created_at: str  # ISO timestamp
    updated_at: str  # ISO timestamp
    transcript_count: int = 0


class CaseTranscriptEntry(BaseModel):
    """Entry in cases/{user_id}/{case_id}/transcripts.json"""
    media_key: str
    added_at: str  # ISO timestamp
    title_label: Optional[str] = None


class CaseIndex(BaseModel):
    """User's case index stored in cases/{user_id}/index.json"""
    user_id: str
    cases: List[CaseMeta]
    updated_at: str  # ISO timestamp


class CaseSearchMatch(BaseModel):
    """A single search match within a transcript line."""
    line_id: str
    page: int
    line: int
    text: str
    speaker: str
    match_type: str  # 'text' or 'speaker'


class CaseSearchResult(BaseModel):
    """Search results for a single transcript within a case."""
    media_key: str
    title_label: str
    matches: List[CaseSearchMatch]
===== END FILE =====

===== FILE: backend/rev_ai_sync.py =====
import copy
import os
import time
import logging
import requests
import re
import tempfile
from datetime import timedelta
from typing import List, Optional, Dict, Any, Tuple
from difflib import SequenceMatcher

from google.cloud import storage
from google import auth
from google.auth.transport import requests as google_requests
from google.auth import compute_engine
from google.auth.compute_engine import credentials as compute_credentials

# Import models with fallback pattern
try:
    from .models import TranscriptTurn, WordTimestamp
except ImportError:
    try:
        from models import TranscriptTurn, WordTimestamp
    except ImportError:
        import models
        TranscriptTurn = models.TranscriptTurn
        WordTimestamp = models.WordTimestamp

logger = logging.getLogger(__name__)

# Rev AI Alignment API (separate from speech-to-text API)
REV_AI_ALIGNMENT_BASE_URL = "https://api.rev.ai/alignment/v1"

# Cloud Storage bucket for temporary files
BUCKET_NAME = "transcribealpha-uploads-1750110926"

ALIGNMENT_SPLIT_RE = re.compile(r"[-–—/\\\\]")
ALIGNMENT_CLEAN_RE = re.compile(r"[^\w]+", re.UNICODE)


def normalize_alignment_token(token: str) -> List[str]:
    if not token:
        return []
    normalized = token.replace("’", "'").replace("‘", "'")
    normalized = normalized.replace("“", "\"").replace("”", "\"")
    normalized = ALIGNMENT_SPLIT_RE.sub(" ", normalized)
    parts = []
    for part in normalized.split():
        cleaned = ALIGNMENT_CLEAN_RE.sub("", part).lower().strip("_")
        if cleaned:
            parts.append(cleaned)
    return parts


class RevAIAligner:
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        self.storage_client = storage.Client()

        # Get credentials for signing URLs on Cloud Run
        self._signing_credentials = None
        self._service_account_email = None
        self._init_signing_credentials()

    def _init_signing_credentials(self):
        """Initialize credentials for signing URLs using IAM signBlob API."""
        try:
            # Get default credentials
            credentials, project = auth.default()

            # Refresh credentials to ensure token is valid
            auth_req = google_requests.Request()
            credentials.refresh(auth_req)

            # On Cloud Run, we need to get the service account email from metadata server
            # The credentials.service_account_email may just return "default"
            try:
                import urllib.request
                metadata_url = "http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/email"
                req = urllib.request.Request(metadata_url, headers={"Metadata-Flavor": "Google"})
                with urllib.request.urlopen(req, timeout=5) as response:
                    self._service_account_email = response.read().decode('utf-8').strip()
                logger.info("Got service account email from metadata: %s", self._service_account_email)
            except Exception as meta_err:
                logger.warning("Could not get SA email from metadata: %s", meta_err)
                # Fallback to credentials attribute
                if hasattr(credentials, 'service_account_email'):
                    self._service_account_email = credentials.service_account_email

            self._signing_credentials = credentials
            logger.info("Initialized signing credentials for: %s", self._service_account_email)
        except Exception as e:
            logger.warning("Could not initialize signing credentials: %s", e)

    def _create_signed_url(self, blob_name: str, expiration_minutes: int = 15) -> str:
        """Create a signed URL for a Cloud Storage blob using IAM signBlob API."""
        bucket = self.storage_client.bucket(BUCKET_NAME)
        blob = bucket.blob(blob_name)

        # Use IAM-based signing which works with Compute Engine credentials
        if self._service_account_email:
            url = blob.generate_signed_url(
                version="v4",
                expiration=timedelta(minutes=expiration_minutes),
                method="GET",
                service_account_email=self._service_account_email,
                access_token=self._signing_credentials.token,
            )
        else:
            # Fallback - try regular signing (works if running with service account key)
            url = blob.generate_signed_url(
                version="v4",
                expiration=timedelta(minutes=expiration_minutes),
                method="GET"
            )

        logger.info("Generated signed URL for %s (expires in %d min)", blob_name, expiration_minutes)
        return url

    def _upload_text_to_gcs(self, text: str, filename: str) -> str:
        """Upload transcript text to Cloud Storage and return blob name."""
        bucket = self.storage_client.bucket(BUCKET_NAME)
        blob_name = f"rev_ai_temp/{filename}"
        blob = bucket.blob(blob_name)

        blob.upload_from_string(text, content_type="text/plain")
        logger.info("Uploaded transcript to GCS: %s", blob_name)

        return blob_name

    def _upload_audio_to_gcs(self, audio_path: str) -> str:
        """Upload audio file to Cloud Storage and return blob name."""
        bucket = self.storage_client.bucket(BUCKET_NAME)
        filename = os.path.basename(audio_path)
        blob_name = f"rev_ai_temp/{int(time.time())}_{filename}"
        blob = bucket.blob(blob_name)

        blob.upload_from_filename(audio_path)
        logger.info("Uploaded audio to GCS: %s", blob_name)

        return blob_name

    def _cleanup_gcs_blob(self, blob_name: str):
        """Delete a temporary blob from Cloud Storage."""
        try:
            bucket = self.storage_client.bucket(BUCKET_NAME)
            blob = bucket.blob(blob_name)
            blob.delete()
            logger.info("Cleaned up GCS blob: %s", blob_name)
        except Exception as e:
            logger.warning("Failed to cleanup GCS blob %s: %s", blob_name, e)

    def submit_alignment_job(self, audio_url: str, transcript_url: str, metadata: str = "") -> str:
        """Submit alignment job to Rev AI using URLs."""
        url = f"{REV_AI_ALIGNMENT_BASE_URL}/jobs"

        payload = {
            "source_config": {
                "url": audio_url
            },
            "source_transcript_config": {
                "url": transcript_url
            }
        }

        if metadata:
            payload["metadata"] = metadata

        logger.info("Submitting alignment job to Rev AI: %s", url)
        logger.info("Audio URL: %s...", audio_url[:100])
        logger.info("Transcript URL: %s...", transcript_url[:100])

        response = requests.post(url, headers=self.headers, json=payload)

        logger.info("Rev AI response status: %s", response.status_code)
        logger.info("Rev AI response body: %s", response.text[:500] if response.text else 'empty')

        if response.status_code not in (200, 201):
            logger.error("Rev AI Job Submit Failed (HTTP %s): %s", response.status_code, response.text)
            raise Exception(f"Failed to submit alignment job (HTTP {response.status_code}): {response.text}")

        return response.json()['id']

    def get_job_details(self, job_id: str) -> Dict[str, Any]:
        """Get job status from Rev AI."""
        url = f"{REV_AI_ALIGNMENT_BASE_URL}/jobs/{job_id}"
        response = requests.get(url, headers=self.headers)
        response.raise_for_status()
        return response.json()

    def get_alignment_result(self, job_id: str) -> Dict[str, Any]:
        """Get alignment results from Rev AI."""
        url = f"{REV_AI_ALIGNMENT_BASE_URL}/jobs/{job_id}/transcript"
        headers = self.headers.copy()
        headers['Accept'] = 'application/vnd.rev.transcript.v1.0+json'

        response = requests.get(url, headers=headers)
        response.raise_for_status()
        return response.json()

    def wait_for_job(self, job_id: str, poll_interval: int = 3, max_wait: int = 600) -> Dict[str, Any]:
        """Poll for job completion."""
        start_time = time.time()

        while time.time() - start_time < max_wait:
            details = self.get_job_details(job_id)
            status = details.get("status")

            logger.info("Rev AI job %s status: %s", job_id, status)

            if status == "completed":
                return self.get_alignment_result(job_id)
            elif status == "failed":
                failure = details.get('failure', 'Unknown error')
                failure_detail = details.get('failure_detail', '')
                raise Exception(f"Alignment job failed: {failure} - {failure_detail}")

            time.sleep(poll_interval)

        raise Exception(f"Alignment job timed out after {max_wait} seconds")

    def align_transcript(
        self,
        turns: List[dict],
        audio_file_path: Optional[str] = None,
        audio_url: Optional[str] = None,
        source_turns: Optional[List[dict]] = None,
    ) -> List[dict]:
        """
        Align transcript with audio using Rev AI Forced Alignment API.

        Timestamp-only approach (preserves original text):
        1. Build plain text from turns for Rev AI alignment
        2. Also build a flat list of original words (with punctuation intact)
        3. Submit to Rev AI and get word-level timestamps
        4. Map Rev AI timestamps back to original words by position
        5. Update original turns with new timestamps, keeping original text
        """

        # Step 1: Build plain text for Rev AI AND track original words
        plain_text_words = []  # Cleaned words for Rev AI
        clean_word_to_original_idx = []
        original_words = []    # Original words with punctuation, indexed globally
        word_to_turn_idx = []  # Maps global word index to (turn_index, word_index_in_turn)
        turn_word_positions = [0] * len(turns)

        for turn_idx, turn in enumerate(turns):
            turn_text = turn.get('text', '')

            for token in turn_text.split():
                clean_parts = normalize_alignment_token(token)
                if not clean_parts:
                    continue
                original_idx = len(original_words)
                original_words.append(token)  # Keep original with punctuation
                word_to_turn_idx.append((turn_idx, turn_word_positions[turn_idx]))
                turn_word_positions[turn_idx] += 1

                for clean_part in clean_parts:
                    plain_text_words.append(clean_part)
                    clean_word_to_original_idx.append(original_idx)

        full_text_for_api = " ".join(plain_text_words)

        if not full_text_for_api.strip():
            logger.warning("No valid text found to align")
            return turns

        logger.info("Prepared %d words for alignment from %d turns", len(plain_text_words), len(turns))

        # Track blobs for cleanup
        temp_blobs = []

        try:
            # Step 2: Upload transcript text to GCS
            transcript_blob_name = self._upload_text_to_gcs(
                full_text_for_api,
                f"transcript_{int(time.time())}.txt"
            )
            temp_blobs.append(transcript_blob_name)
            transcript_url = self._create_signed_url(transcript_blob_name)

            # Handle audio - either use existing URL or upload file
            if audio_url:
                final_audio_url = audio_url
            elif audio_file_path and os.path.exists(audio_file_path):
                audio_blob_name = self._upload_audio_to_gcs(audio_file_path)
                temp_blobs.append(audio_blob_name)
                final_audio_url = self._create_signed_url(audio_blob_name)
            else:
                raise ValueError("Either audio_url or audio_file_path must be provided")

            # Submit job
            logger.info("Submitting alignment job with %d words", len(plain_text_words))
            job_id = self.submit_alignment_job(final_audio_url, transcript_url)
            logger.info("Alignment job submitted: %s", job_id)

            # Wait for result
            result = self.wait_for_job(job_id)

            # Step 3: Extract aligned words and timestamps from Rev AI response
            aligned_tokens = []
            timestamps = []
            last_end_ms = 0.0
            for monologue in result.get('monologues', []):
                for element in monologue.get('elements', []):
                    if element.get('type') != 'text':
                        continue
                    value = element.get('value') or element.get('text') or ''
                    token_parts = normalize_alignment_token(value)
                    if not token_parts:
                        continue

                    ts = element.get('ts')
                    end_ts = element.get('end_ts')
                    confidence = element.get('confidence', 1.0)

                    if ts is not None:
                        start_ms = ts * 1000.0
                    else:
                        start_ms = last_end_ms  # Fallback to end of previous word

                    if end_ts is not None:
                        end_ms = end_ts * 1000.0
                    else:
                        end_ms = start_ms  # Zero duration if unknown

                    for token in token_parts:
                        aligned_tokens.append(token)
                        timestamps.append({
                            'start': start_ms,
                            'end': end_ms,
                            'confidence': confidence,
                        })
                    last_end_ms = end_ms

            logger.info("Rev AI returned %d aligned words (expected %d)", len(aligned_tokens), len(plain_text_words))

            matcher = SequenceMatcher(None, plain_text_words, aligned_tokens, autojunk=False)
            word_matches = {}
            for tag, i1, i2, j1, j2 in matcher.get_opcodes():
                if tag != "equal":
                    continue
                for offset in range(i2 - i1):
                    word_matches[i1 + offset] = j1 + offset

            logger.info("Alignment matched %d/%d words", len(word_matches), len(plain_text_words))

            # Step 4.5: Build source (ASR/Gemini) timestamp map for fallback
            source_word_timestamps = {}
            if source_turns:
                source_words = []
                source_clean_tokens = []
                source_clean_to_word_idx = []
                for turn in source_turns:
                    for word in turn.get('words') or []:
                        word_text = str(word.get('text', '')).strip()
                        if not word_text:
                            continue
                        try:
                            start_ms = float(word.get('start', 0.0))
                            end_ms = float(word.get('end', start_ms))
                        except (TypeError, ValueError):
                            continue
                        source_words.append({
                            'text': word_text,
                            'start': start_ms,
                            'end': end_ms,
                            'confidence': word.get('confidence'),
                        })
                        source_idx = len(source_words) - 1
                        for part in normalize_alignment_token(word_text):
                            source_clean_tokens.append(part)
                            source_clean_to_word_idx.append(source_idx)

                if source_clean_tokens and plain_text_words:
                    source_matcher = SequenceMatcher(None, plain_text_words, source_clean_tokens, autojunk=False)
                    for tag, i1, i2, j1, j2 in source_matcher.get_opcodes():
                        if tag != "equal":
                            continue
                        for offset in range(i2 - i1):
                            current_clean_idx = i1 + offset
                            source_clean_idx = j1 + offset
                            if current_clean_idx >= len(clean_word_to_original_idx) or source_clean_idx >= len(source_clean_to_word_idx):
                                continue
                            original_idx = clean_word_to_original_idx[current_clean_idx]
                            source_word_idx = source_clean_to_word_idx[source_clean_idx]
                            source_word_timestamps.setdefault(original_idx, []).append(source_words[source_word_idx])

            # Step 5: Update original turns with new timestamps
            # Deep copy turns to avoid mutating input
            updated_turns = copy.deepcopy(turns)

            original_word_timestamps = {}
            for clean_idx, aligned_idx in word_matches.items():
                if clean_idx >= len(clean_word_to_original_idx) or aligned_idx >= len(timestamps):
                    continue
                original_idx = clean_word_to_original_idx[clean_idx]
                original_word_timestamps.setdefault(original_idx, []).append(timestamps[aligned_idx])

            rev_word_ranges = {}
            rev_word_confidence = {}
            for original_idx, ts_list in original_word_timestamps.items():
                start_ms = min(ts['start'] for ts in ts_list)
                end_ms = max(ts['end'] for ts in ts_list)
                confidence_values = [ts.get('confidence') for ts in ts_list if ts.get('confidence') is not None]
                confidence = min(confidence_values) if confidence_values else 1.0
                rev_word_ranges[original_idx] = (start_ms, end_ms)
                rev_word_confidence[original_idx] = confidence

            def find_adjacent_rev(idx: int, max_distance: int) -> Tuple[Optional[int], Optional[int]]:
                prev_idx = None
                next_idx = None
                for offset in range(1, max_distance + 1):
                    candidate = idx - offset
                    if candidate >= 0 and candidate in rev_word_ranges:
                        prev_idx = candidate
                        break
                for offset in range(1, max_distance + 1):
                    candidate = idx + offset
                    if candidate < len(original_words) and candidate in rev_word_ranges:
                        next_idx = candidate
                        break
                return prev_idx, next_idx

            turn_word_data = {i: [] for i in range(len(turns))}
            timed_originals = 0
            filled_adjacent = 0
            filled_source = 0
            filled_wide = 0
            missing_words = 0

            for original_idx, (turn_idx, _) in enumerate(word_to_turn_idx):
                original_word = original_words[original_idx]
                start_ms = None
                end_ms = None
                confidence = None

                if original_idx in rev_word_ranges:
                    start_ms, end_ms = rev_word_ranges[original_idx]
                    confidence = rev_word_confidence.get(original_idx)
                else:
                    prev_idx, next_idx = find_adjacent_rev(original_idx, 1)
                    if prev_idx is not None and next_idx is not None:
                        prev_end = rev_word_ranges[prev_idx][1]
                        next_start = rev_word_ranges[next_idx][0]
                        gap_ms = next_start - prev_end
                        if 0 <= gap_ms <= 3000:
                            midpoint = prev_end + gap_ms / 2.0
                            start_ms = midpoint
                            end_ms = midpoint
                            filled_adjacent += 1

                if start_ms is None:
                    ts_list = source_word_timestamps.get(original_idx)
                    if ts_list:
                        start_ms = min(ts['start'] for ts in ts_list)
                        end_ms = max(ts['end'] for ts in ts_list)
                        confidence_values = [ts.get('confidence') for ts in ts_list if ts.get('confidence') is not None]
                        confidence = min(confidence_values) if confidence_values else None
                        filled_source += 1

                if start_ms is None:
                    prev_idx, next_idx = find_adjacent_rev(original_idx, 3)
                    if prev_idx is not None and next_idx is not None:
                        prev_end = rev_word_ranges[prev_idx][1]
                        next_start = rev_word_ranges[next_idx][0]
                        gap_ms = next_start - prev_end
                        if 0 <= gap_ms <= 5500:
                            midpoint = prev_end + gap_ms / 2.0
                            start_ms = midpoint
                            end_ms = midpoint
                            filled_wide += 1

                if start_ms is None or end_ms is None:
                    start_ms = -1.0
                    end_ms = -1.0
                    missing_words += 1

                if start_ms >= 0 and end_ms >= 0:
                    timed_originals += 1

                turn_word_data[turn_idx].append({
                    'text': original_word,
                    'start': start_ms,
                    'end': end_ms,
                    'confidence': confidence,
                    'speaker': turns[turn_idx].get('speaker', 'UNKNOWN'),
                })

            logger.info(
                "Alignment timed %d/%d words (adjacent=%d, source=%d, widened=%d, missing=%d)",
                timed_originals,
                len(original_words),
                filled_adjacent,
                filled_source,
                filled_wide,
                missing_words,
            )

            # Update each turn with new word data and recalculate timestamp
            for turn_idx, turn in enumerate(updated_turns):
                words = turn_word_data.get(turn_idx, [])
                turn['words'] = words

                valid_words = [word for word in words if word.get('start', -1) >= 0 and word.get('end', -1) >= 0]
                if valid_words:
                    turn_start_sec = valid_words[0]['start'] / 1000.0
                    m, s = int(turn_start_sec // 60), int(turn_start_sec % 60)
                    turn['timestamp'] = f"[{m:02d}:{s:02d}]"

            logger.info("Updated %d turns with Rev AI timestamps (text preserved)", len(updated_turns))
            if updated_turns and updated_turns[0].get('words'):
                first_word = updated_turns[0]['words'][0]
                logger.info("Sample first word: text='%s', start=%.1f ms", first_word.get('text'), first_word.get('start'))

            return updated_turns

        finally:
            # Cleanup temporary GCS blobs
            for blob_name in temp_blobs:
                self._cleanup_gcs_blob(blob_name)
===== END FILE =====

===== FILE: backend/server.py =====
import logging
import os
import sys

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Add current directory and backend directory to path
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, current_dir)
sys.path.insert(0, parent_dir)

try:
    from .config import ALLOWED_ORIGINS, APP_VARIANT
except ImportError:
    try:
        from config import ALLOWED_ORIGINS, APP_VARIANT
    except ImportError:
        import config as config_module
        ALLOWED_ORIGINS = config_module.ALLOWED_ORIGINS
        APP_VARIANT = config_module.APP_VARIANT

try:
    from .storage import cleanup_expired_clip_sessions, cleanup_old_files
except ImportError:
    try:
        from storage import cleanup_expired_clip_sessions, cleanup_old_files
    except ImportError:
        import storage as storage_module
        cleanup_expired_clip_sessions = storage_module.cleanup_expired_clip_sessions
        cleanup_old_files = storage_module.cleanup_old_files

try:
    from .api.auth import router as auth_router
except ImportError:
    try:
        from api.auth import router as auth_router
    except ImportError:
        import api.auth as auth_module
        auth_router = auth_module.router

try:
    from .api.transcripts import router as transcripts_router
except ImportError:
    try:
        from api.transcripts import router as transcripts_router
    except ImportError:
        import api.transcripts as transcripts_module
        transcripts_router = transcripts_module.router

try:
    from .api.clips import router as clips_router
except ImportError:
    try:
        from api.clips import router as clips_router
    except ImportError:
        import api.clips as clips_module
        clips_router = clips_module.router

try:
    from .api.media import router as media_router
except ImportError:
    try:
        from api.media import router as media_router
    except ImportError:
        import api.media as media_module
        media_router = media_module.router

try:
    from .api.health import router as health_router
except ImportError:
    try:
        from api.health import router as health_router
    except ImportError:
        import api.health as health_module
        health_router = health_module.router

try:
    from .api.cases import router as cases_router
except ImportError:
    try:
        from api.cases import router as cases_router
    except ImportError:
        import api.cases as cases_module
        cases_router = cases_module.router


app = FastAPI(
    title="TranscribeAlpha API",
    description="Professional Legal Transcript Generator using AssemblyAI",
    version="2.0.0",
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
)


@app.on_event("startup")
async def startup_event():
    """Run cleanup on startup and log Cloud Storage status."""
    if APP_VARIANT == "criminal":
        logger.info("Starting TranscribeAlpha in criminal (local-first) mode — skipping GCS cleanup")
    else:
        logger.info("Starting TranscribeAlpha with Cloud Storage enabled")
        cleanup_old_files()
        cleanup_expired_clip_sessions()


app.include_router(auth_router)
app.include_router(transcripts_router)
app.include_router(health_router)

# Only mount cases, clips, media routers for non-criminal variant
if APP_VARIANT != "criminal":
    app.include_router(cases_router)
    app.include_router(clips_router)
    app.include_router(media_router)

# Mount static files LAST so API routes take precedence
frontend_dir = os.path.join(os.path.dirname(__file__), "..", "frontend")
app.mount("/", StaticFiles(directory=frontend_dir, html=True), name="frontend")


if __name__ == "__main__":
    # Cloud Run uses PORT environment variable, defaults to 8080
    port = int(os.getenv("PORT", 8080))
    host = os.getenv("HOST", "0.0.0.0")

    # Use Hypercorn for HTTP/2 support on Cloud Run
    import hypercorn.asyncio
    import hypercorn.config
    import asyncio

    config = hypercorn.config.Config()
    config.bind = [f"{host}:{port}"]
    config.application_path = "backend.server:app"

    # Enable HTTP/2 support
    config.h2 = True

    # Run the server
    asyncio.run(hypercorn.asyncio.serve(app, config))
===== END FILE =====

===== FILE: backend/storage.py =====
import io
import json
import logging
import os
import tempfile
import uuid
from datetime import datetime, timedelta, timezone
from typing import List, Optional, Tuple

from google.cloud import storage
from google.api_core import exceptions as gcs_exceptions
from fastapi import HTTPException

try:
    from .config import (
        BUCKET_NAME,
        CLIP_SESSION_PREFIX,
        CLIP_SESSION_TTL_DAYS,
        MEDIA_CLEANUP_PREFIXES,
        MEDIA_TTL_DAYS,
        SNAPSHOT_TTL_DAYS,
    )
except ImportError:
    try:
        from config import (
            BUCKET_NAME,
            CLIP_SESSION_PREFIX,
            CLIP_SESSION_TTL_DAYS,
            MEDIA_CLEANUP_PREFIXES,
            MEDIA_TTL_DAYS,
            SNAPSHOT_TTL_DAYS,
        )
    except ImportError:
        import config as config_module
        BUCKET_NAME = config_module.BUCKET_NAME
        CLIP_SESSION_PREFIX = config_module.CLIP_SESSION_PREFIX
        CLIP_SESSION_TTL_DAYS = config_module.CLIP_SESSION_TTL_DAYS
        MEDIA_CLEANUP_PREFIXES = config_module.MEDIA_CLEANUP_PREFIXES
        MEDIA_TTL_DAYS = config_module.MEDIA_TTL_DAYS
        SNAPSHOT_TTL_DAYS = config_module.SNAPSHOT_TTL_DAYS

logger = logging.getLogger(__name__)

storage_client = storage.Client()


def _clip_blob_name(clip_id: str) -> str:
    return f"{CLIP_SESSION_PREFIX}{clip_id}.json"


def save_current_transcript(media_key: str, transcript_data: dict) -> None:
    """Save current working state for a transcript using media_key as identifier."""
    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        blob_name = f"transcripts/{media_key}/current.json"
        blob = bucket.blob(blob_name)

        # Set TTL metadata
        created_at = transcript_data.get("created_at", datetime.now(timezone.utc).isoformat())
        now = datetime.now(timezone.utc).isoformat()

        # Check if transcript is persistent (in a case) - don't set TTL
        is_persistent = transcript_data.get("is_persistent", False) or transcript_data.get("case_id")

        metadata = {
            "media_key": media_key,
            "created_at": created_at,
            "updated_at": now,
            "user_id": transcript_data.get("user_id"),
        }

        if is_persistent:
            metadata["is_persistent"] = "true"
            # No expires_at for persistent transcripts
        else:
            metadata["is_persistent"] = "false"
            metadata["expires_at"] = (datetime.now(timezone.utc) + timedelta(days=30)).isoformat()

        blob.metadata = metadata
        blob.upload_from_string(json.dumps(transcript_data), content_type="application/json")
        logger.info("Saved current transcript for media_key %s (persistent: %s)", media_key, is_persistent)
    except Exception as e:
        logger.error("Failed to save current transcript for %s: %s", media_key, e)
        raise


def load_current_transcript(media_key: str) -> Optional[dict]:
    """Load current working state, with fallback to latest snapshot."""
    try:
        bucket = storage_client.bucket(BUCKET_NAME)

        # Try loading current.json
        blob = bucket.blob(f"transcripts/{media_key}/current.json")
        if blob.exists():
            try:
                blob.reload()
            except Exception:
                pass
            data = json.loads(blob.download_as_string())
            if not data.get("media_key"):
                data["media_key"] = media_key

            # Check expiration
            expires_at_str = blob.metadata.get("expires_at") if blob.metadata else None
            if expires_at_str:
                try:
                    expires_at = datetime.fromisoformat(expires_at_str.replace("Z", "+00:00"))
                    if datetime.now(timezone.utc) > expires_at:
                        # Expired, delete and fall through to history
                        blob.delete()
                        logger.info("Deleted expired current transcript for %s", media_key)
                    else:
                        return data
                except ValueError:
                    # If we can't parse expiration, return the data anyway
                    return data

        # Fallback: Load latest snapshot from history
        return load_latest_snapshot_for_media(media_key)

    except Exception as e:
        logger.error("Failed to load transcript for %s: %s", media_key, e)
        return None


def load_latest_snapshot_for_media(media_key: str, prefer_manual_save: bool = True) -> Optional[dict]:
    """Load most recent snapshot, prioritizing manual saves."""
    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        prefix = f"transcripts/{media_key}/history/"
        blobs = list(bucket.list_blobs(prefix=prefix))

        if not blobs:
            return None

        # Separate manual saves from auto-saves
        manual_saves = []
        auto_saves = []

        for blob in blobs:
            try:
                data = json.loads(blob.download_as_string())
                if data.get("is_manual_save"):
                    manual_saves.append((blob.time_created, data))
                else:
                    auto_saves.append((blob.time_created, data))
            except Exception:
                continue

        # Return newest manual save if exists and preferred
        if prefer_manual_save and manual_saves:
            manual_saves.sort(key=lambda x: x[0], reverse=True)
            snapshot = manual_saves[0][1]
            if not snapshot.get("media_key"):
                snapshot["media_key"] = media_key
            return snapshot

        # Otherwise return newest overall
        all_snapshots = manual_saves + auto_saves
        if all_snapshots:
            all_snapshots.sort(key=lambda x: x[0], reverse=True)
            snapshot = all_snapshots[0][1]
            if not snapshot.get("media_key"):
                snapshot["media_key"] = media_key
            return snapshot

        return None

    except Exception as e:
        logger.error("Failed to load snapshot for %s: %s", media_key, e)
        return None


def list_all_transcripts(user_id: str) -> List[dict]:
    """List all transcripts for a user, grouped by media_key."""
    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        prefix = "transcripts/"

        transcripts = []
        for blob in bucket.list_blobs(prefix=prefix):
            if blob.name.endswith("/current.json"):
                try:
                    data = json.loads(blob.download_as_string())

                    # Check user_id from JSON content (blob.metadata isn't populated by list_blobs)
                    if data.get("user_id") != user_id:
                        continue

                    media_key = blob.name.split("/")[1]

                    title_data = data.get("title_data", {})
                    transcripts.append({
                        "media_key": media_key,
                        "title_label": title_data.get("FILE_NAME") or title_data.get("CASE_NAME") or media_key,
                        "updated_at": blob.updated.isoformat() if blob.updated else None,
                        "line_count": len(data.get("lines", [])),
                    })
                except Exception:
                    continue

        return sorted(transcripts, key=lambda x: x["updated_at"] or "", reverse=True)

    except Exception as e:
        logger.error("Failed to list transcripts: %s", e)
        return []


def save_clip_session(clip_id: str, clip_data: dict) -> None:
    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        blob = bucket.blob(_clip_blob_name(clip_id))
        blob.metadata = {
            "clip_id": clip_id,
            "parent_media_key": clip_data.get("parent_media_key"),
            "created_at": clip_data.get("created_at"),
            "expires_at": clip_data.get("expires_at"),
            "user_id": clip_data.get("user_id"),
        }
        blob.upload_from_string(json.dumps(clip_data), content_type="application/json")
        logger.info("Saved clip session %s", clip_id)
    except Exception as exc:
        logger.error("Failed to save clip session %s: %s", clip_id, exc)
        raise


def load_clip_session(clip_id: str) -> Optional[dict]:
    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        blob = bucket.blob(_clip_blob_name(clip_id))
        if not blob.exists():
            return None
        return json.loads(blob.download_as_text())
    except Exception as exc:
        logger.error("Failed to load clip session %s: %s", clip_id, exc)
        return None


def delete_clip_session(clip_id: str) -> None:
    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        blob = bucket.blob(_clip_blob_name(clip_id))
        if blob.exists():
            blob.delete()
            logger.info("Deleted clip session %s", clip_id)
    except Exception as exc:
        logger.error("Failed to delete clip session %s: %s", clip_id, exc)


def prune_snapshots(media_key: str) -> None:
    """Prune snapshots to keep newest 10, preserving newest manual save."""
    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        limit = 10

        prefix = f"transcripts/{media_key}/history/"
        blobs = list(bucket.list_blobs(prefix=prefix))

        # Phase 1: Delete expired snapshots (14+ days old)
        cutoff = datetime.now(timezone.utc) - timedelta(days=SNAPSHOT_TTL_DAYS)
        for blob in blobs[:]:
            if blob.time_created and blob.time_created < cutoff:
                try:
                    blob.delete()
                    blobs.remove(blob)
                except Exception:
                    logger.warning("Failed to delete expired snapshot %s", blob.name)

        # Phase 2: Enforce per-media limit (10 snapshots)
        if len(blobs) <= limit:
            return

        # Load all snapshot data to check is_manual_save flag
        snapshot_info = []
        for blob in blobs:
            try:
                data = json.loads(blob.download_as_string())
                is_manual = data.get("is_manual_save", data.get("saved", False))
                snapshot_info.append({
                    "blob": blob,
                    "created_at": blob.time_created,
                    "is_manual_save": is_manual,
                })
            except Exception:
                continue

        # Sort by creation time (newest first)
        snapshot_info.sort(key=lambda x: x["created_at"] or datetime.min.replace(tzinfo=timezone.utc), reverse=True)

        # Find newest manual save
        newest_manual_save = next(
            (s for s in snapshot_info if s["is_manual_save"]),
            None
        )

        # Keep newest N snapshots
        to_keep = snapshot_info[:limit]

        # Ensure newest manual save is included
        if newest_manual_save and newest_manual_save not in to_keep:
            to_keep[-1] = newest_manual_save

        # Deduplicate and sort keep list again newest first
        keep_blob_names = []
        deduped_keep = []
        for item in to_keep:
            name = item["blob"].name
            if name in keep_blob_names:
                continue
            keep_blob_names.append(name)
            deduped_keep.append(item)
        deduped_keep.sort(key=lambda x: x["created_at"] or datetime.min.replace(tzinfo=timezone.utc), reverse=True)

        # Delete everything not in to_keep
        keep_names_set = {s["blob"].name for s in deduped_keep}
        for s in snapshot_info:
            if s["blob"].name not in keep_names_set:
                try:
                    s["blob"].delete()
                except Exception:
                    logger.warning("Failed to delete excess snapshot %s", s["blob"].name)

    except Exception as exc:
        logger.error("Snapshot pruning failed for %s: %s", media_key, exc)


def cleanup_expired_clip_sessions():
    """Delete stored clip sessions whose TTL has expired."""
    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        now = datetime.now(timezone.utc)
        for blob in bucket.list_blobs(prefix=CLIP_SESSION_PREFIX):
            try:
                raw = blob.download_as_text()
                clip_data = json.loads(raw)
            except Exception:
                continue

            expires_at = clip_data.get("expires_at")
            if not expires_at:
                continue

            try:
                expires_dt = datetime.fromisoformat(expires_at)
            except ValueError:
                try:
                    expires_dt = datetime.fromisoformat(expires_at.replace("Z", "+00:00"))
                except ValueError:
                    continue

            if expires_dt < now:
                try:
                    blob.delete()
                except Exception:
                    logger.warning("Failed to delete expired clip session %s", blob.name)
    except Exception as exc:
        logger.error("Error during clip session cleanup: %s", exc)


def cleanup_old_files():
    """Clean up media files older than MEDIA_TTL_DAYS from Cloud Storage to prevent billing issues."""
    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        cutoff_date = datetime.now(timezone.utc) - timedelta(days=MEDIA_TTL_DAYS)

        deleted_count = 0
        for prefix in MEDIA_CLEANUP_PREFIXES:
            for blob in bucket.list_blobs(prefix=prefix):
                if blob.time_created and blob.time_created < cutoff_date:
                    blob.delete()
                    deleted_count += 1
                    logger.info("Deleted old media file: %s", blob.name)

        logger.info("Media cleanup completed. Deleted %d files.", deleted_count)
    except Exception as e:
        logger.error("Error during cleanup: %s", str(e))


def _format_gcs_error(error: Exception) -> str:
    if isinstance(error, gcs_exceptions.GoogleAPIError):
        return f"{error.__class__.__name__}: {error.message}"
    return str(error)


def _upload_bytes_to_blob(blob: storage.Blob, file_bytes: bytes, content_type: Optional[str] = None) -> None:
    blob.chunk_size = 5 * 1024 * 1024  # 5MB chunking to support larger files consistently
    buffer = io.BytesIO(file_bytes)
    buffer.seek(0)
    blob.upload_from_file(buffer, size=len(file_bytes), content_type=content_type or "application/octet-stream")


def _upload_file_to_blob(blob: storage.Blob, file_path: str, content_type: Optional[str] = None) -> None:
    blob.chunk_size = 5 * 1024 * 1024  # 5MB chunking to support larger files consistently
    with open(file_path, "rb") as stream:
        blob.upload_from_file(stream, content_type=content_type or "application/octet-stream")


def get_blob_metadata(blob_name: str) -> dict:
    """Get metadata for a blob in Cloud Storage"""
    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        blob = bucket.blob(blob_name)
        if not blob.exists():
            return None

        blob.reload()
        metadata = blob.metadata or {}
        return {
            "filename": metadata.get("original_filename", blob_name.split("_")[-1]),
            "content_type": blob.content_type or metadata.get("content_type", "application/octet-stream"),
            "size": blob.size,
            "created": blob.time_created,
            "user_id": metadata.get("user_id"),
            "media_key": metadata.get("media_key"),
            "parent_media_key": metadata.get("parent_media_key"),
            "file_type": metadata.get("file_type"),
        }
    except Exception as e:
        logger.error("Error getting blob metadata: %s", str(e))
        return None


def upload_preview_file_to_cloud_storage(
    file_bytes: bytes,
    filename: str,
    content_type: Optional[str] = None,
    user_id: Optional[str] = None,
    media_key: Optional[str] = None,
) -> str:
    """Upload preview file to Cloud Storage with metadata."""
    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        blob_name = f"preview_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:8]}_{filename}"
        blob = bucket.blob(blob_name)

        metadata = {
            "original_filename": filename,
            "content_type": content_type or "application/octet-stream",
            "file_type": "preview",
        }
        if user_id:
            metadata["user_id"] = user_id
        if media_key:
            metadata["media_key"] = media_key

        blob.metadata = metadata
        if content_type:
            blob.content_type = content_type

        _upload_bytes_to_blob(blob, file_bytes, content_type)
        logger.info("Uploaded preview file %s to Cloud Storage as %s", filename, blob_name)
        return blob_name
    except Exception as e:
        logger.error("Error uploading preview file to Cloud Storage: %s", _format_gcs_error(e))
        raise


def upload_preview_file_to_cloud_storage_from_path(
    file_path: str,
    filename: str,
    content_type: Optional[str] = None,
    user_id: Optional[str] = None,
    media_key: Optional[str] = None,
) -> str:
    """Upload preview file to Cloud Storage from disk with metadata."""
    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        blob_name = f"preview_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:8]}_{filename}"
        blob = bucket.blob(blob_name)

        metadata = {
            "original_filename": filename,
            "content_type": content_type or "application/octet-stream",
            "file_type": "preview",
        }
        if user_id:
            metadata["user_id"] = user_id
        if media_key:
            metadata["media_key"] = media_key

        blob.metadata = metadata
        if content_type:
            blob.content_type = content_type

        _upload_file_to_blob(blob, file_path, content_type)
        logger.info("Uploaded preview file %s to Cloud Storage as %s", filename, blob_name)
        return blob_name
    except Exception as e:
        logger.error("Error uploading preview file to Cloud Storage: %s", _format_gcs_error(e))
        raise


def download_blob_to_path(blob_name: str) -> Tuple[str, Optional[str]]:
    """Download a blob to a temporary file and return the path and content type."""
    bucket = storage_client.bucket(BUCKET_NAME)
    blob = bucket.blob(blob_name)
    if not blob.exists():
        raise HTTPException(status_code=404, detail="Media blob not found")

    extension = os.path.splitext(blob.name)[1]
    suffix = extension or ".bin"
    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=suffix)
    temp_file.close()
    blob.download_to_filename(temp_file.name)
    return temp_file.name, blob.content_type


def upload_clip_file_to_cloud_storage(
    file_bytes: bytes,
    filename: str,
    content_type: Optional[str],
    user_id: Optional[str] = None,
    parent_media_key: Optional[str] = None,
) -> str:
    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        safe_name = filename or "clip-output"
        blob_name = f"clip_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:8]}_{safe_name}"
        blob = bucket.blob(blob_name)
        metadata = {
            "original_filename": safe_name,
            "content_type": content_type or "application/octet-stream",
            "file_type": "clip",
        }
        if user_id:
            metadata["user_id"] = user_id
        if parent_media_key:
            metadata["parent_media_key"] = parent_media_key
        blob.metadata = metadata
        if content_type:
            blob.content_type = content_type
        _upload_bytes_to_blob(blob, file_bytes, content_type)
        logger.info("Uploaded clip media %s to Cloud Storage", blob_name)
        return blob_name
    except Exception as exc:
        logger.error("Error uploading clip media to Cloud Storage: %s", _format_gcs_error(exc))
        raise


async def save_upload_to_tempfile(upload) -> Tuple[str, int]:
    """Stream an UploadFile to disk and return (path, size)."""
    suffix = os.path.splitext(upload.filename or "")[1]
    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=suffix)
    size = 0
    try:
        while True:
            chunk = await upload.read(1024 * 1024)
            if not chunk:
                break
            size += len(chunk)
            temp_file.write(chunk)
    finally:
        temp_file.close()
    try:
        await upload.seek(0)
    except Exception:
        pass
    return temp_file.name, size


# ============================================================================
# Cases Storage Functions
# ============================================================================


def _case_meta_path(user_id: str, case_id: str) -> str:
    """Return GCS path for case metadata."""
    return f"cases/{user_id}/{case_id}/meta.json"


def _case_transcripts_path(user_id: str, case_id: str) -> str:
    """Return GCS path for case transcript list."""
    return f"cases/{user_id}/{case_id}/transcripts.json"


def _case_index_path(user_id: str) -> str:
    """Return GCS path for user's case index."""
    return f"cases/{user_id}/index.json"


def create_case(user_id: str, case_id: str, name: str, description: Optional[str] = None) -> dict:
    """Create a new case and return its metadata."""
    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        now = datetime.now(timezone.utc).isoformat()

        case_meta = {
            "case_id": case_id,
            "user_id": user_id,
            "name": name,
            "description": description or "",
            "created_at": now,
            "updated_at": now,
            "transcript_count": 0,
        }

        # Save case metadata
        meta_blob = bucket.blob(_case_meta_path(user_id, case_id))
        meta_blob.upload_from_string(json.dumps(case_meta), content_type="application/json")

        # Initialize empty transcripts list
        transcripts_blob = bucket.blob(_case_transcripts_path(user_id, case_id))
        transcripts_blob.upload_from_string(json.dumps([]), content_type="application/json")

        # Update user's case index
        _update_case_index(user_id)

        logger.info("Created case %s for user %s", case_id, user_id)
        return case_meta

    except Exception as e:
        logger.error("Failed to create case %s: %s", case_id, e)
        raise


def load_case_meta(user_id: str, case_id: str) -> Optional[dict]:
    """Load case metadata."""
    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        blob = bucket.blob(_case_meta_path(user_id, case_id))

        if not blob.exists():
            return None

        return json.loads(blob.download_as_string())

    except Exception as e:
        logger.error("Failed to load case meta %s: %s", case_id, e)
        return None


def update_case_meta(user_id: str, case_id: str, updates: dict) -> Optional[dict]:
    """Update case metadata fields (name, description)."""
    try:
        case_meta = load_case_meta(user_id, case_id)
        if not case_meta:
            return None

        # Only allow updating specific fields
        allowed_fields = {"name", "description"}
        for field in allowed_fields:
            if field in updates:
                case_meta[field] = updates[field]

        case_meta["updated_at"] = datetime.now(timezone.utc).isoformat()

        bucket = storage_client.bucket(BUCKET_NAME)
        blob = bucket.blob(_case_meta_path(user_id, case_id))
        blob.upload_from_string(json.dumps(case_meta), content_type="application/json")

        # Update index
        _update_case_index(user_id)

        logger.info("Updated case %s", case_id)
        return case_meta

    except Exception as e:
        logger.error("Failed to update case %s: %s", case_id, e)
        raise


def delete_case(user_id: str, case_id: str, delete_transcripts: bool = False) -> List[str]:
    """
    Delete a case. Returns list of media_keys that were affected.
    If delete_transcripts=True, also deletes the transcripts.
    If delete_transcripts=False, moves transcripts to uncategorized (restores TTL).
    """
    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        affected_keys = []

        # Get transcript list
        transcripts = get_case_transcripts(user_id, case_id)

        for entry in transcripts:
            media_key = entry.get("media_key")
            if not media_key:
                continue

            affected_keys.append(media_key)

            if delete_transcripts:
                # Delete the transcript entirely
                _delete_transcript(media_key)
            else:
                # Remove case association and restore TTL
                _remove_case_from_transcript(media_key)
                restore_transcript_ttl(media_key)

        # Delete case files
        meta_blob = bucket.blob(_case_meta_path(user_id, case_id))
        if meta_blob.exists():
            meta_blob.delete()

        transcripts_blob = bucket.blob(_case_transcripts_path(user_id, case_id))
        if transcripts_blob.exists():
            transcripts_blob.delete()

        # Update index
        _update_case_index(user_id)

        logger.info("Deleted case %s (transcripts deleted: %s)", case_id, delete_transcripts)
        return affected_keys

    except Exception as e:
        logger.error("Failed to delete case %s: %s", case_id, e)
        raise


def list_user_cases(user_id: str) -> List[dict]:
    """List all cases for a user."""
    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        blob = bucket.blob(_case_index_path(user_id))

        if blob.exists():
            index_data = json.loads(blob.download_as_string())
            return index_data.get("cases", [])

        # Fallback: scan for cases if index doesn't exist
        return _rebuild_case_index(user_id)

    except Exception as e:
        logger.error("Failed to list cases for user %s: %s", user_id, e)
        return []


def _update_case_index(user_id: str) -> None:
    """Rebuild and save the user's case index."""
    try:
        cases = _rebuild_case_index(user_id)
        bucket = storage_client.bucket(BUCKET_NAME)
        blob = bucket.blob(_case_index_path(user_id))

        index_data = {
            "user_id": user_id,
            "cases": cases,
            "updated_at": datetime.now(timezone.utc).isoformat(),
        }
        blob.upload_from_string(json.dumps(index_data), content_type="application/json")

    except Exception as e:
        logger.error("Failed to update case index for user %s: %s", user_id, e)


def _rebuild_case_index(user_id: str) -> List[dict]:
    """Scan GCS and rebuild case list for user."""
    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        prefix = f"cases/{user_id}/"
        cases = []

        # Find all case directories by looking for meta.json files
        for blob in bucket.list_blobs(prefix=prefix):
            if blob.name.endswith("/meta.json"):
                try:
                    case_meta = json.loads(blob.download_as_string())
                    cases.append(case_meta)
                except Exception:
                    continue

        # Sort by updated_at descending
        cases.sort(key=lambda x: x.get("updated_at", ""), reverse=True)
        return cases

    except Exception as e:
        logger.error("Failed to rebuild case index for user %s: %s", user_id, e)
        return []


def get_case_transcripts(user_id: str, case_id: str) -> List[dict]:
    """Get list of transcripts in a case."""
    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        blob = bucket.blob(_case_transcripts_path(user_id, case_id))

        if not blob.exists():
            return []

        return json.loads(blob.download_as_string())

    except Exception as e:
        logger.error("Failed to get case transcripts for %s: %s", case_id, e)
        return []


def add_transcript_to_case(user_id: str, case_id: str, media_key: str, title_label: Optional[str] = None) -> bool:
    """
    Add a transcript to a case.
    Also sets the transcript as persistent (removes TTL) and adds case_id to transcript.
    """
    try:
        # Verify case exists and belongs to user
        case_meta = load_case_meta(user_id, case_id)
        if not case_meta:
            logger.warning("Case %s not found for user %s", case_id, user_id)
            return False

        # Verify transcript exists and belongs to user
        transcript = load_current_transcript(media_key)
        if not transcript:
            logger.warning("Transcript %s not found", media_key)
            return False
        if transcript.get("user_id") != user_id:
            logger.warning("Transcript %s does not belong to user %s", media_key, user_id)
            return False

        # Check if transcript is already in another case
        existing_case_id = transcript.get("case_id")
        if existing_case_id and existing_case_id != case_id:
            # Remove from old case first
            remove_transcript_from_case(user_id, existing_case_id, media_key)

        bucket = storage_client.bucket(BUCKET_NAME)
        now = datetime.now(timezone.utc).isoformat()

        # Get current transcripts list
        transcripts = get_case_transcripts(user_id, case_id)

        # Check if already in this case
        if any(t.get("media_key") == media_key for t in transcripts):
            return True  # Already added

        # Add to case
        transcripts.append({
            "media_key": media_key,
            "added_at": now,
            "title_label": title_label or transcript.get("title_data", {}).get("FILE_NAME") or transcript.get("title_data", {}).get("CASE_NAME") or media_key,
        })

        # Save updated transcripts list
        transcripts_blob = bucket.blob(_case_transcripts_path(user_id, case_id))
        transcripts_blob.upload_from_string(json.dumps(transcripts), content_type="application/json")

        # Update case metadata
        case_meta["transcript_count"] = len(transcripts)
        case_meta["updated_at"] = now
        meta_blob = bucket.blob(_case_meta_path(user_id, case_id))
        meta_blob.upload_from_string(json.dumps(case_meta), content_type="application/json")

        # Update transcript with case_id and make persistent
        _set_case_on_transcript(media_key, case_id)
        set_transcript_persistent(media_key)

        # Update index
        _update_case_index(user_id)

        logger.info("Added transcript %s to case %s", media_key, case_id)
        return True

    except Exception as e:
        logger.error("Failed to add transcript %s to case %s: %s", media_key, case_id, e)
        raise


def remove_transcript_from_case(user_id: str, case_id: str, media_key: str) -> bool:
    """
    Remove a transcript from a case.
    Restores TTL on the transcript.
    """
    try:
        bucket = storage_client.bucket(BUCKET_NAME)

        # Get current transcripts list
        transcripts = get_case_transcripts(user_id, case_id)
        original_count = len(transcripts)

        # Remove the transcript
        transcripts = [t for t in transcripts if t.get("media_key") != media_key]

        if len(transcripts) == original_count:
            return False  # Wasn't in the case

        # Save updated list
        transcripts_blob = bucket.blob(_case_transcripts_path(user_id, case_id))
        transcripts_blob.upload_from_string(json.dumps(transcripts), content_type="application/json")

        # Update case metadata
        case_meta = load_case_meta(user_id, case_id)
        if case_meta:
            case_meta["transcript_count"] = len(transcripts)
            case_meta["updated_at"] = datetime.now(timezone.utc).isoformat()
            meta_blob = bucket.blob(_case_meta_path(user_id, case_id))
            meta_blob.upload_from_string(json.dumps(case_meta), content_type="application/json")

        # Remove case_id from transcript and restore TTL
        _remove_case_from_transcript(media_key)
        restore_transcript_ttl(media_key)

        # Update index
        _update_case_index(user_id)

        logger.info("Removed transcript %s from case %s", media_key, case_id)
        return True

    except Exception as e:
        logger.error("Failed to remove transcript %s from case %s: %s", media_key, case_id, e)
        raise


def _set_case_on_transcript(media_key: str, case_id: str) -> None:
    """Set case_id on a transcript's current.json."""
    try:
        transcript = load_current_transcript(media_key)
        if not transcript:
            return

        transcript["case_id"] = case_id
        transcript["is_persistent"] = True
        save_current_transcript(media_key, transcript)

    except Exception as e:
        logger.error("Failed to set case on transcript %s: %s", media_key, e)


def _remove_case_from_transcript(media_key: str) -> None:
    """Remove case_id from a transcript's current.json."""
    try:
        transcript = load_current_transcript(media_key)
        if not transcript:
            return

        transcript["case_id"] = None
        transcript["is_persistent"] = False
        save_current_transcript(media_key, transcript)

    except Exception as e:
        logger.error("Failed to remove case from transcript %s: %s", media_key, e)


def set_transcript_persistent(media_key: str) -> None:
    """Remove TTL from a transcript (make it persistent)."""
    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        blob = bucket.blob(f"transcripts/{media_key}/current.json")

        if not blob.exists():
            return

        blob.reload()
        metadata = blob.metadata or {}

        # Remove expires_at to make persistent
        if "expires_at" in metadata:
            del metadata["expires_at"]
        metadata["is_persistent"] = "true"
        metadata["updated_at"] = datetime.now(timezone.utc).isoformat()

        blob.metadata = metadata
        blob.patch()

        logger.info("Set transcript %s as persistent", media_key)

    except Exception as e:
        logger.error("Failed to set transcript %s as persistent: %s", media_key, e)


def restore_transcript_ttl(media_key: str) -> None:
    """Restore 30-day TTL to a transcript."""
    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        blob = bucket.blob(f"transcripts/{media_key}/current.json")

        if not blob.exists():
            return

        blob.reload()
        metadata = blob.metadata or {}

        # Set new expiration 30 days from now
        metadata["expires_at"] = (datetime.now(timezone.utc) + timedelta(days=30)).isoformat()
        metadata["is_persistent"] = "false"
        metadata["updated_at"] = datetime.now(timezone.utc).isoformat()

        blob.metadata = metadata
        blob.patch()

        logger.info("Restored TTL on transcript %s", media_key)

    except Exception as e:
        logger.error("Failed to restore TTL on transcript %s: %s", media_key, e)


def _delete_transcript(media_key: str) -> None:
    """Delete a transcript and all its history."""
    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        prefix = f"transcripts/{media_key}/"

        for blob in bucket.list_blobs(prefix=prefix):
            try:
                blob.delete()
            except Exception:
                continue

        logger.info("Deleted transcript %s", media_key)

    except Exception as e:
        logger.error("Failed to delete transcript %s: %s", media_key, e)


def _delete_blob_if_exists(blob_name: Optional[str]) -> None:
    if not blob_name:
        return
    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        blob = bucket.blob(str(blob_name))
        if blob.exists():
            blob.delete()
            logger.info("Deleted blob %s", blob_name)
    except Exception as e:
        logger.warning("Failed to delete blob %s: %s", blob_name, e)


def delete_transcript_for_user(user_id: str, media_key: str) -> bool:
    """
    Permanently delete a transcript owned by user_id.
    Also removes case references and linked media/clip blobs when available.
    """
    transcript = load_current_transcript(media_key)
    if not transcript:
        return False

    transcript_user_id = transcript.get("user_id")
    if transcript_user_id and transcript_user_id != user_id:
        raise PermissionError(f"Transcript {media_key} does not belong to user {user_id}")

    case_id = transcript.get("case_id")
    if case_id:
        try:
            remove_transcript_from_case(user_id, case_id, media_key)
        except Exception as e:
            logger.warning("Failed to detach transcript %s from case %s: %s", media_key, case_id, e)

    # Defensive cleanup in case a transcript reference exists in multiple cases.
    try:
        for case_meta in list_user_cases(user_id):
            candidate_case_id = case_meta.get("case_id")
            if not candidate_case_id or candidate_case_id == case_id:
                continue
            entries = get_case_transcripts(user_id, candidate_case_id)
            if any(entry.get("media_key") == media_key for entry in entries):
                try:
                    remove_transcript_from_case(user_id, candidate_case_id, media_key)
                except Exception as e:
                    logger.warning(
                        "Failed to remove transcript %s from case %s during delete: %s",
                        media_key,
                        candidate_case_id,
                        e,
                    )
    except Exception as e:
        logger.warning("Failed scanning cases for transcript %s references: %s", media_key, e)

    media_blob_name = transcript.get("media_blob_name")
    clip_blob_names = set()
    for clip_entry in transcript.get("clips") or []:
        if isinstance(clip_entry, dict):
            clip_blob_name = clip_entry.get("media_blob_name")
            if isinstance(clip_blob_name, str) and clip_blob_name.strip():
                clip_blob_names.add(clip_blob_name.strip())

    _delete_transcript(media_key)
    _delete_blob_if_exists(media_blob_name)
    for clip_blob_name in clip_blob_names:
        _delete_blob_if_exists(clip_blob_name)

    return True


def list_uncategorized_transcripts(user_id: str) -> List[dict]:
    """List transcripts not in any case (with TTL info)."""
    try:
        # Get all user's transcripts
        all_transcripts = list_all_transcripts(user_id)

        # Filter to only those without case_id
        uncategorized = []
        for t in all_transcripts:
            transcript = load_current_transcript(t["media_key"])
            if transcript and not transcript.get("case_id"):
                # Get expiration info from blob metadata
                bucket = storage_client.bucket(BUCKET_NAME)
                blob = bucket.blob(f"transcripts/{t['media_key']}/current.json")
                expires_at = None
                if blob.exists():
                    blob.reload()
                    if blob.metadata:
                        expires_at = blob.metadata.get("expires_at")

                uncategorized.append({
                    **t,
                    "expires_at": expires_at,
                })

        return uncategorized

    except Exception as e:
        logger.error("Failed to list uncategorized transcripts: %s", e)
        return []


def search_case_transcripts(user_id: str, case_id: str, query: str) -> List[dict]:
    """
    Search text and speaker names across all transcripts in a case.
    Returns list of CaseSearchResult-like dicts.
    """
    try:
        if not query or len(query.strip()) < 2:
            return []

        query_lower = query.lower().strip()
        results = []

        # Get all transcripts in case
        transcripts = get_case_transcripts(user_id, case_id)

        for entry in transcripts:
            media_key = entry.get("media_key")
            if not media_key:
                continue

            transcript = load_current_transcript(media_key)
            if not transcript:
                continue

            matches = []
            lines = transcript.get("lines", [])

            for line in lines:
                line_text = line.get("text", "")
                speaker = line.get("speaker", "")
                match_type = None

                # Search in text
                if query_lower in line_text.lower():
                    match_type = "text"
                # Search in speaker name
                elif query_lower in speaker.lower():
                    match_type = "speaker"

                if match_type:
                    matches.append({
                        "line_id": line.get("id", ""),
                        "page": line.get("page", 0),
                        "line": line.get("line", 0),
                        "text": line_text,
                        "speaker": speaker,
                        "match_type": match_type,
                    })

            if matches:
                results.append({
                    "media_key": media_key,
                    "title_label": entry.get("title_label", media_key),
                    "matches": matches,
                })

        return results

    except Exception as e:
        logger.error("Failed to search case %s: %s", case_id, e)
        return []


def check_media_exists(blob_name: str) -> bool:
    """Check if a media blob exists in GCS."""
    try:
        if not blob_name:
            return False

        bucket = storage_client.bucket(BUCKET_NAME)
        blob = bucket.blob(blob_name)
        return blob.exists()

    except Exception as e:
        logger.error("Failed to check media existence for %s: %s", blob_name, e)
        return False


def get_transcript_case_id(media_key: str) -> Optional[str]:
    """Get the case_id for a transcript, if any."""
    try:
        transcript = load_current_transcript(media_key)
        if transcript:
            return transcript.get("case_id")
        return None
    except Exception:
        return None
===== END FILE =====

===== FILE: backend/transcriber.py =====
import os
import io
import json
import inspect
import time
import re
import tempfile
import logging
import shutil
from typing import List, Optional
import sys

# Python 3.9+ type hint compatibility
if sys.version_info >= (3, 9):
    from typing import Tuple
else:
    from typing import Tuple as typing_Tuple
    Tuple = typing_Tuple

import ffmpeg
from pydub import AudioSegment

try:
    from .models import TranscriptTurn, WordTimestamp
except ImportError:
    try:
        from models import TranscriptTurn, WordTimestamp
    except ImportError:
        import models
        TranscriptTurn = models.TranscriptTurn
        WordTimestamp = models.WordTimestamp

# AssemblyAI integration
try:
    import assemblyai as aai
    ASSEMBLYAI_AVAILABLE = True
except ImportError:
    ASSEMBLYAI_AVAILABLE = False
    logging.getLogger(__name__).warning("AssemblyAI SDK not installed. Run: pip install assemblyai")

# Configure both ffmpeg libraries to find ffmpeg
import subprocess
import platform

def find_executable_path(executable_name: str) -> Optional[str]:
    """Cross-platform executable finder"""
    # First try shutil.which (works on all platforms)
    path = shutil.which(executable_name)
    if path:
        return path
    
    # Platform-specific fallback commands
    system = platform.system().lower()
    if system == "windows":
        try:
            result = subprocess.run(['where', executable_name], capture_output=True, text=True, shell=True)
            if result.returncode == 0:
                return result.stdout.strip().split('\n')[0]
        except Exception:
            pass
    else:
        try:
            result = subprocess.run(['which', executable_name], capture_output=True, text=True)
            if result.returncode == 0:
                return result.stdout.strip()
        except Exception:
            pass
    
    return None

def get_ffprobe_path(ffmpeg_path: str) -> Optional[str]:
    """Get ffprobe path from ffmpeg path"""
    if not ffmpeg_path:
        return None
    
    # Get directory and base name
    ffmpeg_dir = os.path.dirname(ffmpeg_path)
    ffmpeg_name = os.path.basename(ffmpeg_path)
    
    # Replace ffmpeg with ffprobe, keeping the same extension
    if ffmpeg_name.endswith('.exe'):
        ffprobe_name = ffmpeg_name.replace('ffmpeg.exe', 'ffprobe.exe')
    else:
        ffprobe_name = ffmpeg_name.replace('ffmpeg', 'ffprobe')
    
    ffprobe_path = os.path.join(ffmpeg_dir, ffprobe_name)
    
    # Check if it exists
    if os.path.exists(ffprobe_path):
        return ffprobe_path
    
    # Try finding ffprobe independently
    return find_executable_path('ffprobe')

# Find ffmpeg and ffprobe
ffmpeg_executable_path = find_executable_path('ffmpeg')
ffprobe_executable_path = None

if ffmpeg_executable_path:
    ffprobe_executable_path = get_ffprobe_path(ffmpeg_executable_path)
    # Configure pydub
    AudioSegment.converter = ffmpeg_executable_path
    AudioSegment.ffmpeg = ffmpeg_executable_path
    if ffprobe_executable_path:
        AudioSegment.ffprobe = ffprobe_executable_path

SUPPORTED_VIDEO_TYPES = ["mp4", "mov", "avi", "mkv"]
SUPPORTED_AUDIO_TYPES = ["mp3", "wav", "m4a", "flac", "ogg", "aac", "aiff"]

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

ASSEMBLYAI_API_KEY = os.getenv("ASSEMBLYAI_API_KEY")
if ASSEMBLYAI_API_KEY and ASSEMBLYAI_AVAILABLE:
    aai.settings.api_key = ASSEMBLYAI_API_KEY
    aai.settings.http_timeout = 300.0
    logger.info("AssemblyAI client initialized successfully")
elif ASSEMBLYAI_AVAILABLE:
    logger.warning("ASSEMBLYAI_API_KEY environment variable not set")

_SPEAKER_LETTER_RE = re.compile(r"^[A-Z]$")
_SPEAKER_NUMERIC_RE = re.compile(r"^[0-9]+$")


def normalize_speaker_label(raw_value: Optional[object], fallback: str = "SPEAKER A") -> str:
    """Normalize diarization labels so downstream exports use SPEAKER X."""
    fallback_value = str(fallback or "").strip().upper() or "SPEAKER A"
    candidate = str(raw_value or "").strip()
    candidate = re.sub(r":+$", "", candidate).strip().upper()

    if not candidate:
        candidate = fallback_value

    if candidate == "UNKNOWN":
        return fallback_value

    if candidate.startswith("SPEAKER"):
        suffix = candidate[len("SPEAKER"):].strip()
        return f"SPEAKER {suffix}" if suffix else "SPEAKER"

    if _SPEAKER_LETTER_RE.fullmatch(candidate) or _SPEAKER_NUMERIC_RE.fullmatch(candidate):
        return f"SPEAKER {candidate}"

    return candidate

def mark_continuation_turns(turns: List[TranscriptTurn]) -> List[TranscriptTurn]:
    """
    Mark turns as continuations when the same speaker has consecutive turns.

    The first turn of each speaker block gets is_continuation=False (shows speaker label).
    Subsequent turns with the same speaker get is_continuation=True (no speaker label).
    """
    if not turns:
        return turns

    prev_speaker = None
    for turn in turns:
        normalized_speaker = turn.speaker.strip().upper()
        if prev_speaker is not None and normalized_speaker == prev_speaker:
            turn.is_continuation = True
        else:
            turn.is_continuation = False
        prev_speaker = normalized_speaker

    return turns


def convert_video_to_audio(input_path: str, output_path: str, format: str = "mp3") -> Optional[str]:
    try:
        logger.info("Converting %s to %s", input_path, output_path)

        if ffmpeg_executable_path:
            cmd = [
                ffmpeg_executable_path,
                '-i', input_path,
                '-acodec', 'libmp3lame',
                '-y',
                output_path
            ]
            logger.debug("Running command: %s", ' '.join(cmd))
            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode == 0:
                logger.info("Successfully converted to %s", output_path)
                time.sleep(0.5)
                return output_path
            else:
                logger.error("ffmpeg failed with return code %d: %s", result.returncode, result.stderr)
                return None
        else:
            logger.debug("Using ffmpeg-python library as fallback")
            ffmpeg.input(input_path).output(output_path, format=format, acodec='libmp3lame').overwrite_output().run(quiet=True)
            return output_path
    except Exception as e:
        logger.error("Unexpected error in convert_video_to_audio: %s", e)
        return None


def get_audio_mime_type(ext: str) -> Optional[str]:
    mime_map = {
        "mp3": "audio/mpeg",
        "wav": "audio/wav",
        "aiff": "audio/aiff",
        "aac": "audio/aac",
        "ogg": "audio/ogg",
        "flac": "audio/flac",
    }
    return mime_map.get(ext.lower())


def transcribe_with_assemblyai(
    audio_path: str,
    speakers_expected: Optional[int] = None,
    include_timestamps: bool = True
) -> Optional[List[TranscriptTurn]]:
    """
    Transcribe audio using AssemblyAI with speaker diarization and word-level timestamps.

    Args:
        audio_path: Path to audio file (local file path)
        speakers_expected: Optional exact speaker count for diarization
        include_timestamps: Whether to include timestamps in output

    Returns:
        List of TranscriptTurn objects with word-level timing data, or None on failure

    Note:
        Bare diarization tokens (A/B/C, 1/2/3, etc.) are normalized to SPEAKER X.
    """
    if not ASSEMBLYAI_AVAILABLE:
        logger.error("AssemblyAI SDK not available")
        return None

    if not ASSEMBLYAI_API_KEY:
        logger.error("ASSEMBLYAI_API_KEY not configured")
        return None

    def _build_primary_config() -> "aai.TranscriptionConfig":
        # Configure transcription with speaker diarization
        prompt = (
            "Produce a verbatim transcript. Include disfluencies and fillers (um, uh, er, ah, hmm, mhm, like, you know, I mean), "
            "repetitions (I I, the the), restarts (I was- I went), stutters (th-that, b-but), "
            "and informal speech (gonna, wanna, gotta)."
        )

        config_kwargs = {
            "speech_models": ["universal-3-pro"],
            "prompt": prompt,
            "format_text": True,
            "speaker_labels": True,
        }
        if speakers_expected is not None:
            config_kwargs["speakers_expected"] = speakers_expected

        # `temperature` is supported in newer SDK versions.
        if "temperature" in inspect.signature(aai.TranscriptionConfig).parameters:
            config_kwargs["temperature"] = 0.1
        else:
            logger.warning("AssemblyAI SDK does not support `temperature`; upgrade to assemblyai>=0.50.0")

        return aai.TranscriptionConfig(**config_kwargs)

    try:
        logger.info(f"Starting AssemblyAI transcription for: {audio_path}")
        logger.info(
            "Speaker diarization enabled, expected speakers: %s",
            speakers_expected if speakers_expected is not None else "auto-detect",
        )

        transcriber = aai.Transcriber()
        config = _build_primary_config()
        transcript = transcriber.transcribe(audio_path, config=config)

        # Check for errors
        if transcript.status == aai.TranscriptStatus.error:
            primary_error = str(transcript.error or "unknown error")
            raise RuntimeError(f"AssemblyAI transcription failed (universal-3-pro): {primary_error}")

        logger.info("AssemblyAI transcription completed successfully")
        logger.info(
            "Found %s speaker turns",
            len(transcript.utterances) if transcript.utterances else 0,
        )

        # Convert AssemblyAI utterances to TranscriptTurn format
        turns: List[TranscriptTurn] = []

        for utterance in transcript.utterances or []:
            speaker_label = getattr(utterance, "speaker", None)
            speaker_name = normalize_speaker_label(speaker_label, fallback="SPEAKER A")

            # Convert timestamp from milliseconds to [MM:SS] format for consistency
            timestamp_str = None
            if include_timestamps and getattr(utterance, "start", None) is not None:
                start_ms = utterance.start
                start_seconds = start_ms / 1000.0
                minutes = int(start_seconds // 60)
                seconds = int(start_seconds % 60)
                timestamp_str = f"[{minutes:02d}:{seconds:02d}]"

            # Extract word-level timestamps from utterance
            word_timestamps: List[WordTimestamp] = []
            if hasattr(utterance, "words") and utterance.words:
                for word in utterance.words:
                    word_speaker_raw = getattr(word, "speaker", None)
                    word_speaker = normalize_speaker_label(word_speaker_raw, fallback=speaker_name)
                    word_timestamps.append(
                        WordTimestamp(
                            text=word.text,
                            start=float(word.start),
                            end=float(word.end),
                            confidence=float(word.confidence)
                            if hasattr(word, "confidence") and word.confidence is not None
                            else None,
                            speaker=word_speaker,
                        )
                    )

            turns.append(
                TranscriptTurn(
                    speaker=speaker_name,
                    text=utterance.text,
                    timestamp=timestamp_str,
                    words=word_timestamps if word_timestamps else None,
                )
            )

        logger.info("Converted %s utterances to TranscriptTurn format", len(turns))
        # Mark continuation turns (same speaker as previous)
        turns = mark_continuation_turns(turns)
        return turns

    except Exception as e:
        logger.error("AssemblyAI transcription error: %s", str(e))
        import traceback

        logger.error(traceback.format_exc())
        raise RuntimeError(f"AssemblyAI transcription error: {e}") from e


def get_media_duration(file_path: str) -> Optional[float]:
    """Return the duration of an audio/video file in **seconds** using ffprobe.
    
    Uses the cross-platform ffprobe path detection.
    """
    if not ffprobe_executable_path:
        return None  # ffprobe not available

    try:
        cmd = [
            ffprobe_executable_path,
            "-i",
            file_path,
            "-v",
            "error",
            "-show_entries",
            "format=duration",
            "-of",
            "default=noprint_wrappers=1:nokey=1",
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        duration_str = result.stdout.strip()
        if duration_str:
            return float(duration_str)
    except Exception as e:
        logger.debug("ffprobe duration extraction failed: %s", e)
    return None

def process_transcription(
    file_bytes: Optional[bytes],
    filename: str,
    speakers_expected: Optional[int],
    title_data: dict,
    input_path: Optional[str] = None,
):
    with tempfile.TemporaryDirectory() as temp_dir:
        if input_path:
            source_path = input_path
        else:
            if file_bytes is None:
                raise ValueError("file_bytes required when input_path is not provided")
            source_path = os.path.join(temp_dir, filename)
            with open(source_path, "wb") as f:
                f.write(file_bytes)

        ext = filename.split('.')[-1].lower()
        audio_path = None
        if ext in SUPPORTED_VIDEO_TYPES:
            output_audio_filename = f"{os.path.splitext(os.path.basename(filename))[0]}.mp3"
            output_path = os.path.join(temp_dir, output_audio_filename)
            converted_audio_path = convert_video_to_audio(source_path, output_path)
            if converted_audio_path:
                audio_path = converted_audio_path
                ext = "mp3"
            else:
                # Fallback to source media if conversion fails; AssemblyAI accepts many video containers directly.
                logger.warning("Video conversion failed for %s; using source media for transcription", filename)
                audio_path = source_path
        elif ext in SUPPORTED_AUDIO_TYPES:
            audio_path = source_path
        else:
            raise ValueError("Unsupported file type")

        # ------------------------------------------------------------------
        # Retrieve media duration – prefer direct ffprobe for robustness
        # ------------------------------------------------------------------
        duration_seconds = get_media_duration(audio_path)

        if duration_seconds is None:
            # Fallback to pydub if ffprobe failed for some reason
            audio_segment = None
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    audio_segment = AudioSegment.from_file(audio_path)
                    break
                except (PermissionError, FileNotFoundError) as e:
                    if attempt < max_retries - 1:
                        logger.warning("Attempt %d failed to load audio file: %s. Retrying...", attempt + 1, e)
                        time.sleep(1)
                    else:
                        raise e
            if audio_segment is not None:
                duration_seconds = len(audio_segment) / 1000.0
            else:
                duration_seconds = None

        if duration_seconds is None:
            logger.warning("Unable to determine media duration for %s; defaulting to 0s", filename)
            duration_seconds = 0.0

        # ------------------------------------------------------------------
        # Format and store duration for title data
        # ------------------------------------------------------------------
        hours, rem = divmod(duration_seconds, 3600)
        minutes, seconds = divmod(rem, 60)
        file_duration_str = "{:0>2}:{:0>2}:{:0>2}".format(int(hours), int(minutes), int(round(seconds)))
        title_data["FILE_DURATION"] = file_duration_str

        # ------------------------------------------------------------------
        # Proceed with upload & transcription (AssemblyAI only)
        # ------------------------------------------------------------------
        logger.info("Using AssemblyAI transcription engine")

        if not ASSEMBLYAI_AVAILABLE:
            raise RuntimeError("AssemblyAI SDK not installed. Run: pip install assemblyai")

        if not ASSEMBLYAI_API_KEY:
            raise RuntimeError("ASSEMBLYAI_API_KEY environment variable not set")

        turns = transcribe_with_assemblyai(audio_path, speakers_expected=speakers_expected)

        if not turns:
            raise RuntimeError("AssemblyAI transcription failed: no utterances returned")

        return turns, duration_seconds
===== END FILE =====

===== FILE: backend/transcript_formatting.py =====
import io
import logging
import os
import re
from collections import defaultdict
from typing import Dict, List, Optional, Tuple

from reportlab.lib import colors
from reportlab.lib.pagesizes import letter
from reportlab.lib.units import inch
from reportlab.pdfgen import canvas

try:
    from .models import TranscriptTurn, WordTimestamp
except ImportError:
    try:
        from models import TranscriptTurn, WordTimestamp
    except ImportError:
        import models
        TranscriptTurn = models.TranscriptTurn
        WordTimestamp = models.WordTimestamp

logger = logging.getLogger(__name__)


# Shared layout constants used for XML generation and editor exports
SPEAKER_PREFIX_SPACES = 10  # Leading spaces before speaker name in XML (visual simulation)
CONTINUATION_SPACES = 0     # Leading spaces for continuation lines in XML (visual simulation)
SPEAKER_COLON = ":   "      # Colon and spaces after speaker name (total 4 chars)
MAX_TOTAL_LINE_WIDTH = 64   # Maximum total characters per XML line for speaker lines
MAX_CONTINUATION_WIDTH = 64 # Maximum total characters per XML line for continuation lines
MIN_LINE_DURATION_SECONDS = 1.25

# OnCue XML constants
ONCUE_FIRST_PGLN = 101      # First page-line number (page 1, line 1 = 101)
DEFAULT_VIDEO_ID = "1"      # Default video ID for single-video transcripts

# PDF layout constants (mirrors transcript_template.docx transcript section)
PDF_PAGE_WIDTH, PDF_PAGE_HEIGHT = letter
PDF_MARGIN_LEFT = 1.0 * inch
PDF_MARGIN_RIGHT = 1.0 * inch
PDF_MARGIN_TOP = 0.75 * inch
PDF_MARGIN_BOTTOM = 0.75 * inch
PDF_LINE_NUMBER_GUTTER = 0.7 * inch
# Slightly above strict double-spacing so the 25-line block fills the page more evenly.
PDF_LINE_HEIGHT = 25.0
PDF_TEXT_FONT = "Courier"
PDF_TEXT_FONT_BOLD = "Courier-Bold"
PDF_TEXT_SIZE = 12
PDF_LINE_NUMBER_SIZE = 10
PDF_PAGE_NUMBER_SIZE = 10
PDF_BORDER_INSET = 0.33 * inch
PDF_BORDER_GAP = 4.0


def timestamp_to_seconds(timestamp: Optional[str]) -> float:
    """Convert timestamp like '[MM:SS]' or 'MM:SS' to seconds."""
    if not timestamp:
        return 0.0
    ts = timestamp.strip('[]').strip()
    parts = ts.split(':')
    try:
        if len(parts) == 3:
            h, m, s = map(float, parts)
            return h * 3600 + m * 60 + s
        if len(parts) == 2:
            m, s = map(float, parts)
            return m * 60 + s
        return float(ts)
    except ValueError:
        return 0.0


def seconds_to_timestamp(seconds: float) -> str:
    """Convert seconds float to OnCue-style [MM:SS] or [HH:MM:SS] timestamp."""
    if seconds < 0:
        seconds = 0.0
    total_seconds = int(round(seconds))
    hours, remainder = divmod(total_seconds, 3600)
    minutes, secs = divmod(remainder, 60)
    if hours > 0:
        return f"[{hours:02d}:{minutes:02d}:{secs:02d}]"
    return f"[{minutes:02d}:{secs:02d}]"


def wrap_text_for_transcript(text: str, max_width: int) -> List[str]:
    """
    Wrap text to fit within max_width characters, preserving word boundaries.

    Args:
        text: The text to wrap
        max_width: Maximum characters per line of text content

    Returns:
        List of wrapped lines
    """
    if not text:
        return [""]

    if max_width <= 0:
        return [text]

    words = text.split()
    lines = []
    current_line = []
    current_length = 0

    for word in words:
        word_length = len(word)
        # +1 for space before word (except first word)
        space_needed = word_length + (1 if current_line else 0)

        if current_length + space_needed <= max_width:
            current_line.append(word)
            current_length += space_needed
        else:
            if current_line:
                lines.append(" ".join(current_line))
            current_line = [word]
            current_length = word_length

    if current_line:
        lines.append(" ".join(current_line))

    return lines if lines else [""]


def _safe_text(value: Optional[str]) -> str:
    if value is None:
        return ""
    return str(value).strip()


def _draw_double_page_border(pdf_canvas: canvas.Canvas) -> None:
    outer_x = PDF_BORDER_INSET
    outer_y = PDF_BORDER_INSET
    outer_w = PDF_PAGE_WIDTH - (2 * PDF_BORDER_INSET)
    outer_h = PDF_PAGE_HEIGHT - (2 * PDF_BORDER_INSET)

    inner_x = outer_x + (PDF_BORDER_GAP / 2.0)
    inner_y = outer_y + (PDF_BORDER_GAP / 2.0)
    inner_w = outer_w - PDF_BORDER_GAP
    inner_h = outer_h - PDF_BORDER_GAP

    pdf_canvas.setStrokeColor(colors.black)
    pdf_canvas.setLineWidth(0.8)
    pdf_canvas.rect(outer_x, outer_y, outer_w, outer_h, stroke=1, fill=0)
    pdf_canvas.rect(inner_x, inner_y, inner_w, inner_h, stroke=1, fill=0)


def _draw_title_page(pdf_canvas: canvas.Canvas, title_data: dict) -> None:
    center_x = PDF_PAGE_WIDTH / 2.0
    y = PDF_PAGE_HEIGHT - (1.7 * inch)

    firm_name = _safe_text(title_data.get("FIRM_OR_ORGANIZATION_NAME"))
    if firm_name:
        pdf_canvas.setFont(PDF_TEXT_FONT_BOLD, 14)
        pdf_canvas.drawCentredString(center_x, y, firm_name)
        y -= 0.6 * inch

    pdf_canvas.setFont(PDF_TEXT_FONT_BOLD, 18)
    pdf_canvas.drawCentredString(center_x, y, "Generated Transcript")
    y -= 0.6 * inch

    metadata_lines = [
        f"Case Name: {_safe_text(title_data.get('CASE_NAME'))}",
        f"Case Number: {_safe_text(title_data.get('CASE_NUMBER'))}",
        "",
        f"Date: {_safe_text(title_data.get('DATE'))}",
        f"Time: {_safe_text(title_data.get('TIME'))}",
        f"Location: {_safe_text(title_data.get('LOCATION'))}",
        "",
        f"Original File: {_safe_text(title_data.get('FILE_NAME'))}",
        f"Duration: {_safe_text(title_data.get('FILE_DURATION'))}",
    ]

    pdf_canvas.setFont(PDF_TEXT_FONT, PDF_TEXT_SIZE)
    for line in metadata_lines:
        if line:
            pdf_canvas.drawCentredString(center_x, y, line)
        y -= 0.35 * inch


def _draw_transcript_page(
    pdf_canvas: canvas.Canvas,
    page_entries: List[dict],
    lines_per_page: int,
    page_number: int,
) -> None:
    _draw_double_page_border(pdf_canvas)

    content_top = PDF_PAGE_HEIGHT - PDF_MARGIN_TOP
    content_bottom = PDF_MARGIN_BOTTOM
    available_height = content_top - content_bottom
    line_block_height = ((max(lines_per_page, 1) - 1) * PDF_LINE_HEIGHT) + PDF_TEXT_SIZE
    vertical_padding = max((available_height - line_block_height) / 2.0, 0.0)
    top_baseline = content_top - vertical_padding - PDF_TEXT_SIZE
    number_right_x = PDF_MARGIN_LEFT - 6.0
    text_x = PDF_MARGIN_LEFT

    sorted_entries = sorted(page_entries, key=lambda entry: (int(entry.get("line", 0) or 0), entry.get("id", "")))
    for entry in sorted_entries:
        try:
            line_number = int(entry.get("line", 0) or 0)
        except (TypeError, ValueError):
            line_number = 0
        if line_number <= 0 or line_number > lines_per_page:
            continue

        y = top_baseline - ((line_number - 1) * PDF_LINE_HEIGHT)
        if y < PDF_MARGIN_BOTTOM:
            continue

        pdf_canvas.setFillColor(colors.Color(0.45, 0.45, 0.45))
        pdf_canvas.setFont(PDF_TEXT_FONT, PDF_LINE_NUMBER_SIZE)
        pdf_canvas.drawRightString(number_right_x, y, str(line_number))

        line_text = str(entry.get("rendered_text", ""))
        pdf_canvas.setFillColor(colors.black)
        pdf_canvas.setFont(PDF_TEXT_FONT, PDF_TEXT_SIZE)
        pdf_canvas.drawString(text_x, y, line_text)

    # Keep transcript page numbers aligned with OnCue/HTML logical page numbering.
    page_number_y = PDF_BORDER_INSET + (PDF_BORDER_GAP / 2.0) + 8.0
    pdf_canvas.setFillColor(colors.black)
    pdf_canvas.setFont(PDF_TEXT_FONT, PDF_PAGE_NUMBER_SIZE)
    pdf_canvas.drawCentredString(PDF_PAGE_WIDTH / 2.0, page_number_y, str(page_number))


def create_pdf(title_data: dict, line_entries: List[dict], lines_per_page: int = 25) -> bytes:
    """
    Create a deterministic PDF transcript from precomputed line entries.

    The PDF uses the same wrapped line/page assignments as XML and HTML outputs.
    """
    output = io.BytesIO()
    pdf_canvas = canvas.Canvas(output, pagesize=letter, pageCompression=1)

    _draw_title_page(pdf_canvas, title_data)
    pdf_canvas.showPage()

    pages: Dict[int, List[dict]] = defaultdict(list)
    for entry in line_entries:
        try:
            page_number = int(entry.get("page", 1) or 1)
        except (TypeError, ValueError):
            page_number = 1
        pages[page_number].append(entry)

    if not pages:
        pages[1] = []

    for page_number in sorted(pages):
        _draw_transcript_page(pdf_canvas, pages[page_number], lines_per_page, page_number)
        pdf_canvas.showPage()

    pdf_canvas.save()
    output.seek(0)
    return output.read()


def calculate_line_timestamps_from_words(
    text_line: str,
    all_words: List[WordTimestamp],
    start_offset: int = 0,
) -> Tuple[float, float, int, bool]:
    """
    Calculate accurate start/stop timestamps for a wrapped line using word-level data.

    This function matches words in the text line to their precise timestamps from
    word-level data, eliminating the need for linear interpolation.

    Args:
        text_line: The text content of the line (without speaker prefix)
        all_words: List of WordTimestamp objects for the entire speaker turn
        start_offset: Index in all_words to start searching from (for continuation lines)

    Returns:
        Tuple of (start_seconds, stop_seconds, words_consumed, boundary_missing)
        - start_seconds: Start time of first word in line (seconds, float)
        - stop_seconds: End time of last word in line (seconds, float)
        - words_consumed: Number of words from all_words that were used
        - boundary_missing: True if the first or last word in the line lacks a valid timestamp
    """
    if not all_words or not text_line.strip():
        logger.debug("calculate_line_timestamps: empty words or text_line")
        return (0.0, 0.0, 0, True)

    line_text_clean = text_line.strip().lower()
    if not line_text_clean:
        return (0.0, 0.0, 0, True)

    raw_line_words = line_text_clean.split()

    def normalize_word_for_match(word: str) -> str:
        normalized = word.lower()
        normalized = normalized.replace("’", "'").replace("‘", "'")
        normalized = re.sub(r"[^\w]+", "", normalized)
        return normalized.strip("_")

    line_words = [word for word in raw_line_words if normalize_word_for_match(word)]
    if not line_words:
        return (0.0, 0.0, 0, True)

    # Matching words in order with flexible punctuation handling
    matched_words: List[WordTimestamp] = []
    word_idx = start_offset
    line_idx = 0

    while word_idx < len(all_words) and line_idx < len(line_words):
        line_word = normalize_word_for_match(line_words[line_idx])
        if not line_word:
            line_idx += 1
            continue

        current_word = all_words[word_idx]
        current_word_clean = normalize_word_for_match(current_word.text)

        if current_word_clean == line_word:
            matched_words.append(current_word)
            line_idx += 1
        else:
            if line_word in current_word_clean or current_word_clean in line_word:
                matched_words.append(current_word)
                line_idx += 1

        word_idx += 1

    if not matched_words:
        logger.debug("No words matched for line: %s", text_line)
        return (0.0, 0.0, 0, True)

    first_word = matched_words[0]
    last_word = matched_words[-1]

    start_seconds = (first_word.start or 0.0) / 1000.0
    stop_seconds = (last_word.end or 0.0) / 1000.0
    words_consumed = len(matched_words)

    boundary_missing = False
    if first_word.start is None or last_word.end is None:
        boundary_missing = True

    return (start_seconds, stop_seconds, words_consumed, boundary_missing)


def enforce_min_line_durations(
    line_entries: List[dict],
    audio_duration: float,
    min_duration: float = MIN_LINE_DURATION_SECONDS,
) -> List[dict]:
    if not line_entries or min_duration <= 0:
        return line_entries

    starts: List[float] = []
    ends: List[float] = []
    for entry in line_entries:
        try:
            start_val = float(entry.get("start", 0.0))
        except (TypeError, ValueError):
            start_val = 0.0
        try:
            end_val = float(entry.get("end", start_val))
        except (TypeError, ValueError):
            end_val = start_val
        if end_val < start_val:
            end_val = start_val
        starts.append(start_val)
        ends.append(end_val)

    count = len(line_entries)
    gaps: List[float] = []
    for idx in range(count - 1):
        gap = starts[idx + 1] - ends[idx]
        gaps.append(gap if gap > 0 else 0.0)

    left_gap = [0.0] * count
    right_gap = [0.0] * count

    left_gap[0] = starts[0] if starts[0] > 0 else 0.0
    for idx in range(1, count):
        left_gap[idx] = gaps[idx - 1]
    for idx in range(count - 1):
        right_gap[idx] = gaps[idx]
    if audio_duration and audio_duration > 0:
        right_gap[count - 1] = max(audio_duration - ends[count - 1], 0.0)
    else:
        right_gap[count - 1] = 0.0

    desired_left = [0.0] * count
    desired_right = [0.0] * count

    for idx in range(count):
        duration = ends[idx] - starts[idx]
        if duration >= min_duration:
            continue
        need = min_duration - duration
        half = need / 2.0
        left_take = min(half, left_gap[idx])
        right_take = min(half, right_gap[idx])
        remaining = need - (left_take + right_take)
        if remaining > 0:
            left_cap = max(left_gap[idx] - left_take, 0.0)
            right_cap = max(right_gap[idx] - right_take, 0.0)
            if right_cap > left_cap:
                extra_right = min(remaining, right_cap)
                right_take += extra_right
                remaining -= extra_right
            extra_left = min(remaining, left_cap)
            left_take += extra_left
        desired_left[idx] = left_take
        desired_right[idx] = right_take

    left_alloc = [0.0] * count
    right_alloc = [0.0] * count
    left_alloc[0] = min(desired_left[0], left_gap[0])
    right_alloc[count - 1] = min(desired_right[count - 1], right_gap[count - 1])

    for idx in range(count - 1):
        gap = gaps[idx]
        total = desired_right[idx] + desired_left[idx + 1]
        if total <= 0:
            right_alloc[idx] = 0.0
            left_alloc[idx + 1] = 0.0
        elif total <= gap:
            right_alloc[idx] = desired_right[idx]
            left_alloc[idx + 1] = desired_left[idx + 1]
        else:
            scale = gap / total if total > 0 else 0.0
            right_alloc[idx] = desired_right[idx] * scale
            left_alloc[idx + 1] = desired_left[idx + 1] * scale

    for idx, entry in enumerate(line_entries):
        new_start = starts[idx] - left_alloc[idx]
        new_end = ends[idx] + right_alloc[idx]
        if new_start < 0:
            new_start = 0.0
        if audio_duration and audio_duration > 0 and new_end > audio_duration:
            new_end = audio_duration
        if new_end < new_start:
            new_end = new_start
        entry["start"] = new_start
        entry["end"] = new_end

    return line_entries


def compute_transcript_line_entries(
    transcript_turns: List[TranscriptTurn],
    audio_duration: float,
    lines_per_page: int = 25,
    enforce_min_duration: bool = True,
) -> Tuple[List[dict], int]:
    """
    Build per-line timing/layout data from transcript turns for re-use in XML and editor exports.
    """
    line_entries: List[dict] = []
    page = 1
    line_in_page = 1
    last_pgln = ONCUE_FIRST_PGLN

    for turn_idx, turn in enumerate(transcript_turns):
        start_sec = timestamp_to_seconds(turn.timestamp)
        stop_sec: Optional[float] = None

        if turn.words:
            word_starts = [word.start for word in turn.words if word.start is not None and word.start >= 0]
            word_ends = [word.end for word in turn.words if word.end is not None and word.end >= 0]
            if word_starts and word_ends:
                start_sec = min(word_starts) / 1000.0
                stop_sec = max(word_ends) / 1000.0

        if stop_sec is None:
            if turn_idx < len(transcript_turns) - 1:
                stop_sec = timestamp_to_seconds(transcript_turns[turn_idx + 1].timestamp)
            else:
                stop_sec = audio_duration

        if stop_sec < start_sec:
            stop_sec = start_sec

        speaker_name = turn.speaker.upper()
        text = turn.text.strip()

        # Check if this turn is a continuation of the same speaker
        is_turn_continuation = getattr(turn, 'is_continuation', False)

        if is_turn_continuation:
            # Continuation turn: no speaker prefix, use continuation formatting
            speaker_prefix = ""
            max_first_line_text = MAX_CONTINUATION_WIDTH - CONTINUATION_SPACES
        else:
            # New speaker: include speaker prefix
            speaker_prefix = " " * SPEAKER_PREFIX_SPACES + speaker_name + SPEAKER_COLON
            max_first_line_text = MAX_TOTAL_LINE_WIDTH - len(speaker_prefix)

        wrapped_lines = wrap_text_for_transcript(text, max_first_line_text)
        if not wrapped_lines:
            wrapped_lines = [""]

        max_continuation_text = MAX_CONTINUATION_WIDTH - CONTINUATION_SPACES
        remaining_text = " ".join(wrapped_lines[1:])
        continuation_wrapped = []
        if remaining_text:
            continuation_wrapped = wrap_text_for_transcript(remaining_text, max_continuation_text)

        all_lines = [wrapped_lines[0]] + continuation_wrapped
        total_lines = len(all_lines)

        def interpolate_line_block(block_start: float, block_end: float, count: int) -> List[Tuple[float, float]]:
            if count <= 0:
                return []
            if block_end < block_start:
                block_end = block_start
            duration = block_end - block_start
            step = duration / count if count > 0 else duration
            return [(block_start + step * idx, block_start + step * (idx + 1)) for idx in range(count)]

        line_timings: List[Optional[Tuple[float, float]]] = []
        line_errors: List[bool] = []

        if turn.words:
            word_offset = 0

            for line_text in all_lines:
                line_start, line_stop, words_used, boundary_missing = calculate_line_timestamps_from_words(
                    line_text,
                    turn.words,
                    word_offset,
                )
                if words_used == 0:
                    line_timings.append(None)
                    line_errors.append(True)
                else:
                    line_timings.append((line_start, line_stop))
                    line_errors.append(boundary_missing)
                    word_offset += words_used
        else:
            logger.warning("Turn %d has NO word data, using interpolation", turn_idx)
            line_timings = [None for _ in range(total_lines)]
            line_errors = [True for _ in range(total_lines)]

        if any(timing is None for timing in line_timings):
            filled_timings: List[Tuple[float, float]] = []
            idx = 0
            prev_end = start_sec
            while idx < total_lines:
                timing = line_timings[idx]
                if timing is not None:
                    filled_timings.append(timing)
                    prev_end = timing[1]
                    idx += 1
                    continue

                next_idx = idx
                while next_idx < total_lines and line_timings[next_idx] is None:
                    next_idx += 1
                next_start = line_timings[next_idx][0] if next_idx < total_lines else stop_sec
                block = interpolate_line_block(prev_end, next_start, next_idx - idx)
                filled_timings.extend(block)
                if block:
                    prev_end = block[-1][1]
                idx = next_idx

            line_timings = [timing for timing in filled_timings]

        first_line_start, first_line_stop = line_timings[0] if line_timings else (start_sec, start_sec)
        continuation_timings: List[Tuple[float, float]] = []
        for cont_idx in range(1, total_lines):
            continuation_timings.append(line_timings[cont_idx])

        # First line of turn (with or without speaker prefix depending on continuation status)
        pgln = page * 100 + line_in_page
        last_pgln = pgln

        if is_turn_continuation:
            # Continuation turn: format like a continuation line (no speaker)
            rendered_first_line = " " * CONTINUATION_SPACES + wrapped_lines[0]
        else:
            # New speaker: include speaker prefix
            rendered_first_line = speaker_prefix + wrapped_lines[0]

        line_entries.append(
            {
                "id": f"{turn_idx}-0",
                "turn_index": turn_idx,
                "line_index": 0,
                "speaker": speaker_name,
                "text": wrapped_lines[0],
                "rendered_text": rendered_first_line,
                "start": first_line_start,
                "end": first_line_stop,
                "page": page,
                "line": line_in_page,
                "pgln": pgln,
                "is_continuation": is_turn_continuation,
                "total_lines_in_turn": total_lines,
                "timestamp_error": line_errors[0] if line_errors else False,
            }
        )

        line_in_page += 1
        if line_in_page > lines_per_page:
            page += 1
            line_in_page = 1

        # Continuation lines
        for cont_idx, continuation_text in enumerate(continuation_wrapped):
            line_start, line_stop = continuation_timings[cont_idx]

            pgln = page * 100 + line_in_page
            last_pgln = pgln
            line_entries.append(
                {
                    "id": f"{turn_idx}-{cont_idx + 1}",
                    "turn_index": turn_idx,
                    "line_index": cont_idx + 1,
                    "speaker": speaker_name,
                    "text": continuation_text,
                    "rendered_text": " " * CONTINUATION_SPACES + continuation_text,
                    "start": line_start,
                    "end": line_stop,
                    "page": page,
                    "line": line_in_page,
                    "pgln": pgln,
                    "is_continuation": True,
                    "total_lines_in_turn": total_lines,
                    "timestamp_error": line_errors[cont_idx + 1] if line_errors else False,
                }
            )

            line_in_page += 1
            if line_in_page > lines_per_page:
                page += 1
                line_in_page = 1

    if enforce_min_duration:
        enforce_min_line_durations(line_entries, audio_duration, MIN_LINE_DURATION_SECONDS)

    return line_entries, last_pgln


def generate_oncue_xml(
    transcript_turns: List[TranscriptTurn],
    metadata: dict,
    audio_duration: float,
    lines_per_page: int = 25,
    enforce_min_duration: bool = True,
    precomputed_line_entries: Optional[List[dict]] = None,
) -> str:
    """Generate OnCue-compatible XML from transcript turns or precomputed line entries."""
    if precomputed_line_entries is None:
        line_entries, _ = compute_transcript_line_entries(
            transcript_turns,
            audio_duration,
            lines_per_page,
            enforce_min_duration=enforce_min_duration,
        )
    else:
        line_entries = precomputed_line_entries

    return generate_oncue_xml_from_line_entries(
        line_entries,
        metadata,
        audio_duration,
        lines_per_page,
    )


def generate_oncue_xml_from_line_entries(
    line_entries: List[dict],
    metadata: dict,
    audio_duration: float,
    lines_per_page: int = 25,
) -> str:
    """Generate OnCue-compatible XML from already-computed line entries."""
    from xml.etree.ElementTree import Element, SubElement, tostring

    root = Element(
        "onCue",
        {
            "xmlns:xsd": "http://www.w3.org/2001/XMLSchema",
            "xmlns:xsi": "http://www.w3.org/2001/XMLSchema-instance",
        },
    )

    media_id = metadata.get("MEDIA_ID") or os.path.splitext(metadata.get("FILE_NAME", "deposition"))[0]
    depo_attrs = {
        "mediaId": str(media_id),
        "linesPerPage": str(lines_per_page),
    }
    if metadata.get("DATE"):
        depo_attrs["date"] = metadata["DATE"]

    deposition = SubElement(root, "deposition", depo_attrs)

    video_attrs = {
        "ID": DEFAULT_VIDEO_ID,
        "filename": metadata.get("FILE_NAME", "audio.mp3"),
        "startTime": "0",
        "stopTime": str(int(round(audio_duration))),
        "firstPGLN": str(ONCUE_FIRST_PGLN),
        "lastPGLN": "0",  # placeholder
        "startTuned": "no",
        "stopTuned": "no",
    }
    depo_video = SubElement(deposition, "depoVideo", video_attrs)

    for entry in line_entries:
        page_value = int(entry.get("page", 1) or 1)
        line_value = int(entry.get("line", 1) or 1)
        pgln_value = int(entry.get("pgln", (page_value * 100) + line_value) or ((page_value * 100) + line_value))
        start_value = float(entry.get("start", 0.0) or 0.0)
        stop_value = float(entry.get("end", start_value) or start_value)
        SubElement(
            depo_video,
            "depoLine",
            {
                "prefix": "",
                "text": str(entry.get("rendered_text", "")),
                "page": str(page_value),
                "line": str(line_value),
                "pgLN": str(pgln_value),
                "videoID": DEFAULT_VIDEO_ID,
                "videoStart": f"{start_value:.2f}",
                "videoStop": f"{stop_value:.2f}",
                "isEdited": "no",
                "isSynched": "yes",
                "isRedacted": "no",
            },
        )

    last_pgln = ONCUE_FIRST_PGLN
    if line_entries:
        try:
            last_pgln = int(line_entries[-1].get("pgln", ONCUE_FIRST_PGLN) or ONCUE_FIRST_PGLN)
        except (TypeError, ValueError):
            last_pgln = ONCUE_FIRST_PGLN

    depo_video.set("lastPGLN", str(last_pgln))

    xml_bytes = tostring(root, encoding="utf-8", method="xml")
    xml_str = xml_bytes.decode("utf-8")
    xml_str = "".join(xml_str.splitlines())  # single line like sample
    return xml_str
===== END FILE =====

===== FILE: backend/transcript_utils.py =====
import base64
import json
import logging
import os
import re
import xml.etree.ElementTree as ET
from datetime import datetime, timezone
from typing import Any, Dict, List, Optional, Tuple

from fastapi import HTTPException

try:
    from .config import DEFAULT_LINES_PER_PAGE, APP_VARIANT
except ImportError:
    try:
        from config import DEFAULT_LINES_PER_PAGE, APP_VARIANT
    except ImportError:
        import config as config_module
        DEFAULT_LINES_PER_PAGE = config_module.DEFAULT_LINES_PER_PAGE
        APP_VARIANT = config_module.APP_VARIANT

# Viewer module for criminal variant
try:
    from .viewer import render_viewer_html
except ImportError:
    try:
        from viewer import render_viewer_html
    except ImportError:
        try:
            import viewer as viewer_module
            render_viewer_html = viewer_module.render_viewer_html
        except ImportError:
            render_viewer_html = None  # Viewer not available

try:
    from .models import TranscriptTurn, WordTimestamp
except ImportError:
    try:
        from models import TranscriptTurn, WordTimestamp
    except ImportError:
        import models
        TranscriptTurn = models.TranscriptTurn
        WordTimestamp = models.WordTimestamp

try:
    from .transcript_formatting import (
        create_pdf,
        generate_oncue_xml_from_line_entries,
        compute_transcript_line_entries,
        seconds_to_timestamp,
    )
except ImportError:
    try:
        from transcript_formatting import (
            create_pdf,
            generate_oncue_xml_from_line_entries,
            compute_transcript_line_entries,
            seconds_to_timestamp,
        )
    except ImportError:
        import transcript_formatting as transcript_formatting_module
        create_pdf = transcript_formatting_module.create_pdf
        generate_oncue_xml_from_line_entries = transcript_formatting_module.generate_oncue_xml_from_line_entries
        compute_transcript_line_entries = transcript_formatting_module.compute_transcript_line_entries
        seconds_to_timestamp = transcript_formatting_module.seconds_to_timestamp

logger = logging.getLogger(__name__)
_VIEWER_DATA_RE = re.compile(
    r'<script[^>]*id=["\']transcript-data["\'][^>]*>(.*?)</script>',
    re.IGNORECASE | re.DOTALL,
)
_SPEAKER_LETTER_RE = re.compile(r"^[A-Z]$")
_SPEAKER_NUMERIC_RE = re.compile(r"^[0-9]+$")


def normalize_speaker_label(raw_value: Any, fallback: str = "SPEAKER") -> str:
    """Normalize diarization labels so exports consistently use SPEAKER X."""
    fallback_value = str(fallback or "").strip().upper() or "SPEAKER"
    candidate = str(raw_value or "").strip()
    candidate = re.sub(r":+$", "", candidate).strip().upper()

    if not candidate:
        candidate = fallback_value

    if candidate == "UNKNOWN":
        return fallback_value

    if candidate.startswith("SPEAKER"):
        suffix = candidate[len("SPEAKER"):].strip()
        return f"SPEAKER {suffix}" if suffix else "SPEAKER"

    if _SPEAKER_LETTER_RE.fullmatch(candidate) or _SPEAKER_NUMERIC_RE.fullmatch(candidate):
        return f"SPEAKER {candidate}"

    return candidate


def _extract_media_key(data: dict) -> str:
    """Extract media key from session/payload data using priority chain.

    Priority: media_key field > title_data.MEDIA_ID > XML mediaId > filename > blob name > "unknown"
    """
    title_data = data.get("title_data") or {}

    # Direct media_key field
    if data.get("media_key"):
        return str(data["media_key"])

    # MEDIA_ID from title data
    if title_data.get("MEDIA_ID"):
        return str(title_data["MEDIA_ID"])

    # Try to extract from OnCue XML
    xml_filename = title_data.get("FILE_NAME") or title_data.get("CASE_NAME")
    media_id_from_xml = None
    xml_b64 = data.get("oncue_xml_base64")
    if xml_b64:
        try:
            xml_text = base64.b64decode(xml_b64).decode("utf-8", errors="replace")
            root = ET.fromstring(xml_text)
            deposition = root.find(".//deposition")
            if deposition is not None:
                media_id_from_xml = deposition.get("mediaId") or deposition.get("mediaID")
        except Exception:
            media_id_from_xml = None

    # Fallback chain
    key = media_id_from_xml or xml_filename or data.get("media_blob_name") or "unknown"
    return str(key)


def snapshot_media_key(session_data: dict) -> str:
    """Extract media key from session data. Wrapper for backwards compatibility."""
    return _extract_media_key(session_data)


def derive_media_key_from_payload(payload: dict) -> str:
    """Extract media key from payload data. Wrapper for backwards compatibility."""
    return _extract_media_key(payload)


def serialize_transcript_turns(turns: List[TranscriptTurn]) -> List[dict]:
    serialized: List[dict] = []
    for turn in turns:
        turn_dict = turn.model_dump()
        if turn_dict.get("words"):
            sanitized_words = []
            for word in turn_dict["words"]:
                sanitized_words.append(
                    {
                        "text": word.get("text"),
                        "start": float(word.get("start", 0.0)),
                        "end": float(word.get("end", 0.0)),
                        "confidence": word.get("confidence"),
                        "speaker": word.get("speaker"),
                    }
                )
            turn_dict["words"] = sanitized_words
        serialized.append(turn_dict)
    return serialized


def format_transcript_text(turns: List[TranscriptTurn]) -> str:
    return "\n\n".join(
        [
            f"{(turn.timestamp + ' ') if turn.timestamp else ''}{turn.speaker.upper()}:\t\t{turn.text}"
            for turn in turns
        ]
    )


def serialize_line_entries(line_entries: List[dict]) -> List[dict]:
    """Convert line entry timestamps to float for JSON serialization."""
    serialized = []
    for entry in line_entries:
        serialized.append(
            {
                **entry,
                "start": float(entry.get("start", 0.0)),
                "end": float(entry.get("end", 0.0)),
                "timestamp_error": bool(entry.get("timestamp_error", False)),
            }
        )
    return serialized


def build_session_artifacts(
    turns: List[TranscriptTurn],
    title_data: dict,
    audio_duration: float,
    lines_per_page: int,
    enforce_min_line_duration: bool = True,
) -> Tuple[bytes, str, str, List[dict]]:
    line_entries, _ = compute_transcript_line_entries(
        turns,
        audio_duration,
        lines_per_page,
        enforce_min_duration=enforce_min_line_duration,
    )
    pdf_bytes = create_pdf(title_data, line_entries, lines_per_page=lines_per_page)
    oncue_xml = generate_oncue_xml_from_line_entries(
        line_entries,
        title_data,
        audio_duration,
        lines_per_page,
    )
    transcript_text = format_transcript_text(turns)
    serialized_entries = serialize_line_entries(line_entries)
    return pdf_bytes, oncue_xml, transcript_text, serialized_entries


def build_viewer_payload(
    line_entries: List[dict],
    title_data: dict,
    audio_duration: float,
    lines_per_page: int,
    media_filename: str = "media.mp4",
    media_content_type: str = "video/mp4",
) -> Dict[str, Any]:
    """
    Build the JSON payload for the standalone HTML viewer.

    Args:
        line_entries: Serialized line entries from compute_transcript_line_entries
        title_data: Metadata dict (CASE_NAME, FILE_NAME, DATE, LOCATION, etc.)
        audio_duration: Total duration in seconds
        lines_per_page: Lines per page for pagination
        media_filename: Relative path to media file
        media_content_type: MIME type of media file

    Returns:
        Dict payload ready for render_viewer_html
    """
    # Format duration as HH:MM:SS
    total_secs = int(audio_duration)
    hours, remainder = divmod(total_secs, 3600)
    minutes, secs = divmod(remainder, 60)
    if hours > 0:
        duration_str = f"{hours:02d}:{minutes:02d}:{secs:02d}"
    else:
        duration_str = f"{minutes:02d}:{secs:02d}"

    # Build title metadata
    meta_title = {
        "CASE_NAME": title_data.get("CASE_NAME", ""),
        "CASE_NUMBER": title_data.get("CASE_NUMBER", ""),
        "FIRM_OR_ORGANIZATION_NAME": title_data.get("FIRM_OR_ORGANIZATION_NAME", ""),
        "DATE": title_data.get("DATE", ""),
        "TIME": title_data.get("TIME", ""),
        "LOCATION": title_data.get("LOCATION", ""),
        "FILE_NAME": title_data.get("FILE_NAME", media_filename),
        "FILE_DURATION": duration_str,
    }

    # Extract unique speakers
    speakers = list(set(
        entry.get("speaker", "")
        for entry in line_entries
        if entry.get("speaker")
    ))

    # Build lines array for viewer
    lines = []
    for idx, entry in enumerate(line_entries):
        lines.append({
            "id": entry.get("id", f"line-{idx}"),
            "speaker": entry.get("speaker", ""),
            "text": entry.get("text", ""),
            "rendered_text": entry.get("rendered_text", ""),
            "start": entry.get("start", 0),
            "end": entry.get("end", 0),
            "page_number": entry.get("page", 1),  # Fixed: was "page_number", should be "page"
            "line_number": entry.get("line", idx + 1),  # Fixed: was "line_number", should be "line"
            "pgln": entry.get("pgln", 101 + idx),
            "is_continuation": entry.get("is_continuation", False),
        })

    # Build pages array
    pages = []
    page_lines: Dict[int, List[int]] = {}
    for idx, line in enumerate(lines):
        page_num = line.get("page_number", 1)
        if page_num not in page_lines:
            page_lines[page_num] = []
        page_lines[page_num].append(idx)

    for page_num in sorted(page_lines.keys()):
        line_indexes = page_lines[page_num]
        pages.append({
            "page_number": page_num,
            "line_indexes": line_indexes,
            "pgln_start": lines[line_indexes[0]]["pgln"] if line_indexes else 101,
            "pgln_end": lines[line_indexes[-1]]["pgln"] if line_indexes else 101,
        })

    return {
        "meta": {
            "title": meta_title,
            "duration_seconds": audio_duration,
            "lines_per_page": lines_per_page,
            "speakers": speakers,
        },
        "media": {
            "filename": media_filename,
            "content_type": media_content_type,
            "relative_path": media_filename,
        },
        "lines": lines,
        "pages": pages,
    }


def generate_viewer_html_from_artifacts(
    line_entries: List[dict],
    title_data: dict,
    audio_duration: float,
    lines_per_page: int,
    media_filename: str = "media.mp4",
    media_content_type: str = "video/mp4",
) -> str:
    """
    Generate standalone HTML viewer from session artifacts.

    Returns:
        HTML string for the standalone viewer

    Raises:
        RuntimeError: If viewer module is not available
    """
    if render_viewer_html is None:
        raise RuntimeError("Viewer module not available")

    payload = build_viewer_payload(
        line_entries,
        title_data,
        audio_duration,
        lines_per_page,
        media_filename,
        media_content_type,
    )
    return render_viewer_html(payload)


def resolve_media_filename(title_data: dict, media_blob_name: Optional[str] = None, fallback: str = "media.mp4") -> str:
    if isinstance(title_data, dict):
        name = title_data.get("FILE_NAME")
        if isinstance(name, str) and name.strip():
            return os.path.basename(name.strip())
    if isinstance(fallback, str) and fallback.strip():
        return os.path.basename(fallback.strip())
    if media_blob_name:
        return os.path.basename(str(media_blob_name).strip())
    return "media.mp4"


def build_variant_exports(
    app_variant: str,
    line_entries: List[dict],
    title_data: dict,
    audio_duration: float,
    lines_per_page: int,
    media_filename: str,
    media_content_type: Optional[str],
    oncue_xml: Optional[str] = None,
) -> Dict[str, str]:
    """Build base64 exports for the active variant to avoid drift across flows."""
    if app_variant == "criminal":
        viewer_html = generate_viewer_html_from_artifacts(
            line_entries,
            title_data,
            audio_duration,
            lines_per_page,
            media_filename=media_filename,
            media_content_type=media_content_type or "video/mp4",
        )
        exports = {"viewer_html_base64": base64.b64encode(viewer_html.encode("utf-8")).decode("ascii")}
        if oncue_xml is not None:
            exports["oncue_xml_base64"] = base64.b64encode(oncue_xml.encode("utf-8")).decode("ascii")
        return exports
    if oncue_xml is None:
        raise ValueError("oncue_xml is required for oncue exports")
    return {"oncue_xml_base64": base64.b64encode(oncue_xml.encode("utf-8")).decode("ascii")}


def parse_viewer_html(html_text: str) -> Dict[str, Any]:
    """Parse the embedded payload from a standalone HTML viewer export."""
    if not html_text:
        raise ValueError("Viewer HTML is empty")
    match = _VIEWER_DATA_RE.search(html_text)
    if not match:
        raise ValueError("Viewer HTML payload not found")
    json_blob = match.group(1).strip()
    if not json_blob:
        raise ValueError("Viewer HTML payload is empty")

    try:
        payload = json.loads(json_blob)
    except json.JSONDecodeError as exc:
        raise ValueError("Viewer HTML payload is not valid JSON") from exc

    meta = payload.get("meta") if isinstance(payload, dict) else {}
    title_data = meta.get("title") if isinstance(meta, dict) else {}
    duration_seconds = float(meta.get("duration_seconds") or 0.0) if isinstance(meta, dict) else 0.0
    lines_per_page = meta.get("lines_per_page") if isinstance(meta, dict) else None
    try:
        lines_per_page = int(lines_per_page) if lines_per_page else DEFAULT_LINES_PER_PAGE
    except (TypeError, ValueError):
        lines_per_page = DEFAULT_LINES_PER_PAGE

    media = payload.get("media") if isinstance(payload, dict) else {}
    media_filename = media.get("relative_path") or media.get("filename") if isinstance(media, dict) else None
    media_content_type = media.get("content_type") if isinstance(media, dict) else None

    raw_lines = payload.get("lines") if isinstance(payload, dict) else []
    normalized_lines: List[dict] = []
    if isinstance(raw_lines, list):
        for idx, entry in enumerate(raw_lines):
            if not isinstance(entry, dict):
                continue
            text_value = entry.get("text")
            rendered_text = entry.get("rendered_text")
            text = text_value if isinstance(text_value, str) else rendered_text if isinstance(rendered_text, str) else ""
            speaker_value = entry.get("speaker")
            speaker = normalize_speaker_label(speaker_value, fallback="SPEAKER")
            start_val = entry.get("start")
            end_val = entry.get("end")
            try:
                start = float(start_val) if start_val is not None else 0.0
            except (TypeError, ValueError):
                start = 0.0
            try:
                end = float(end_val) if end_val is not None else start
            except (TypeError, ValueError):
                end = start

            page_val = entry.get("page_number")
            line_val = entry.get("line_number")
            pgln_val = entry.get("pgln")
            try:
                page = int(page_val) if page_val is not None else None
            except (TypeError, ValueError):
                page = None
            try:
                line = int(line_val) if line_val is not None else None
            except (TypeError, ValueError):
                line = None
            try:
                pgln = int(pgln_val) if pgln_val is not None else None
            except (TypeError, ValueError):
                pgln = None

            normalized_lines.append(
                {
                    "id": str(entry.get("id") or f"line-{idx}"),
                    "speaker": speaker,
                    "text": text,
                    "start": start,
                    "end": end,
                    "page": page,
                    "line": line,
                    "pgln": pgln,
                    "is_continuation": bool(entry.get("is_continuation", False)),
                }
            )

    return {
        "lines": normalized_lines,
        "title_data": title_data if isinstance(title_data, dict) else {},
        "audio_duration": duration_seconds,
        "lines_per_page": lines_per_page,
        "media_filename": media_filename,
        "media_content_type": media_content_type,
    }


def ensure_session_clip_list(session_data: dict) -> List[dict]:
    clips_list = session_data.get("clips")
    if not isinstance(clips_list, list):
        clips_list = []
        session_data["clips"] = clips_list
    return clips_list


def parse_timecode_to_seconds(value: Any) -> Optional[float]:
    if value is None:
        return None
    if isinstance(value, (int, float)):
        return float(value)

    text = str(value).strip()
    if not text:
        return None

    if ":" not in text:
        try:
            return float(text)
        except ValueError:
            return None

    parts = text.split(":")
    if len(parts) > 3:
        return None

    try:
        parts = [float(part) for part in parts]
    except ValueError:
        return None

    if len(parts) == 3:
        hours, minutes, seconds = parts
    elif len(parts) == 2:
        hours = 0.0
        minutes, seconds = parts
    else:
        hours = 0.0
        minutes = 0.0
        seconds = parts[0]

    return hours * 3600 + minutes * 60 + seconds


def parse_pgln(value: Any) -> Optional[int]:
    if value is None:
        return None
    if isinstance(value, int):
        return value
    if isinstance(value, float):
        return int(value)
    text = str(value).strip()
    if not text:
        return None
    try:
        return int(float(text))
    except ValueError:
        return None


def find_line_index_by_id(lines: List[dict], line_id: Any) -> Optional[int]:
    if line_id is None:
        return None
    for idx, line in enumerate(lines):
        if line.get("id") == line_id:
            return idx
    return None


def find_line_index_by_pgln(lines: List[dict], pgln: Optional[int]) -> Optional[int]:
    if pgln is None:
        return None
    for idx, line in enumerate(lines):
        if parse_pgln(line.get("pgln")) == pgln:
            return idx
    return None


def find_line_index_by_time(
    lines: List[dict],
    time_seconds: Optional[float],
    prefer_start: bool,
) -> Optional[int]:
    if time_seconds is None:
        return None
    best_idx = None
    best_delta = None
    for idx, line in enumerate(lines):
        start_val = float(line.get("start", 0.0) or 0.0)
        end_val = float(line.get("end", start_val) or start_val)
        target = start_val if prefer_start else end_val
        delta = abs(target - time_seconds)
        if best_delta is None or delta < best_delta:
            best_delta = delta
            best_idx = idx
    return best_idx


def resolve_line_index(
    lines: List[dict],
    line_id: Any,
    pgln: Optional[int],
    time_seconds: Optional[float],
    prefer_start: bool,
) -> Optional[int]:
    candidate = find_line_index_by_id(lines, line_id)
    if candidate is not None:
        return candidate

    candidate = find_line_index_by_pgln(lines, parse_pgln(pgln))
    if candidate is not None:
        return candidate

    candidate = find_line_index_by_time(lines, time_seconds, prefer_start)
    if candidate is not None:
        return candidate

    return None


def sanitize_clip_label(label: Optional[str], default_name: str) -> str:
    if not label:
        return default_name
    cleaned = str(label).strip()
    if not cleaned:
        return default_name
    # Collapse whitespace and limit length for storage
    cleaned = re.sub(r"\s+", " ", cleaned)
    if len(cleaned) > 120:
        cleaned = cleaned[:120].rstrip()
    return cleaned


def slugify_filename(name: str, default: str = "clip") -> str:
    cleaned = re.sub(r"[^A-Za-z0-9._-]+", "-", name.strip()) if name else ""
    cleaned = cleaned.strip("-._")
    return cleaned or default


def normalize_line_payloads(
    lines_payload: List[dict],
    duration_seconds: float,
) -> Tuple[List[dict], float]:
    normalized_lines = []
    max_end = duration_seconds

    for idx, line in enumerate(lines_payload):
        try:
            start_val = float(line.get("start", 0.0))
            end_val = float(line.get("end", start_val))
        except (TypeError, ValueError):
            raise HTTPException(status_code=400, detail=f"Invalid start/end for line index {idx}")

        if end_val < start_val:
            end_val = start_val

        if duration_seconds > 0:
            start_val = max(0.0, min(start_val, duration_seconds))
            end_val = max(0.0, min(end_val, duration_seconds))
        else:
            start_val = max(0.0, start_val)
            end_val = max(start_val, end_val)

        speaker_name = normalize_speaker_label(line.get("speaker", ""), fallback="SPEAKER")
        text_value = str(line.get("text", "")).strip()

        normalized_line = {
            "id": line.get("id") or f"{idx}",
            "speaker": speaker_name.upper(),
            "text": text_value,
            "start": start_val,
            "end": end_val,
            "is_continuation": bool(line.get("is_continuation", False)),
            "timestamp_error": bool(line.get("timestamp_error", False)),
        }

        # Pass through word-level timestamps if present
        if "words" in line and isinstance(line["words"], list):
            normalized_line["words"] = line["words"]

        normalized_lines.append(normalized_line)

        max_end = max(max_end, end_val)

    if duration_seconds == 0 and max_end > 0:
        duration_seconds = max_end
    elif max_end > duration_seconds:
        duration_seconds = max_end

    if any(line.get("timestamp_error") for line in normalized_lines):
        return normalized_lines, duration_seconds

    normalized_lines = sorted(
        enumerate(normalized_lines),
        key=lambda item: (item[1]["start"], item[0]),
    )

    return [item[1] for item in normalized_lines], duration_seconds


def construct_turns_from_lines(normalized_lines: List[dict]) -> List[TranscriptTurn]:
    turns: List[TranscriptTurn] = []
    current_speaker: Optional[str] = None
    current_text_parts: List[str] = []
    current_words: List[WordTimestamp] = []
    current_start: Optional[float] = None

    def flush_turn():
        nonlocal current_speaker, current_text_parts, current_words, current_start
        if current_speaker is None:
            return
        full_text = " ".join([part for part in current_text_parts if part]).strip()
        timestamp_str = seconds_to_timestamp(current_start) if current_start is not None else None
        turns.append(
            TranscriptTurn(
                speaker=current_speaker,
                text=full_text,
                timestamp=timestamp_str,
                words=current_words if current_words else None,
            )
        )
        current_speaker = None
        current_text_parts = []
        current_words = []
        current_start = None

    for line in normalized_lines:
        speaker = normalize_speaker_label(line.get("speaker", ""), fallback="SPEAKER")
        text_val = str(line.get("text", "")).strip()
        start_val = float(line.get("start", 0.0))
        end_val = float(line.get("end", start_val))

        should_start_new = current_speaker is None or speaker.upper() != current_speaker

        if should_start_new:
            flush_turn()
            current_speaker = speaker.upper()
            current_start = start_val

        current_text_parts.append(text_val)

        line_words = line.get("words")
        if isinstance(line_words, list) and len(line_words) > 0:
            for word_data in line_words:
                if not isinstance(word_data, dict):
                    continue
                word_text = str(word_data.get("text", "")).strip()
                if not word_text:
                    continue
                word_start = float(word_data.get("start", 0.0))
                word_end = float(word_data.get("end", word_start))
                current_words.append(
                    WordTimestamp(
                        text=word_text,
                        start=word_start * 1000.0,
                        end=max(word_end * 1000.0, word_start * 1000.0),
                        confidence=None,
                        speaker=current_speaker,
                    )
                )
        else:
            tokens = [tok for tok in text_val.split() if tok]
            if not tokens:
                continue
            line_duration = max(end_val - start_val, 0.01)
            word_count = len(tokens)
            for word_idx, token in enumerate(tokens):
                token_start = start_val + (line_duration * word_idx / word_count)
                if word_idx < word_count - 1:
                    token_end = start_val + (line_duration * (word_idx + 1) / word_count)
                else:
                    token_end = end_val
                current_words.append(
                    WordTimestamp(
                        text=token,
                        start=token_start * 1000.0,
                        end=token_end * 1000.0,
                        confidence=None,
                        speaker=current_speaker,
                    )
                )

    flush_turn()

    # Mark continuation turns (same speaker as previous)
    prev_speaker = None
    for turn in turns:
        if prev_speaker is not None and turn.speaker.strip().upper() == prev_speaker:
            turn.is_continuation = True
        else:
            turn.is_continuation = False
        prev_speaker = turn.speaker.strip().upper()

    return turns


def parse_oncue_xml(xml_text: str) -> Dict[str, Any]:
    try:
        root = ET.fromstring(xml_text)
    except ET.ParseError as exc:
        raise HTTPException(status_code=400, detail=f"Invalid OnCue XML: {exc}")

    deposition = root.find(".//deposition")
    depo_video = root.find(".//depoVideo")

    def first_attr(element: Optional[ET.Element], keys: List[str]) -> str:
        if element is None:
            return ""
        for key in keys:
            value = element.attrib.get(key)
            if value:
                return value.strip()
        return ""

    def first_text(keys: List[str]) -> str:
        for key in keys:
            node = root.find(f".//{key}")
            if node is not None and node.text:
                text_value = node.text.strip()
                if text_value:
                    return text_value
        return ""

    case_name = first_attr(deposition, ["caseName", "case", "case_name", "caption"]) or first_text(
        ["caseName", "case", "caption", "case_name"]
    )
    case_number = first_attr(deposition, ["caseNumber", "caseNo", "case_number"]) or first_text(
        ["caseNumber", "caseNo", "case_number"]
    )
    firm_name = first_attr(
        deposition,
        ["firm", "firmName", "organization", "organizationName", "firmOrOrganization"],
    ) or first_text(["firm", "firmName", "organization", "organizationName", "firmOrOrganization"])
    date_value = first_attr(deposition, ["date"]) or first_text(["date"])
    time_value = first_attr(deposition, ["time"]) or first_text(["time"])
    location_value = first_attr(deposition, ["location", "place"]) or first_text(["location", "place"])
    file_name = (
        first_attr(depo_video, ["filename"])
        or first_attr(deposition, ["filename", "fileName", "file_name"])
        or first_text(["FILE_NAME", "fileName", "file_name"])
    )

    title_data = {
        "CASE_NAME": case_name,
        "CASE_NUMBER": case_number,
        "FIRM_OR_ORGANIZATION_NAME": firm_name,
        "DATE": date_value,
        "TIME": time_value,
        "LOCATION": location_value,
        "FILE_NAME": file_name or "imported.xml",
        "FILE_DURATION": "",
    }

    lines: List[dict] = []
    current_speaker: Optional[str] = None
    max_end = 0.0

    for line_idx, line_elem in enumerate(root.findall(".//depoLine")):
        raw_text = line_elem.attrib.get("text", "")
        video_start = float(line_elem.attrib.get("videoStart", "0") or 0)
        video_stop = float(line_elem.attrib.get("videoStop", "0") or video_start)
        page = line_elem.attrib.get("page")
        line_number = line_elem.attrib.get("line")
        pgln = line_elem.attrib.get("pgLN")

        trimmed = raw_text.lstrip()
        speaker = current_speaker
        text_content = trimmed
        is_continuation = True

        if trimmed:
            if ":   " in trimmed:
                potential_speaker, remainder = trimmed.split(":   ", 1)
                if potential_speaker.strip():
                    speaker = normalize_speaker_label(
                        potential_speaker,
                        fallback=current_speaker or "SPEAKER",
                    )
                    text_content = remainder.strip()
                    is_continuation = False
            elif current_speaker is None:
                speaker = normalize_speaker_label("", fallback="SPEAKER")
                text_content = trimmed.strip()
                is_continuation = False
        else:
            text_content = ""

        if speaker is None:
            speaker = normalize_speaker_label("", fallback=current_speaker or "SPEAKER")

        current_speaker = speaker
        max_end = max(max_end, video_stop)

        lines.append(
            {
                "id": line_elem.attrib.get("pgLN", f"{line_idx}"),
                "speaker": speaker,
                "text": text_content,
                "start": video_start,
                "end": video_stop,
                "page": int(page) if page and page.isdigit() else None,
                "line": int(line_number) if line_number and line_number.isdigit() else None,
                "pgln": int(pgln) if pgln and pgln.isdigit() else None,
                "is_continuation": is_continuation,
            }
        )

    duration_seconds = max_end
    hours, rem = divmod(duration_seconds, 3600)
    minutes, seconds = divmod(rem, 60)
    title_data["FILE_DURATION"] = "{:0>2}:{:0>2}:{:0>2}".format(int(hours), int(minutes), int(round(seconds)))

    return {
        "lines": lines,
        "title_data": title_data,
        "audio_duration": duration_seconds,
    }


def build_snapshot_payload(
    session_data: dict,
    lines_override: Optional[List[dict]] = None,
    title_override: Optional[dict] = None,
    is_manual_save: bool = False,
) -> dict:
    """Create a snapshot payload with XML + lines + media references."""
    xml_b64 = session_data.get("oncue_xml_base64")
    title_data = title_override or session_data.get("title_data") or {}
    lines_per_page = session_data.get("lines_per_page", DEFAULT_LINES_PER_PAGE)
    audio_duration = float(session_data.get("audio_duration") or 0.0)
    source_lines = lines_override if lines_override is not None else session_data.get("lines") or []

    # CRITICAL FIX: Always include media references for playback recovery
    media_blob_name = session_data.get("media_blob_name")
    media_content_type = session_data.get("media_content_type")

    if not xml_b64:
        # Rebuild XML from lines as a fallback
        normalized_lines, audio_duration = normalize_line_payloads(source_lines, audio_duration)
        turns = construct_turns_from_lines(normalized_lines)
        if not turns:
            raise HTTPException(status_code=400, detail="Unable to build snapshot XML from transcript lines")
        _, oncue_xml, _, updated_lines = build_session_artifacts(
            turns,
            title_data,
            audio_duration,
            lines_per_page,
            enforce_min_line_duration=False,
        )
        xml_b64 = base64.b64encode(oncue_xml.encode("utf-8")).decode()
        source_lines = updated_lines

    created_at = datetime.now(timezone.utc).isoformat()
    snapshot_payload = {
        "media_key": snapshot_media_key(session_data),
        "created_at": created_at,
        "title_data": title_data,
        "title_label": title_data.get("FILE_NAME") or title_data.get("CASE_NAME") or "",
        "audio_duration": audio_duration,
        "lines_per_page": lines_per_page,
        "lines": source_lines,
        "oncue_xml_base64": xml_b64,
        "line_count": len(source_lines),
        "is_manual_save": is_manual_save,
        "user_id": session_data.get("user_id"),
        # CRITICAL: Include media references for playback recovery
        "media_blob_name": media_blob_name,
        "media_content_type": media_content_type,
    }
    viewer_html_b64 = session_data.get("viewer_html_base64")
    if viewer_html_b64:
        snapshot_payload["viewer_html_base64"] = viewer_html_b64
    if session_data.get("source_turns"):
        snapshot_payload["source_turns"] = session_data["source_turns"]
    return snapshot_payload


def parse_iso_datetime(value: Optional[str]) -> Optional[datetime]:
    if not value:
        return None
    try:
        return datetime.fromisoformat(value)
    except ValueError:
        try:
            return datetime.fromisoformat(value.replace("Z", "+00:00"))
        except ValueError:
            return None
===== END FILE =====

===== FILE: backend/viewer/__init__.py =====
"""HTML viewer rendering utilities for criminal/DA-PD variant."""
from __future__ import annotations

import json
from pathlib import Path
from typing import Any, Dict

_TEMPLATE_CACHE: str | None = None
_PLACEHOLDER = "__TRANSCRIPT_JSON__"


def _load_template() -> str:
    global _TEMPLATE_CACHE
    if _TEMPLATE_CACHE is None:
        template_path = Path(__file__).with_name("template.html")
        _TEMPLATE_CACHE = template_path.read_text(encoding="utf-8")
    return _TEMPLATE_CACHE


def get_viewer_template() -> str:
    """Return the raw standalone viewer template HTML."""
    return _load_template()


def render_viewer_html(payload: Dict[str, Any]) -> str:
    """Render the standalone HTML viewer with embedded transcript payload."""
    import re
    template = _load_template()
    json_blob = json.dumps(payload, ensure_ascii=False)
    # Escape </script> case-insensitively to prevent breaking out of script tag
    safe_blob = re.sub(r'</script', r'<\\/script', json_blob, flags=re.IGNORECASE)
    return template.replace(_PLACEHOLDER, safe_blob)
===== END FILE =====

===== FILE: backend/viewer/template.html =====
<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Transcript Viewer</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600&display=swap" rel="stylesheet">
  <style>
    *, *::before, *::after { box-sizing: border-box; }

    :root {
      --page-width: 8.5in;
      --page-margin-left: 1in;
      --page-margin-right: 1in;
      --page-margin-top: 0.75in;
      --page-margin-bottom: 0.75in;
      --line-number-width: 0.7in;
      --font-size: 12pt;
      --line-height: 2.0;
      --lines-per-page: 25;
      --sidebar-width: 320px;

      /* App color palette - slate tones */
      --color-50: #f8fafc;
      --color-100: #f1f5f9;
      --color-200: #e2e8f0;
      --color-300: #cbd5e1;
      --color-400: #94a3b8;
      --color-500: #64748b;
      --color-600: #475569;
      --color-700: #334155;
      --color-800: #1e293b;
      --color-900: #0f172a;

      --bg-app: var(--color-100);
      --bg-sidebar: #ffffff;
      --bg-card: #ffffff;
      --bg-page: #ffffff;
      --text-primary: var(--color-900);
      --text-secondary: var(--color-600);
      --text-muted: var(--color-400);
      --accent: var(--color-700);
      --accent-light: var(--color-600);
      --border: var(--color-200);
      --border-light: var(--color-100);
      --shadow-sm: 0 1px 2px rgba(0,0,0,0.05);
      --shadow-md: 0 4px 6px -1px rgba(0,0,0,0.1), 0 2px 4px -2px rgba(0,0,0,0.1);
      --shadow-lg: 0 10px 15px -3px rgba(0,0,0,0.1), 0 4px 6px -4px rgba(0,0,0,0.1);
      --amber-100: #fef3c7;
      --amber-300: #fcd34d;
      --amber-500: #f59e0b;
    }

    body {
      margin: 0;
      background: var(--bg-app);
      color: var(--text-primary);
      font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
      -webkit-font-smoothing: antialiased;
      min-height: 100vh;
      overflow: hidden;
    }

    .app { height: 100vh; display: flex; }

    /* Sidebar */
    .sidebar {
      width: var(--sidebar-width);
      background: var(--bg-sidebar);
      border-right: 1px solid var(--border);
      display: flex;
      flex-direction: column;
      flex-shrink: 0;
      box-shadow: var(--shadow-md);
      z-index: 50;
    }

    .sidebar.collapsed { display: none; }

    .sidebar-header {
      padding: 16px 20px;
      border-bottom: 1px solid var(--border);
      display: flex;
      justify-content: space-between;
      align-items: center;
      background: var(--accent);
    }

    .sidebar-title {
      font-size: 14px;
      font-weight: 600;
      color: #ffffff;
      display: flex;
      align-items: center;
      gap: 8px;
    }

    .sidebar-close {
      appearance: none;
      border: none;
      background: rgba(255,255,255,0.15);
      color: #ffffff;
      width: 28px;
      height: 28px;
      border-radius: 6px;
      cursor: pointer;
      display: flex;
      align-items: center;
      justify-content: center;
      transition: background 0.15s;
    }
    .sidebar-close:hover { background: rgba(255,255,255,0.25); }
    .sidebar-close svg { width: 16px; height: 16px; fill: currentColor; }

    .sidebar-content { flex: 1; overflow-y: auto; padding: 16px; }

    /* Search */
    .search-box {
      position: relative;
      margin-bottom: 16px;
    }
    .search-input {
      width: 100%;
      padding: 10px 12px;
      padding-right: 90px;
      border: 1px solid var(--border);
      border-radius: 8px;
      font-size: 13px;
      background: var(--color-50);
      color: var(--text-primary);
      outline: none;
      transition: border-color 0.15s, box-shadow 0.15s;
    }
    .search-input:focus { border-color: var(--accent); box-shadow: 0 0 0 3px rgba(51,65,85,0.1); }
    .search-input::placeholder { color: var(--text-muted); }
    .search-controls {
      position: absolute;
      right: 8px;
      top: 50%;
      transform: translateY(-50%);
      display: none;
      align-items: center;
      gap: 2px;
    }
    .search-controls.visible { display: flex; }
    .search-count { font-size: 11px; color: var(--text-muted); margin-right: 4px; }
    .search-btn {
      appearance: none;
      border: none;
      background: transparent;
      color: var(--text-muted);
      width: 24px;
      height: 24px;
      border-radius: 4px;
      cursor: pointer;
      display: flex;
      align-items: center;
      justify-content: center;
      transition: color 0.15s, background 0.15s;
    }
    .search-btn:hover { color: var(--text-primary); background: var(--color-100); }
    .search-btn svg { width: 14px; height: 14px; fill: currentColor; }

    /* Sidebar Sections */
    .sidebar-section { margin-bottom: 20px; }
    .sidebar-section:last-child { margin-bottom: 0; }
    .section-title {
      font-size: 11px;
      font-weight: 600;
      text-transform: uppercase;
      letter-spacing: 0.05em;
      color: var(--text-muted);
      margin-bottom: 10px;
    }

    /* Clip Creator */
    .clip-creator {
      background: var(--color-50);
      border: 1px solid var(--border);
      border-radius: 10px;
      padding: 14px;
      margin-bottom: 16px;
    }
    .clip-creator-title { font-size: 12px; font-weight: 600; color: var(--text-primary); margin-bottom: 12px; }
    .clip-row { display: flex; gap: 8px; margin-bottom: 10px; }
    .clip-input {
      flex: 1;
      padding: 8px 10px;
      border: 1px solid var(--border);
      border-radius: 6px;
      font-size: 12px;
      background: #ffffff;
      color: var(--text-primary);
      outline: none;
    }
    .clip-input:focus { border-color: var(--accent); }
    .clip-input::placeholder { color: var(--text-muted); }
    .clip-time { width: 70px; text-align: center; font-family: 'SF Mono', 'Monaco', monospace; font-size: 11px; }
    .clip-actions { display: flex; gap: 6px; }

    /* Buttons */
    .btn {
      appearance: none;
      border: 1px solid var(--border);
      background: #ffffff;
      color: var(--text-secondary);
      padding: 6px 12px;
      border-radius: 6px;
      font-size: 12px;
      font-weight: 500;
      cursor: pointer;
      display: inline-flex;
      align-items: center;
      gap: 6px;
      transition: all 0.15s;
    }
    .btn:hover { border-color: var(--color-300); background: var(--color-50); color: var(--text-primary); }
    .btn svg { width: 14px; height: 14px; fill: currentColor; }
    .btn-primary {
      background: var(--accent);
      border-color: var(--accent);
      color: #ffffff;
    }
    .btn-primary:hover { background: var(--accent-light); border-color: var(--accent-light); color: #ffffff; }
    .btn-row { display: flex; gap: 8px; margin-bottom: 12px; }
    .btn-row .btn { flex: 1; justify-content: center; }

    /* Clips List */
    .clips-list { max-height: 200px; overflow-y: auto; }
    .clip-item {
      padding: 10px 12px;
      border: 1px solid var(--border);
      border-radius: 8px;
      margin-bottom: 8px;
      cursor: pointer;
      transition: all 0.15s;
      background: #ffffff;
    }
    .clip-item:hover { border-color: var(--color-300); background: var(--color-50); }
    .clip-item.active { border-color: var(--accent); background: rgba(51,65,85,0.05); }
    .clip-item-header { display: flex; justify-content: space-between; align-items: flex-start; }
    .clip-item-name { font-size: 13px; font-weight: 500; color: var(--text-primary); }
    .clip-item-time { font-size: 11px; color: var(--text-muted); margin-top: 2px; }
    .clip-item-delete {
      appearance: none;
      border: none;
      background: transparent;
      color: var(--text-muted);
      width: 22px;
      height: 22px;
      border-radius: 4px;
      cursor: pointer;
      display: flex;
      align-items: center;
      justify-content: center;
    }
    .clip-item-delete:hover { color: #dc2626; background: #fef2f2; }
    .clip-item-delete svg { width: 14px; height: 14px; fill: currentColor; }
    .no-clips { font-size: 12px; color: var(--text-muted); text-align: center; padding: 16px; }

    /* Media */
    .media-meta {
      background: var(--color-50);
      border: 1px solid var(--border);
      border-radius: 8px;
      padding: 10px;
    }
    .media-name {
      font-size: 12px;
      font-weight: 600;
      color: var(--text-primary);
      margin-bottom: 4px;
      white-space: nowrap;
      overflow: hidden;
      text-overflow: ellipsis;
    }
    .media-hint {
      font-size: 11px;
      color: var(--text-muted);
      line-height: 1.4;
    }

    /* Settings */
    .setting-row {
      display: flex;
      justify-content: space-between;
      align-items: center;
      padding: 8px 0;
      font-size: 13px;
      color: var(--text-secondary);
    }
    .setting-toggle {
      width: 40px;
      height: 22px;
      background: var(--color-200);
      border-radius: 11px;
      cursor: pointer;
      position: relative;
      transition: background 0.2s;
    }
    .setting-toggle.active { background: var(--accent); }
    .setting-toggle::after {
      content: '';
      position: absolute;
      top: 3px;
      left: 3px;
      width: 16px;
      height: 16px;
      background: #ffffff;
      border-radius: 50%;
      transition: transform 0.2s;
      box-shadow: var(--shadow-sm);
    }
    .setting-toggle.active::after { transform: translateX(18px); }

    /* View Toggle */
    .view-toggle {
      display: flex;
      background: var(--color-100);
      border-radius: 6px;
      padding: 2px;
    }
    .view-btn {
      appearance: none;
      border: none;
      background: transparent;
      color: var(--text-muted);
      padding: 5px 12px;
      border-radius: 5px;
      font-size: 12px;
      font-weight: 500;
      cursor: pointer;
      transition: all 0.15s;
    }
    .view-btn.active { background: #ffffff; color: var(--text-primary); box-shadow: var(--shadow-sm); }

    /* Main Content */
    .main-content { flex: 1; display: flex; flex-direction: column; min-width: 0; }

    .main-header {
      padding: 12px 20px;
      background: var(--bg-card);
      border-bottom: 1px solid var(--border);
      display: flex;
      align-items: center;
      gap: 12px;
    }

    .menu-btn {
      appearance: none;
      border: 1px solid var(--border);
      background: #ffffff;
      color: var(--text-secondary);
      width: 36px;
      height: 36px;
      border-radius: 8px;
      cursor: pointer;
      display: flex;
      align-items: center;
      justify-content: center;
      transition: all 0.15s;
    }
    .menu-btn:hover { border-color: var(--color-300); color: var(--text-primary); }
    .menu-btn svg { width: 18px; height: 18px; fill: currentColor; }

    .header-title {
      font-size: 14px;
      font-weight: 500;
      color: var(--text-primary);
      flex: 1;
      white-space: nowrap;
      overflow: hidden;
      text-overflow: ellipsis;
    }

    /* Content Area */
    .content-area {
      flex: 1;
      display: flex;
      overflow: hidden;
    }

    /* Video Pane */
    .video-pane {
      flex: 0 0 50%;
      display: flex;
      flex-direction: column;
      background: var(--color-900);
    }

    .video-container {
      flex: 1;
      position: relative;
      display: flex;
      align-items: center;
      justify-content: center;
      background: #000000;
    }

    .video-container video {
      max-width: 100%;
      max-height: 100%;
      width: 100%;
      height: 100%;
      object-fit: contain;
    }

    /* Caption Overlay */
    .caption-overlay {
      position: absolute;
      inset: 0;
      display: none;
      flex-direction: column;
      justify-content: center;
      align-items: stretch;
      background: rgba(0,0,0,0.85);
      padding: 40px 60px;
      pointer-events: none;
      overflow: hidden;
    }
    .video-pane.caption-mode .caption-overlay { display: flex; }
    .caption-line {
      font-family: 'Courier New', Courier, monospace;
      font-size: 14px;
      color: rgba(255,255,255,0.4);
      padding: 4px 12px;
      white-space: pre-wrap;
      transition: all 0.2s ease;
      border-left: 3px solid transparent;
    }
    .caption-line.current {
      color: #ffffff;
      font-weight: 500;
      background: rgba(255,255,255,0.1);
      border-left-color: var(--amber-500);
      font-size: 16px;
      padding: 8px 12px;
    }
    .caption-line.prev-1 { color: rgba(255,255,255,0.6); }
    .caption-line.prev-2 { color: rgba(255,255,255,0.35); }
    .caption-line.next-1 { color: rgba(255,255,255,0.6); }
    .caption-line.next-2 { color: rgba(255,255,255,0.35); }

    /* Title Card */
    .title-card {
      position: absolute;
      inset: 0;
      display: none;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      background: rgba(0,0,0,0.85);
      opacity: 0;
      transition: opacity 0.5s;
    }
    .title-card.visible { display: flex; opacity: 1; }
    .title-card-name { font-size: 28px; font-weight: 600; color: #ffffff; margin-bottom: 8px; }
    .title-card-meta { font-size: 16px; color: rgba(255,255,255,0.7); }

    /* Video Controls */
    .controls {
      background: var(--color-800);
      padding: 12px 16px;
      display: flex;
      align-items: center;
      gap: 12px;
    }

    .ctrl-btn {
      appearance: none;
      border: none;
      background: transparent;
      color: rgba(255,255,255,0.8);
      width: 36px;
      height: 36px;
      border-radius: 8px;
      cursor: pointer;
      display: flex;
      align-items: center;
      justify-content: center;
      transition: all 0.15s;
    }
    .ctrl-btn:hover { background: rgba(255,255,255,0.1); color: #ffffff; }
    .ctrl-btn svg { width: 20px; height: 20px; fill: currentColor; }
    .ctrl-btn.play-btn { width: 42px; height: 42px; }
    .ctrl-btn.play-btn svg { width: 24px; height: 24px; }

    .progress-area { flex: 1; display: flex; align-items: center; gap: 10px; }
    .time-label { font-size: 12px; color: rgba(255,255,255,0.7); font-variant-numeric: tabular-nums; min-width: 50px; }
    .time-label:last-child { text-align: right; }

    .progress-track {
      flex: 1;
      height: 6px;
      background: rgba(255,255,255,0.2);
      border-radius: 3px;
      position: relative;
      cursor: pointer;
    }
    .progress-fill {
      height: 100%;
      background: #ffffff;
      border-radius: 3px;
      width: 0;
      pointer-events: none;
    }
    .progress-input {
      position: absolute;
      inset: 0;
      width: 100%;
      height: 100%;
      opacity: 0;
      cursor: pointer;
      margin: 0;
    }

    .volume-area { display: flex; align-items: center; gap: 6px; }
    .volume-slider {
      width: 70px;
      height: 4px;
      -webkit-appearance: none;
      appearance: none;
      background: rgba(255,255,255,0.3);
      border-radius: 2px;
      cursor: pointer;
    }
    .volume-slider::-webkit-slider-thumb {
      -webkit-appearance: none;
      width: 12px;
      height: 12px;
      background: #ffffff;
      border-radius: 50%;
      cursor: pointer;
    }

    /* Document Pane */
    .document-pane {
      flex: 1;
      display: flex;
      flex-direction: column;
      background: var(--color-100);
      border-left: 1px solid var(--border);
    }

    .doc-header {
      padding: 12px 20px;
      background: var(--bg-card);
      border-bottom: 1px solid var(--border);
      display: flex;
      align-items: center;
      justify-content: space-between;
    }

    .page-info { font-size: 13px; color: var(--text-secondary); }

    .page-nav { display: flex; gap: 6px; }
    .page-btn {
      appearance: none;
      border: 1px solid var(--border);
      background: #ffffff;
      color: var(--text-secondary);
      width: 32px;
      height: 32px;
      border-radius: 6px;
      cursor: pointer;
      display: flex;
      align-items: center;
      justify-content: center;
      transition: all 0.15s;
    }
    .page-btn:hover:not(:disabled) { border-color: var(--color-300); color: var(--text-primary); }
    .page-btn:disabled { opacity: 0.4; cursor: not-allowed; }
    .page-btn svg { width: 16px; height: 16px; fill: currentColor; }

    .doc-scroll {
      flex: 1;
      overflow-y: auto;
      padding: 24px;
      display: flex;
      flex-direction: column;
      align-items: center;
    }

    .doc-page {
      width: var(--page-width);
      max-width: 100%;
      background: var(--bg-page);
      box-shadow: 0 4px 24px rgba(15,23,42,0.12);
      padding: 0.33in;
      position: relative;
      display: none;
    }
    .doc-page.active { display: block; }
    .doc-page::before,
    .doc-page::after {
      content: '';
      position: absolute;
      pointer-events: none;
      border: 1px solid var(--color-400);
    }
    .doc-page::before {
      top: 0.33in; right: 0.33in; bottom: 0.33in; left: 0.33in;
    }
    .doc-page::after {
      top: calc(0.33in + 4px); right: calc(0.33in + 4px); bottom: calc(0.33in + 4px); left: calc(0.33in + 4px);
    }
    .doc-page-inner {
      position: relative;
      padding: calc(var(--page-margin-top) - 0.33in) calc(var(--page-margin-right) - 0.33in) calc(var(--page-margin-bottom) - 0.33in) calc(var(--page-margin-left) - 0.33in);
    }
    .doc-page-number {
      text-align: center;
      font-family: 'Courier New', Courier, monospace;
      font-size: 10px;
      color: var(--text-muted);
      padding-top: 8px;
      user-select: none;
    }

    .doc-line {
      display: flex;
      font-family: 'Courier New', Courier, monospace;
      font-size: var(--font-size);
      line-height: var(--line-height);
      cursor: pointer;
      border-radius: 2px;
      margin: 0 calc(-1 * var(--line-number-width) - 8px) 0 -8px;
      padding: 0 8px 0 calc(var(--line-number-width) + 8px);
      transition: background 0.1s;
    }
    .doc-line:hover { background: var(--color-100); }
    .doc-line.active { background: var(--amber-100); }
    .doc-line.search-match { background: var(--amber-100); }
    .doc-line.search-current { background: var(--amber-300); }

    .line-num {
      width: var(--line-number-width);
      margin-left: calc(-1 * var(--line-number-width));
      flex-shrink: 0;
      color: var(--text-muted);
      font-size: 10px;
      text-align: right;
      padding-right: 12px;
      user-select: none;
    }

    .line-text {
      flex: 1;
      white-space: pre-wrap;
      word-break: break-word;
      color: var(--text-primary);
    }
    .line-text .speaker-name { font-weight: bold; }

    .doc-empty {
      text-align: center;
      padding: 48px;
      color: var(--text-muted);
    }

    /* Audio Waveform Visualizer */
    .waveform-canvas {
      width: 100%;
      height: 100%;
      display: block;
    }

    /* Caption Mode - hide document pane, video takes full width */
    .content-area.caption-mode .document-pane { display: none; }
    .content-area.caption-mode .video-pane { flex: 1; }

    /* Fullscreen - hide sidebar/header but keep transcript view */
    .app.fullscreen .sidebar,
    .app.fullscreen .main-header { display: none !important; }
    .app.fullscreen .video-pane { flex: 0 0 50%; }
    .app.fullscreen .document-pane { flex: 1; }
    .app.fullscreen .controls { background: transparent; position: absolute; bottom: 0; left: 0; right: 0; opacity: 0; transition: opacity 0.3s; z-index: 10; }
    .app.fullscreen:hover .controls { opacity: 1; }
    /* Fullscreen + caption mode - video full with captions */
    .app.fullscreen .content-area.caption-mode .video-pane { flex: 1; }
    .app.fullscreen .content-area.caption-mode .document-pane { display: none; }

    /* Responsive */
    @media (max-width: 1024px) {
      .content-area { flex-direction: column; }
      .video-pane { flex: 0 0 45vh; }
      .document-pane { flex: 1; border-left: none; border-top: 1px solid var(--border); }
      .sidebar { position: fixed; left: 0; top: 0; bottom: 0; box-shadow: var(--shadow-lg); }
    }

    /* Hidden */
    .hidden { display: none !important; }

    /* Print */
    @media print {
      .video-pane, .controls, .sidebar, .main-header, .doc-header { display: none !important; }
      .document-pane { border: none; }
      .doc-scroll { padding: 0; }
      .doc-page { box-shadow: none; border: none; display: block !important; page-break-after: always; }
    }
  </style>
</head>
<body>
  <div class="app" id="app">
    <aside class="sidebar collapsed" id="sidebar">
      <div class="sidebar-header">
        <span class="sidebar-title">
          <svg viewBox="0 0 24 24" width="16" height="16" fill="currentColor"><path d="M14 2H6a2 2 0 00-2 2v16a2 2 0 002 2h12a2 2 0 002-2V8l-6-6zm4 18H6V4h7v5h5v11z"/></svg>
          Transcript Tools
        </span>
        <button type="button" class="sidebar-close" id="sidebarClose" aria-label="Close sidebar">
          <svg viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </div>
      <div class="sidebar-content">
        <div class="search-box">
          <input type="text" class="search-input" id="searchInput" placeholder="Search transcript...">
          <div class="search-controls" id="searchControls">
            <span class="search-count" id="searchCount">0/0</span>
            <button type="button" class="search-btn" id="searchPrev" title="Previous"><svg viewBox="0 0 24 24"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"/></svg></button>
            <button type="button" class="search-btn" id="searchNext" title="Next"><svg viewBox="0 0 24 24"><path d="M7.41 8.59L12 13.17l4.59-4.58L18 10l-6 6-6-6z"/></svg></button>
            <button type="button" class="search-btn" id="searchClear" title="Clear"><svg viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg></button>
          </div>
        </div>

        <div class="clip-creator">
          <div class="clip-creator-title">Create Clip</div>
          <div class="clip-row">
            <input type="text" class="clip-input" id="clipName" placeholder="Clip name">
          </div>
          <div class="clip-row">
            <input type="text" class="clip-input clip-time" id="clipStart" placeholder="0:00">
            <span style="color: var(--text-muted); font-size: 12px;">to</span>
            <input type="text" class="clip-input clip-time" id="clipEnd" placeholder="0:00">
          </div>
          <div class="clip-actions">
            <button type="button" class="btn" id="setStart">Set Start</button>
            <button type="button" class="btn" id="setEnd">Set End</button>
            <button type="button" class="btn btn-primary" id="addClip">Add</button>
          </div>
        </div>

        <div class="sidebar-section">
          <div class="section-title">Clips</div>
          <div class="btn-row">
            <button type="button" class="btn" id="importClips"><svg viewBox="0 0 24 24"><path d="M5 20h14v-2H5v2zm0-10h4v6h6v-6h4l-7-7-7 7z"/></svg>Import</button>
            <button type="button" class="btn" id="exportClips"><svg viewBox="0 0 24 24"><path d="M19 9h-4V3H9v6H5l7 7 7-7zM5 18v2h14v-2H5z"/></svg>Export</button>
          </div>
          <div class="clips-list" id="clipsList">
            <div class="no-clips">No clips yet</div>
          </div>
        </div>

        <div class="sidebar-section">
          <div class="section-title">Media</div>
          <div class="btn-row">
            <button type="button" class="btn" id="loadMediaBtn">
              <svg viewBox="0 0 24 24"><path d="M8 5v14l11-7z"/></svg>
              Load Media
            </button>
          </div>
          <div class="media-meta">
            <div class="media-name" id="mediaName">No media file selected</div>
            <div class="media-hint">Attach a local audio/video file for playback. This does not import transcripts.</div>
          </div>
        </div>

        <div class="sidebar-section">
          <div class="section-title">Transcript Sources</div>
          <div class="btn-row">
            <button type="button" class="btn" id="importSource"><svg viewBox="0 0 24 24"><path d="M19 13h-6v6h-2v-6H5v-2h6V5h2v6h6v2z"/></svg>Add Source</button>
          </div>
          <div id="sourcesList"></div>
        </div>

        <div class="sidebar-section">
          <div class="section-title">Settings</div>
          <div class="setting-row">
            <span>View mode</span>
            <div class="view-toggle">
              <button type="button" class="view-btn active" data-view="document">Doc</button>
              <button type="button" class="view-btn" data-view="caption">Caption</button>
            </div>
          </div>
          <div class="setting-row">
            <span>Title cards</span>
            <div class="setting-toggle" id="titleCardToggle"></div>
          </div>
        </div>
      </div>
    </aside>

    <div class="main-content">
      <div class="main-header">
        <button type="button" class="menu-btn" id="menuBtn" aria-label="Open menu">
          <svg viewBox="0 0 24 24"><path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/></svg>
        </button>
        <div class="header-title" id="headerTitle">Transcript Viewer</div>
        <button type="button" class="menu-btn" id="fullscreenBtn" aria-label="Fullscreen">
          <svg viewBox="0 0 24 24" id="fsIcon"><path d="M7 14H5v5h5v-2H7v-3zm-2-4h2V7h3V5H5v5zm12 7h-3v2h5v-5h-2v3zM14 5v2h3v3h2V5h-5z"/></svg>
        </button>
      </div>

      <div class="content-area" id="contentArea">
        <div class="video-pane" id="videoPane">
          <div class="video-container">
            <video id="video" preload="metadata" playsinline></video>
            <canvas id="waveformCanvas" class="waveform-canvas" style="display:none;"></canvas>
            <div class="caption-overlay" id="captionOverlay">
              <div class="caption-line prev-2" id="captionPrev2"></div>
              <div class="caption-line prev-1" id="captionPrev1"></div>
              <div class="caption-line current" id="captionCurrent"></div>
              <div class="caption-line next-1" id="captionNext1"></div>
              <div class="caption-line next-2" id="captionNext2"></div>
            </div>
            <div class="title-card" id="titleCard">
              <div class="title-card-name" id="titleCardName"></div>
              <div class="title-card-meta" id="titleCardMeta"></div>
            </div>
          </div>
          <div class="controls">
            <button type="button" class="ctrl-btn" id="rewindBtn"><svg viewBox="0 0 24 24"><path d="M11 18V6l-8.5 6 8.5 6zm.5-6l8.5 6V6l-8.5 6z"/></svg></button>
            <button type="button" class="ctrl-btn play-btn" id="playBtn"><svg viewBox="0 0 24 24" id="playIcon"><polygon points="5,3 19,12 5,21"/></svg></button>
            <button type="button" class="ctrl-btn" id="forwardBtn"><svg viewBox="0 0 24 24"><path d="M4 18l8.5-6L4 6v12zm9-12v12l8.5-6L13 6z"/></svg></button>
            <div class="progress-area">
              <span class="time-label" id="currentTime">0:00</span>
              <div class="progress-track">
                <div class="progress-fill" id="progressFill"></div>
                <input type="range" class="progress-input" id="progressBar" min="0" max="100" step="0.1" value="0">
              </div>
              <span class="time-label" id="duration">0:00</span>
            </div>
            <div class="volume-area">
              <button type="button" class="ctrl-btn" id="muteBtn"><svg viewBox="0 0 24 24" id="volIcon"><path d="M3 9v6h4l5 5V4L7 9H3zm13.5 3A4.5 4.5 0 0014 7.97v8.05c1.48-.73 2.5-2.25 2.5-4.02zM14 3.23v2.06c2.89.86 5 3.54 5 6.71s-2.11 5.85-5 6.71v2.06c4.01-.91 7-4.49 7-8.77s-2.99-7.86-7-8.77z"/></svg></button>
              <input type="range" class="volume-slider" id="volumeSlider" min="0" max="1" step="0.01" value="1">
            </div>
          </div>
        </div>

        <div class="document-pane" id="documentPane">
          <div class="doc-header">
            <span class="page-info" id="pageInfo">Page 1 of 1</span>
            <div class="page-nav">
              <button type="button" class="page-btn" id="prevPage" disabled><svg viewBox="0 0 24 24"><path d="M15.41 7.41L14 6l-6 6 6 6 1.41-1.41L10.83 12z"/></svg></button>
              <button type="button" class="page-btn" id="nextPage" disabled><svg viewBox="0 0 24 24"><path d="M10 6L8.59 7.41 13.17 12l-4.58 4.59L10 18l6-6z"/></svg></button>
            </div>
          </div>
          <div class="doc-scroll" id="docScroll">
            <div id="pages"></div>
          </div>
        </div>
      </div>
    </div>
  </div>

  <input type="file" class="hidden" id="importSourceFile" accept=".html,.htm">
  <input type="file" class="hidden" id="importClipsFile" accept=".json">
  <input type="file" class="hidden" id="loadMediaFile" accept="audio/*,video/*">

  <script id="transcript-data" type="application/json">__TRANSCRIPT_JSON__</script>
  <script id="media-data" type="application/octet-stream"></script>
  <script>
(function() {
  'use strict';

  // Parse payload
  const dataEl = document.getElementById('transcript-data');
  const mediaDataEl = document.getElementById('media-data');
  let payload = {};
  try {
    const raw = dataEl ? dataEl.textContent : '{}';
    // Check if it starts with { (valid JSON) rather than __ (placeholder)
    if (raw && raw.charAt(0) === '{') payload = JSON.parse(raw);
  } catch(e) { console.error('JSON parse error:', e); }
  if (dataEl) dataEl.remove();

  // Data
  const allLines = Array.isArray(payload.lines) ? payload.lines : [];
  const meta = payload.meta || {};
  const titleData = meta.title || {};
  const mediaMeta = payload.media || {};
  const durationSec = Number(meta.duration_seconds) || 0;
  const linesPerPage = Number(meta.lines_per_page) || 25;
  const mediaPath = mediaMeta.relative_path || mediaMeta.filename || '';

  // Elements
  const $ = id => document.getElementById(id);
  const app = $('app');
  const sidebar = $('sidebar');
  const menuBtn = $('menuBtn');
  const sidebarClose = $('sidebarClose');
  const video = $('video');
  const playBtn = $('playBtn');
  const playIcon = $('playIcon');
  const rewindBtn = $('rewindBtn');
  const forwardBtn = $('forwardBtn');
  const progressBar = $('progressBar');
  const progressFill = $('progressFill');
  const currentTimeEl = $('currentTime');
  const durationEl = $('duration');
  const muteBtn = $('muteBtn');
  const volIcon = $('volIcon');
  const volumeSlider = $('volumeSlider');
  const fullscreenBtn = $('fullscreenBtn');
  const fsIcon = $('fsIcon');
  const videoPane = $('videoPane');
  const contentArea = $('contentArea');
  const pageInfo = $('pageInfo');
  const prevPage = $('prevPage');
  const nextPage = $('nextPage');
  const pages = $('pages');
  const docScroll = $('docScroll');
  const headerTitle = $('headerTitle');
  const captionPrev2 = $('captionPrev2');
  const captionPrev1 = $('captionPrev1');
  const captionCurrent = $('captionCurrent');
  const captionNext1 = $('captionNext1');
  const captionNext2 = $('captionNext2');
  const titleCard = $('titleCard');
  const titleCardName = $('titleCardName');
  const titleCardMeta = $('titleCardMeta');
  const searchInput = $('searchInput');
  const searchControls = $('searchControls');
  const searchCount = $('searchCount');
  const searchPrev = $('searchPrev');
  const searchNext = $('searchNext');
  const searchClear = $('searchClear');
  const clipName = $('clipName');
  const clipStart = $('clipStart');
  const clipEnd = $('clipEnd');
  const setStartBtn = $('setStart');
  const setEndBtn = $('setEnd');
  const addClipBtn = $('addClip');
  const clipsList = $('clipsList');
  const importClipsBtn = $('importClips');
  const exportClipsBtn = $('exportClips');
  const importSourceBtn = $('importSource');
  const sourcesList = $('sourcesList');
  const titleCardToggle = $('titleCardToggle');
  const importSourceFile = $('importSourceFile');
  const importClipsFile = $('importClipsFile');
  const loadMediaBtn = $('loadMediaBtn');
  const loadMediaFile = $('loadMediaFile');
  const mediaName = $('mediaName');

  // State
  let clips = [];
  let sources = [{ id: 'primary', name: titleData.FILE_NAME || 'Primary', lines: allLines }];
  let currentPage = 0;
  let pageEls = [];
  let lineEls = new Map();
  let activeLineIdx = -1;
  let activeClip = null;
  let viewMode = 'document';
  let showTitleCards = false;
  let searchMatches = [];
  let searchIdx = -1;
  let isFullscreen = false;
  let localMediaUrl = null;

  // Icons
  const icons = {
    play: '<polygon points="5,3 19,12 5,21"/>',
    pause: '<path d="M6 4h4v16H6zM14 4h4v16h-4z"/>',
    volHigh: '<path d="M3 9v6h4l5 5V4L7 9H3zm13.5 3A4.5 4.5 0 0014 7.97v8.05c1.48-.73 2.5-2.25 2.5-4.02zM14 3.23v2.06c2.89.86 5 3.54 5 6.71s-2.11 5.85-5 6.71v2.06c4.01-.91 7-4.49 7-8.77s-2.99-7.86-7-8.77z"/>',
    volMute: '<path d="M16.5 12A4.5 4.5 0 0014 7.97v2.21l2.45 2.45c.03-.2.05-.41.05-.63zm2.5 0c0 .94-.2 1.82-.54 2.64l1.51 1.51A8.796 8.796 0 0021 12c0-4.28-2.99-7.86-7-8.77v2.06c2.89.86 5 3.54 5 6.71zM4.27 3L3 4.27 7.73 9H3v6h4l5 5v-6.73l4.25 4.25c-.67.52-1.42.93-2.25 1.18v2.06a8.99 8.99 0 003.69-1.81L19.73 21 21 19.73l-9-9L4.27 3zM12 4L9.91 6.09 12 8.18V4z"/>',
    fsEnter: '<path d="M7 14H5v5h5v-2H7v-3zm-2-4h2V7h3V5H5v5zm12 7h-3v2h5v-5h-2v3zM14 5v2h3v3h2V5h-5z"/>',
    fsExit: '<path d="M5 16h3v3h2v-5H5v2zm3-8H5v2h5V5H8v3zm6 11h2v-3h3v-2h-5v5zm2-11V5h-2v5h5V8h-3z"/>',
    del: '<path d="M6 19c0 1.1.9 2 2 2h8c1.1 0 2-.9 2-2V7H6v12zM19 4h-3.5l-1-1h-5l-1 1H5v2h14V4z"/>'
  };

  // Utils
  function fmt(sec) {
    if (!Number.isFinite(sec) || sec < 0) return '0:00';
    const s = Math.floor(sec);
    const h = Math.floor(s / 3600);
    const m = Math.floor((s % 3600) / 60);
    const ss = s % 60;
    return h > 0 ? `${h}:${String(m).padStart(2,'0')}:${String(ss).padStart(2,'0')}` : `${m}:${String(ss).padStart(2,'0')}`;
  }

  function parseTime(str) {
    if (!str) return 0;
    const p = str.trim().split(':').map(Number);
    if (p.length === 3) return p[0]*3600 + p[1]*60 + p[2];
    if (p.length === 2) return p[0]*60 + p[1];
    return p[0] || 0;
  }

  // Setup video
  function updateMediaLabel(label) {
    if (!mediaName) return;
    const value = label || 'No media file selected';
    mediaName.textContent = value;
    mediaName.title = value;
  }

  function clearVideoSources() {
    while (video.firstChild) {
      video.removeChild(video.firstChild);
    }
  }

  function setVideoSources(srcList, contentType) {
    clearVideoSources();
    srcList.forEach(src => {
      const s = document.createElement('source');
      s.src = src;
      if (contentType) s.type = contentType;
      video.appendChild(s);
    });
    video.load();
  }

  function setupVideo() {
    const embeddedMedia = mediaDataEl && mediaDataEl.textContent
      ? mediaDataEl.textContent.replace(/\s+/g, '')
      : '';
    if (embeddedMedia) {
      try {
        const binary = atob(embeddedMedia);
        const bytes = new Uint8Array(binary.length);
        for (let i = 0; i < binary.length; i++) {
          bytes[i] = binary.charCodeAt(i);
        }
        const blob = new Blob([bytes], { type: mediaMeta.content_type || 'video/mp4' });
        const url = URL.createObjectURL(blob);
        if (localMediaUrl) {
          URL.revokeObjectURL(localMediaUrl);
        }
        localMediaUrl = url;
        setVideoSources([url], mediaMeta.content_type);
        updateMediaLabel(titleData.FILE_NAME || mediaMeta.filename || 'Embedded media');
        return;
      } catch (err) {
        console.warn('Unable to decode embedded media, falling back to path sources.', err);
      }
    }

    if (!mediaPath) {
      updateMediaLabel('');
      return;
    }
    const paths = [mediaPath];
    const fname = mediaPath.split('/').pop().split('\\').pop();
    if (fname !== mediaPath) paths.push(fname);
    setVideoSources(paths, mediaMeta.content_type);
    updateMediaLabel(titleData.FILE_NAME || fname || mediaPath);
  }

  function loadLocalMedia(file) {
    if (!file) return;
    if (localMediaUrl) {
      URL.revokeObjectURL(localMediaUrl);
    }
    localMediaUrl = URL.createObjectURL(file);
    setVideoSources([localMediaUrl], file.type || mediaMeta.content_type);
    updateMediaLabel(file.name);
  }

  // Build pages
  function buildPages() {
    pages.innerHTML = '';
    lineEls.clear();
    pageEls = [];
    if (!allLines.length) {
      pages.innerHTML = '<div class="doc-empty">No transcript available</div>';
      return;
    }

    const pageMap = new Map();
    allLines.forEach((ln, i) => {
      const pn = ln.page_number || Math.floor(i / linesPerPage) + 1;
      if (!pageMap.has(pn)) pageMap.set(pn, []);
      pageMap.get(pn).push(i);
    });

    const pageNums = Array.from(pageMap.keys()).sort((a,b) => a-b);
    pageNums.forEach((pn, pi) => {
      const pageEl = document.createElement('div');
      pageEl.className = 'doc-page' + (pi === 0 ? ' active' : '');

      const innerEl = document.createElement('div');
      innerEl.className = 'doc-page-inner';

      pageMap.get(pn).forEach(idx => {
        const ln = allLines[idx];
        const row = document.createElement('div');
        row.className = 'doc-line';
        row.dataset.idx = idx;

        const num = document.createElement('span');
        num.className = 'line-num';
        num.textContent = ln.line_number || ((idx % linesPerPage) + 1);

        const txt = document.createElement('span');
        txt.className = 'line-text';
        const lineText = ln.rendered_text || ln.text || '';
        // Bold speaker names (format: "          SPEAKER X:   text")
        if (!ln.is_continuation && ln.speaker) {
          const speakerMatch = lineText.match(/^(\s*)([A-Z][A-Z\s]+:)(\s*)/);
          if (speakerMatch) {
            txt.innerHTML = speakerMatch[1] + '<span class="speaker-name">' + speakerMatch[2] + '</span>' + speakerMatch[3] + lineText.slice(speakerMatch[0].length).replace(/</g, '&lt;').replace(/>/g, '&gt;');
          } else {
            txt.textContent = lineText;
          }
        } else {
          txt.textContent = lineText;
        }

        row.appendChild(num);
        row.appendChild(txt);
        row.addEventListener('click', () => {
          if (typeof ln.start === 'number') {
            video.currentTime = Math.max(0, ln.start - 0.05);
            if (video.paused) video.play().catch(() => {});
          }
        });

        innerEl.appendChild(row);
        lineEls.set(idx, row);
      });

      // Page number at bottom center
      const pageNum = document.createElement('div');
      pageNum.className = 'doc-page-number';
      pageNum.textContent = String(pn);
      innerEl.appendChild(pageNum);

      pageEl.appendChild(innerEl);
      pages.appendChild(pageEl);
      pageEls.push({ el: pageEl, lineIdxs: pageMap.get(pn) });
    });

    updatePageInfo();
  }

  function showPage(idx) {
    if (idx < 0 || idx >= pageEls.length) return;
    pageEls.forEach((p, i) => p.el.classList.toggle('active', i === idx));
    currentPage = idx;
    updatePageInfo();
  }

  function updatePageInfo() {
    pageInfo.textContent = `Page ${currentPage + 1} of ${pageEls.length || 1}`;
    prevPage.disabled = currentPage <= 0;
    nextPage.disabled = currentPage >= pageEls.length - 1;
  }

  // Find active line
  function findLine(t) {
    for (let i = 0; i < allLines.length; i++) {
      const ln = allLines[i];
      if (t >= ln.start && t < ln.end) return i;
    }
    return -1;
  }

  function setActiveLine(idx) {
    if (activeLineIdx === idx) return;
    if (activeLineIdx >= 0) {
      const prev = lineEls.get(activeLineIdx);
      if (prev) prev.classList.remove('active');
    }
    activeLineIdx = idx;
    if (idx >= 0) {
      const el = lineEls.get(idx);
      if (el) {
        el.classList.add('active');
        // Find page
        for (let p = 0; p < pageEls.length; p++) {
          if (pageEls[p].lineIdxs.includes(idx)) {
            if (p !== currentPage) showPage(p);
            break;
          }
        }
        el.scrollIntoView({ behavior: 'smooth', block: 'center' });
      }
    }
  }

  // Captions
  function updateCaptions() {
    if (viewMode !== 'caption') return;
    const get = i => (allLines[i] && allLines[i].rendered_text) || '';
    captionPrev2.textContent = get(activeLineIdx - 2);
    captionPrev1.textContent = get(activeLineIdx - 1);
    captionCurrent.textContent = get(activeLineIdx);
    captionNext1.textContent = get(activeLineIdx + 1);
    captionNext2.textContent = get(activeLineIdx + 2);
  }

  // Time update
  function onTimeUpdate() {
    const t = video.currentTime;
    const d = video.duration || durationSec || 0;
    if (d > 0) {
      const pct = (t / d) * 100;
      progressBar.value = pct;
      progressFill.style.width = pct + '%';
      durationEl.textContent = fmt(d);
    }
    currentTimeEl.textContent = fmt(t);

    const li = findLine(t);
    if (li !== activeLineIdx) {
      setActiveLine(li);
      updateCaptions();
    }

    // Clip end check
    if (activeClip && t >= activeClip.end) {
      video.pause();
      activeClip = null;
    }
  }

  // Controls
  playBtn.addEventListener('click', () => video.paused ? video.play().catch(()=>{}) : video.pause());
  rewindBtn.addEventListener('click', () => video.currentTime = Math.max(0, video.currentTime - 10));
  forwardBtn.addEventListener('click', () => video.currentTime = Math.min(video.duration || 0, video.currentTime + 10));

  progressBar.addEventListener('input', e => {
    const d = video.duration || durationSec || 0;
    if (d) {
      video.currentTime = (Number(e.target.value) / 100) * d;
      progressFill.style.width = e.target.value + '%';
    }
  });

  volumeSlider.addEventListener('input', () => {
    video.volume = Number(volumeSlider.value);
    updateVolIcon();
  });

  muteBtn.addEventListener('click', () => {
    if (video.volume > 0) {
      volumeSlider.dataset.prev = video.volume;
      video.volume = 0;
      volumeSlider.value = 0;
    } else {
      const v = Number(volumeSlider.dataset.prev) || 1;
      video.volume = v;
      volumeSlider.value = v;
    }
    updateVolIcon();
  });

  function updateVolIcon() {
    volIcon.innerHTML = video.volume === 0 ? icons.volMute : icons.volHigh;
  }

  video.addEventListener('play', () => playIcon.innerHTML = icons.pause);
  video.addEventListener('pause', () => playIcon.innerHTML = icons.play);
  video.addEventListener('timeupdate', onTimeUpdate);
  video.addEventListener('loadedmetadata', () => {
    durationEl.textContent = fmt(video.duration);
  });

  // Fullscreen
  fullscreenBtn.addEventListener('click', () => {
    if (!document.fullscreenElement) app.requestFullscreen().catch(()=>{});
    else document.exitFullscreen();
  });

  document.addEventListener('fullscreenchange', () => {
    isFullscreen = !!document.fullscreenElement;
    app.classList.toggle('fullscreen', isFullscreen);
    fsIcon.innerHTML = isFullscreen ? icons.fsExit : icons.fsEnter;
  });

  // Sidebar
  menuBtn.addEventListener('click', () => sidebar.classList.remove('collapsed'));
  sidebarClose.addEventListener('click', () => sidebar.classList.add('collapsed'));

  // Pages
  prevPage.addEventListener('click', () => showPage(currentPage - 1));
  nextPage.addEventListener('click', () => showPage(currentPage + 1));

  // View mode
  document.querySelectorAll('.view-btn').forEach(btn => {
    btn.addEventListener('click', () => {
      viewMode = btn.dataset.view;
      const isCaptionMode = viewMode === 'caption';
      videoPane.classList.toggle('caption-mode', isCaptionMode);
      contentArea.classList.toggle('caption-mode', isCaptionMode);
      document.querySelectorAll('.view-btn').forEach(b => b.classList.toggle('active', b === btn));
      if (isCaptionMode) updateCaptions();
    });
  });

  // Title cards toggle
  titleCardToggle.addEventListener('click', () => {
    showTitleCards = !showTitleCards;
    titleCardToggle.classList.toggle('active', showTitleCards);
  });

  // Search
  function doSearch(q) {
    lineEls.forEach(el => el.classList.remove('search-match', 'search-current'));
    searchMatches = [];
    searchIdx = -1;
    if (!q.trim()) {
      searchControls.classList.remove('visible');
      return;
    }
    const lq = q.toLowerCase();
    allLines.forEach((ln, i) => {
      const txt = (ln.rendered_text || ln.text || '').toLowerCase();
      if (txt.includes(lq)) {
        searchMatches.push(i);
        const el = lineEls.get(i);
        if (el) el.classList.add('search-match');
      }
    });
    searchControls.classList.add('visible');
    if (searchMatches.length) goSearch(0);
    else searchCount.textContent = '0/0';
  }

  function goSearch(idx) {
    if (!searchMatches.length) return;
    if (searchIdx >= 0) {
      const prev = lineEls.get(searchMatches[searchIdx]);
      if (prev) prev.classList.remove('search-current');
    }
    searchIdx = ((idx % searchMatches.length) + searchMatches.length) % searchMatches.length;
    const li = searchMatches[searchIdx];
    const el = lineEls.get(li);
    if (el) {
      el.classList.add('search-current');
      for (let p = 0; p < pageEls.length; p++) {
        if (pageEls[p].lineIdxs.includes(li)) {
          if (p !== currentPage) showPage(p);
          break;
        }
      }
      el.scrollIntoView({ behavior: 'smooth', block: 'center' });
    }
    searchCount.textContent = `${searchIdx + 1}/${searchMatches.length}`;
  }

  searchInput.addEventListener('input', () => doSearch(searchInput.value));
  searchInput.addEventListener('keydown', e => {
    if (e.key === 'Enter') { e.preventDefault(); goSearch(searchIdx + (e.shiftKey ? -1 : 1)); }
    if (e.key === 'Escape') { searchInput.value = ''; doSearch(''); searchInput.blur(); }
  });
  searchPrev.addEventListener('click', () => goSearch(searchIdx - 1));
  searchNext.addEventListener('click', () => goSearch(searchIdx + 1));
  searchClear.addEventListener('click', () => { searchInput.value = ''; doSearch(''); });

  // Clips
  function buildClips() {
    if (!clips.length) {
      clipsList.innerHTML = '<div class="no-clips">No clips yet</div>';
      return;
    }
    clipsList.innerHTML = '';
    clips.forEach((c, i) => {
      const item = document.createElement('div');
      item.className = 'clip-item';
      item.innerHTML = `
        <div class="clip-item-header">
          <div>
            <div class="clip-item-name">${c.name || 'Clip ' + (i+1)}</div>
            <div class="clip-item-time">${fmt(c.start)} - ${fmt(c.end)}</div>
          </div>
          <button type="button" class="clip-item-delete" data-idx="${i}"><svg viewBox="0 0 24 24">${icons.del}</svg></button>
        </div>
      `;
      item.addEventListener('click', e => { if (!e.target.closest('.clip-item-delete')) playClip(i); });
      item.querySelector('.clip-item-delete').addEventListener('click', e => { e.stopPropagation(); deleteClip(i); });
      clipsList.appendChild(item);
    });
  }

  function playClip(idx) {
    const c = clips[idx];
    if (!c) return;
    const doPlay = () => {
      activeClip = { end: c.end };
      video.currentTime = c.start;
      video.play().catch(()=>{});
    };
    if (showTitleCards) {
      titleCardName.textContent = c.name || 'Clip';
      titleCardMeta.textContent = fmt(c.start);
      titleCard.classList.add('visible');
      setTimeout(() => { titleCard.classList.remove('visible'); setTimeout(doPlay, 500); }, 3000);
    } else {
      doPlay();
    }
  }

  function deleteClip(idx) { clips.splice(idx, 1); buildClips(); }

  setStartBtn.addEventListener('click', () => clipStart.value = fmt(video.currentTime));
  setEndBtn.addEventListener('click', () => clipEnd.value = fmt(video.currentTime));
  addClipBtn.addEventListener('click', () => {
    const s = parseTime(clipStart.value);
    const e = parseTime(clipEnd.value);
    if (e > s) {
      clips.push({ name: clipName.value || '', start: s, end: e });
      clipName.value = ''; clipStart.value = ''; clipEnd.value = '';
      buildClips();
    }
  });

  // Import/Export clips
  exportClipsBtn.addEventListener('click', () => {
    if (!clips.length) return;
    const data = JSON.stringify({ clips, exportedAt: new Date().toISOString() }, null, 2);
    const blob = new Blob([data], { type: 'application/json' });
    const a = document.createElement('a');
    a.href = URL.createObjectURL(blob);
    a.download = 'clips.json';
    a.click();
  });

  importClipsBtn.addEventListener('click', () => importClipsFile.click());
  importClipsFile.addEventListener('change', e => {
    const f = e.target.files[0];
    if (!f) return;
    const r = new FileReader();
    r.onload = () => {
      try {
        const d = JSON.parse(r.result);
        if (Array.isArray(d.clips)) { clips = d.clips; buildClips(); }
      } catch(err) { alert('Invalid clips file'); }
    };
    r.readAsText(f);
    e.target.value = '';
  });

  // Import source
  importSourceBtn.addEventListener('click', () => importSourceFile.click());
  importSourceFile.addEventListener('change', e => {
    const f = e.target.files[0];
    if (!f) return;
    const r = new FileReader();
    r.onload = () => {
      try {
        const html = r.result;
        const m = html.match(/<script[^>]*id="transcript-data"[^>]*>([\s\S]*?)<\/script>/);
        if (!m) throw new Error('No transcript data found');
        const json = m[1].trim();
        if (!json || json.charAt(0) !== '{') throw new Error('Template file');
        const d = JSON.parse(json);
        const name = (d.meta?.title?.FILE_NAME) || f.name;
        sources.push({ id: 'src-' + Date.now(), name, lines: d.lines || [] });
        buildSources();
      } catch(err) { alert('Could not import: ' + err.message); }
    };
    r.readAsText(f);
    e.target.value = '';
  });

  // Load local media (playback only, does not import transcripts)
  if (loadMediaBtn && loadMediaFile) {
    loadMediaBtn.addEventListener('click', () => loadMediaFile.click());
    loadMediaFile.addEventListener('change', e => {
      const f = e.target.files[0];
      if (!f) return;
      loadLocalMedia(f);
      e.target.value = '';
    });
  }

  function buildSources() {
    sourcesList.innerHTML = '';
    sources.forEach(s => {
      const item = document.createElement('div');
      item.className = 'clip-item';
      item.innerHTML = `<div class="clip-item-name">${s.name}</div><div class="clip-item-time">${s.lines.length} lines</div>`;
      sourcesList.appendChild(item);
    });
  }

  // Keyboard
  document.addEventListener('keydown', e => {
    if ((e.ctrlKey || e.metaKey) && e.key === 'f') {
      e.preventDefault();
      sidebar.classList.remove('collapsed');
      searchInput.focus();
      searchInput.select();
      return;
    }
    if (e.target.tagName === 'INPUT') return;
    switch(e.key) {
      case ' ': e.preventDefault(); video.paused ? video.play().catch(()=>{}) : video.pause(); break;
      case 'ArrowLeft': video.currentTime = Math.max(0, video.currentTime - 10); break;
      case 'ArrowRight': video.currentTime = Math.min(video.duration || 0, video.currentTime + 10); break;
      case 'ArrowUp': e.preventDefault(); showPage(currentPage - 1); break;
      case 'ArrowDown': e.preventDefault(); showPage(currentPage + 1); break;
      case 'f': case 'F': fullscreenBtn.click(); break;
      case 'c': case 'C': document.querySelector(`.view-btn[data-view="${viewMode === 'caption' ? 'document' : 'caption'}"]`).click(); break;
      case 'Escape': if (isFullscreen) document.exitFullscreen(); break;
    }
  });

  video.addEventListener('dblclick', () => fullscreenBtn.click());

  // Audio waveform visualizer (Web Audio API)
  const waveformCanvas = document.getElementById('waveformCanvas');
  let audioCtx = null;
  let analyser = null;
  let animFrameId = null;
  let waveformConnected = false;

  function isAudioOnly() {
    const ct = (mediaMeta.content_type || '').toLowerCase();
    return ct.startsWith('audio/') || (!ct.startsWith('video/') && !video.videoWidth);
  }

  function initWaveform() {
    if (waveformConnected || !waveformCanvas) return;
    try {
      audioCtx = new (window.AudioContext || window.webkitAudioContext)();
      analyser = audioCtx.createAnalyser();
      analyser.fftSize = 256;
      const source = audioCtx.createMediaElementSource(video);
      source.connect(analyser);
      analyser.connect(audioCtx.destination);
      waveformConnected = true;
    } catch(err) {
      console.warn('Waveform init failed:', err);
    }
  }

  function drawWaveform() {
    if (!analyser || !waveformCanvas) return;
    const ctx = waveformCanvas.getContext('2d');
    const rect = waveformCanvas.parentElement.getBoundingClientRect();
    waveformCanvas.width = rect.width * (window.devicePixelRatio || 1);
    waveformCanvas.height = rect.height * (window.devicePixelRatio || 1);
    ctx.scale(window.devicePixelRatio || 1, window.devicePixelRatio || 1);
    const w = rect.width;
    const h = rect.height;

    const bufLen = analyser.frequencyBinCount;
    const dataArray = new Uint8Array(bufLen);
    analyser.getByteFrequencyData(dataArray);

    ctx.clearRect(0, 0, w, h);

    const barCount = Math.min(bufLen, 80);
    const totalBarWidth = w * 0.85;
    const barW = totalBarWidth / barCount;
    const gap = barW * 0.3;
    const effectiveBarW = barW - gap;
    const startX = (w - totalBarWidth) / 2;
    const centerY = h / 2;

    for (let i = 0; i < barCount; i++) {
      const val = dataArray[i] / 255.0;
      const barH = Math.max(val * (h * 0.45), 2);
      const x = startX + i * barW;

      const gradient = ctx.createLinearGradient(0, centerY - barH, 0, centerY + barH);
      gradient.addColorStop(0, 'rgba(148, 163, 184, 0.9)');
      gradient.addColorStop(0.5, 'rgba(203, 213, 225, 0.95)');
      gradient.addColorStop(1, 'rgba(148, 163, 184, 0.9)');
      ctx.fillStyle = gradient;

      ctx.beginPath();
      const r = Math.min(effectiveBarW / 2, 3);
      const bx = x, by = centerY - barH, bw = effectiveBarW, bh = barH * 2;
      ctx.moveTo(bx + r, by);
      ctx.lineTo(bx + bw - r, by);
      ctx.quadraticCurveTo(bx + bw, by, bx + bw, by + r);
      ctx.lineTo(bx + bw, by + bh - r);
      ctx.quadraticCurveTo(bx + bw, by + bh, bx + bw - r, by + bh);
      ctx.lineTo(bx + r, by + bh);
      ctx.quadraticCurveTo(bx, by + bh, bx, by + bh - r);
      ctx.lineTo(bx, by + r);
      ctx.quadraticCurveTo(bx, by, bx + r, by);
      ctx.fill();
    }

    animFrameId = requestAnimationFrame(drawWaveform);
  }

  function startWaveform() {
    if (!waveformCanvas) return;
    if (!waveformConnected) initWaveform();
    if (audioCtx && audioCtx.state === 'suspended') audioCtx.resume();
    waveformCanvas.style.display = 'block';
    video.style.display = 'none';
    if (!animFrameId) drawWaveform();
  }

  function stopWaveform() {
    if (animFrameId) {
      cancelAnimationFrame(animFrameId);
      animFrameId = null;
    }
  }

  function checkAudioVisual() {
    if (isAudioOnly()) {
      if (!video.paused) startWaveform();
      else {
        if (waveformCanvas) {
          waveformCanvas.style.display = 'block';
          video.style.display = 'none';
        }
        stopWaveform();
      }
    } else {
      if (waveformCanvas) waveformCanvas.style.display = 'none';
      video.style.display = '';
      stopWaveform();
    }
  }

  video.addEventListener('play', checkAudioVisual);
  video.addEventListener('pause', checkAudioVisual);
  video.addEventListener('loadedmetadata', checkAudioVisual);

  // Init
  headerTitle.textContent = titleData.CASE_NAME || titleData.FILE_NAME || 'Transcript Viewer';
  document.title = headerTitle.textContent;
  setupVideo();
  buildPages();
  buildClips();
  buildSources();
  updateVolIcon();
})();
  </script>
</body>
</html>
===== END FILE =====

===== FILE: backend/word_legacy.py =====
"""
Deprecated Word/DOCX helpers.

This module keeps legacy Word logic isolated from the active PDF pipeline.
New transcript exports should use PDF generation in transcript_formatting.py.
"""

import io
import logging
import os
import re
from typing import List, Optional

from docx import Document
from docx.shared import Inches, Pt

try:
    from .models import TranscriptTurn
except ImportError:
    try:
        from models import TranscriptTurn
    except ImportError:
        import models
        TranscriptTurn = models.TranscriptTurn

logger = logging.getLogger(__name__)


def replace_placeholder_text(element, placeholder: str, replacement: str) -> None:
    if hasattr(element, "paragraphs"):
        for paragraph in element.paragraphs:
            replace_placeholder_text(paragraph, placeholder, replacement)
    if hasattr(element, "runs"):
        if placeholder in element.text:
            inline = element.runs
            for idx in range(len(inline)):
                if placeholder in inline[idx].text:
                    inline[idx].text = inline[idx].text.replace(placeholder, replacement)
    if hasattr(element, "tables"):
        for table in element.tables:
            for row in table.rows:
                for cell in row.cells:
                    replace_placeholder_text(cell, placeholder, replacement)


def _resolve_docx_template_path() -> Optional[str]:
    candidates = [
        os.path.join(os.path.dirname(__file__), "..", "transcript_template.docx"),
        os.path.join(os.getcwd(), "transcript_template.docx"),
    ]
    for path in candidates:
        if path and os.path.exists(path):
            return path
    return None


def _resolve_clip_template_path() -> Optional[str]:
    candidates = [
        os.path.join(os.path.dirname(__file__), "..", "clip_template.docx"),
        os.path.join(os.getcwd(), "clip_template.docx"),
    ]
    for path in candidates:
        if path and os.path.exists(path):
            return path
    return None


def create_docx(title_data: dict, transcript_turns: List[TranscriptTurn]) -> bytes:
    """
    Deprecated DOCX export helper retained for legacy workflows only.
    """
    template_path = _resolve_docx_template_path()
    if template_path:
        doc = Document(template_path)
    else:
        logger.warning("DOCX template not found; falling back to a blank document.")
        doc = Document()

    for key, value in title_data.items():
        placeholder = f"{{{{{key}}}}}"
        replace_placeholder_text(doc, placeholder, str(value) if value else "")

    body_placeholder = "{{TRANSCRIPT_BODY}}"
    placeholder_paragraph = None
    for paragraph in doc.paragraphs:
        if body_placeholder in paragraph.text:
            placeholder_paragraph = paragraph
            break

    if placeholder_paragraph:
        paragraph_element = placeholder_paragraph._element
        paragraph_element.getparent().remove(paragraph_element)
        for turn in transcript_turns:
            p = doc.add_paragraph()
            p.paragraph_format.left_indent = Inches(0.0)
            p.paragraph_format.first_line_indent = Inches(1.0)
            p.paragraph_format.line_spacing = 2.0
            p.paragraph_format.space_after = Pt(0)
            p.paragraph_format.widow_control = False

            if not turn.is_continuation:
                speaker_run = p.add_run(f"{turn.speaker.upper()}:   ")
                speaker_run.font.name = "Courier New"
            text_run = p.add_run(turn.text)
            text_run.font.name = "Courier New"
    else:
        for turn in transcript_turns:
            p = doc.add_paragraph()
            p.paragraph_format.left_indent = Inches(0.0)
            p.paragraph_format.first_line_indent = Inches(1.0)
            p.paragraph_format.line_spacing = 2.0
            p.paragraph_format.space_after = Pt(0)
            p.paragraph_format.widow_control = False

            if not turn.is_continuation:
                speaker_run = p.add_run(f"{turn.speaker.upper()}:   ")
                speaker_run.font.name = "Courier New"
            text_run = p.add_run(turn.text)
            text_run.font.name = "Courier New"

    buffer = io.BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer.read()


def create_clip_docx(title_data: dict, transcript_turns: List[TranscriptTurn], clip_title: str) -> bytes:
    """
    Deprecated clip DOCX export helper retained for legacy workflows only.
    """
    template_path = _resolve_clip_template_path()
    if not template_path:
        logger.warning("Clip template not found; falling back to standard template.")
        template_path = _resolve_docx_template_path()

    if template_path:
        doc = Document(template_path)
    else:
        logger.warning("No DOCX template found; using blank document.")
        doc = Document()

    clip_title_data = dict(title_data)
    clip_title_data["CLIP_TITLE"] = clip_title

    for key, value in clip_title_data.items():
        placeholder = f"{{{{{key}}}}}"
        replace_placeholder_text(doc, placeholder, str(value) if value else "")

    body_placeholder = "{{TRANSCRIPT_BODY}}"
    placeholder_paragraph = None
    for paragraph in doc.paragraphs:
        if body_placeholder in paragraph.text:
            placeholder_paragraph = paragraph
            break

    if placeholder_paragraph:
        paragraph_element = placeholder_paragraph._element
        paragraph_element.getparent().remove(paragraph_element)
        for turn in transcript_turns:
            p = doc.add_paragraph()
            p.paragraph_format.left_indent = Inches(0.0)
            p.paragraph_format.first_line_indent = Inches(1.0)
            p.paragraph_format.line_spacing = 2.0
            p.paragraph_format.space_after = Pt(0)
            p.paragraph_format.widow_control = False

            if not turn.is_continuation:
                speaker_run = p.add_run(f"{turn.speaker.upper()}:   ")
                speaker_run.font.name = "Courier New"
            text_run = p.add_run(turn.text)
            text_run.font.name = "Courier New"
    else:
        for turn in transcript_turns:
            p = doc.add_paragraph()
            p.paragraph_format.left_indent = Inches(0.0)
            p.paragraph_format.first_line_indent = Inches(1.0)
            p.paragraph_format.line_spacing = 2.0
            p.paragraph_format.space_after = Pt(0)
            p.paragraph_format.widow_control = False

            if not turn.is_continuation:
                speaker_run = p.add_run(f"{turn.speaker.upper()}:   ")
                speaker_run.font.name = "Courier New"
            text_run = p.add_run(turn.text)
            text_run.font.name = "Courier New"

    buffer = io.BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer.read()


def parse_docx_to_turns(docx_bytes: bytes) -> List[dict]:
    """
    Parse a DOCX transcript into speaker/text turns.
    """
    buffer = io.BytesIO(docx_bytes)
    doc = Document(buffer)

    title_page_patterns = [
        r"^generated\s+transcript\s*$",
        r"^case\s+name:\s*",
        r"^case\s+number:\s*",
        r"^date:\s*",
        r"^time:\s*",
        r"^location:\s*",
        r"^original\s+file:\s*",
        r"^duration:\s*",
        r"^firm\s*(name|or\s+organization)?\s*:\s*",
    ]
    title_page_regex = re.compile("|".join(title_page_patterns), re.IGNORECASE)

    turns = []
    for para in doc.paragraphs:
        text = para.text.strip()
        if not text:
            continue

        if title_page_regex.match(text):
            continue

        match = re.match(r"^([A-Z][A-Z0-9\s\-\.\']*?):\s{1,5}(.+)$", text, re.IGNORECASE)
        if match:
            speaker = match.group(1).strip().upper()
            content = match.group(2).strip()
            if speaker and content:
                turns.append(
                    {
                        "speaker": speaker,
                        "text": content,
                        "is_continuation": bool(turns and turns[-1]["speaker"] == speaker),
                    }
                )
        else:
            if turns and not text.startswith("["):
                turns.append(
                    {
                        "speaker": turns[-1]["speaker"],
                        "text": text,
                        "is_continuation": True,
                    }
                )
            elif text and not text.startswith("["):
                turns.append(
                    {
                        "speaker": "UNKNOWN",
                        "text": text,
                        "is_continuation": False,
                    }
                )

    logger.info("Parsed %d turns from DOCX (legacy parser)", len(turns))
    return turns
===== END FILE =====

===== FILE: cloudbuild-criminal.yaml =====
steps:
  # Build the container image for Criminal (DA/PD) variant
  - name: 'gcr.io/cloud-builders/docker'
    args:
      - 'build'
      - '--build-arg'
      - 'APP_VARIANT=criminal'
      - '-t'
      - 'us-central1-docker.pkg.dev/$PROJECT_ID/transcribealpha/app-criminal:$COMMIT_SHA'
      - '.'

  # Push the container image to Artifact Registry
  - name: 'gcr.io/cloud-builders/docker'
    args: ['push', 'us-central1-docker.pkg.dev/$PROJECT_ID/transcribealpha/app-criminal:$COMMIT_SHA']

  # Deploy container image to Cloud Run
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: gcloud
    args:
      - 'run'
      - 'deploy'
      - 'transcribealpha-criminal'
      - '--image'
      - 'us-central1-docker.pkg.dev/$PROJECT_ID/transcribealpha/app-criminal:$COMMIT_SHA'
      - '--region'
      - 'us-central1'
      - '--platform'
      - 'managed'
      - '--allow-unauthenticated'
      - '--memory'
      - '2Gi'
      - '--cpu'
      - '1'
      - '--max-instances'
      - '10'
      - '--timeout'
      - '900'
      - '--port'
      - '8080'
      - '--use-http2'
      - '--set-env-vars'
      - 'APP_VARIANT=criminal,ASSEMBLYAI_API_KEY=${_ASSEMBLYAI_API_KEY},GEMINI_API_KEY=${_GEMINI_API_KEY},GEMINI_MODEL_NAME=${_GEMINI_MODEL_NAME},JWT_SECRET_KEY=${_JWT_SECRET_KEY},REV_AI_API_KEY=${_REV_AI_API_KEY},ENVIRONMENT=production,GOOGLE_CLOUD_PROJECT=${PROJECT_ID}'

# Store images in Google Artifact Registry
images:
  - us-central1-docker.pkg.dev/$PROJECT_ID/transcribealpha/app-criminal:$COMMIT_SHA

# Substitution variables (set these in Cloud Build trigger)
substitutions:
  _ASSEMBLYAI_API_KEY: 'your-assemblyai-key-here'
  _GEMINI_API_KEY: 'your-gemini-key-here'
  _GEMINI_MODEL_NAME: 'models/gemini-3-pro-preview'
  _JWT_SECRET_KEY: 'your-jwt-secret-key-here-use-a-long-random-string'
  _REV_AI_API_KEY: 'your-rev-ai-key-here'

# Build options
options:
  logging: CLOUD_LOGGING_ONLY
  machineType: 'E2_HIGHCPU_8'

# Build timeout
timeout: '1200s'
===== END FILE =====

===== FILE: cloudbuild-oncue.yaml =====
steps:
  # Build the container image for OnCue variant
  - name: 'gcr.io/cloud-builders/docker'
    args:
      - 'build'
      - '--build-arg'
      - 'APP_VARIANT=oncue'
      - '-t'
      - 'us-central1-docker.pkg.dev/$PROJECT_ID/transcribealpha/app-oncue:$COMMIT_SHA'
      - '.'

  # Push the container image to Artifact Registry
  - name: 'gcr.io/cloud-builders/docker'
    args: ['push', 'us-central1-docker.pkg.dev/$PROJECT_ID/transcribealpha/app-oncue:$COMMIT_SHA']

  # Deploy container image to Cloud Run
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: gcloud
    args:
      - 'run'
      - 'deploy'
      - 'transcribealpha-assemblyai'
      - '--image'
      - 'us-central1-docker.pkg.dev/$PROJECT_ID/transcribealpha/app-oncue:$COMMIT_SHA'
      - '--region'
      - 'us-central1'
      - '--platform'
      - 'managed'
      - '--allow-unauthenticated'
      - '--memory'
      - '2Gi'
      - '--cpu'
      - '1'
      - '--max-instances'
      - '10'
      - '--port'
      - '8080'
      - '--use-http2'
      - '--set-env-vars'
      - 'APP_VARIANT=oncue,ASSEMBLYAI_API_KEY=${_ASSEMBLYAI_API_KEY},GEMINI_API_KEY=${_GEMINI_API_KEY},GEMINI_MODEL_NAME=${_GEMINI_MODEL_NAME},JWT_SECRET_KEY=${_JWT_SECRET_KEY},REV_AI_API_KEY=${_REV_AI_API_KEY},ENVIRONMENT=production,GOOGLE_CLOUD_PROJECT=${PROJECT_ID}'

# Store images in Google Artifact Registry
images:
  - us-central1-docker.pkg.dev/$PROJECT_ID/transcribealpha/app-oncue:$COMMIT_SHA

# Substitution variables (set these in Cloud Build trigger)
substitutions:
  _ASSEMBLYAI_API_KEY: 'your-assemblyai-key-here'
  _GEMINI_API_KEY: 'your-gemini-key-here'
  _GEMINI_MODEL_NAME: 'models/gemini-3-pro-preview'
  _JWT_SECRET_KEY: 'your-jwt-secret-key-here-use-a-long-random-string'
  _REV_AI_API_KEY: 'your-rev-ai-key-here'

# Build options
options:
  logging: CLOUD_LOGGING_ONLY
  machineType: 'E2_HIGHCPU_8'

# Build timeout
timeout: '1200s'
===== END FILE =====

===== FILE: cloudbuild.yaml =====
steps:
  # Build the container image
  - name: 'gcr.io/cloud-builders/docker'
    args: ['build', '-t', 'us-central1-docker.pkg.dev/$PROJECT_ID/transcribealpha/app:$COMMIT_SHA', '.']
  
  # Push the container image to Artifact Registry
  - name: 'gcr.io/cloud-builders/docker'
    args: ['push', 'us-central1-docker.pkg.dev/$PROJECT_ID/transcribealpha/app:$COMMIT_SHA']
  
  # Deploy container image to Cloud Run
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: gcloud
    args:
      - 'run'
      - 'deploy'
      - 'transcribealpha-assemblyai'
      - '--image'
      - 'us-central1-docker.pkg.dev/$PROJECT_ID/transcribealpha/app:$COMMIT_SHA'
      - '--region'
      - 'us-central1'
      - '--platform'
      - 'managed'
      - '--allow-unauthenticated'
      - '--memory'
      - '2Gi'
      - '--cpu'
      - '1'
      - '--max-instances'
      - '10'
      - '--port'
      - '8080'
      - '--use-http2'
      - '--set-env-vars'
      - 'ASSEMBLYAI_API_KEY=${_ASSEMBLYAI_API_KEY},GEMINI_API_KEY=${_GEMINI_API_KEY},GEMINI_MODEL_NAME=${_GEMINI_MODEL_NAME},JWT_SECRET_KEY=${_JWT_SECRET_KEY},REV_AI_API_KEY=${_REV_AI_API_KEY},ENVIRONMENT=production,GOOGLE_CLOUD_PROJECT=${PROJECT_ID}'

# Store images in Google Artifact Registry
images:
  - us-central1-docker.pkg.dev/$PROJECT_ID/transcribealpha/app:$COMMIT_SHA

# Substitution variables (set these in Cloud Build trigger)
substitutions:
  _ASSEMBLYAI_API_KEY: 'your-assemblyai-key-here'
  _GEMINI_API_KEY: 'your-gemini-key-here'
  _GEMINI_MODEL_NAME: 'models/gemini-3-pro-preview'
  _JWT_SECRET_KEY: 'your-jwt-secret-key-here-use-a-long-random-string'
  _REV_AI_API_KEY: 'your-rev-ai-key-here'

# Build options
options:
  logging: CLOUD_LOGGING_ONLY
  machineType: 'E2_HIGHCPU_8'

# Build timeout
timeout: '1200s'

# Trigger rebuild (no functional changes)
===== END FILE =====

===== FILE: frontend-next/.eslintrc.json =====
{
  "extends": "next/core-web-vitals"
}
===== END FILE =====

===== FILE: frontend-next/next-env.d.ts =====
/// <reference types="next" />
/// <reference types="next/image-types/global" />

// NOTE: This file should not be edited
// see https://nextjs.org/docs/basic-features/typescript for more information.
===== END FILE =====

===== FILE: frontend-next/next.config.js =====
/** @type {import('next').NextConfig} */
const nextConfig = {
  output: 'export',
  trailingSlash: true,
  images: {
    unoptimized: true
  },
  assetPrefix: '',
  basePath: '',
}

module.exports = nextConfig
===== END FILE =====

===== FILE: frontend-next/package-lock.json =====
{
  "name": "transcribealpha-frontend",
  "version": "1.0.0",
  "lockfileVersion": 3,
  "requires": true,
  "packages": {
    "": {
      "name": "transcribealpha-frontend",
      "version": "1.0.0",
      "hasInstallScript": true,
      "dependencies": {
        "@ffmpeg/core": "^0.12.10",
        "@ffmpeg/ffmpeg": "^0.12.15",
        "@ffmpeg/util": "^0.12.2",
        "@types/node": "^20.0.0",
        "@types/react": "^18.2.0",
        "@types/react-dom": "^18.2.0",
        "jszip": "^3.10.1",
        "next": "14.0.0",
        "react": "^18.2.0",
        "react-dom": "^18.2.0",
        "typescript": "^5.0.0",
        "wavesurfer.js": "^7.12.1"
      },
      "devDependencies": {
        "autoprefixer": "^10.4.0",
        "eslint": "^8.0.0",
        "eslint-config-next": "14.0.0",
        "postcss": "^8.4.0",
        "tailwindcss": "^3.3.0"
      }
    },
    "node_modules/@alloc/quick-lru": {
      "version": "5.2.0",
      "resolved": "https://registry.npmjs.org/@alloc/quick-lru/-/quick-lru-5.2.0.tgz",
      "integrity": "sha512-UrcABB+4bUrFABwbluTIBErXwvbsU/V7TZWfmbgJfbkwiBuziS9gxdODUyuiecfdGQ85jglMW6juS3+z5TsKLw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/@emnapi/core": {
      "version": "1.4.5",
      "resolved": "https://registry.npmjs.org/@emnapi/core/-/core-1.4.5.tgz",
      "integrity": "sha512-XsLw1dEOpkSX/WucdqUhPWP7hDxSvZiY+fsUC14h+FtQ2Ifni4znbBt8punRX+Uj2JG/uDb8nEHVKvrVlvdZ5Q==",
      "dev": true,
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "@emnapi/wasi-threads": "1.0.4",
        "tslib": "^2.4.0"
      }
    },
    "node_modules/@emnapi/runtime": {
      "version": "1.4.5",
      "resolved": "https://registry.npmjs.org/@emnapi/runtime/-/runtime-1.4.5.tgz",
      "integrity": "sha512-++LApOtY0pEEz1zrd9vy1/zXVaVJJ/EbAF3u0fXIzPJEDtnITsBGbbK0EkM72amhl/R5b+5xx0Y/QhcVOpuulg==",
      "dev": true,
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "tslib": "^2.4.0"
      }
    },
    "node_modules/@emnapi/wasi-threads": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/@emnapi/wasi-threads/-/wasi-threads-1.0.4.tgz",
      "integrity": "sha512-PJR+bOmMOPH8AtcTGAyYNiuJ3/Fcoj2XN/gBEWzDIKh254XO+mM9XoXHk5GNEhodxeMznbg7BlRojVbKN+gC6g==",
      "dev": true,
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "tslib": "^2.4.0"
      }
    },
    "node_modules/@eslint-community/eslint-utils": {
      "version": "4.7.0",
      "resolved": "https://registry.npmjs.org/@eslint-community/eslint-utils/-/eslint-utils-4.7.0.tgz",
      "integrity": "sha512-dyybb3AcajC7uha6CvhdVRJqaKyn7w2YKqKyAN37NKYgZT36w+iRb0Dymmc5qEJ549c/S31cMMSFd75bteCpCw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "eslint-visitor-keys": "^3.4.3"
      },
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      },
      "peerDependencies": {
        "eslint": "^6.0.0 || ^7.0.0 || >=8.0.0"
      }
    },
    "node_modules/@eslint-community/regexpp": {
      "version": "4.12.1",
      "resolved": "https://registry.npmjs.org/@eslint-community/regexpp/-/regexpp-4.12.1.tgz",
      "integrity": "sha512-CCZCDJuduB9OUkFkY2IgppNZMi2lBQgD2qzwXkEia16cge2pijY/aXi96CJMquDMn3nJdlPV1A5KrJEXwfLNzQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": "^12.0.0 || ^14.0.0 || >=16.0.0"
      }
    },
    "node_modules/@eslint/eslintrc": {
      "version": "2.1.4",
      "resolved": "https://registry.npmjs.org/@eslint/eslintrc/-/eslintrc-2.1.4.tgz",
      "integrity": "sha512-269Z39MS6wVJtsoUl10L60WdkhJVdPG24Q4eZTH3nnF6lpvSShEK3wQjDX9JRWAUPvPh7COouPpU9IrqaZFvtQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ajv": "^6.12.4",
        "debug": "^4.3.2",
        "espree": "^9.6.0",
        "globals": "^13.19.0",
        "ignore": "^5.2.0",
        "import-fresh": "^3.2.1",
        "js-yaml": "^4.1.0",
        "minimatch": "^3.1.2",
        "strip-json-comments": "^3.1.1"
      },
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      }
    },
    "node_modules/@eslint/js": {
      "version": "8.57.1",
      "resolved": "https://registry.npmjs.org/@eslint/js/-/js-8.57.1.tgz",
      "integrity": "sha512-d9zaMRSTIKDLhctzH12MtXvJKSSUhaHcjV+2Z+GK+EEY7XKpP5yR4x+N3TAcHTcu963nIr+TMcCb4DBCYX1z6Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      }
    },
    "node_modules/@ffmpeg/core": {
      "version": "0.12.10",
      "resolved": "https://registry.npmjs.org/@ffmpeg/core/-/core-0.12.10.tgz",
      "integrity": "sha512-dzNplnn2Nxle2c2i2rrDhqcB19q9cglCkWnoMTDN9Q9l3PvdjZWd1HfSPjCNWc/p8Q3CT+Es9fWOR0UhAeYQZA==",
      "license": "GPL-2.0-or-later",
      "engines": {
        "node": ">=16.x"
      }
    },
    "node_modules/@ffmpeg/ffmpeg": {
      "version": "0.12.15",
      "resolved": "https://registry.npmjs.org/@ffmpeg/ffmpeg/-/ffmpeg-0.12.15.tgz",
      "integrity": "sha512-1C8Obr4GsN3xw+/1Ww6PFM84wSQAGsdoTuTWPOj2OizsRDLT4CXTaVjPhkw6ARyDus1B9X/L2LiXHqYYsGnRFw==",
      "license": "MIT",
      "dependencies": {
        "@ffmpeg/types": "^0.12.4"
      },
      "engines": {
        "node": ">=18.x"
      }
    },
    "node_modules/@ffmpeg/types": {
      "version": "0.12.4",
      "resolved": "https://registry.npmjs.org/@ffmpeg/types/-/types-0.12.4.tgz",
      "integrity": "sha512-k9vJQNBGTxE5AhYDtOYR5rO5fKsspbg51gbcwtbkw2lCdoIILzklulcjJfIDwrtn7XhDeF2M+THwJ2FGrLeV6A==",
      "license": "MIT",
      "engines": {
        "node": ">=16.x"
      }
    },
    "node_modules/@ffmpeg/util": {
      "version": "0.12.2",
      "resolved": "https://registry.npmjs.org/@ffmpeg/util/-/util-0.12.2.tgz",
      "integrity": "sha512-ouyoW+4JB7WxjeZ2y6KpRvB+dLp7Cp4ro8z0HIVpZVCM7AwFlHa0c4R8Y/a4M3wMqATpYKhC7lSFHQ0T11MEDw==",
      "license": "MIT",
      "engines": {
        "node": ">=18.x"
      }
    },
    "node_modules/@humanwhocodes/config-array": {
      "version": "0.13.0",
      "resolved": "https://registry.npmjs.org/@humanwhocodes/config-array/-/config-array-0.13.0.tgz",
      "integrity": "sha512-DZLEEqFWQFiyK6h5YIeynKx7JlvCYWL0cImfSRXZ9l4Sg2efkFGTuFf6vzXjK1cq6IYkU+Eg/JizXw+TD2vRNw==",
      "deprecated": "Use @eslint/config-array instead",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "@humanwhocodes/object-schema": "^2.0.3",
        "debug": "^4.3.1",
        "minimatch": "^3.0.5"
      },
      "engines": {
        "node": ">=10.10.0"
      }
    },
    "node_modules/@humanwhocodes/module-importer": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/@humanwhocodes/module-importer/-/module-importer-1.0.1.tgz",
      "integrity": "sha512-bxveV4V8v5Yb4ncFTT3rPSgZBOpCkjfK0y4oVVVJwIuDVBRMDXrPyXRL988i5ap9m9bnyEEjWfm5WkBmtffLfA==",
      "dev": true,
      "license": "Apache-2.0",
      "engines": {
        "node": ">=12.22"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/nzakas"
      }
    },
    "node_modules/@humanwhocodes/object-schema": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/@humanwhocodes/object-schema/-/object-schema-2.0.3.tgz",
      "integrity": "sha512-93zYdMES/c1D69yZiKDBj0V24vqNzB/koF26KPaagAfd3P/4gUlh3Dys5ogAK+Exi9QyzlD8x/08Zt7wIKcDcA==",
      "deprecated": "Use @eslint/object-schema instead",
      "dev": true,
      "license": "BSD-3-Clause"
    },
    "node_modules/@isaacs/cliui": {
      "version": "8.0.2",
      "resolved": "https://registry.npmjs.org/@isaacs/cliui/-/cliui-8.0.2.tgz",
      "integrity": "sha512-O8jcjabXaleOG9DQ0+ARXWZBTfnP4WNAqzuiJK7ll44AmxGKv/J2M4TPjxjY3znBCfvBXFzucm1twdyFybFqEA==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "string-width": "^5.1.2",
        "string-width-cjs": "npm:string-width@^4.2.0",
        "strip-ansi": "^7.0.1",
        "strip-ansi-cjs": "npm:strip-ansi@^6.0.1",
        "wrap-ansi": "^8.1.0",
        "wrap-ansi-cjs": "npm:wrap-ansi@^7.0.0"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@isaacs/cliui/node_modules/ansi-regex": {
      "version": "6.1.0",
      "resolved": "https://registry.npmjs.org/ansi-regex/-/ansi-regex-6.1.0.tgz",
      "integrity": "sha512-7HSX4QQb4CspciLpVFwyRe79O3xsIZDDLER21kERQ71oaPodF8jL725AgJMFAYbooIqolJoRLuM81SpeUkpkvA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-regex?sponsor=1"
      }
    },
    "node_modules/@isaacs/cliui/node_modules/strip-ansi": {
      "version": "7.1.0",
      "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-7.1.0.tgz",
      "integrity": "sha512-iq6eVVI64nQQTRYq2KtEg2d2uU7LElhTJwsH4YzIHZshxlgZms/wIc4VoDQTlG/IvVIrBKG06CrZnp0qv7hkcQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-regex": "^6.0.1"
      },
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/strip-ansi?sponsor=1"
      }
    },
    "node_modules/@jridgewell/gen-mapping": {
      "version": "0.3.13",
      "resolved": "https://registry.npmjs.org/@jridgewell/gen-mapping/-/gen-mapping-0.3.13.tgz",
      "integrity": "sha512-2kkt/7niJ6MgEPxF0bYdQ6etZaA+fQvDcLKckhy1yIQOzaoKjBBjSj63/aLVjYE3qhRt5dvM+uUyfCg6UKCBbA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jridgewell/sourcemap-codec": "^1.5.0",
        "@jridgewell/trace-mapping": "^0.3.24"
      }
    },
    "node_modules/@jridgewell/resolve-uri": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/@jridgewell/resolve-uri/-/resolve-uri-3.1.2.tgz",
      "integrity": "sha512-bRISgCIjP20/tbWSPWMEi54QVPRZExkuD9lJL+UIxUKtwVJA8wW1Trb1jMs1RFXo1CBTNZ/5hpC9QvmKWdopKw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.0.0"
      }
    },
    "node_modules/@jridgewell/sourcemap-codec": {
      "version": "1.5.5",
      "resolved": "https://registry.npmjs.org/@jridgewell/sourcemap-codec/-/sourcemap-codec-1.5.5.tgz",
      "integrity": "sha512-cYQ9310grqxueWbl+WuIUIaiUaDcj7WOq5fVhEljNVgRfOUhY9fy2zTvfoqWsnebh8Sl70VScFbICvJnLKB0Og==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@jridgewell/trace-mapping": {
      "version": "0.3.30",
      "resolved": "https://registry.npmjs.org/@jridgewell/trace-mapping/-/trace-mapping-0.3.30.tgz",
      "integrity": "sha512-GQ7Nw5G2lTu/BtHTKfXhKHok2WGetd4XYcVKGx00SjAk8GMwgJM3zr6zORiPGuOE+/vkc90KtTosSSvaCjKb2Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jridgewell/resolve-uri": "^3.1.0",
        "@jridgewell/sourcemap-codec": "^1.4.14"
      }
    },
    "node_modules/@napi-rs/wasm-runtime": {
      "version": "0.2.12",
      "resolved": "https://registry.npmjs.org/@napi-rs/wasm-runtime/-/wasm-runtime-0.2.12.tgz",
      "integrity": "sha512-ZVWUcfwY4E/yPitQJl481FjFo3K22D6qF0DuFH6Y/nbnE11GY5uguDxZMGXPQ8WQ0128MXQD7TnfHyK4oWoIJQ==",
      "dev": true,
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "@emnapi/core": "^1.4.3",
        "@emnapi/runtime": "^1.4.3",
        "@tybys/wasm-util": "^0.10.0"
      }
    },
    "node_modules/@next/env": {
      "version": "14.0.0",
      "resolved": "https://registry.npmjs.org/@next/env/-/env-14.0.0.tgz",
      "integrity": "sha512-cIKhxkfVELB6hFjYsbtEeTus2mwrTC+JissfZYM0n+8Fv+g8ucUfOlm3VEDtwtwydZ0Nuauv3bl0qF82nnCAqA==",
      "license": "MIT"
    },
    "node_modules/@next/eslint-plugin-next": {
      "version": "14.0.0",
      "resolved": "https://registry.npmjs.org/@next/eslint-plugin-next/-/eslint-plugin-next-14.0.0.tgz",
      "integrity": "sha512-Ye37nNI09V3yt7pzuzSQtwlvuJ2CGzFszHXkcTHHZgNr7EhTMFLipn3VSJChy+e5+ahTdNApPphc3qCPUsn10A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "glob": "7.1.7"
      }
    },
    "node_modules/@next/swc-darwin-arm64": {
      "version": "14.0.0",
      "resolved": "https://registry.npmjs.org/@next/swc-darwin-arm64/-/swc-darwin-arm64-14.0.0.tgz",
      "integrity": "sha512-HQKi159jCz4SRsPesVCiNN6tPSAFUkOuSkpJsqYTIlbHLKr1mD6be/J0TvWV6fwJekj81bZV9V/Tgx3C2HO9lA==",
      "cpu": [
        "arm64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/swc-darwin-x64": {
      "version": "14.0.0",
      "resolved": "https://registry.npmjs.org/@next/swc-darwin-x64/-/swc-darwin-x64-14.0.0.tgz",
      "integrity": "sha512-4YyQLMSaCgX/kgC1jjF3s3xSoBnwHuDhnF6WA1DWNEYRsbOOPWjcYhv8TKhRe2ApdOam+VfQSffC4ZD+X4u1Cg==",
      "cpu": [
        "x64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/swc-linux-arm64-gnu": {
      "version": "14.0.0",
      "resolved": "https://registry.npmjs.org/@next/swc-linux-arm64-gnu/-/swc-linux-arm64-gnu-14.0.0.tgz",
      "integrity": "sha512-io7fMkJ28Glj7SH8yvnlD6naIhRDnDxeE55CmpQkj3+uaA2Hko6WGY2pT5SzpQLTnGGnviK85cy8EJ2qsETj/g==",
      "cpu": [
        "arm64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/swc-linux-arm64-musl": {
      "version": "14.0.0",
      "resolved": "https://registry.npmjs.org/@next/swc-linux-arm64-musl/-/swc-linux-arm64-musl-14.0.0.tgz",
      "integrity": "sha512-nC2h0l1Jt8LEzyQeSs/BKpXAMe0mnHIMykYALWaeddTqCv5UEN8nGO3BG8JAqW/Y8iutqJsaMe2A9itS0d/r8w==",
      "cpu": [
        "arm64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/swc-linux-x64-gnu": {
      "version": "14.0.0",
      "resolved": "https://registry.npmjs.org/@next/swc-linux-x64-gnu/-/swc-linux-x64-gnu-14.0.0.tgz",
      "integrity": "sha512-Wf+WjXibJQ7hHXOdNOmSMW5bxeJHVf46Pwb3eLSD2L76NrytQlif9NH7JpHuFlYKCQGfKfgSYYre5rIfmnSwQw==",
      "cpu": [
        "x64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/swc-linux-x64-musl": {
      "version": "14.0.0",
      "resolved": "https://registry.npmjs.org/@next/swc-linux-x64-musl/-/swc-linux-x64-musl-14.0.0.tgz",
      "integrity": "sha512-WTZb2G7B+CTsdigcJVkRxfcAIQj7Lf0ipPNRJ3vlSadU8f0CFGv/ST+sJwF5eSwIe6dxKoX0DG6OljDBaad+rg==",
      "cpu": [
        "x64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/swc-win32-arm64-msvc": {
      "version": "14.0.0",
      "resolved": "https://registry.npmjs.org/@next/swc-win32-arm64-msvc/-/swc-win32-arm64-msvc-14.0.0.tgz",
      "integrity": "sha512-7R8/x6oQODmNpnWVW00rlWX90sIlwluJwcvMT6GXNIBOvEf01t3fBg0AGURNKdTJg2xNuP7TyLchCL7Lh2DTiw==",
      "cpu": [
        "arm64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/swc-win32-ia32-msvc": {
      "version": "14.0.0",
      "resolved": "https://registry.npmjs.org/@next/swc-win32-ia32-msvc/-/swc-win32-ia32-msvc-14.0.0.tgz",
      "integrity": "sha512-RLK1nELvhCnxaWPF07jGU4x3tjbyx2319q43loZELqF0+iJtKutZ+Lk8SVmf/KiJkYBc7Cragadz7hb3uQvz4g==",
      "cpu": [
        "ia32"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/swc-win32-x64-msvc": {
      "version": "14.0.0",
      "resolved": "https://registry.npmjs.org/@next/swc-win32-x64-msvc/-/swc-win32-x64-msvc-14.0.0.tgz",
      "integrity": "sha512-g6hLf1SUko+hnnaywQQZzzb3BRecQsoKkF3o/C+F+dOA4w/noVAJngUVkfwF0+2/8FzNznM7ofM6TGZO9svn7w==",
      "cpu": [
        "x64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@nodelib/fs.scandir": {
      "version": "2.1.5",
      "resolved": "https://registry.npmjs.org/@nodelib/fs.scandir/-/fs.scandir-2.1.5.tgz",
      "integrity": "sha512-vq24Bq3ym5HEQm2NKCr3yXDwjc7vTsEThRDnkp2DK9p1uqLR+DHurm/NOTo0KG7HYHU7eppKZj3MyqYuMBf62g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@nodelib/fs.stat": "2.0.5",
        "run-parallel": "^1.1.9"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/@nodelib/fs.stat": {
      "version": "2.0.5",
      "resolved": "https://registry.npmjs.org/@nodelib/fs.stat/-/fs.stat-2.0.5.tgz",
      "integrity": "sha512-RkhPPp2zrqDAQA/2jNhnztcPAlv64XdhIp7a7454A5ovI7Bukxgt7MX7udwAu3zg1DcpPU0rz3VV1SeaqvY4+A==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/@nodelib/fs.walk": {
      "version": "1.2.8",
      "resolved": "https://registry.npmjs.org/@nodelib/fs.walk/-/fs.walk-1.2.8.tgz",
      "integrity": "sha512-oGB+UxlgWcgQkgwo8GcEGwemoTFt3FIO9ababBmaGwXIoBKZ+GTy0pP185beGg7Llih/NSHSV2XAs1lnznocSg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@nodelib/fs.scandir": "2.1.5",
        "fastq": "^1.6.0"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/@nolyfill/is-core-module": {
      "version": "1.0.39",
      "resolved": "https://registry.npmjs.org/@nolyfill/is-core-module/-/is-core-module-1.0.39.tgz",
      "integrity": "sha512-nn5ozdjYQpUCZlWGuxcJY/KpxkWQs4DcbMCmKojjyrYDEAGy4Ce19NN4v5MduafTwJlbKc99UA8YhSVqq9yPZA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=12.4.0"
      }
    },
    "node_modules/@pkgjs/parseargs": {
      "version": "0.11.0",
      "resolved": "https://registry.npmjs.org/@pkgjs/parseargs/-/parseargs-0.11.0.tgz",
      "integrity": "sha512-+1VkjdD0QBLPodGrJUeqarH8VAIvQODIbwh9XpP5Syisf7YoQgsJKPNFoqqLQlu+VQ/tVSshMR6loPMn8U+dPg==",
      "dev": true,
      "license": "MIT",
      "optional": true,
      "engines": {
        "node": ">=14"
      }
    },
    "node_modules/@rtsao/scc": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/@rtsao/scc/-/scc-1.1.0.tgz",
      "integrity": "sha512-zt6OdqaDoOnJ1ZYsCYGt9YmWzDXl4vQdKTyJev62gFhRGKdx7mcT54V9KIjg+d2wi9EXsPvAPKe7i7WjfVWB8g==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@rushstack/eslint-patch": {
      "version": "1.12.0",
      "resolved": "https://registry.npmjs.org/@rushstack/eslint-patch/-/eslint-patch-1.12.0.tgz",
      "integrity": "sha512-5EwMtOqvJMMa3HbmxLlF74e+3/HhwBTMcvt3nqVJgGCozO6hzIPOBlwm8mGVNR9SN2IJpxSnlxczyDjcn7qIyw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@swc/helpers": {
      "version": "0.5.2",
      "resolved": "https://registry.npmjs.org/@swc/helpers/-/helpers-0.5.2.tgz",
      "integrity": "sha512-E4KcWTpoLHqwPHLxidpOqQbcrZVgi0rsmmZXUle1jXmJfuIf/UWpczUJ7MZZ5tlxytgJXyp0w4PGkkeLiuIdZw==",
      "license": "Apache-2.0",
      "dependencies": {
        "tslib": "^2.4.0"
      }
    },
    "node_modules/@tybys/wasm-util": {
      "version": "0.10.0",
      "resolved": "https://registry.npmjs.org/@tybys/wasm-util/-/wasm-util-0.10.0.tgz",
      "integrity": "sha512-VyyPYFlOMNylG45GoAe0xDoLwWuowvf92F9kySqzYh8vmYm7D2u4iUJKa1tOUpS70Ku13ASrOkS4ScXFsTaCNQ==",
      "dev": true,
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "tslib": "^2.4.0"
      }
    },
    "node_modules/@types/json5": {
      "version": "0.0.29",
      "resolved": "https://registry.npmjs.org/@types/json5/-/json5-0.0.29.tgz",
      "integrity": "sha512-dRLjCWHYg4oaA77cxO64oO+7JwCwnIzkZPdrrC71jQmQtlhM556pwKo5bUzqvZndkVbeFLIIi+9TC40JNF5hNQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@types/node": {
      "version": "20.19.10",
      "resolved": "https://registry.npmjs.org/@types/node/-/node-20.19.10.tgz",
      "integrity": "sha512-iAFpG6DokED3roLSP0K+ybeDdIX6Bc0Vd3mLW5uDqThPWtNos3E+EqOM11mPQHKzfWHqEBuLjIlsBQQ8CsISmQ==",
      "license": "MIT",
      "dependencies": {
        "undici-types": "~6.21.0"
      }
    },
    "node_modules/@types/prop-types": {
      "version": "15.7.15",
      "resolved": "https://registry.npmjs.org/@types/prop-types/-/prop-types-15.7.15.tgz",
      "integrity": "sha512-F6bEyamV9jKGAFBEmlQnesRPGOQqS2+Uwi0Em15xenOxHaf2hv6L8YCVn3rPdPJOiJfPiCnLIRyvwVaqMY3MIw==",
      "license": "MIT"
    },
    "node_modules/@types/react": {
      "version": "18.3.23",
      "resolved": "https://registry.npmjs.org/@types/react/-/react-18.3.23.tgz",
      "integrity": "sha512-/LDXMQh55EzZQ0uVAZmKKhfENivEvWz6E+EYzh+/MCjMhNsotd+ZHhBGIjFDTi6+fz0OhQQQLbTgdQIxxCsC0w==",
      "license": "MIT",
      "dependencies": {
        "@types/prop-types": "*",
        "csstype": "^3.0.2"
      }
    },
    "node_modules/@types/react-dom": {
      "version": "18.3.7",
      "resolved": "https://registry.npmjs.org/@types/react-dom/-/react-dom-18.3.7.tgz",
      "integrity": "sha512-MEe3UeoENYVFXzoXEWsvcpg6ZvlrFNlOQ7EOsvhI3CfAXwzPfO8Qwuxd40nepsYKqyyVQnTdEfv68q91yLcKrQ==",
      "license": "MIT",
      "peerDependencies": {
        "@types/react": "^18.0.0"
      }
    },
    "node_modules/@typescript-eslint/parser": {
      "version": "6.21.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/parser/-/parser-6.21.0.tgz",
      "integrity": "sha512-tbsV1jPne5CkFQCgPBcDOt30ItF7aJoZL997JSF7MhGQqOeT3svWRYxiqlfA5RUdlHN6Fi+EI9bxqbdyAUZjYQ==",
      "dev": true,
      "license": "BSD-2-Clause",
      "dependencies": {
        "@typescript-eslint/scope-manager": "6.21.0",
        "@typescript-eslint/types": "6.21.0",
        "@typescript-eslint/typescript-estree": "6.21.0",
        "@typescript-eslint/visitor-keys": "6.21.0",
        "debug": "^4.3.4"
      },
      "engines": {
        "node": "^16.0.0 || >=18.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      },
      "peerDependencies": {
        "eslint": "^7.0.0 || ^8.0.0"
      },
      "peerDependenciesMeta": {
        "typescript": {
          "optional": true
        }
      }
    },
    "node_modules/@typescript-eslint/scope-manager": {
      "version": "6.21.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/scope-manager/-/scope-manager-6.21.0.tgz",
      "integrity": "sha512-OwLUIWZJry80O99zvqXVEioyniJMa+d2GrqpUTqi5/v5D5rOrppJVBPa0yKCblcigC0/aYAzxxqQ1B+DS2RYsg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@typescript-eslint/types": "6.21.0",
        "@typescript-eslint/visitor-keys": "6.21.0"
      },
      "engines": {
        "node": "^16.0.0 || >=18.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      }
    },
    "node_modules/@typescript-eslint/types": {
      "version": "6.21.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/types/-/types-6.21.0.tgz",
      "integrity": "sha512-1kFmZ1rOm5epu9NZEZm1kckCDGj5UJEf7P1kliH4LKu/RkwpsfqqGmY2OOcUs18lSlQBKLDYBOGxRVtrMN5lpg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": "^16.0.0 || >=18.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      }
    },
    "node_modules/@typescript-eslint/typescript-estree": {
      "version": "6.21.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/typescript-estree/-/typescript-estree-6.21.0.tgz",
      "integrity": "sha512-6npJTkZcO+y2/kr+z0hc4HwNfrrP4kNYh57ek7yCNlrBjWQ1Y0OS7jiZTkgumrvkX5HkEKXFZkkdFNkaW2wmUQ==",
      "dev": true,
      "license": "BSD-2-Clause",
      "dependencies": {
        "@typescript-eslint/types": "6.21.0",
        "@typescript-eslint/visitor-keys": "6.21.0",
        "debug": "^4.3.4",
        "globby": "^11.1.0",
        "is-glob": "^4.0.3",
        "minimatch": "9.0.3",
        "semver": "^7.5.4",
        "ts-api-utils": "^1.0.1"
      },
      "engines": {
        "node": "^16.0.0 || >=18.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      },
      "peerDependenciesMeta": {
        "typescript": {
          "optional": true
        }
      }
    },
    "node_modules/@typescript-eslint/typescript-estree/node_modules/brace-expansion": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/brace-expansion/-/brace-expansion-2.0.2.tgz",
      "integrity": "sha512-Jt0vHyM+jmUBqojB7E1NIYadt0vI0Qxjxd2TErW94wDz+E2LAm5vKMXXwg6ZZBTHPuUlDgQHKXvjGBdfcF1ZDQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "balanced-match": "^1.0.0"
      }
    },
    "node_modules/@typescript-eslint/typescript-estree/node_modules/minimatch": {
      "version": "9.0.3",
      "resolved": "https://registry.npmjs.org/minimatch/-/minimatch-9.0.3.tgz",
      "integrity": "sha512-RHiac9mvaRw0x3AYRgDC1CxAP7HTcNrrECeA8YYJeWnpo+2Q5CegtZjaotWTWxDG3UeGA1coE05iH1mPjT/2mg==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "brace-expansion": "^2.0.1"
      },
      "engines": {
        "node": ">=16 || 14 >=14.17"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/@typescript-eslint/visitor-keys": {
      "version": "6.21.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/visitor-keys/-/visitor-keys-6.21.0.tgz",
      "integrity": "sha512-JJtkDduxLi9bivAB+cYOVMtbkqdPOhZ+ZI5LC47MIRrDV4Yn2o+ZnW10Nkmr28xRpSpdJ6Sm42Hjf2+REYXm0A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@typescript-eslint/types": "6.21.0",
        "eslint-visitor-keys": "^3.4.1"
      },
      "engines": {
        "node": "^16.0.0 || >=18.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      }
    },
    "node_modules/@ungap/structured-clone": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/@ungap/structured-clone/-/structured-clone-1.3.0.tgz",
      "integrity": "sha512-WmoN8qaIAo7WTYWbAZuG8PYEhn5fkz7dZrqTBZ7dtt//lL2Gwms1IcnQ5yHqjDfX8Ft5j4YzDM23f87zBfDe9g==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/@unrs/resolver-binding-android-arm-eabi": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-android-arm-eabi/-/resolver-binding-android-arm-eabi-1.11.1.tgz",
      "integrity": "sha512-ppLRUgHVaGRWUx0R0Ut06Mjo9gBaBkg3v/8AxusGLhsIotbBLuRk51rAzqLC8gq6NyyAojEXglNjzf6R948DNw==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "android"
      ]
    },
    "node_modules/@unrs/resolver-binding-android-arm64": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-android-arm64/-/resolver-binding-android-arm64-1.11.1.tgz",
      "integrity": "sha512-lCxkVtb4wp1v+EoN+HjIG9cIIzPkX5OtM03pQYkG+U5O/wL53LC4QbIeazgiKqluGeVEeBlZahHalCaBvU1a2g==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "android"
      ]
    },
    "node_modules/@unrs/resolver-binding-darwin-arm64": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-darwin-arm64/-/resolver-binding-darwin-arm64-1.11.1.tgz",
      "integrity": "sha512-gPVA1UjRu1Y/IsB/dQEsp2V1pm44Of6+LWvbLc9SDk1c2KhhDRDBUkQCYVWe6f26uJb3fOK8saWMgtX8IrMk3g==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ]
    },
    "node_modules/@unrs/resolver-binding-darwin-x64": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-darwin-x64/-/resolver-binding-darwin-x64-1.11.1.tgz",
      "integrity": "sha512-cFzP7rWKd3lZaCsDze07QX1SC24lO8mPty9vdP+YVa3MGdVgPmFc59317b2ioXtgCMKGiCLxJ4HQs62oz6GfRQ==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ]
    },
    "node_modules/@unrs/resolver-binding-freebsd-x64": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-freebsd-x64/-/resolver-binding-freebsd-x64-1.11.1.tgz",
      "integrity": "sha512-fqtGgak3zX4DCB6PFpsH5+Kmt/8CIi4Bry4rb1ho6Av2QHTREM+47y282Uqiu3ZRF5IQioJQ5qWRV6jduA+iGw==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "freebsd"
      ]
    },
    "node_modules/@unrs/resolver-binding-linux-arm-gnueabihf": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-linux-arm-gnueabihf/-/resolver-binding-linux-arm-gnueabihf-1.11.1.tgz",
      "integrity": "sha512-u92mvlcYtp9MRKmP+ZvMmtPN34+/3lMHlyMj7wXJDeXxuM0Vgzz0+PPJNsro1m3IZPYChIkn944wW8TYgGKFHw==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@unrs/resolver-binding-linux-arm-musleabihf": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-linux-arm-musleabihf/-/resolver-binding-linux-arm-musleabihf-1.11.1.tgz",
      "integrity": "sha512-cINaoY2z7LVCrfHkIcmvj7osTOtm6VVT16b5oQdS4beibX2SYBwgYLmqhBjA1t51CarSaBuX5YNsWLjsqfW5Cw==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@unrs/resolver-binding-linux-arm64-gnu": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-linux-arm64-gnu/-/resolver-binding-linux-arm64-gnu-1.11.1.tgz",
      "integrity": "sha512-34gw7PjDGB9JgePJEmhEqBhWvCiiWCuXsL9hYphDF7crW7UgI05gyBAi6MF58uGcMOiOqSJ2ybEeCvHcq0BCmQ==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@unrs/resolver-binding-linux-arm64-musl": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-linux-arm64-musl/-/resolver-binding-linux-arm64-musl-1.11.1.tgz",
      "integrity": "sha512-RyMIx6Uf53hhOtJDIamSbTskA99sPHS96wxVE/bJtePJJtpdKGXO1wY90oRdXuYOGOTuqjT8ACccMc4K6QmT3w==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@unrs/resolver-binding-linux-ppc64-gnu": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-linux-ppc64-gnu/-/resolver-binding-linux-ppc64-gnu-1.11.1.tgz",
      "integrity": "sha512-D8Vae74A4/a+mZH0FbOkFJL9DSK2R6TFPC9M+jCWYia/q2einCubX10pecpDiTmkJVUH+y8K3BZClycD8nCShA==",
      "cpu": [
        "ppc64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@unrs/resolver-binding-linux-riscv64-gnu": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-linux-riscv64-gnu/-/resolver-binding-linux-riscv64-gnu-1.11.1.tgz",
      "integrity": "sha512-frxL4OrzOWVVsOc96+V3aqTIQl1O2TjgExV4EKgRY09AJ9leZpEg8Ak9phadbuX0BA4k8U5qtvMSQQGGmaJqcQ==",
      "cpu": [
        "riscv64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@unrs/resolver-binding-linux-riscv64-musl": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-linux-riscv64-musl/-/resolver-binding-linux-riscv64-musl-1.11.1.tgz",
      "integrity": "sha512-mJ5vuDaIZ+l/acv01sHoXfpnyrNKOk/3aDoEdLO/Xtn9HuZlDD6jKxHlkN8ZhWyLJsRBxfv9GYM2utQ1SChKew==",
      "cpu": [
        "riscv64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@unrs/resolver-binding-linux-s390x-gnu": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-linux-s390x-gnu/-/resolver-binding-linux-s390x-gnu-1.11.1.tgz",
      "integrity": "sha512-kELo8ebBVtb9sA7rMe1Cph4QHreByhaZ2QEADd9NzIQsYNQpt9UkM9iqr2lhGr5afh885d/cB5QeTXSbZHTYPg==",
      "cpu": [
        "s390x"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@unrs/resolver-binding-linux-x64-gnu": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-linux-x64-gnu/-/resolver-binding-linux-x64-gnu-1.11.1.tgz",
      "integrity": "sha512-C3ZAHugKgovV5YvAMsxhq0gtXuwESUKc5MhEtjBpLoHPLYM+iuwSj3lflFwK3DPm68660rZ7G8BMcwSro7hD5w==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@unrs/resolver-binding-linux-x64-musl": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-linux-x64-musl/-/resolver-binding-linux-x64-musl-1.11.1.tgz",
      "integrity": "sha512-rV0YSoyhK2nZ4vEswT/QwqzqQXw5I6CjoaYMOX0TqBlWhojUf8P94mvI7nuJTeaCkkds3QE4+zS8Ko+GdXuZtA==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@unrs/resolver-binding-wasm32-wasi": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-wasm32-wasi/-/resolver-binding-wasm32-wasi-1.11.1.tgz",
      "integrity": "sha512-5u4RkfxJm+Ng7IWgkzi3qrFOvLvQYnPBmjmZQ8+szTK/b31fQCnleNl1GgEt7nIsZRIf5PLhPwT0WM+q45x/UQ==",
      "cpu": [
        "wasm32"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "@napi-rs/wasm-runtime": "^0.2.11"
      },
      "engines": {
        "node": ">=14.0.0"
      }
    },
    "node_modules/@unrs/resolver-binding-win32-arm64-msvc": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-win32-arm64-msvc/-/resolver-binding-win32-arm64-msvc-1.11.1.tgz",
      "integrity": "sha512-nRcz5Il4ln0kMhfL8S3hLkxI85BXs3o8EYoattsJNdsX4YUU89iOkVn7g0VHSRxFuVMdM4Q1jEpIId1Ihim/Uw==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ]
    },
    "node_modules/@unrs/resolver-binding-win32-ia32-msvc": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-win32-ia32-msvc/-/resolver-binding-win32-ia32-msvc-1.11.1.tgz",
      "integrity": "sha512-DCEI6t5i1NmAZp6pFonpD5m7i6aFrpofcp4LA2i8IIq60Jyo28hamKBxNrZcyOwVOZkgsRp9O2sXWBWP8MnvIQ==",
      "cpu": [
        "ia32"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ]
    },
    "node_modules/@unrs/resolver-binding-win32-x64-msvc": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-win32-x64-msvc/-/resolver-binding-win32-x64-msvc-1.11.1.tgz",
      "integrity": "sha512-lrW200hZdbfRtztbygyaq/6jP6AKE8qQN2KvPcJ+x7wiD038YtnYtZ82IMNJ69GJibV7bwL3y9FgK+5w/pYt6g==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ]
    },
    "node_modules/acorn": {
      "version": "8.15.0",
      "resolved": "https://registry.npmjs.org/acorn/-/acorn-8.15.0.tgz",
      "integrity": "sha512-NZyJarBfL7nWwIq+FDL6Zp/yHEhePMNnnJ0y3qfieCrmNvYct8uvtiV41UvlSe6apAfk0fY1FbWx+NwfmpvtTg==",
      "dev": true,
      "license": "MIT",
      "bin": {
        "acorn": "bin/acorn"
      },
      "engines": {
        "node": ">=0.4.0"
      }
    },
    "node_modules/acorn-jsx": {
      "version": "5.3.2",
      "resolved": "https://registry.npmjs.org/acorn-jsx/-/acorn-jsx-5.3.2.tgz",
      "integrity": "sha512-rq9s+JNhf0IChjtDXxllJ7g41oZk5SlXtp0LHwyA5cejwn7vKmKp4pPri6YEePv2PU65sAsegbXtIinmDFDXgQ==",
      "dev": true,
      "license": "MIT",
      "peerDependencies": {
        "acorn": "^6.0.0 || ^7.0.0 || ^8.0.0"
      }
    },
    "node_modules/ajv": {
      "version": "6.12.6",
      "resolved": "https://registry.npmjs.org/ajv/-/ajv-6.12.6.tgz",
      "integrity": "sha512-j3fVLgvTo527anyYyJOGTYJbG+vnnQYvE0m5mmkc1TK+nxAppkCLMIL0aZ4dblVCNoGShhm+kzE4ZUykBoMg4g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "fast-deep-equal": "^3.1.1",
        "fast-json-stable-stringify": "^2.0.0",
        "json-schema-traverse": "^0.4.1",
        "uri-js": "^4.2.2"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/epoberezkin"
      }
    },
    "node_modules/ansi-regex": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/ansi-regex/-/ansi-regex-5.0.1.tgz",
      "integrity": "sha512-quJQXlTSUGL2LH9SUXo8VwsY4soanhgo6LNSm84E1LBcE8s3O0wpdiRzyR9z/ZZJMlMWv37qOOb9pdJlMUEKFQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/ansi-styles": {
      "version": "4.3.0",
      "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-4.3.0.tgz",
      "integrity": "sha512-zbB9rCJAT1rbjiVDb2hqKFHNYLxgtk8NURxZ3IZwD3F6NtxbXZQCnnSi1Lkx+IDohdPlFp222wVALIheZJQSEg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "color-convert": "^2.0.1"
      },
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-styles?sponsor=1"
      }
    },
    "node_modules/any-promise": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/any-promise/-/any-promise-1.3.0.tgz",
      "integrity": "sha512-7UvmKalWRt1wgjL1RrGxoSJW/0QZFIegpeGvZG9kjp8vrRu55XTHbwnqq2GpXm9uLbcuhxm3IqX9OB4MZR1b2A==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/anymatch": {
      "version": "3.1.3",
      "resolved": "https://registry.npmjs.org/anymatch/-/anymatch-3.1.3.tgz",
      "integrity": "sha512-KMReFUr0B4t+D+OBkjR3KYqvocp2XaSzO55UcB6mgQMd3KbcE+mWTyvVV7D/zsdEbNnV6acZUutkiHQXvTr1Rw==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "normalize-path": "^3.0.0",
        "picomatch": "^2.0.4"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/arg": {
      "version": "5.0.2",
      "resolved": "https://registry.npmjs.org/arg/-/arg-5.0.2.tgz",
      "integrity": "sha512-PYjyFOLKQ9y57JvQ6QLo8dAgNqswh8M1RMJYdQduT6xbWSgK36P/Z/v+p888pM69jMMfS8Xd8F6I1kQ/I9HUGg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/argparse": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/argparse/-/argparse-2.0.1.tgz",
      "integrity": "sha512-8+9WqebbFzpX9OR+Wa6O29asIogeRMzcGtAINdpMHHyAg10f05aSFVBbcEqGf/PXw1EjAZ+q2/bEBg3DvurK3Q==",
      "dev": true,
      "license": "Python-2.0"
    },
    "node_modules/aria-query": {
      "version": "5.3.2",
      "resolved": "https://registry.npmjs.org/aria-query/-/aria-query-5.3.2.tgz",
      "integrity": "sha512-COROpnaoap1E2F000S62r6A60uHZnmlvomhfyT2DlTcrY1OrBKn2UhH7qn5wTC9zMvD0AY7csdPSNwKP+7WiQw==",
      "dev": true,
      "license": "Apache-2.0",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/array-buffer-byte-length": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/array-buffer-byte-length/-/array-buffer-byte-length-1.0.2.tgz",
      "integrity": "sha512-LHE+8BuR7RYGDKvnrmcuSq3tDcKv9OFEXQt/HpbZhY7V6h0zlUXutnAD82GiFx9rdieCMjkvtcsPqBwgUl1Iiw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "is-array-buffer": "^3.0.5"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/array-includes": {
      "version": "3.1.9",
      "resolved": "https://registry.npmjs.org/array-includes/-/array-includes-3.1.9.tgz",
      "integrity": "sha512-FmeCCAenzH0KH381SPT5FZmiA/TmpndpcaShhfgEN9eCVjnFBqq3l1xrI42y8+PPLI6hypzou4GXw00WHmPBLQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.4",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.24.0",
        "es-object-atoms": "^1.1.1",
        "get-intrinsic": "^1.3.0",
        "is-string": "^1.1.1",
        "math-intrinsics": "^1.1.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/array-union": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/array-union/-/array-union-2.1.0.tgz",
      "integrity": "sha512-HGyxoOTYUyCM6stUe6EJgnd4EoewAI7zMdfqO+kGjnlZmBDz/cR5pf8r/cR4Wq60sL/p0IkcjUEEPwS3GFrIyw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/array.prototype.findlast": {
      "version": "1.2.5",
      "resolved": "https://registry.npmjs.org/array.prototype.findlast/-/array.prototype.findlast-1.2.5.tgz",
      "integrity": "sha512-CVvd6FHg1Z3POpBLxO6E6zr+rSKEQ9L6rZHAaY7lLfhKsWYUBBOuMs0e9o24oopj6H+geRCX0YJ+TJLBK2eHyQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.7",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.2",
        "es-errors": "^1.3.0",
        "es-object-atoms": "^1.0.0",
        "es-shim-unscopables": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/array.prototype.findlastindex": {
      "version": "1.2.6",
      "resolved": "https://registry.npmjs.org/array.prototype.findlastindex/-/array.prototype.findlastindex-1.2.6.tgz",
      "integrity": "sha512-F/TKATkzseUExPlfvmwQKGITM3DGTK+vkAsCZoDc5daVygbJBnjEUCbgkAvVFsgfXfX4YIqZ/27G3k3tdXrTxQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.4",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.9",
        "es-errors": "^1.3.0",
        "es-object-atoms": "^1.1.1",
        "es-shim-unscopables": "^1.1.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/array.prototype.flat": {
      "version": "1.3.3",
      "resolved": "https://registry.npmjs.org/array.prototype.flat/-/array.prototype.flat-1.3.3.tgz",
      "integrity": "sha512-rwG/ja1neyLqCuGZ5YYrznA62D4mZXg0i1cIskIUKSiqF3Cje9/wXAls9B9s1Wa2fomMsIv8czB8jZcPmxCXFg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.5",
        "es-shim-unscopables": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/array.prototype.flatmap": {
      "version": "1.3.3",
      "resolved": "https://registry.npmjs.org/array.prototype.flatmap/-/array.prototype.flatmap-1.3.3.tgz",
      "integrity": "sha512-Y7Wt51eKJSyi80hFrJCePGGNo5ktJCslFuboqJsbf57CCPcm5zztluPlc4/aD8sWsKvlwatezpV4U1efk8kpjg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.5",
        "es-shim-unscopables": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/array.prototype.tosorted": {
      "version": "1.1.4",
      "resolved": "https://registry.npmjs.org/array.prototype.tosorted/-/array.prototype.tosorted-1.1.4.tgz",
      "integrity": "sha512-p6Fx8B7b7ZhL/gmUsAy0D15WhvDccw3mnGNbZpi3pmeJdxtWsj2jEaI4Y6oo3XiHfzuSgPwKc04MYt6KgvC/wA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.7",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.3",
        "es-errors": "^1.3.0",
        "es-shim-unscopables": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/arraybuffer.prototype.slice": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/arraybuffer.prototype.slice/-/arraybuffer.prototype.slice-1.0.4.tgz",
      "integrity": "sha512-BNoCY6SXXPQ7gF2opIP4GBE+Xw7U+pHMYKuzjgCN3GwiaIR09UUeKfheyIry77QtrCBlC0KK0q5/TER/tYh3PQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "array-buffer-byte-length": "^1.0.1",
        "call-bind": "^1.0.8",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.5",
        "es-errors": "^1.3.0",
        "get-intrinsic": "^1.2.6",
        "is-array-buffer": "^3.0.4"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/ast-types-flow": {
      "version": "0.0.8",
      "resolved": "https://registry.npmjs.org/ast-types-flow/-/ast-types-flow-0.0.8.tgz",
      "integrity": "sha512-OH/2E5Fg20h2aPrbe+QL8JZQFko0YZaF+j4mnQ7BGhfavO7OpSLa8a0y9sBwomHdSbkhTS8TQNayBfnW5DwbvQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/async-function": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/async-function/-/async-function-1.0.0.tgz",
      "integrity": "sha512-hsU18Ae8CDTR6Kgu9DYf0EbCr/a5iGL0rytQDobUcdpYOKokk8LEjVphnXkDkgpi0wYVsqrXuP0bZxJaTqdgoA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/autoprefixer": {
      "version": "10.4.21",
      "resolved": "https://registry.npmjs.org/autoprefixer/-/autoprefixer-10.4.21.tgz",
      "integrity": "sha512-O+A6LWV5LDHSJD3LjHYoNi4VLsj/Whi7k6zG12xTYaU4cQ8oxQGckXNX8cRHK5yOZ/ppVHe0ZBXGzSV9jXdVbQ==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/postcss/"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/autoprefixer"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "browserslist": "^4.24.4",
        "caniuse-lite": "^1.0.30001702",
        "fraction.js": "^4.3.7",
        "normalize-range": "^0.1.2",
        "picocolors": "^1.1.1",
        "postcss-value-parser": "^4.2.0"
      },
      "bin": {
        "autoprefixer": "bin/autoprefixer"
      },
      "engines": {
        "node": "^10 || ^12 || >=14"
      },
      "peerDependencies": {
        "postcss": "^8.1.0"
      }
    },
    "node_modules/available-typed-arrays": {
      "version": "1.0.7",
      "resolved": "https://registry.npmjs.org/available-typed-arrays/-/available-typed-arrays-1.0.7.tgz",
      "integrity": "sha512-wvUjBtSGN7+7SjNpq/9M2Tg350UZD3q62IFZLbRAR1bSMlCo1ZaeW+BJ+D090e4hIIZLBcTDWe4Mh4jvUDajzQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "possible-typed-array-names": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/axe-core": {
      "version": "4.10.3",
      "resolved": "https://registry.npmjs.org/axe-core/-/axe-core-4.10.3.tgz",
      "integrity": "sha512-Xm7bpRXnDSX2YE2YFfBk2FnF0ep6tmG7xPh8iHee8MIcrgq762Nkce856dYtJYLkuIoYZvGfTs/PbZhideTcEg==",
      "dev": true,
      "license": "MPL-2.0",
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/axobject-query": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/axobject-query/-/axobject-query-4.1.0.tgz",
      "integrity": "sha512-qIj0G9wZbMGNLjLmg1PT6v2mE9AH2zlnADJD/2tC6E00hgmhUOfEB6greHPAfLRSufHqROIUTkw6E+M3lH0PTQ==",
      "dev": true,
      "license": "Apache-2.0",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/balanced-match": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/balanced-match/-/balanced-match-1.0.2.tgz",
      "integrity": "sha512-3oSeUO0TMV67hN1AmbXsK4yaqU7tjiHlbxRDZOpH0KW9+CeX4bRAaX0Anxt0tx2MrpRpWwQaPwIlISEJhYU5Pw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/binary-extensions": {
      "version": "2.3.0",
      "resolved": "https://registry.npmjs.org/binary-extensions/-/binary-extensions-2.3.0.tgz",
      "integrity": "sha512-Ceh+7ox5qe7LJuLHoY0feh3pHuUDHAcRUeyL2VYghZwfpkNIy/+8Ocg0a3UuSoYzavmylwuLWQOf3hl0jjMMIw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/brace-expansion": {
      "version": "1.1.12",
      "resolved": "https://registry.npmjs.org/brace-expansion/-/brace-expansion-1.1.12.tgz",
      "integrity": "sha512-9T9UjW3r0UW5c1Q7GTwllptXwhvYmEzFhzMfZ9H7FQWt+uZePjZPjBP/W1ZEyZ1twGWom5/56TF4lPcqjnDHcg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "balanced-match": "^1.0.0",
        "concat-map": "0.0.1"
      }
    },
    "node_modules/braces": {
      "version": "3.0.3",
      "resolved": "https://registry.npmjs.org/braces/-/braces-3.0.3.tgz",
      "integrity": "sha512-yQbXgO/OSZVD2IsiLlro+7Hf6Q18EJrKSEsdoMzKePKXct3gvD8oLcOQdIzGupr5Fj+EDe8gO/lxc1BzfMpxvA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "fill-range": "^7.1.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/browserslist": {
      "version": "4.25.2",
      "resolved": "https://registry.npmjs.org/browserslist/-/browserslist-4.25.2.tgz",
      "integrity": "sha512-0si2SJK3ooGzIawRu61ZdPCO1IncZwS8IzuX73sPZsXW6EQ/w/DAfPyKI8l1ETTCr2MnvqWitmlCUxgdul45jA==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/browserslist"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/browserslist"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "caniuse-lite": "^1.0.30001733",
        "electron-to-chromium": "^1.5.199",
        "node-releases": "^2.0.19",
        "update-browserslist-db": "^1.1.3"
      },
      "bin": {
        "browserslist": "cli.js"
      },
      "engines": {
        "node": "^6 || ^7 || ^8 || ^9 || ^10 || ^11 || ^12 || >=13.7"
      }
    },
    "node_modules/busboy": {
      "version": "1.6.0",
      "resolved": "https://registry.npmjs.org/busboy/-/busboy-1.6.0.tgz",
      "integrity": "sha512-8SFQbg/0hQ9xy3UNTB0YEnsNBbWfhf7RtnzpL7TkBiTBRfrQ9Fxcnz7VJsleJpyp6rVLvXiuORqjlHi5q+PYuA==",
      "dependencies": {
        "streamsearch": "^1.1.0"
      },
      "engines": {
        "node": ">=10.16.0"
      }
    },
    "node_modules/call-bind": {
      "version": "1.0.8",
      "resolved": "https://registry.npmjs.org/call-bind/-/call-bind-1.0.8.tgz",
      "integrity": "sha512-oKlSFMcMwpUg2ednkhQ454wfWiU/ul3CkJe/PEHcTKuiX6RpbehUiFMXu13HalGZxfUwCQzZG747YXBn1im9ww==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind-apply-helpers": "^1.0.0",
        "es-define-property": "^1.0.0",
        "get-intrinsic": "^1.2.4",
        "set-function-length": "^1.2.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/call-bind-apply-helpers": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/call-bind-apply-helpers/-/call-bind-apply-helpers-1.0.2.tgz",
      "integrity": "sha512-Sp1ablJ0ivDkSzjcaJdxEunN5/XvksFJ2sMBFfq6x0ryhQV/2b/KwFe21cMpmHtPOSij8K99/wSfoEuTObmuMQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0",
        "function-bind": "^1.1.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/call-bound": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/call-bound/-/call-bound-1.0.4.tgz",
      "integrity": "sha512-+ys997U96po4Kx/ABpBCqhA9EuxJaQWDQg7295H4hBphv3IZg0boBKuwYpt4YXp6MZ5AmZQnU/tyMTlRpaSejg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind-apply-helpers": "^1.0.2",
        "get-intrinsic": "^1.3.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/callsites": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/callsites/-/callsites-3.1.0.tgz",
      "integrity": "sha512-P8BjAsXvZS+VIDUI11hHCQEv74YT67YUi5JJFNWIqL235sBmjX4+qx9Muvls5ivyNENctx46xQLQ3aTuE7ssaQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/camelcase-css": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/camelcase-css/-/camelcase-css-2.0.1.tgz",
      "integrity": "sha512-QOSvevhslijgYwRx6Rv7zKdMF8lbRmx+uQGx2+vDc+KI/eBnsy9kit5aj23AgGu3pa4t9AgwbnXWqS+iOY+2aA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/caniuse-lite": {
      "version": "1.0.30001735",
      "resolved": "https://registry.npmjs.org/caniuse-lite/-/caniuse-lite-1.0.30001735.tgz",
      "integrity": "sha512-EV/laoX7Wq2J9TQlyIXRxTJqIw4sxfXS4OYgudGxBYRuTv0q7AM6yMEpU/Vo1I94thg9U6EZ2NfZx9GJq83u7w==",
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/browserslist"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/caniuse-lite"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "CC-BY-4.0"
    },
    "node_modules/chalk": {
      "version": "4.1.2",
      "resolved": "https://registry.npmjs.org/chalk/-/chalk-4.1.2.tgz",
      "integrity": "sha512-oKnbhFyRIXpUuez8iBMmyEa4nbj4IOQyuhc/wy9kY7/WVPcwIO9VA668Pu8RkO7+0G76SLROeyw9CpQ061i4mA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-styles": "^4.1.0",
        "supports-color": "^7.1.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/chalk/chalk?sponsor=1"
      }
    },
    "node_modules/chokidar": {
      "version": "3.6.0",
      "resolved": "https://registry.npmjs.org/chokidar/-/chokidar-3.6.0.tgz",
      "integrity": "sha512-7VT13fmjotKpGipCW9JEQAusEPE+Ei8nl6/g4FBAmIm0GOOLMua9NDDo/DWp0ZAxCr3cPq5ZpBqmPAQgDda2Pw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "anymatch": "~3.1.2",
        "braces": "~3.0.2",
        "glob-parent": "~5.1.2",
        "is-binary-path": "~2.1.0",
        "is-glob": "~4.0.1",
        "normalize-path": "~3.0.0",
        "readdirp": "~3.6.0"
      },
      "engines": {
        "node": ">= 8.10.0"
      },
      "funding": {
        "url": "https://paulmillr.com/funding/"
      },
      "optionalDependencies": {
        "fsevents": "~2.3.2"
      }
    },
    "node_modules/chokidar/node_modules/glob-parent": {
      "version": "5.1.2",
      "resolved": "https://registry.npmjs.org/glob-parent/-/glob-parent-5.1.2.tgz",
      "integrity": "sha512-AOIgSQCepiJYwP3ARnGx+5VnTu2HBYdzbGP45eLw1vr3zB3vZLeyed1sC9hnbcOc9/SrMyM5RPQrkGz4aS9Zow==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "is-glob": "^4.0.1"
      },
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/client-only": {
      "version": "0.0.1",
      "resolved": "https://registry.npmjs.org/client-only/-/client-only-0.0.1.tgz",
      "integrity": "sha512-IV3Ou0jSMzZrd3pZ48nLkT9DA7Ag1pnPzaiQhpW7c3RbcqqzvzzVu+L8gfqMp/8IM2MQtSiqaCxrrcfu8I8rMA==",
      "license": "MIT"
    },
    "node_modules/color-convert": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/color-convert/-/color-convert-2.0.1.tgz",
      "integrity": "sha512-RRECPsj7iu/xb5oKYcsFHSppFNnsj/52OVTRKb4zP5onXwVF3zVmmToNcOfGC+CRDpfK/U584fMg38ZHCaElKQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "color-name": "~1.1.4"
      },
      "engines": {
        "node": ">=7.0.0"
      }
    },
    "node_modules/color-name": {
      "version": "1.1.4",
      "resolved": "https://registry.npmjs.org/color-name/-/color-name-1.1.4.tgz",
      "integrity": "sha512-dOy+3AuW3a2wNbZHIuMZpTcgjGuLU/uBL/ubcZF9OXbDo8ff4O8yVp5Bf0efS8uEoYo5q4Fx7dY9OgQGXgAsQA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/commander": {
      "version": "4.1.1",
      "resolved": "https://registry.npmjs.org/commander/-/commander-4.1.1.tgz",
      "integrity": "sha512-NOKm8xhkzAjzFx8B2v5OAHT+u5pRQc2UCa2Vq9jYL/31o2wi9mxBA7LIFs3sV5VSC49z6pEhfbMULvShKj26WA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/concat-map": {
      "version": "0.0.1",
      "resolved": "https://registry.npmjs.org/concat-map/-/concat-map-0.0.1.tgz",
      "integrity": "sha512-/Srv4dswyQNBfohGpz9o6Yb3Gz3SrUDqBH5rTuhGR7ahtlbYKnVxw2bCFMRljaA7EXHaXZ8wsHdodFvbkhKmqg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/core-util-is": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/core-util-is/-/core-util-is-1.0.3.tgz",
      "integrity": "sha512-ZQBvi1DcpJ4GDqanjucZ2Hj3wEO5pZDS89BWbkcrvdxksJorwUDDZamX9ldFkp9aw2lmBDLgkObEA4DWNJ9FYQ==",
      "license": "MIT"
    },
    "node_modules/cross-spawn": {
      "version": "7.0.6",
      "resolved": "https://registry.npmjs.org/cross-spawn/-/cross-spawn-7.0.6.tgz",
      "integrity": "sha512-uV2QOWP2nWzsy2aMp8aRibhi9dlzF5Hgh5SHaB9OiTGEyDTiJJyx0uy51QXdyWbtAHNua4XJzUKca3OzKUd3vA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "path-key": "^3.1.0",
        "shebang-command": "^2.0.0",
        "which": "^2.0.1"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/cssesc": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/cssesc/-/cssesc-3.0.0.tgz",
      "integrity": "sha512-/Tb/JcjK111nNScGob5MNtsntNM1aCNUDipB/TkwZFhyDrrE47SOx/18wF2bbjgc3ZzCSKW1T5nt5EbFoAz/Vg==",
      "dev": true,
      "license": "MIT",
      "bin": {
        "cssesc": "bin/cssesc"
      },
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/csstype": {
      "version": "3.1.3",
      "resolved": "https://registry.npmjs.org/csstype/-/csstype-3.1.3.tgz",
      "integrity": "sha512-M1uQkMl8rQK/szD0LNhtqxIPLpimGm8sOBwU7lLnCpSbTyY3yeU1Vc7l4KT5zT4s/yOxHH5O7tIuuLOCnLADRw==",
      "license": "MIT"
    },
    "node_modules/damerau-levenshtein": {
      "version": "1.0.8",
      "resolved": "https://registry.npmjs.org/damerau-levenshtein/-/damerau-levenshtein-1.0.8.tgz",
      "integrity": "sha512-sdQSFB7+llfUcQHUQO3+B8ERRj0Oa4w9POWMI/puGtuf7gFywGmkaLCElnudfTiKZV+NvHqL0ifzdrI8Ro7ESA==",
      "dev": true,
      "license": "BSD-2-Clause"
    },
    "node_modules/data-view-buffer": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/data-view-buffer/-/data-view-buffer-1.0.2.tgz",
      "integrity": "sha512-EmKO5V3OLXh1rtK2wgXRansaK1/mtVdTUEiEI0W8RkvgT05kfxaH29PliLnpLP73yYO6142Q72QNa8Wx/A5CqQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "es-errors": "^1.3.0",
        "is-data-view": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/data-view-byte-length": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/data-view-byte-length/-/data-view-byte-length-1.0.2.tgz",
      "integrity": "sha512-tuhGbE6CfTM9+5ANGf+oQb72Ky/0+s3xKUpHvShfiz2RxMFgFPjsXuRLBVMtvMs15awe45SRb83D6wH4ew6wlQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "es-errors": "^1.3.0",
        "is-data-view": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/inspect-js"
      }
    },
    "node_modules/data-view-byte-offset": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/data-view-byte-offset/-/data-view-byte-offset-1.0.1.tgz",
      "integrity": "sha512-BS8PfmtDGnrgYdOonGZQdLZslWIeCGFP9tpan0hi1Co2Zr2NKADsvGYA8XxuG/4UWgJ6Cjtv+YJnB6MM69QGlQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.2",
        "es-errors": "^1.3.0",
        "is-data-view": "^1.0.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/debug": {
      "version": "4.4.1",
      "resolved": "https://registry.npmjs.org/debug/-/debug-4.4.1.tgz",
      "integrity": "sha512-KcKCqiftBJcZr++7ykoDIEwSa3XWowTfNPo92BYxjXiyYEVrUQh2aLyhxBCwww+heortUFxEJYcRzosstTEBYQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ms": "^2.1.3"
      },
      "engines": {
        "node": ">=6.0"
      },
      "peerDependenciesMeta": {
        "supports-color": {
          "optional": true
        }
      }
    },
    "node_modules/deep-is": {
      "version": "0.1.4",
      "resolved": "https://registry.npmjs.org/deep-is/-/deep-is-0.1.4.tgz",
      "integrity": "sha512-oIPzksmTg4/MriiaYGO+okXDT7ztn/w3Eptv/+gSIdMdKsJo0u4CfYNFJPy+4SKMuCqGw2wxnA+URMg3t8a/bQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/define-data-property": {
      "version": "1.1.4",
      "resolved": "https://registry.npmjs.org/define-data-property/-/define-data-property-1.1.4.tgz",
      "integrity": "sha512-rBMvIzlpA8v6E+SJZoo++HAYqsLrkg7MSfIinMPFhmkorw7X+dOXVJQs+QT69zGkzMyfDnIMN2Wid1+NbL3T+A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "es-define-property": "^1.0.0",
        "es-errors": "^1.3.0",
        "gopd": "^1.0.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/define-properties": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/define-properties/-/define-properties-1.2.1.tgz",
      "integrity": "sha512-8QmQKqEASLd5nx0U1B1okLElbUuuttJ/AnYmRXbbbGDWh6uS208EjD4Xqq/I9wK7u0v6O08XhTWnt5XtEbR6Dg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "define-data-property": "^1.0.1",
        "has-property-descriptors": "^1.0.0",
        "object-keys": "^1.1.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/didyoumean": {
      "version": "1.2.2",
      "resolved": "https://registry.npmjs.org/didyoumean/-/didyoumean-1.2.2.tgz",
      "integrity": "sha512-gxtyfqMg7GKyhQmb056K7M3xszy/myH8w+B4RT+QXBQsvAOdc3XymqDDPHx1BgPgsdAA5SIifona89YtRATDzw==",
      "dev": true,
      "license": "Apache-2.0"
    },
    "node_modules/dir-glob": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/dir-glob/-/dir-glob-3.0.1.tgz",
      "integrity": "sha512-WkrWp9GR4KXfKGYzOLmTuGVi1UWFfws377n9cc55/tb6DuqyF6pcQ5AbiHEshaDpY9v6oaSr2XCDidGmMwdzIA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "path-type": "^4.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/dlv": {
      "version": "1.1.3",
      "resolved": "https://registry.npmjs.org/dlv/-/dlv-1.1.3.tgz",
      "integrity": "sha512-+HlytyjlPKnIG8XuRG8WvmBP8xs8P71y+SKKS6ZXWoEgLuePxtDoUEiH7WkdePWrQ5JBpE6aoVqfZfJUQkjXwA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/doctrine": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/doctrine/-/doctrine-3.0.0.tgz",
      "integrity": "sha512-yS+Q5i3hBf7GBkd4KG8a7eBNNWNGLTaEwwYWUijIYM7zrlYDM0BFXHjjPWlWZ1Rg7UaddZeIDmi9jF3HmqiQ2w==",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "esutils": "^2.0.2"
      },
      "engines": {
        "node": ">=6.0.0"
      }
    },
    "node_modules/dunder-proto": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/dunder-proto/-/dunder-proto-1.0.1.tgz",
      "integrity": "sha512-KIN/nDJBQRcXw0MLVhZE9iQHmG68qAVIBg9CqmUYjmQIhgij9U5MFvrqkUL5FbtyyzZuOeOt0zdeRe4UY7ct+A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind-apply-helpers": "^1.0.1",
        "es-errors": "^1.3.0",
        "gopd": "^1.2.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/eastasianwidth": {
      "version": "0.2.0",
      "resolved": "https://registry.npmjs.org/eastasianwidth/-/eastasianwidth-0.2.0.tgz",
      "integrity": "sha512-I88TYZWc9XiYHRQ4/3c5rjjfgkjhLyW2luGIheGERbNQ6OY7yTybanSpDXZa8y7VUP9YmDcYa+eyq4ca7iLqWA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/electron-to-chromium": {
      "version": "1.5.201",
      "resolved": "https://registry.npmjs.org/electron-to-chromium/-/electron-to-chromium-1.5.201.tgz",
      "integrity": "sha512-ZG65vsrLClodGqywuigc+7m0gr4ISoTQttfVh7nfpLv0M7SIwF4WbFNEOywcqTiujs12AUeeXbFyQieDICAIxg==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/emoji-regex": {
      "version": "9.2.2",
      "resolved": "https://registry.npmjs.org/emoji-regex/-/emoji-regex-9.2.2.tgz",
      "integrity": "sha512-L18DaJsXSUk2+42pv8mLs5jJT2hqFkFE4j21wOmgbUqsZ2hL72NsUU785g9RXgo3s0ZNgVl42TiHp3ZtOv/Vyg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/es-abstract": {
      "version": "1.24.0",
      "resolved": "https://registry.npmjs.org/es-abstract/-/es-abstract-1.24.0.tgz",
      "integrity": "sha512-WSzPgsdLtTcQwm4CROfS5ju2Wa1QQcVeT37jFjYzdFz1r9ahadC8B8/a4qxJxM+09F18iumCdRmlr96ZYkQvEg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "array-buffer-byte-length": "^1.0.2",
        "arraybuffer.prototype.slice": "^1.0.4",
        "available-typed-arrays": "^1.0.7",
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.4",
        "data-view-buffer": "^1.0.2",
        "data-view-byte-length": "^1.0.2",
        "data-view-byte-offset": "^1.0.1",
        "es-define-property": "^1.0.1",
        "es-errors": "^1.3.0",
        "es-object-atoms": "^1.1.1",
        "es-set-tostringtag": "^2.1.0",
        "es-to-primitive": "^1.3.0",
        "function.prototype.name": "^1.1.8",
        "get-intrinsic": "^1.3.0",
        "get-proto": "^1.0.1",
        "get-symbol-description": "^1.1.0",
        "globalthis": "^1.0.4",
        "gopd": "^1.2.0",
        "has-property-descriptors": "^1.0.2",
        "has-proto": "^1.2.0",
        "has-symbols": "^1.1.0",
        "hasown": "^2.0.2",
        "internal-slot": "^1.1.0",
        "is-array-buffer": "^3.0.5",
        "is-callable": "^1.2.7",
        "is-data-view": "^1.0.2",
        "is-negative-zero": "^2.0.3",
        "is-regex": "^1.2.1",
        "is-set": "^2.0.3",
        "is-shared-array-buffer": "^1.0.4",
        "is-string": "^1.1.1",
        "is-typed-array": "^1.1.15",
        "is-weakref": "^1.1.1",
        "math-intrinsics": "^1.1.0",
        "object-inspect": "^1.13.4",
        "object-keys": "^1.1.1",
        "object.assign": "^4.1.7",
        "own-keys": "^1.0.1",
        "regexp.prototype.flags": "^1.5.4",
        "safe-array-concat": "^1.1.3",
        "safe-push-apply": "^1.0.0",
        "safe-regex-test": "^1.1.0",
        "set-proto": "^1.0.0",
        "stop-iteration-iterator": "^1.1.0",
        "string.prototype.trim": "^1.2.10",
        "string.prototype.trimend": "^1.0.9",
        "string.prototype.trimstart": "^1.0.8",
        "typed-array-buffer": "^1.0.3",
        "typed-array-byte-length": "^1.0.3",
        "typed-array-byte-offset": "^1.0.4",
        "typed-array-length": "^1.0.7",
        "unbox-primitive": "^1.1.0",
        "which-typed-array": "^1.1.19"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/es-define-property": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/es-define-property/-/es-define-property-1.0.1.tgz",
      "integrity": "sha512-e3nRfgfUZ4rNGL232gUgX06QNyyez04KdjFrF+LTRoOXmrOgFKDg4BCdsjW8EnT69eqdYGmRpJwiPVYNrCaW3g==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-errors": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/es-errors/-/es-errors-1.3.0.tgz",
      "integrity": "sha512-Zf5H2Kxt2xjTvbJvP2ZWLEICxA6j+hAmMzIlypy4xcBg1vKVnx89Wy0GbS+kf5cwCVFFzdCFh2XSCFNULS6csw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-iterator-helpers": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/es-iterator-helpers/-/es-iterator-helpers-1.2.1.tgz",
      "integrity": "sha512-uDn+FE1yrDzyC0pCo961B2IHbdM8y/ACZsKD4dG6WqrjV53BADjwa7D+1aom2rsNVfLyDgU/eigvlJGJ08OQ4w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.3",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.6",
        "es-errors": "^1.3.0",
        "es-set-tostringtag": "^2.0.3",
        "function-bind": "^1.1.2",
        "get-intrinsic": "^1.2.6",
        "globalthis": "^1.0.4",
        "gopd": "^1.2.0",
        "has-property-descriptors": "^1.0.2",
        "has-proto": "^1.2.0",
        "has-symbols": "^1.1.0",
        "internal-slot": "^1.1.0",
        "iterator.prototype": "^1.1.4",
        "safe-array-concat": "^1.1.3"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-object-atoms": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/es-object-atoms/-/es-object-atoms-1.1.1.tgz",
      "integrity": "sha512-FGgH2h8zKNim9ljj7dankFPcICIK9Cp5bm+c2gQSYePhpaG5+esrLODihIorn+Pe6FGJzWhXQotPv73jTaldXA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-set-tostringtag": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/es-set-tostringtag/-/es-set-tostringtag-2.1.0.tgz",
      "integrity": "sha512-j6vWzfrGVfyXxge+O0x5sh6cvxAog0a/4Rdd2K36zCMV5eJ+/+tOAngRO8cODMNWbVRdVlmGZQL2YS3yR8bIUA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0",
        "get-intrinsic": "^1.2.6",
        "has-tostringtag": "^1.0.2",
        "hasown": "^2.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-shim-unscopables": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/es-shim-unscopables/-/es-shim-unscopables-1.1.0.tgz",
      "integrity": "sha512-d9T8ucsEhh8Bi1woXCf+TIKDIROLG5WCkxg8geBCbvk22kzwC5G2OnXVMO6FUsvQlgUUXQ2itephWDLqDzbeCw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "hasown": "^2.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-to-primitive": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/es-to-primitive/-/es-to-primitive-1.3.0.tgz",
      "integrity": "sha512-w+5mJ3GuFL+NjVtJlvydShqE1eN3h3PbI7/5LAsYJP/2qtuMXjfL2LpHSRqo4b4eSF5K/DH1JXKUAHSB2UW50g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-callable": "^1.2.7",
        "is-date-object": "^1.0.5",
        "is-symbol": "^1.0.4"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/escalade": {
      "version": "3.2.0",
      "resolved": "https://registry.npmjs.org/escalade/-/escalade-3.2.0.tgz",
      "integrity": "sha512-WUj2qlxaQtO4g6Pq5c29GTcWGDyd8itL8zTlipgECz3JesAiiOKotd8JU6otB3PACgG6xkJUyVhboMS+bje/jA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/escape-string-regexp": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/escape-string-regexp/-/escape-string-regexp-4.0.0.tgz",
      "integrity": "sha512-TtpcNJ3XAzx3Gq8sWRzJaVajRs0uVxA2YAkdb1jm2YkPz4G6egUFAyA3n5vtEIZefPk5Wa4UXbKuS5fKkJWdgA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/eslint": {
      "version": "8.57.1",
      "resolved": "https://registry.npmjs.org/eslint/-/eslint-8.57.1.tgz",
      "integrity": "sha512-ypowyDxpVSYpkXr9WPv2PAZCtNip1Mv5KTW0SCurXv/9iOpcrH9PaqUElksqEB6pChqHGDRCFTyrZlGhnLNGiA==",
      "deprecated": "This version is no longer supported. Please see https://eslint.org/version-support for other options.",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@eslint-community/eslint-utils": "^4.2.0",
        "@eslint-community/regexpp": "^4.6.1",
        "@eslint/eslintrc": "^2.1.4",
        "@eslint/js": "8.57.1",
        "@humanwhocodes/config-array": "^0.13.0",
        "@humanwhocodes/module-importer": "^1.0.1",
        "@nodelib/fs.walk": "^1.2.8",
        "@ungap/structured-clone": "^1.2.0",
        "ajv": "^6.12.4",
        "chalk": "^4.0.0",
        "cross-spawn": "^7.0.2",
        "debug": "^4.3.2",
        "doctrine": "^3.0.0",
        "escape-string-regexp": "^4.0.0",
        "eslint-scope": "^7.2.2",
        "eslint-visitor-keys": "^3.4.3",
        "espree": "^9.6.1",
        "esquery": "^1.4.2",
        "esutils": "^2.0.2",
        "fast-deep-equal": "^3.1.3",
        "file-entry-cache": "^6.0.1",
        "find-up": "^5.0.0",
        "glob-parent": "^6.0.2",
        "globals": "^13.19.0",
        "graphemer": "^1.4.0",
        "ignore": "^5.2.0",
        "imurmurhash": "^0.1.4",
        "is-glob": "^4.0.0",
        "is-path-inside": "^3.0.3",
        "js-yaml": "^4.1.0",
        "json-stable-stringify-without-jsonify": "^1.0.1",
        "levn": "^0.4.1",
        "lodash.merge": "^4.6.2",
        "minimatch": "^3.1.2",
        "natural-compare": "^1.4.0",
        "optionator": "^0.9.3",
        "strip-ansi": "^6.0.1",
        "text-table": "^0.2.0"
      },
      "bin": {
        "eslint": "bin/eslint.js"
      },
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      }
    },
    "node_modules/eslint-config-next": {
      "version": "14.0.0",
      "resolved": "https://registry.npmjs.org/eslint-config-next/-/eslint-config-next-14.0.0.tgz",
      "integrity": "sha512-jtXeE+/pGQ3h9n11QyyuPN50kO13GO5XvjU5ZRq6W+XTpOMjyobWmK2s7aowy0FtzA49krJzYzEU9s1RMwoJ6g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@next/eslint-plugin-next": "14.0.0",
        "@rushstack/eslint-patch": "^1.3.3",
        "@typescript-eslint/parser": "^5.4.2 || ^6.0.0",
        "eslint-import-resolver-node": "^0.3.6",
        "eslint-import-resolver-typescript": "^3.5.2",
        "eslint-plugin-import": "^2.28.1",
        "eslint-plugin-jsx-a11y": "^6.7.1",
        "eslint-plugin-react": "^7.33.2",
        "eslint-plugin-react-hooks": "^4.5.0 || 5.0.0-canary-7118f5dd7-20230705"
      },
      "peerDependencies": {
        "eslint": "^7.23.0 || ^8.0.0",
        "typescript": ">=3.3.1"
      },
      "peerDependenciesMeta": {
        "typescript": {
          "optional": true
        }
      }
    },
    "node_modules/eslint-import-resolver-node": {
      "version": "0.3.9",
      "resolved": "https://registry.npmjs.org/eslint-import-resolver-node/-/eslint-import-resolver-node-0.3.9.tgz",
      "integrity": "sha512-WFj2isz22JahUv+B788TlO3N6zL3nNJGU8CcZbPZvVEkBPaJdCV4vy5wyghty5ROFbCRnm132v8BScu5/1BQ8g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "debug": "^3.2.7",
        "is-core-module": "^2.13.0",
        "resolve": "^1.22.4"
      }
    },
    "node_modules/eslint-import-resolver-node/node_modules/debug": {
      "version": "3.2.7",
      "resolved": "https://registry.npmjs.org/debug/-/debug-3.2.7.tgz",
      "integrity": "sha512-CFjzYYAi4ThfiQvizrFQevTTXHtnCqWfe7x1AhgEscTz6ZbLbfoLRLPugTQyBth6f8ZERVUSyWHFD/7Wu4t1XQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ms": "^2.1.1"
      }
    },
    "node_modules/eslint-import-resolver-typescript": {
      "version": "3.10.1",
      "resolved": "https://registry.npmjs.org/eslint-import-resolver-typescript/-/eslint-import-resolver-typescript-3.10.1.tgz",
      "integrity": "sha512-A1rHYb06zjMGAxdLSkN2fXPBwuSaQ0iO5M/hdyS0Ajj1VBaRp0sPD3dn1FhME3c/JluGFbwSxyCfqdSbtQLAHQ==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "@nolyfill/is-core-module": "1.0.39",
        "debug": "^4.4.0",
        "get-tsconfig": "^4.10.0",
        "is-bun-module": "^2.0.0",
        "stable-hash": "^0.0.5",
        "tinyglobby": "^0.2.13",
        "unrs-resolver": "^1.6.2"
      },
      "engines": {
        "node": "^14.18.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint-import-resolver-typescript"
      },
      "peerDependencies": {
        "eslint": "*",
        "eslint-plugin-import": "*",
        "eslint-plugin-import-x": "*"
      },
      "peerDependenciesMeta": {
        "eslint-plugin-import": {
          "optional": true
        },
        "eslint-plugin-import-x": {
          "optional": true
        }
      }
    },
    "node_modules/eslint-module-utils": {
      "version": "2.12.1",
      "resolved": "https://registry.npmjs.org/eslint-module-utils/-/eslint-module-utils-2.12.1.tgz",
      "integrity": "sha512-L8jSWTze7K2mTg0vos/RuLRS5soomksDPoJLXIslC7c8Wmut3bx7CPpJijDcBZtxQ5lrbUdM+s0OlNbz0DCDNw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "debug": "^3.2.7"
      },
      "engines": {
        "node": ">=4"
      },
      "peerDependenciesMeta": {
        "eslint": {
          "optional": true
        }
      }
    },
    "node_modules/eslint-module-utils/node_modules/debug": {
      "version": "3.2.7",
      "resolved": "https://registry.npmjs.org/debug/-/debug-3.2.7.tgz",
      "integrity": "sha512-CFjzYYAi4ThfiQvizrFQevTTXHtnCqWfe7x1AhgEscTz6ZbLbfoLRLPugTQyBth6f8ZERVUSyWHFD/7Wu4t1XQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ms": "^2.1.1"
      }
    },
    "node_modules/eslint-plugin-import": {
      "version": "2.32.0",
      "resolved": "https://registry.npmjs.org/eslint-plugin-import/-/eslint-plugin-import-2.32.0.tgz",
      "integrity": "sha512-whOE1HFo/qJDyX4SnXzP4N6zOWn79WhnCUY/iDR0mPfQZO8wcYE4JClzI2oZrhBnnMUCBCHZhO6VQyoBU95mZA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@rtsao/scc": "^1.1.0",
        "array-includes": "^3.1.9",
        "array.prototype.findlastindex": "^1.2.6",
        "array.prototype.flat": "^1.3.3",
        "array.prototype.flatmap": "^1.3.3",
        "debug": "^3.2.7",
        "doctrine": "^2.1.0",
        "eslint-import-resolver-node": "^0.3.9",
        "eslint-module-utils": "^2.12.1",
        "hasown": "^2.0.2",
        "is-core-module": "^2.16.1",
        "is-glob": "^4.0.3",
        "minimatch": "^3.1.2",
        "object.fromentries": "^2.0.8",
        "object.groupby": "^1.0.3",
        "object.values": "^1.2.1",
        "semver": "^6.3.1",
        "string.prototype.trimend": "^1.0.9",
        "tsconfig-paths": "^3.15.0"
      },
      "engines": {
        "node": ">=4"
      },
      "peerDependencies": {
        "eslint": "^2 || ^3 || ^4 || ^5 || ^6 || ^7.2.0 || ^8 || ^9"
      }
    },
    "node_modules/eslint-plugin-import/node_modules/debug": {
      "version": "3.2.7",
      "resolved": "https://registry.npmjs.org/debug/-/debug-3.2.7.tgz",
      "integrity": "sha512-CFjzYYAi4ThfiQvizrFQevTTXHtnCqWfe7x1AhgEscTz6ZbLbfoLRLPugTQyBth6f8ZERVUSyWHFD/7Wu4t1XQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ms": "^2.1.1"
      }
    },
    "node_modules/eslint-plugin-import/node_modules/doctrine": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/doctrine/-/doctrine-2.1.0.tgz",
      "integrity": "sha512-35mSku4ZXK0vfCuHEDAwt55dg2jNajHZ1odvF+8SSr82EsZY4QmXfuWso8oEd8zRhVObSN18aM0CjSdoBX7zIw==",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "esutils": "^2.0.2"
      },
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/eslint-plugin-import/node_modules/semver": {
      "version": "6.3.1",
      "resolved": "https://registry.npmjs.org/semver/-/semver-6.3.1.tgz",
      "integrity": "sha512-BR7VvDCVHO+q2xBEWskxS6DJE1qRnb7DxzUrogb71CWoSficBxYsiAGd+Kl0mmq/MprG9yArRkyrQxTO6XjMzA==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "semver": "bin/semver.js"
      }
    },
    "node_modules/eslint-plugin-jsx-a11y": {
      "version": "6.10.2",
      "resolved": "https://registry.npmjs.org/eslint-plugin-jsx-a11y/-/eslint-plugin-jsx-a11y-6.10.2.tgz",
      "integrity": "sha512-scB3nz4WmG75pV8+3eRUQOHZlNSUhFNq37xnpgRkCCELU3XMvXAxLk1eqWWyE22Ki4Q01Fnsw9BA3cJHDPgn2Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "aria-query": "^5.3.2",
        "array-includes": "^3.1.8",
        "array.prototype.flatmap": "^1.3.2",
        "ast-types-flow": "^0.0.8",
        "axe-core": "^4.10.0",
        "axobject-query": "^4.1.0",
        "damerau-levenshtein": "^1.0.8",
        "emoji-regex": "^9.2.2",
        "hasown": "^2.0.2",
        "jsx-ast-utils": "^3.3.5",
        "language-tags": "^1.0.9",
        "minimatch": "^3.1.2",
        "object.fromentries": "^2.0.8",
        "safe-regex-test": "^1.0.3",
        "string.prototype.includes": "^2.0.1"
      },
      "engines": {
        "node": ">=4.0"
      },
      "peerDependencies": {
        "eslint": "^3 || ^4 || ^5 || ^6 || ^7 || ^8 || ^9"
      }
    },
    "node_modules/eslint-plugin-react": {
      "version": "7.37.5",
      "resolved": "https://registry.npmjs.org/eslint-plugin-react/-/eslint-plugin-react-7.37.5.tgz",
      "integrity": "sha512-Qteup0SqU15kdocexFNAJMvCJEfa2xUKNV4CC1xsVMrIIqEy3SQ/rqyxCWNzfrd3/ldy6HMlD2e0JDVpDg2qIA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "array-includes": "^3.1.8",
        "array.prototype.findlast": "^1.2.5",
        "array.prototype.flatmap": "^1.3.3",
        "array.prototype.tosorted": "^1.1.4",
        "doctrine": "^2.1.0",
        "es-iterator-helpers": "^1.2.1",
        "estraverse": "^5.3.0",
        "hasown": "^2.0.2",
        "jsx-ast-utils": "^2.4.1 || ^3.0.0",
        "minimatch": "^3.1.2",
        "object.entries": "^1.1.9",
        "object.fromentries": "^2.0.8",
        "object.values": "^1.2.1",
        "prop-types": "^15.8.1",
        "resolve": "^2.0.0-next.5",
        "semver": "^6.3.1",
        "string.prototype.matchall": "^4.0.12",
        "string.prototype.repeat": "^1.0.0"
      },
      "engines": {
        "node": ">=4"
      },
      "peerDependencies": {
        "eslint": "^3 || ^4 || ^5 || ^6 || ^7 || ^8 || ^9.7"
      }
    },
    "node_modules/eslint-plugin-react-hooks": {
      "version": "5.0.0-canary-7118f5dd7-20230705",
      "resolved": "https://registry.npmjs.org/eslint-plugin-react-hooks/-/eslint-plugin-react-hooks-5.0.0-canary-7118f5dd7-20230705.tgz",
      "integrity": "sha512-AZYbMo/NW9chdL7vk6HQzQhT+PvTAEVqWk9ziruUoW2kAOcN5qNyelv70e0F1VNQAbvutOC9oc+xfWycI9FxDw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "peerDependencies": {
        "eslint": "^3.0.0 || ^4.0.0 || ^5.0.0 || ^6.0.0 || ^7.0.0 || ^8.0.0-0"
      }
    },
    "node_modules/eslint-plugin-react/node_modules/doctrine": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/doctrine/-/doctrine-2.1.0.tgz",
      "integrity": "sha512-35mSku4ZXK0vfCuHEDAwt55dg2jNajHZ1odvF+8SSr82EsZY4QmXfuWso8oEd8zRhVObSN18aM0CjSdoBX7zIw==",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "esutils": "^2.0.2"
      },
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/eslint-plugin-react/node_modules/resolve": {
      "version": "2.0.0-next.5",
      "resolved": "https://registry.npmjs.org/resolve/-/resolve-2.0.0-next.5.tgz",
      "integrity": "sha512-U7WjGVG9sH8tvjW5SmGbQuui75FiyjAX72HX15DwBBwF9dNiQZRQAg9nnPhYy+TUnE0+VcrttuvNI8oSxZcocA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-core-module": "^2.13.0",
        "path-parse": "^1.0.7",
        "supports-preserve-symlinks-flag": "^1.0.0"
      },
      "bin": {
        "resolve": "bin/resolve"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/eslint-plugin-react/node_modules/semver": {
      "version": "6.3.1",
      "resolved": "https://registry.npmjs.org/semver/-/semver-6.3.1.tgz",
      "integrity": "sha512-BR7VvDCVHO+q2xBEWskxS6DJE1qRnb7DxzUrogb71CWoSficBxYsiAGd+Kl0mmq/MprG9yArRkyrQxTO6XjMzA==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "semver": "bin/semver.js"
      }
    },
    "node_modules/eslint-scope": {
      "version": "7.2.2",
      "resolved": "https://registry.npmjs.org/eslint-scope/-/eslint-scope-7.2.2.tgz",
      "integrity": "sha512-dOt21O7lTMhDM+X9mB4GX+DZrZtCUJPL/wlcTqxyrx5IvO0IYtILdtrQGQp+8n5S0gwSVmOf9NQrjMOgfQZlIg==",
      "dev": true,
      "license": "BSD-2-Clause",
      "dependencies": {
        "esrecurse": "^4.3.0",
        "estraverse": "^5.2.0"
      },
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      }
    },
    "node_modules/eslint-visitor-keys": {
      "version": "3.4.3",
      "resolved": "https://registry.npmjs.org/eslint-visitor-keys/-/eslint-visitor-keys-3.4.3.tgz",
      "integrity": "sha512-wpc+LXeiyiisxPlEkUzU6svyS1frIO3Mgxj1fdy7Pm8Ygzguax2N3Fa/D/ag1WqbOprdI+uY6wMUl8/a2G+iag==",
      "dev": true,
      "license": "Apache-2.0",
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      }
    },
    "node_modules/espree": {
      "version": "9.6.1",
      "resolved": "https://registry.npmjs.org/espree/-/espree-9.6.1.tgz",
      "integrity": "sha512-oruZaFkjorTpF32kDSI5/75ViwGeZginGGy2NoOSg3Q9bnwlnmDm4HLnkl0RE3n+njDXR037aY1+x58Z/zFdwQ==",
      "dev": true,
      "license": "BSD-2-Clause",
      "dependencies": {
        "acorn": "^8.9.0",
        "acorn-jsx": "^5.3.2",
        "eslint-visitor-keys": "^3.4.1"
      },
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      }
    },
    "node_modules/esquery": {
      "version": "1.6.0",
      "resolved": "https://registry.npmjs.org/esquery/-/esquery-1.6.0.tgz",
      "integrity": "sha512-ca9pw9fomFcKPvFLXhBKUK90ZvGibiGOvRJNbjljY7s7uq/5YO4BOzcYtJqExdx99rF6aAcnRxHmcUHcz6sQsg==",
      "dev": true,
      "license": "BSD-3-Clause",
      "dependencies": {
        "estraverse": "^5.1.0"
      },
      "engines": {
        "node": ">=0.10"
      }
    },
    "node_modules/esrecurse": {
      "version": "4.3.0",
      "resolved": "https://registry.npmjs.org/esrecurse/-/esrecurse-4.3.0.tgz",
      "integrity": "sha512-KmfKL3b6G+RXvP8N1vr3Tq1kL/oCFgn2NYXEtqP8/L3pKapUA4G8cFVaoF3SU323CD4XypR/ffioHmkti6/Tag==",
      "dev": true,
      "license": "BSD-2-Clause",
      "dependencies": {
        "estraverse": "^5.2.0"
      },
      "engines": {
        "node": ">=4.0"
      }
    },
    "node_modules/estraverse": {
      "version": "5.3.0",
      "resolved": "https://registry.npmjs.org/estraverse/-/estraverse-5.3.0.tgz",
      "integrity": "sha512-MMdARuVEQziNTeJD8DgMqmhwR11BRQ/cBP+pLtYdSTnf3MIO8fFeiINEbX36ZdNlfU/7A9f3gUw49B3oQsvwBA==",
      "dev": true,
      "license": "BSD-2-Clause",
      "engines": {
        "node": ">=4.0"
      }
    },
    "node_modules/esutils": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/esutils/-/esutils-2.0.3.tgz",
      "integrity": "sha512-kVscqXk4OCp68SZ0dkgEKVi6/8ij300KBWTJq32P/dYeWTSwK41WyTxalN1eRmA5Z9UU/LX9D7FWSmV9SAYx6g==",
      "dev": true,
      "license": "BSD-2-Clause",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/fast-deep-equal": {
      "version": "3.1.3",
      "resolved": "https://registry.npmjs.org/fast-deep-equal/-/fast-deep-equal-3.1.3.tgz",
      "integrity": "sha512-f3qQ9oQy9j2AhBe/H9VC91wLmKBCCU/gDOnKNAYG5hswO7BLKj09Hc5HYNz9cGI++xlpDCIgDaitVs03ATR84Q==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/fast-glob": {
      "version": "3.3.3",
      "resolved": "https://registry.npmjs.org/fast-glob/-/fast-glob-3.3.3.tgz",
      "integrity": "sha512-7MptL8U0cqcFdzIzwOTHoilX9x5BrNqye7Z/LuC7kCMRio1EMSyqRK3BEAUD7sXRq4iT4AzTVuZdhgQ2TCvYLg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@nodelib/fs.stat": "^2.0.2",
        "@nodelib/fs.walk": "^1.2.3",
        "glob-parent": "^5.1.2",
        "merge2": "^1.3.0",
        "micromatch": "^4.0.8"
      },
      "engines": {
        "node": ">=8.6.0"
      }
    },
    "node_modules/fast-glob/node_modules/glob-parent": {
      "version": "5.1.2",
      "resolved": "https://registry.npmjs.org/glob-parent/-/glob-parent-5.1.2.tgz",
      "integrity": "sha512-AOIgSQCepiJYwP3ARnGx+5VnTu2HBYdzbGP45eLw1vr3zB3vZLeyed1sC9hnbcOc9/SrMyM5RPQrkGz4aS9Zow==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "is-glob": "^4.0.1"
      },
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/fast-json-stable-stringify": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/fast-json-stable-stringify/-/fast-json-stable-stringify-2.1.0.tgz",
      "integrity": "sha512-lhd/wF+Lk98HZoTCtlVraHtfh5XYijIjalXck7saUtuanSDyLMxnHhSXEDJqHxD7msR8D0uCmqlkwjCV8xvwHw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/fast-levenshtein": {
      "version": "2.0.6",
      "resolved": "https://registry.npmjs.org/fast-levenshtein/-/fast-levenshtein-2.0.6.tgz",
      "integrity": "sha512-DCXu6Ifhqcks7TZKY3Hxp3y6qphY5SJZmrWMDrKcERSOXWQdMhU9Ig/PYrzyw/ul9jOIyh0N4M0tbC5hodg8dw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/fastq": {
      "version": "1.19.1",
      "resolved": "https://registry.npmjs.org/fastq/-/fastq-1.19.1.tgz",
      "integrity": "sha512-GwLTyxkCXjXbxqIhTsMI2Nui8huMPtnxg7krajPJAjnEG/iiOS7i+zCtWGZR9G0NBKbXKh6X9m9UIsYX/N6vvQ==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "reusify": "^1.0.4"
      }
    },
    "node_modules/file-entry-cache": {
      "version": "6.0.1",
      "resolved": "https://registry.npmjs.org/file-entry-cache/-/file-entry-cache-6.0.1.tgz",
      "integrity": "sha512-7Gps/XWymbLk2QLYK4NzpMOrYjMhdIxXuIvy2QBsLE6ljuodKvdkWs/cpyJJ3CVIVpH0Oi1Hvg1ovbMzLdFBBg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "flat-cache": "^3.0.4"
      },
      "engines": {
        "node": "^10.12.0 || >=12.0.0"
      }
    },
    "node_modules/fill-range": {
      "version": "7.1.1",
      "resolved": "https://registry.npmjs.org/fill-range/-/fill-range-7.1.1.tgz",
      "integrity": "sha512-YsGpe3WHLK8ZYi4tWDg2Jy3ebRz2rXowDxnld4bkQB00cc/1Zw9AWnC0i9ztDJitivtQvaI9KaLyKrc+hBW0yg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "to-regex-range": "^5.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/find-up": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/find-up/-/find-up-5.0.0.tgz",
      "integrity": "sha512-78/PXT1wlLLDgTzDs7sjq9hzz0vXD+zn+7wypEe4fXQxCmdmqfGsEPQxmiCSQI3ajFV91bVSsvNtrJRiW6nGng==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "locate-path": "^6.0.0",
        "path-exists": "^4.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/flat-cache": {
      "version": "3.2.0",
      "resolved": "https://registry.npmjs.org/flat-cache/-/flat-cache-3.2.0.tgz",
      "integrity": "sha512-CYcENa+FtcUKLmhhqyctpclsq7QF38pKjZHsGNiSQF5r4FtoKDWabFDl3hzaEQMvT1LHEysw5twgLvpYYb4vbw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "flatted": "^3.2.9",
        "keyv": "^4.5.3",
        "rimraf": "^3.0.2"
      },
      "engines": {
        "node": "^10.12.0 || >=12.0.0"
      }
    },
    "node_modules/flatted": {
      "version": "3.3.3",
      "resolved": "https://registry.npmjs.org/flatted/-/flatted-3.3.3.tgz",
      "integrity": "sha512-GX+ysw4PBCz0PzosHDepZGANEuFCMLrnRTiEy9McGjmkCQYwRq4A/X786G/fjM/+OjsWSU1ZrY5qyARZmO/uwg==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/for-each": {
      "version": "0.3.5",
      "resolved": "https://registry.npmjs.org/for-each/-/for-each-0.3.5.tgz",
      "integrity": "sha512-dKx12eRCVIzqCxFGplyFKJMPvLEWgmNtUrpTiJIR5u97zEhRG8ySrtboPHZXx7daLxQVrl643cTzbab2tkQjxg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-callable": "^1.2.7"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/foreground-child": {
      "version": "3.3.1",
      "resolved": "https://registry.npmjs.org/foreground-child/-/foreground-child-3.3.1.tgz",
      "integrity": "sha512-gIXjKqtFuWEgzFRJA9WCQeSJLZDjgJUOMCMzxtvFq/37KojM1BFGufqsCy0r4qSQmYLsZYMeyRqzIWOMup03sw==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "cross-spawn": "^7.0.6",
        "signal-exit": "^4.0.1"
      },
      "engines": {
        "node": ">=14"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/fraction.js": {
      "version": "4.3.7",
      "resolved": "https://registry.npmjs.org/fraction.js/-/fraction.js-4.3.7.tgz",
      "integrity": "sha512-ZsDfxO51wGAXREY55a7la9LScWpwv9RxIrYABrlvOFBlH/ShPnrtsXeuUIfXKKOVicNxQ+o8JTbJvjS4M89yew==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": "*"
      },
      "funding": {
        "type": "patreon",
        "url": "https://github.com/sponsors/rawify"
      }
    },
    "node_modules/fs.realpath": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/fs.realpath/-/fs.realpath-1.0.0.tgz",
      "integrity": "sha512-OO0pH2lK6a0hZnAdau5ItzHPI6pUlvI7jMVnxUQRtw4owF2wk8lOSabtGDCTP4Ggrg2MbGnWO9X8K1t4+fGMDw==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/fsevents": {
      "version": "2.3.3",
      "resolved": "https://registry.npmjs.org/fsevents/-/fsevents-2.3.3.tgz",
      "integrity": "sha512-5xoDfX+fL7faATnagmWPpbFtwh/R77WmMMqqHGS65C3vvB0YHrgF+B1YmZ3441tMj5n63k0212XNoJwzlhffQw==",
      "dev": true,
      "hasInstallScript": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": "^8.16.0 || ^10.6.0 || >=11.0.0"
      }
    },
    "node_modules/function-bind": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/function-bind/-/function-bind-1.1.2.tgz",
      "integrity": "sha512-7XHNxH7qX9xG5mIwxkhumTox/MIRNcOgDrxWsMt2pAr23WHp6MrRlN7FBSFpCpr+oVO0F744iUgR82nJMfG2SA==",
      "dev": true,
      "license": "MIT",
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/function.prototype.name": {
      "version": "1.1.8",
      "resolved": "https://registry.npmjs.org/function.prototype.name/-/function.prototype.name-1.1.8.tgz",
      "integrity": "sha512-e5iwyodOHhbMr/yNrc7fDYG4qlbIvI5gajyzPnb5TCwyhjApznQh1BMFou9b30SevY43gCJKXycoCBjMbsuW0Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.3",
        "define-properties": "^1.2.1",
        "functions-have-names": "^1.2.3",
        "hasown": "^2.0.2",
        "is-callable": "^1.2.7"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/functions-have-names": {
      "version": "1.2.3",
      "resolved": "https://registry.npmjs.org/functions-have-names/-/functions-have-names-1.2.3.tgz",
      "integrity": "sha512-xckBUXyTIqT97tq2x2AMb+g163b5JFysYk0x4qxNFwbfQkmNZoiRHb6sPzI9/QV33WeuvVYBUIiD4NzNIyqaRQ==",
      "dev": true,
      "license": "MIT",
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/get-intrinsic": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/get-intrinsic/-/get-intrinsic-1.3.0.tgz",
      "integrity": "sha512-9fSjSaos/fRIVIp+xSJlE6lfwhES7LNtKaCBIamHsjr2na1BiABJPo0mOjjz8GJDURarmCPGqaiVg5mfjb98CQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind-apply-helpers": "^1.0.2",
        "es-define-property": "^1.0.1",
        "es-errors": "^1.3.0",
        "es-object-atoms": "^1.1.1",
        "function-bind": "^1.1.2",
        "get-proto": "^1.0.1",
        "gopd": "^1.2.0",
        "has-symbols": "^1.1.0",
        "hasown": "^2.0.2",
        "math-intrinsics": "^1.1.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/get-proto": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/get-proto/-/get-proto-1.0.1.tgz",
      "integrity": "sha512-sTSfBjoXBp89JvIKIefqw7U2CCebsc74kiY6awiGogKtoSGbgjYE/G/+l9sF3MWFPNc9IcoOC4ODfKHfxFmp0g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "dunder-proto": "^1.0.1",
        "es-object-atoms": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/get-symbol-description": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/get-symbol-description/-/get-symbol-description-1.1.0.tgz",
      "integrity": "sha512-w9UMqWwJxHNOvoNzSJ2oPF5wvYcvP7jUvYzhp67yEhTi17ZDBBC1z9pTdGuzjD+EFIqLSYRweZjqfiPzQ06Ebg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "es-errors": "^1.3.0",
        "get-intrinsic": "^1.2.6"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/get-tsconfig": {
      "version": "4.10.1",
      "resolved": "https://registry.npmjs.org/get-tsconfig/-/get-tsconfig-4.10.1.tgz",
      "integrity": "sha512-auHyJ4AgMz7vgS8Hp3N6HXSmlMdUyhSUrfBF16w153rxtLIEOE+HGqaBppczZvnHLqQJfiHotCYpNhl0lUROFQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "resolve-pkg-maps": "^1.0.0"
      },
      "funding": {
        "url": "https://github.com/privatenumber/get-tsconfig?sponsor=1"
      }
    },
    "node_modules/glob": {
      "version": "7.1.7",
      "resolved": "https://registry.npmjs.org/glob/-/glob-7.1.7.tgz",
      "integrity": "sha512-OvD9ENzPLbegENnYP5UUfJIirTg4+XwMWGaQfQTY0JenxNvvIKP3U3/tAQSPIu/lHxXYSZmpXlUHeqAIdKzBLQ==",
      "deprecated": "Glob versions prior to v9 are no longer supported",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "fs.realpath": "^1.0.0",
        "inflight": "^1.0.4",
        "inherits": "2",
        "minimatch": "^3.0.4",
        "once": "^1.3.0",
        "path-is-absolute": "^1.0.0"
      },
      "engines": {
        "node": "*"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/glob-parent": {
      "version": "6.0.2",
      "resolved": "https://registry.npmjs.org/glob-parent/-/glob-parent-6.0.2.tgz",
      "integrity": "sha512-XxwI8EOhVQgWp6iDL+3b0r86f4d6AX6zSU55HfB4ydCEuXLXc5FcYeOu+nnGftS4TEju/11rt4KJPTMgbfmv4A==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "is-glob": "^4.0.3"
      },
      "engines": {
        "node": ">=10.13.0"
      }
    },
    "node_modules/glob-to-regexp": {
      "version": "0.4.1",
      "resolved": "https://registry.npmjs.org/glob-to-regexp/-/glob-to-regexp-0.4.1.tgz",
      "integrity": "sha512-lkX1HJXwyMcprw/5YUZc2s7DrpAiHB21/V+E1rHUrVNokkvB6bqMzT0VfV6/86ZNabt1k14YOIaT7nDvOX3Iiw==",
      "license": "BSD-2-Clause"
    },
    "node_modules/globals": {
      "version": "13.24.0",
      "resolved": "https://registry.npmjs.org/globals/-/globals-13.24.0.tgz",
      "integrity": "sha512-AhO5QUcj8llrbG09iWhPU2B204J1xnPeL8kQmVorSsy+Sjj1sk8gIyh6cUocGmH4L0UuhAJy+hJMRA4mgA4mFQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "type-fest": "^0.20.2"
      },
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/globalthis": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/globalthis/-/globalthis-1.0.4.tgz",
      "integrity": "sha512-DpLKbNU4WylpxJykQujfCcwYWiV/Jhm50Goo0wrVILAv5jOr9d+H+UR3PhSCD2rCCEIg0uc+G+muBTwD54JhDQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "define-properties": "^1.2.1",
        "gopd": "^1.0.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/globby": {
      "version": "11.1.0",
      "resolved": "https://registry.npmjs.org/globby/-/globby-11.1.0.tgz",
      "integrity": "sha512-jhIXaOzy1sb8IyocaruWSn1TjmnBVs8Ayhcy83rmxNJ8q2uWKCAj3CnJY+KpGSXCueAPc0i05kVvVKtP1t9S3g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "array-union": "^2.1.0",
        "dir-glob": "^3.0.1",
        "fast-glob": "^3.2.9",
        "ignore": "^5.2.0",
        "merge2": "^1.4.1",
        "slash": "^3.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/gopd": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/gopd/-/gopd-1.2.0.tgz",
      "integrity": "sha512-ZUKRh6/kUFoAiTAtTYPZJ3hw9wNxx+BIBOijnlG9PnrJsCcSjs1wyyD6vJpaYtgnzDrKYRSqf3OO6Rfa93xsRg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/graceful-fs": {
      "version": "4.2.11",
      "resolved": "https://registry.npmjs.org/graceful-fs/-/graceful-fs-4.2.11.tgz",
      "integrity": "sha512-RbJ5/jmFcNNCcDV5o9eTnBLJ/HszWV0P73bc+Ff4nS/rJj+YaS6IGyiOL0VoBYX+l1Wrl3k63h/KrH+nhJ0XvQ==",
      "license": "ISC"
    },
    "node_modules/graphemer": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/graphemer/-/graphemer-1.4.0.tgz",
      "integrity": "sha512-EtKwoO6kxCL9WO5xipiHTZlSzBm7WLT627TqC/uVRd0HKmq8NXyebnNYxDoBi7wt8eTWrUrKXCOVaFq9x1kgag==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/has-bigints": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/has-bigints/-/has-bigints-1.1.0.tgz",
      "integrity": "sha512-R3pbpkcIqv2Pm3dUwgjclDRVmWpTJW2DcMzcIhEXEx1oh/CEMObMm3KLmRJOdvhM7o4uQBnwr8pzRK2sJWIqfg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/has-flag": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/has-flag/-/has-flag-4.0.0.tgz",
      "integrity": "sha512-EykJT/Q1KjTWctppgIAgfSO0tKVuZUjhgMr17kqTumMl6Afv3EISleU7qZUzoXDFTAHTDC4NOoG/ZxU3EvlMPQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/has-property-descriptors": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/has-property-descriptors/-/has-property-descriptors-1.0.2.tgz",
      "integrity": "sha512-55JNKuIW+vq4Ke1BjOTjM2YctQIvCT7GFzHwmfZPGo5wnrgkid0YQtnAleFSqumZm4az3n2BS+erby5ipJdgrg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "es-define-property": "^1.0.0"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/has-proto": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/has-proto/-/has-proto-1.2.0.tgz",
      "integrity": "sha512-KIL7eQPfHQRC8+XluaIw7BHUwwqL19bQn4hzNgdr+1wXoU0KKj6rufu47lhY7KbJR2C6T6+PfyN0Ea7wkSS+qQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "dunder-proto": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/has-symbols": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/has-symbols/-/has-symbols-1.1.0.tgz",
      "integrity": "sha512-1cDNdwJ2Jaohmb3sg4OmKaMBwuC48sYni5HUw2DvsC8LjGTLK9h+eb1X6RyuOHe4hT0ULCW68iomhjUoKUqlPQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/has-tostringtag": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/has-tostringtag/-/has-tostringtag-1.0.2.tgz",
      "integrity": "sha512-NqADB8VjPFLM2V0VvHUewwwsw0ZWBaIdgo+ieHtK3hasLz4qeCRjYcqfB6AQrBggRKppKF8L52/VqdVsO47Dlw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "has-symbols": "^1.0.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/hasown": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/hasown/-/hasown-2.0.2.tgz",
      "integrity": "sha512-0hJU9SCPvmMzIBdZFqNPXWa6dqh7WdH0cII9y+CyS8rG3nL48Bclra9HmKhVVUHyPWNH5Y7xDwAB7bfgSjkUMQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "function-bind": "^1.1.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/ignore": {
      "version": "5.3.2",
      "resolved": "https://registry.npmjs.org/ignore/-/ignore-5.3.2.tgz",
      "integrity": "sha512-hsBTNUqQTDwkWtcdYI2i06Y/nUBEsNEDJKjWdigLvegy8kDuJAS8uRlpkkcQpyEXL0Z/pjDy5HBmMjRCJ2gq+g==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 4"
      }
    },
    "node_modules/immediate": {
      "version": "3.0.6",
      "resolved": "https://registry.npmjs.org/immediate/-/immediate-3.0.6.tgz",
      "integrity": "sha512-XXOFtyqDjNDAQxVfYxuF7g9Il/IbWmmlQg2MYKOH8ExIT1qg6xc4zyS3HaEEATgs1btfzxq15ciUiY7gjSXRGQ==",
      "license": "MIT"
    },
    "node_modules/import-fresh": {
      "version": "3.3.1",
      "resolved": "https://registry.npmjs.org/import-fresh/-/import-fresh-3.3.1.tgz",
      "integrity": "sha512-TR3KfrTZTYLPB6jUjfx6MF9WcWrHL9su5TObK4ZkYgBdWKPOFoSoQIdEuTuR82pmtxH2spWG9h6etwfr1pLBqQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "parent-module": "^1.0.0",
        "resolve-from": "^4.0.0"
      },
      "engines": {
        "node": ">=6"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/imurmurhash": {
      "version": "0.1.4",
      "resolved": "https://registry.npmjs.org/imurmurhash/-/imurmurhash-0.1.4.tgz",
      "integrity": "sha512-JmXMZ6wuvDmLiHEml9ykzqO6lwFbof0GG4IkcGaENdCRDDmMVnny7s5HsIgHCbaq0w2MyPhDqkhTUgS2LU2PHA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.8.19"
      }
    },
    "node_modules/inflight": {
      "version": "1.0.6",
      "resolved": "https://registry.npmjs.org/inflight/-/inflight-1.0.6.tgz",
      "integrity": "sha512-k92I/b08q4wvFscXCLvqfsHCrjrF7yiXsQuIVvVE7N82W3+aqpzuUdBbfhWcy/FZR3/4IgflMgKLOsvPDrGCJA==",
      "deprecated": "This module is not supported, and leaks memory. Do not use it. Check out lru-cache if you want a good and tested way to coalesce async requests by a key value, which is much more comprehensive and powerful.",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "once": "^1.3.0",
        "wrappy": "1"
      }
    },
    "node_modules/inherits": {
      "version": "2.0.4",
      "resolved": "https://registry.npmjs.org/inherits/-/inherits-2.0.4.tgz",
      "integrity": "sha512-k/vGaX4/Yla3WzyMCvTQOXYeIHvqOKtnqBduzTHpzpQZzAskKMhZ2K+EnBiSM9zGSoIFeMpXKxa4dYeZIQqewQ==",
      "license": "ISC"
    },
    "node_modules/internal-slot": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/internal-slot/-/internal-slot-1.1.0.tgz",
      "integrity": "sha512-4gd7VpWNQNB4UKKCFFVcp1AVv+FMOgs9NKzjHKusc8jTMhd5eL1NqQqOpE0KzMds804/yHlglp3uxgluOqAPLw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0",
        "hasown": "^2.0.2",
        "side-channel": "^1.1.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/is-array-buffer": {
      "version": "3.0.5",
      "resolved": "https://registry.npmjs.org/is-array-buffer/-/is-array-buffer-3.0.5.tgz",
      "integrity": "sha512-DDfANUiiG2wC1qawP66qlTugJeL5HyzMpfr8lLK+jMQirGzNod0B12cFB/9q838Ru27sBwfw78/rdoU7RERz6A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.3",
        "get-intrinsic": "^1.2.6"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-async-function": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/is-async-function/-/is-async-function-2.1.1.tgz",
      "integrity": "sha512-9dgM/cZBnNvjzaMYHVoxxfPj2QXt22Ev7SuuPrs+xav0ukGB0S6d4ydZdEiM48kLx5kDV+QBPrpVnFyefL8kkQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "async-function": "^1.0.0",
        "call-bound": "^1.0.3",
        "get-proto": "^1.0.1",
        "has-tostringtag": "^1.0.2",
        "safe-regex-test": "^1.1.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-bigint": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/is-bigint/-/is-bigint-1.1.0.tgz",
      "integrity": "sha512-n4ZT37wG78iz03xPRKJrHTdZbe3IicyucEtdRsV5yglwc3GyUfbAfpSeD0FJ41NbUNSt5wbhqfp1fS+BgnvDFQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "has-bigints": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-binary-path": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/is-binary-path/-/is-binary-path-2.1.0.tgz",
      "integrity": "sha512-ZMERYes6pDydyuGidse7OsHxtbI7WVeUEozgR/g7rd0xUimYNlvZRE/K2MgZTjWy725IfelLeVcEM97mmtRGXw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "binary-extensions": "^2.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/is-boolean-object": {
      "version": "1.2.2",
      "resolved": "https://registry.npmjs.org/is-boolean-object/-/is-boolean-object-1.2.2.tgz",
      "integrity": "sha512-wa56o2/ElJMYqjCjGkXri7it5FbebW5usLw/nPmCMs5DeZ7eziSYZhSmPRn0txqeW4LnAmQQU7FgqLpsEFKM4A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "has-tostringtag": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-bun-module": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/is-bun-module/-/is-bun-module-2.0.0.tgz",
      "integrity": "sha512-gNCGbnnnnFAUGKeZ9PdbyeGYJqewpmc2aKHUEMO5nQPWU9lOmv7jcmQIv+qHD8fXW6W7qfuCwX4rY9LNRjXrkQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "semver": "^7.7.1"
      }
    },
    "node_modules/is-callable": {
      "version": "1.2.7",
      "resolved": "https://registry.npmjs.org/is-callable/-/is-callable-1.2.7.tgz",
      "integrity": "sha512-1BC0BVFhS/p0qtw6enp8e+8OD0UrK0oFLztSjNzhcKA3WDuJxxAPXzPuPtKkjEY9UUoEWlX/8fgKeu2S8i9JTA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-core-module": {
      "version": "2.16.1",
      "resolved": "https://registry.npmjs.org/is-core-module/-/is-core-module-2.16.1.tgz",
      "integrity": "sha512-UfoeMA6fIJ8wTYFEUjelnaGI67v6+N7qXJEvQuIGa99l4xsCruSYOVSQ0uPANn4dAzm8lkYPaKLrrijLq7x23w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "hasown": "^2.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-data-view": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/is-data-view/-/is-data-view-1.0.2.tgz",
      "integrity": "sha512-RKtWF8pGmS87i2D6gqQu/l7EYRlVdfzemCJN/P3UOs//x1QE7mfhvzHIApBTRf7axvT6DMGwSwBXYCT0nfB9xw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.2",
        "get-intrinsic": "^1.2.6",
        "is-typed-array": "^1.1.13"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-date-object": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/is-date-object/-/is-date-object-1.1.0.tgz",
      "integrity": "sha512-PwwhEakHVKTdRNVOw+/Gyh0+MzlCl4R6qKvkhuvLtPMggI1WAHt9sOwZxQLSGpUaDnrdyDsomoRgNnCfKNSXXg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.2",
        "has-tostringtag": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-extglob": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/is-extglob/-/is-extglob-2.1.1.tgz",
      "integrity": "sha512-SbKbANkN603Vi4jEZv49LeVJMn4yGwsbzZworEoyEiutsN3nJYdbO36zfhGJ6QEDpOZIFkDtnq5JRxmvl3jsoQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/is-finalizationregistry": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/is-finalizationregistry/-/is-finalizationregistry-1.1.1.tgz",
      "integrity": "sha512-1pC6N8qWJbWoPtEjgcL2xyhQOP491EQjeUo3qTKcmV8YSDDJrOepfG8pcC7h/QgnQHYSv0mJ3Z/ZWxmatVrysg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-fullwidth-code-point": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/is-fullwidth-code-point/-/is-fullwidth-code-point-3.0.0.tgz",
      "integrity": "sha512-zymm5+u+sCsSWyD9qNaejV3DFvhCKclKdizYaJUuHA83RLjb7nSuGnddCHGv0hk+KY7BMAlsWeK4Ueg6EV6XQg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/is-generator-function": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/is-generator-function/-/is-generator-function-1.1.0.tgz",
      "integrity": "sha512-nPUB5km40q9e8UfN/Zc24eLlzdSf9OfKByBw9CIdw4H1giPMeA0OIJvbchsCu4npfI2QcMVBsGEBHKZ7wLTWmQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "get-proto": "^1.0.0",
        "has-tostringtag": "^1.0.2",
        "safe-regex-test": "^1.1.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-glob": {
      "version": "4.0.3",
      "resolved": "https://registry.npmjs.org/is-glob/-/is-glob-4.0.3.tgz",
      "integrity": "sha512-xelSayHH36ZgE7ZWhli7pW34hNbNl8Ojv5KVmkJD4hBdD3th8Tfk9vYasLM+mXWOZhFkgZfxhLSnrwRr4elSSg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-extglob": "^2.1.1"
      },
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/is-map": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/is-map/-/is-map-2.0.3.tgz",
      "integrity": "sha512-1Qed0/Hr2m+YqxnM09CjA2d/i6YZNfF6R2oRAOj36eUdS6qIV/huPJNSEpKbupewFs+ZsJlxsjjPbc0/afW6Lw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-negative-zero": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/is-negative-zero/-/is-negative-zero-2.0.3.tgz",
      "integrity": "sha512-5KoIu2Ngpyek75jXodFvnafB6DJgr3u8uuK0LEZJjrU19DrMD3EVERaR8sjz8CCGgpZvxPl9SuE1GMVPFHx1mw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-number": {
      "version": "7.0.0",
      "resolved": "https://registry.npmjs.org/is-number/-/is-number-7.0.0.tgz",
      "integrity": "sha512-41Cifkg6e8TylSpdtTpeLVMqvSBEVzTttHvERD741+pnZ8ANv0004MRL43QKPDlK9cGvNp6NZWZUBlbGXYxxng==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.12.0"
      }
    },
    "node_modules/is-number-object": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/is-number-object/-/is-number-object-1.1.1.tgz",
      "integrity": "sha512-lZhclumE1G6VYD8VHe35wFaIif+CTy5SJIi5+3y4psDgWu4wPDoBhF8NxUOinEc7pHgiTsT6MaBb92rKhhD+Xw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "has-tostringtag": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-path-inside": {
      "version": "3.0.3",
      "resolved": "https://registry.npmjs.org/is-path-inside/-/is-path-inside-3.0.3.tgz",
      "integrity": "sha512-Fd4gABb+ycGAmKou8eMftCupSir5lRxqf4aD/vd0cD2qc4HL07OjCeuHMr8Ro4CoMaeCKDB0/ECBOVWjTwUvPQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/is-regex": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/is-regex/-/is-regex-1.2.1.tgz",
      "integrity": "sha512-MjYsKHO5O7mCsmRGxWcLWheFqN9DJ/2TmngvjKXihe6efViPqc274+Fx/4fYj/r03+ESvBdTXK0V6tA3rgez1g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.2",
        "gopd": "^1.2.0",
        "has-tostringtag": "^1.0.2",
        "hasown": "^2.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-set": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/is-set/-/is-set-2.0.3.tgz",
      "integrity": "sha512-iPAjerrse27/ygGLxw+EBR9agv9Y6uLeYVJMu+QNCoouJ1/1ri0mGrcWpfCqFZuzzx3WjtwxG098X+n4OuRkPg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-shared-array-buffer": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/is-shared-array-buffer/-/is-shared-array-buffer-1.0.4.tgz",
      "integrity": "sha512-ISWac8drv4ZGfwKl5slpHG9OwPNty4jOWPRIhBpxOoD+hqITiwuipOQ2bNthAzwA3B4fIjO4Nln74N0S9byq8A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-string": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/is-string/-/is-string-1.1.1.tgz",
      "integrity": "sha512-BtEeSsoaQjlSPBemMQIrY1MY0uM6vnS1g5fmufYOtnxLGUZM2178PKbhsk7Ffv58IX+ZtcvoGwccYsh0PglkAA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "has-tostringtag": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-symbol": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/is-symbol/-/is-symbol-1.1.1.tgz",
      "integrity": "sha512-9gGx6GTtCQM73BgmHQXfDmLtfjjTUDSyoxTCbp5WtoixAhfgsDirWIcVQ/IHpvI5Vgd5i/J5F7B9cN/WlVbC/w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.2",
        "has-symbols": "^1.1.0",
        "safe-regex-test": "^1.1.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-typed-array": {
      "version": "1.1.15",
      "resolved": "https://registry.npmjs.org/is-typed-array/-/is-typed-array-1.1.15.tgz",
      "integrity": "sha512-p3EcsicXjit7SaskXHs1hA91QxgTw46Fv6EFKKGS5DRFLD8yKnohjF3hxoju94b/OcMZoQukzpPpBE9uLVKzgQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "which-typed-array": "^1.1.16"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-weakmap": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/is-weakmap/-/is-weakmap-2.0.2.tgz",
      "integrity": "sha512-K5pXYOm9wqY1RgjpL3YTkF39tni1XajUIkawTLUo9EZEVUFga5gSQJF8nNS7ZwJQ02y+1YCNYcMh+HIf1ZqE+w==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-weakref": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/is-weakref/-/is-weakref-1.1.1.tgz",
      "integrity": "sha512-6i9mGWSlqzNMEqpCp93KwRS1uUOodk2OJ6b+sq7ZPDSy2WuI5NFIxp/254TytR8ftefexkWn5xNiHUNpPOfSew==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-weakset": {
      "version": "2.0.4",
      "resolved": "https://registry.npmjs.org/is-weakset/-/is-weakset-2.0.4.tgz",
      "integrity": "sha512-mfcwb6IzQyOKTs84CQMrOwW4gQcaTOAWJ0zzJCl2WSPDrWk/OzDaImWFH3djXhb24g4eudZfLRozAvPGw4d9hQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "get-intrinsic": "^1.2.6"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/isarray": {
      "version": "2.0.5",
      "resolved": "https://registry.npmjs.org/isarray/-/isarray-2.0.5.tgz",
      "integrity": "sha512-xHjhDr3cNBK0BzdUJSPXZntQUx/mwMS5Rw4A7lPJ90XGAO6ISP/ePDNuo0vhqOZU+UD5JoodwCAAoZQd3FeAKw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/isexe": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/isexe/-/isexe-2.0.0.tgz",
      "integrity": "sha512-RHxMLp9lnKHGHRng9QFhRCMbYAcVpn69smSGcq3f36xjgVVWThj4qqLbTLlq7Ssj8B+fIQ1EuCEGI2lKsyQeIw==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/iterator.prototype": {
      "version": "1.1.5",
      "resolved": "https://registry.npmjs.org/iterator.prototype/-/iterator.prototype-1.1.5.tgz",
      "integrity": "sha512-H0dkQoCa3b2VEeKQBOxFph+JAbcrQdE7KC0UkqwpLmv2EC4P41QXP+rqo9wYodACiG5/WM5s9oDApTU8utwj9g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "define-data-property": "^1.1.4",
        "es-object-atoms": "^1.0.0",
        "get-intrinsic": "^1.2.6",
        "get-proto": "^1.0.0",
        "has-symbols": "^1.1.0",
        "set-function-name": "^2.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/jackspeak": {
      "version": "3.4.3",
      "resolved": "https://registry.npmjs.org/jackspeak/-/jackspeak-3.4.3.tgz",
      "integrity": "sha512-OGlZQpz2yfahA/Rd1Y8Cd9SIEsqvXkLVoSw/cgwhnhFMDbsQFeZYoJJ7bIZBS9BcamUW96asq/npPWugM+RQBw==",
      "dev": true,
      "license": "BlueOak-1.0.0",
      "dependencies": {
        "@isaacs/cliui": "^8.0.2"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      },
      "optionalDependencies": {
        "@pkgjs/parseargs": "^0.11.0"
      }
    },
    "node_modules/jiti": {
      "version": "1.21.7",
      "resolved": "https://registry.npmjs.org/jiti/-/jiti-1.21.7.tgz",
      "integrity": "sha512-/imKNG4EbWNrVjoNC/1H5/9GFy+tqjGBHCaSsN+P2RnPqjsLmv6UD3Ej+Kj8nBWaRAwyk7kK5ZUc+OEatnTR3A==",
      "dev": true,
      "license": "MIT",
      "bin": {
        "jiti": "bin/jiti.js"
      }
    },
    "node_modules/js-tokens": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/js-tokens/-/js-tokens-4.0.0.tgz",
      "integrity": "sha512-RdJUflcE3cUzKiMqQgsCu06FPu9UdIJO0beYbPhHN4k6apgJtifcoCtT9bcxOpYBtpD2kCM6Sbzg4CausW/PKQ==",
      "license": "MIT"
    },
    "node_modules/js-yaml": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/js-yaml/-/js-yaml-4.1.0.tgz",
      "integrity": "sha512-wpxZs9NoxZaJESJGIZTyDEaYpl0FKSA+FB9aJiyemKhMwkxQg63h4T1KJgUGHpTqPDNRcmmYLugrRjJlBtWvRA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "argparse": "^2.0.1"
      },
      "bin": {
        "js-yaml": "bin/js-yaml.js"
      }
    },
    "node_modules/json-buffer": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/json-buffer/-/json-buffer-3.0.1.tgz",
      "integrity": "sha512-4bV5BfR2mqfQTJm+V5tPPdf+ZpuhiIvTuAB5g8kcrXOZpTT/QwwVRWBywX1ozr6lEuPdbHxwaJlm9G6mI2sfSQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/json-schema-traverse": {
      "version": "0.4.1",
      "resolved": "https://registry.npmjs.org/json-schema-traverse/-/json-schema-traverse-0.4.1.tgz",
      "integrity": "sha512-xbbCH5dCYU5T8LcEhhuh7HJ88HXuW3qsI3Y0zOZFKfZEHcpWiHU/Jxzk629Brsab/mMiHQti9wMP+845RPe3Vg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/json-stable-stringify-without-jsonify": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/json-stable-stringify-without-jsonify/-/json-stable-stringify-without-jsonify-1.0.1.tgz",
      "integrity": "sha512-Bdboy+l7tA3OGW6FjyFHWkP5LuByj1Tk33Ljyq0axyzdk9//JSi2u3fP1QSmd1KNwq6VOKYGlAu87CisVir6Pw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/json5": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/json5/-/json5-1.0.2.tgz",
      "integrity": "sha512-g1MWMLBiz8FKi1e4w0UyVL3w+iJceWAFBAaBnnGKOpNa5f8TLktkbre1+s6oICydWAm+HRUGTmI+//xv2hvXYA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "minimist": "^1.2.0"
      },
      "bin": {
        "json5": "lib/cli.js"
      }
    },
    "node_modules/jsx-ast-utils": {
      "version": "3.3.5",
      "resolved": "https://registry.npmjs.org/jsx-ast-utils/-/jsx-ast-utils-3.3.5.tgz",
      "integrity": "sha512-ZZow9HBI5O6EPgSJLUb8n2NKgmVWTwCvHGwFuJlMjvLFqlGG6pjirPhtdsseaLZjSibD8eegzmYpUZwoIlj2cQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "array-includes": "^3.1.6",
        "array.prototype.flat": "^1.3.1",
        "object.assign": "^4.1.4",
        "object.values": "^1.1.6"
      },
      "engines": {
        "node": ">=4.0"
      }
    },
    "node_modules/jszip": {
      "version": "3.10.1",
      "resolved": "https://registry.npmjs.org/jszip/-/jszip-3.10.1.tgz",
      "integrity": "sha512-xXDvecyTpGLrqFrvkrUSoxxfJI5AH7U8zxxtVclpsUtMCq4JQ290LY8AW5c7Ggnr/Y/oK+bQMbqK2qmtk3pN4g==",
      "license": "(MIT OR GPL-3.0-or-later)",
      "dependencies": {
        "lie": "~3.3.0",
        "pako": "~1.0.2",
        "readable-stream": "~2.3.6",
        "setimmediate": "^1.0.5"
      }
    },
    "node_modules/keyv": {
      "version": "4.5.4",
      "resolved": "https://registry.npmjs.org/keyv/-/keyv-4.5.4.tgz",
      "integrity": "sha512-oxVHkHR/EJf2CNXnWxRLW6mg7JyCCUcG0DtEGmL2ctUo1PNTin1PUil+r/+4r5MpVgC/fn1kjsx7mjSujKqIpw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "json-buffer": "3.0.1"
      }
    },
    "node_modules/language-subtag-registry": {
      "version": "0.3.23",
      "resolved": "https://registry.npmjs.org/language-subtag-registry/-/language-subtag-registry-0.3.23.tgz",
      "integrity": "sha512-0K65Lea881pHotoGEa5gDlMxt3pctLi2RplBb7Ezh4rRdLEOtgi7n4EwK9lamnUCkKBqaeKRVebTq6BAxSkpXQ==",
      "dev": true,
      "license": "CC0-1.0"
    },
    "node_modules/language-tags": {
      "version": "1.0.9",
      "resolved": "https://registry.npmjs.org/language-tags/-/language-tags-1.0.9.tgz",
      "integrity": "sha512-MbjN408fEndfiQXbFQ1vnd+1NoLDsnQW41410oQBXiyXDMYH5z505juWa4KUE1LqxRC7DgOgZDbKLxHIwm27hA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "language-subtag-registry": "^0.3.20"
      },
      "engines": {
        "node": ">=0.10"
      }
    },
    "node_modules/levn": {
      "version": "0.4.1",
      "resolved": "https://registry.npmjs.org/levn/-/levn-0.4.1.tgz",
      "integrity": "sha512-+bT2uH4E5LGE7h/n3evcS/sQlJXCpIp6ym8OWJ5eV6+67Dsql/LaaT7qJBAt2rzfoa/5QBGBhxDix1dMt2kQKQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "prelude-ls": "^1.2.1",
        "type-check": "~0.4.0"
      },
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/lie": {
      "version": "3.3.0",
      "resolved": "https://registry.npmjs.org/lie/-/lie-3.3.0.tgz",
      "integrity": "sha512-UaiMJzeWRlEujzAuw5LokY1L5ecNQYZKfmyZ9L7wDHb/p5etKaxXhohBcrw0EYby+G/NA52vRSN4N39dxHAIwQ==",
      "license": "MIT",
      "dependencies": {
        "immediate": "~3.0.5"
      }
    },
    "node_modules/lilconfig": {
      "version": "3.1.3",
      "resolved": "https://registry.npmjs.org/lilconfig/-/lilconfig-3.1.3.tgz",
      "integrity": "sha512-/vlFKAoH5Cgt3Ie+JLhRbwOsCQePABiU3tJ1egGvyQ+33R/vcwM2Zl2QR/LzjsBeItPt3oSVXapn+m4nQDvpzw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=14"
      },
      "funding": {
        "url": "https://github.com/sponsors/antonk52"
      }
    },
    "node_modules/lines-and-columns": {
      "version": "1.2.4",
      "resolved": "https://registry.npmjs.org/lines-and-columns/-/lines-and-columns-1.2.4.tgz",
      "integrity": "sha512-7ylylesZQ/PV29jhEDl3Ufjo6ZX7gCqJr5F7PKrqc93v7fzSymt1BpwEU8nAUXs8qzzvqhbjhK5QZg6Mt/HkBg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/locate-path": {
      "version": "6.0.0",
      "resolved": "https://registry.npmjs.org/locate-path/-/locate-path-6.0.0.tgz",
      "integrity": "sha512-iPZK6eYjbxRu3uB4/WZ3EsEIMJFMqAoopl3R+zuq0UjcAm/MO6KCweDgPfP3elTztoKP3KtnVHxTn2NHBSDVUw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "p-locate": "^5.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/lodash.merge": {
      "version": "4.6.2",
      "resolved": "https://registry.npmjs.org/lodash.merge/-/lodash.merge-4.6.2.tgz",
      "integrity": "sha512-0KpjqXRVvrYyCsX1swR/XTK0va6VQkQM6MNo7PqW77ByjAhoARA8EfrP1N4+KlKj8YS0ZUCtRT/YUuhyYDujIQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/loose-envify": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/loose-envify/-/loose-envify-1.4.0.tgz",
      "integrity": "sha512-lyuxPGr/Wfhrlem2CL/UcnUc1zcqKAImBDzukY7Y5F/yQiNdko6+fRLevlw1HgMySw7f611UIY408EtxRSoK3Q==",
      "license": "MIT",
      "dependencies": {
        "js-tokens": "^3.0.0 || ^4.0.0"
      },
      "bin": {
        "loose-envify": "cli.js"
      }
    },
    "node_modules/lru-cache": {
      "version": "10.4.3",
      "resolved": "https://registry.npmjs.org/lru-cache/-/lru-cache-10.4.3.tgz",
      "integrity": "sha512-JNAzZcXrCt42VGLuYz0zfAzDfAvJWW6AfYlDBQyDV5DClI2m5sAmK+OIO7s59XfsRsWHp02jAJrRadPRGTt6SQ==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/math-intrinsics": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/math-intrinsics/-/math-intrinsics-1.1.0.tgz",
      "integrity": "sha512-/IXtbwEk5HTPyEwyKX6hGkYXxM9nbj64B+ilVJnC/R6B0pH5G4V3b0pVbL7DBj4tkhBAppbQUlf6F6Xl9LHu1g==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/merge2": {
      "version": "1.4.1",
      "resolved": "https://registry.npmjs.org/merge2/-/merge2-1.4.1.tgz",
      "integrity": "sha512-8q7VEgMJW4J8tcfVPy8g09NcQwZdbwFEqhe/WZkoIzjn/3TGDwtOCYtXGxA3O8tPzpczCCDgv+P2P5y00ZJOOg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/micromatch": {
      "version": "4.0.8",
      "resolved": "https://registry.npmjs.org/micromatch/-/micromatch-4.0.8.tgz",
      "integrity": "sha512-PXwfBhYu0hBCPw8Dn0E+WDYb7af3dSLVWKi3HGv84IdF4TyFoC0ysxFd0Goxw7nSv4T/PzEJQxsYsEiFCKo2BA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "braces": "^3.0.3",
        "picomatch": "^2.3.1"
      },
      "engines": {
        "node": ">=8.6"
      }
    },
    "node_modules/minimatch": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/minimatch/-/minimatch-3.1.2.tgz",
      "integrity": "sha512-J7p63hRiAjw1NDEww1W7i37+ByIrOWO5XQQAzZ3VOcL0PNybwpfmV/N05zFAzwQ9USyEcX6t3UO+K5aqBQOIHw==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "brace-expansion": "^1.1.7"
      },
      "engines": {
        "node": "*"
      }
    },
    "node_modules/minimist": {
      "version": "1.2.8",
      "resolved": "https://registry.npmjs.org/minimist/-/minimist-1.2.8.tgz",
      "integrity": "sha512-2yyAR8qBkN3YuheJanUpWC5U3bb5osDywNB8RzDVlDwDHbocAJveqqj1u8+SVD7jkWT4yvsHCpWqqWqAxb0zCA==",
      "dev": true,
      "license": "MIT",
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/minipass": {
      "version": "7.1.2",
      "resolved": "https://registry.npmjs.org/minipass/-/minipass-7.1.2.tgz",
      "integrity": "sha512-qOOzS1cBTWYF4BH8fVePDBOO9iptMnGUEZwNc/cMWnTV2nVLZ7VoNWEPHkYczZA0pdoA7dl6e7FL659nX9S2aw==",
      "dev": true,
      "license": "ISC",
      "engines": {
        "node": ">=16 || 14 >=14.17"
      }
    },
    "node_modules/ms": {
      "version": "2.1.3",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.3.tgz",
      "integrity": "sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/mz": {
      "version": "2.7.0",
      "resolved": "https://registry.npmjs.org/mz/-/mz-2.7.0.tgz",
      "integrity": "sha512-z81GNO7nnYMEhrGh9LeymoE4+Yr0Wn5McHIZMK5cfQCl+NDX08sCZgUc9/6MHni9IWuFLm1Z3HTCXu2z9fN62Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "any-promise": "^1.0.0",
        "object-assign": "^4.0.1",
        "thenify-all": "^1.0.0"
      }
    },
    "node_modules/nanoid": {
      "version": "3.3.11",
      "resolved": "https://registry.npmjs.org/nanoid/-/nanoid-3.3.11.tgz",
      "integrity": "sha512-N8SpfPUnUp1bK+PMYW8qSWdl9U+wwNWI4QKxOYDy9JAro3WMX7p2OeVRF9v+347pnakNevPmiHhNmZ2HbFA76w==",
      "funding": [
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "bin": {
        "nanoid": "bin/nanoid.cjs"
      },
      "engines": {
        "node": "^10 || ^12 || ^13.7 || ^14 || >=15.0.1"
      }
    },
    "node_modules/napi-postinstall": {
      "version": "0.3.3",
      "resolved": "https://registry.npmjs.org/napi-postinstall/-/napi-postinstall-0.3.3.tgz",
      "integrity": "sha512-uTp172LLXSxuSYHv/kou+f6KW3SMppU9ivthaVTXian9sOt3XM/zHYHpRZiLgQoxeWfYUnslNWQHF1+G71xcow==",
      "dev": true,
      "license": "MIT",
      "bin": {
        "napi-postinstall": "lib/cli.js"
      },
      "engines": {
        "node": "^12.20.0 || ^14.18.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/napi-postinstall"
      }
    },
    "node_modules/natural-compare": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/natural-compare/-/natural-compare-1.4.0.tgz",
      "integrity": "sha512-OWND8ei3VtNC9h7V60qff3SVobHr996CTwgxubgyQYEpg290h9J0buyECNNJexkFm5sOajh5G116RYA1c8ZMSw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/next": {
      "version": "14.0.0",
      "resolved": "https://registry.npmjs.org/next/-/next-14.0.0.tgz",
      "integrity": "sha512-J0jHKBJpB9zd4+c153sair0sz44mbaCHxggs8ryVXSFBuBqJ8XdE9/ozoV85xGh2VnSjahwntBZZgsihL9QznA==",
      "license": "MIT",
      "dependencies": {
        "@next/env": "14.0.0",
        "@swc/helpers": "0.5.2",
        "busboy": "1.6.0",
        "caniuse-lite": "^1.0.30001406",
        "postcss": "8.4.31",
        "styled-jsx": "5.1.1",
        "watchpack": "2.4.0"
      },
      "bin": {
        "next": "dist/bin/next"
      },
      "engines": {
        "node": ">=18.17.0"
      },
      "optionalDependencies": {
        "@next/swc-darwin-arm64": "14.0.0",
        "@next/swc-darwin-x64": "14.0.0",
        "@next/swc-linux-arm64-gnu": "14.0.0",
        "@next/swc-linux-arm64-musl": "14.0.0",
        "@next/swc-linux-x64-gnu": "14.0.0",
        "@next/swc-linux-x64-musl": "14.0.0",
        "@next/swc-win32-arm64-msvc": "14.0.0",
        "@next/swc-win32-ia32-msvc": "14.0.0",
        "@next/swc-win32-x64-msvc": "14.0.0"
      },
      "peerDependencies": {
        "@opentelemetry/api": "^1.1.0",
        "react": "^18.2.0",
        "react-dom": "^18.2.0",
        "sass": "^1.3.0"
      },
      "peerDependenciesMeta": {
        "@opentelemetry/api": {
          "optional": true
        },
        "sass": {
          "optional": true
        }
      }
    },
    "node_modules/next/node_modules/postcss": {
      "version": "8.4.31",
      "resolved": "https://registry.npmjs.org/postcss/-/postcss-8.4.31.tgz",
      "integrity": "sha512-PS08Iboia9mts/2ygV3eLpY5ghnUcfLV/EXTOW1E2qYxJKGGBUtNjN76FYHnMs36RmARn41bC0AZmn+rR0OVpQ==",
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/postcss/"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/postcss"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "nanoid": "^3.3.6",
        "picocolors": "^1.0.0",
        "source-map-js": "^1.0.2"
      },
      "engines": {
        "node": "^10 || ^12 || >=14"
      }
    },
    "node_modules/node-releases": {
      "version": "2.0.19",
      "resolved": "https://registry.npmjs.org/node-releases/-/node-releases-2.0.19.tgz",
      "integrity": "sha512-xxOWJsBKtzAq7DY0J+DTzuz58K8e7sJbdgwkbMWQe8UYB6ekmsQ45q0M/tJDsGaZmbC+l7n57UV8Hl5tHxO9uw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/normalize-path": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/normalize-path/-/normalize-path-3.0.0.tgz",
      "integrity": "sha512-6eZs5Ls3WtCisHWp9S2GUy8dqkpGi4BVSz3GaqiE6ezub0512ESztXUwUB6C6IKbQkY2Pnb/mD4WYojCRwcwLA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/normalize-range": {
      "version": "0.1.2",
      "resolved": "https://registry.npmjs.org/normalize-range/-/normalize-range-0.1.2.tgz",
      "integrity": "sha512-bdok/XvKII3nUpklnV6P2hxtMNrCboOjAcyBuQnWEhO665FwrSNRxU+AqpsyvO6LgGYPspN+lu5CLtw4jPRKNA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/object-assign": {
      "version": "4.1.1",
      "resolved": "https://registry.npmjs.org/object-assign/-/object-assign-4.1.1.tgz",
      "integrity": "sha512-rJgTQnkUnH1sFw8yT6VSU3zD3sWmu6sZhIseY8VX+GRu3P6F7Fu+JNDoXfklElbLJSnc3FUQHVe4cU5hj+BcUg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/object-hash": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/object-hash/-/object-hash-3.0.0.tgz",
      "integrity": "sha512-RSn9F68PjH9HqtltsSnqYC1XXoWe9Bju5+213R98cNGttag9q9yAOTzdbsqvIa7aNm5WffBZFpWYr2aWrklWAw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/object-inspect": {
      "version": "1.13.4",
      "resolved": "https://registry.npmjs.org/object-inspect/-/object-inspect-1.13.4.tgz",
      "integrity": "sha512-W67iLl4J2EXEGTbfeHCffrjDfitvLANg0UlX3wFUUSTx92KXRFegMHUVgSqE+wvhAbi4WqjGg9czysTV2Epbew==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/object-keys": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/object-keys/-/object-keys-1.1.1.tgz",
      "integrity": "sha512-NuAESUOUMrlIXOfHKzD6bpPu3tYt3xvjNdRIQ+FeT0lNb4K8WR70CaDxhuNguS2XG+GjkyMwOzsN5ZktImfhLA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/object.assign": {
      "version": "4.1.7",
      "resolved": "https://registry.npmjs.org/object.assign/-/object.assign-4.1.7.tgz",
      "integrity": "sha512-nK28WOo+QIjBkDduTINE4JkF/UJJKyf2EJxvJKfblDpyg0Q+pkOHNTL0Qwy6NP6FhE/EnzV73BxxqcJaXY9anw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.3",
        "define-properties": "^1.2.1",
        "es-object-atoms": "^1.0.0",
        "has-symbols": "^1.1.0",
        "object-keys": "^1.1.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/object.entries": {
      "version": "1.1.9",
      "resolved": "https://registry.npmjs.org/object.entries/-/object.entries-1.1.9.tgz",
      "integrity": "sha512-8u/hfXFRBD1O0hPUjioLhoWFHRmt6tKA4/vZPyckBr18l1KE9uHrFaFaUi8MDRTpi4uak2goyPTSNJLXX2k2Hw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.4",
        "define-properties": "^1.2.1",
        "es-object-atoms": "^1.1.1"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/object.fromentries": {
      "version": "2.0.8",
      "resolved": "https://registry.npmjs.org/object.fromentries/-/object.fromentries-2.0.8.tgz",
      "integrity": "sha512-k6E21FzySsSK5a21KRADBd/NGneRegFO5pLHfdQLpRDETUNJueLXs3WCzyQ3tFRDYgbq3KHGXfTbi2bs8WQ6rQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.7",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.2",
        "es-object-atoms": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/object.groupby": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/object.groupby/-/object.groupby-1.0.3.tgz",
      "integrity": "sha512-+Lhy3TQTuzXI5hevh8sBGqbmurHbbIjAi0Z4S63nthVLmLxfbj4T54a4CfZrXIrt9iP4mVAPYMo/v99taj3wjQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.7",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/object.values": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/object.values/-/object.values-1.2.1.tgz",
      "integrity": "sha512-gXah6aZrcUxjWg2zR2MwouP2eHlCBzdV4pygudehaKXSGW4v2AsRQUK+lwwXhii6KFZcunEnmSUoYp5CXibxtA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.3",
        "define-properties": "^1.2.1",
        "es-object-atoms": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/once": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/once/-/once-1.4.0.tgz",
      "integrity": "sha512-lNaJgI+2Q5URQBkccEKHTQOPaXdUxnZZElQTZY0MFUAuaEqe1E+Nyvgdz/aIyNi6Z9MzO5dv1H8n58/GELp3+w==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "wrappy": "1"
      }
    },
    "node_modules/optionator": {
      "version": "0.9.4",
      "resolved": "https://registry.npmjs.org/optionator/-/optionator-0.9.4.tgz",
      "integrity": "sha512-6IpQ7mKUxRcZNLIObR0hz7lxsapSSIYNZJwXPGeF0mTVqGKFIXj1DQcMoT22S3ROcLyY/rz0PWaWZ9ayWmad9g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "deep-is": "^0.1.3",
        "fast-levenshtein": "^2.0.6",
        "levn": "^0.4.1",
        "prelude-ls": "^1.2.1",
        "type-check": "^0.4.0",
        "word-wrap": "^1.2.5"
      },
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/own-keys": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/own-keys/-/own-keys-1.0.1.tgz",
      "integrity": "sha512-qFOyK5PjiWZd+QQIh+1jhdb9LpxTF0qs7Pm8o5QHYZ0M3vKqSqzsZaEB6oWlxZ+q2sJBMI/Ktgd2N5ZwQoRHfg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "get-intrinsic": "^1.2.6",
        "object-keys": "^1.1.1",
        "safe-push-apply": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/p-limit": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/p-limit/-/p-limit-3.1.0.tgz",
      "integrity": "sha512-TYOanM3wGwNGsZN2cVTYPArw454xnXj5qmWF1bEoAc4+cU/ol7GVh7odevjp1FNHduHc3KZMcFduxU5Xc6uJRQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "yocto-queue": "^0.1.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/p-locate": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/p-locate/-/p-locate-5.0.0.tgz",
      "integrity": "sha512-LaNjtRWUBY++zB5nE/NwcaoMylSPk+S+ZHNB1TzdbMJMny6dynpAGt7X/tl/QYq3TIeE6nxHppbo2LGymrG5Pw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "p-limit": "^3.0.2"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/package-json-from-dist": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/package-json-from-dist/-/package-json-from-dist-1.0.1.tgz",
      "integrity": "sha512-UEZIS3/by4OC8vL3P2dTXRETpebLI2NiI5vIrjaD/5UtrkFX/tNbwjTSRAGC/+7CAo2pIcBaRgWmcBBHcsaCIw==",
      "dev": true,
      "license": "BlueOak-1.0.0"
    },
    "node_modules/pako": {
      "version": "1.0.11",
      "resolved": "https://registry.npmjs.org/pako/-/pako-1.0.11.tgz",
      "integrity": "sha512-4hLB8Py4zZce5s4yd9XzopqwVv/yGNhV1Bl8NTmCq1763HeK2+EwVTv+leGeL13Dnh2wfbqowVPXCIO0z4taYw==",
      "license": "(MIT AND Zlib)"
    },
    "node_modules/parent-module": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/parent-module/-/parent-module-1.0.1.tgz",
      "integrity": "sha512-GQ2EWRpQV8/o+Aw8YqtfZZPfNRWZYkbidE9k5rpl/hC3vtHHBfGm2Ifi6qWV+coDGkrUKZAxE3Lot5kcsRlh+g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "callsites": "^3.0.0"
      },
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/path-exists": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/path-exists/-/path-exists-4.0.0.tgz",
      "integrity": "sha512-ak9Qy5Q7jYb2Wwcey5Fpvg2KoAc/ZIhLSLOSBmRmygPsGwkVVt0fZa0qrtMz+m6tJTAHfZQ8FnmB4MG4LWy7/w==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/path-is-absolute": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/path-is-absolute/-/path-is-absolute-1.0.1.tgz",
      "integrity": "sha512-AVbw3UJ2e9bq64vSaS9Am0fje1Pa8pbGqTTsmXfaIiMpnr5DlDhfJOuLj9Sf95ZPVDAUerDfEk88MPmPe7UCQg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/path-key": {
      "version": "3.1.1",
      "resolved": "https://registry.npmjs.org/path-key/-/path-key-3.1.1.tgz",
      "integrity": "sha512-ojmeN0qd+y0jszEtoY48r0Peq5dwMEkIlCOu6Q5f41lfkswXuKtYrhgoTpLnyIcHm24Uhqx+5Tqm2InSwLhE6Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/path-parse": {
      "version": "1.0.7",
      "resolved": "https://registry.npmjs.org/path-parse/-/path-parse-1.0.7.tgz",
      "integrity": "sha512-LDJzPVEEEPR+y48z93A0Ed0yXb8pAByGWo/k5YYdYgpY2/2EsOsksJrq7lOHxryrVOn1ejG6oAp8ahvOIQD8sw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/path-scurry": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/path-scurry/-/path-scurry-1.11.1.tgz",
      "integrity": "sha512-Xa4Nw17FS9ApQFJ9umLiJS4orGjm7ZzwUrwamcGQuHSzDyth9boKDaycYdDcZDuqYATXw4HFXgaqWTctW/v1HA==",
      "dev": true,
      "license": "BlueOak-1.0.0",
      "dependencies": {
        "lru-cache": "^10.2.0",
        "minipass": "^5.0.0 || ^6.0.2 || ^7.0.0"
      },
      "engines": {
        "node": ">=16 || 14 >=14.18"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/path-type": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/path-type/-/path-type-4.0.0.tgz",
      "integrity": "sha512-gDKb8aZMDeD/tZWs9P6+q0J9Mwkdl6xMV8TjnGP3qJVJ06bdMgkbBlLU8IdfOsIsFz2BW1rNVT3XuNEl8zPAvw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/picocolors": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/picocolors/-/picocolors-1.1.1.tgz",
      "integrity": "sha512-xceH2snhtb5M9liqDsmEw56le376mTZkEX/jEb/RxNFyegNul7eNslCXP9FDj/Lcu0X8KEyMceP2ntpaHrDEVA==",
      "license": "ISC"
    },
    "node_modules/picomatch": {
      "version": "2.3.1",
      "resolved": "https://registry.npmjs.org/picomatch/-/picomatch-2.3.1.tgz",
      "integrity": "sha512-JU3teHTNjmE2VCGFzuY8EXzCDVwEqB2a8fsIvwaStHhAWJEeVd1o1QD80CU6+ZdEXXSLbSsuLwJjkCBWqRQUVA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8.6"
      },
      "funding": {
        "url": "https://github.com/sponsors/jonschlinkert"
      }
    },
    "node_modules/pify": {
      "version": "2.3.0",
      "resolved": "https://registry.npmjs.org/pify/-/pify-2.3.0.tgz",
      "integrity": "sha512-udgsAY+fTnvv7kI7aaxbqwWNb0AHiB0qBO89PZKPkoTmGOgdbrHDKD+0B2X4uTfJ/FT1R09r9gTsjUjNJotuog==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/pirates": {
      "version": "4.0.7",
      "resolved": "https://registry.npmjs.org/pirates/-/pirates-4.0.7.tgz",
      "integrity": "sha512-TfySrs/5nm8fQJDcBDuUng3VOUKsd7S+zqvbOTiGXHfxX4wK31ard+hoNuvkicM/2YFzlpDgABOevKSsB4G/FA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/possible-typed-array-names": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/possible-typed-array-names/-/possible-typed-array-names-1.1.0.tgz",
      "integrity": "sha512-/+5VFTchJDoVj3bhoqi6UeymcD00DAwb1nJwamzPvHEszJ4FpF6SNNbUbOS8yI56qHzdV8eK0qEfOSiodkTdxg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/postcss": {
      "version": "8.5.6",
      "resolved": "https://registry.npmjs.org/postcss/-/postcss-8.5.6.tgz",
      "integrity": "sha512-3Ybi1tAuwAP9s0r1UQ2J4n5Y0G05bJkpUIO0/bI9MhwmD70S5aTWbXGBwxHrelT+XM1k6dM0pk+SwNkpTRN7Pg==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/postcss/"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/postcss"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "nanoid": "^3.3.11",
        "picocolors": "^1.1.1",
        "source-map-js": "^1.2.1"
      },
      "engines": {
        "node": "^10 || ^12 || >=14"
      }
    },
    "node_modules/postcss-import": {
      "version": "15.1.0",
      "resolved": "https://registry.npmjs.org/postcss-import/-/postcss-import-15.1.0.tgz",
      "integrity": "sha512-hpr+J05B2FVYUAXHeK1YyI267J/dDDhMU6B6civm8hSY1jYJnBXxzKDKDswzJmtLHryrjhnDjqqp/49t8FALew==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "postcss-value-parser": "^4.0.0",
        "read-cache": "^1.0.0",
        "resolve": "^1.1.7"
      },
      "engines": {
        "node": ">=14.0.0"
      },
      "peerDependencies": {
        "postcss": "^8.0.0"
      }
    },
    "node_modules/postcss-js": {
      "version": "4.0.1",
      "resolved": "https://registry.npmjs.org/postcss-js/-/postcss-js-4.0.1.tgz",
      "integrity": "sha512-dDLF8pEO191hJMtlHFPRa8xsizHaM82MLfNkUHdUtVEV3tgTp5oj+8qbEqYM57SLfc74KSbw//4SeJma2LRVIw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "camelcase-css": "^2.0.1"
      },
      "engines": {
        "node": "^12 || ^14 || >= 16"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/postcss/"
      },
      "peerDependencies": {
        "postcss": "^8.4.21"
      }
    },
    "node_modules/postcss-nested": {
      "version": "6.2.0",
      "resolved": "https://registry.npmjs.org/postcss-nested/-/postcss-nested-6.2.0.tgz",
      "integrity": "sha512-HQbt28KulC5AJzG+cZtj9kvKB93CFCdLvog1WFLf1D+xmMvPGlBstkpTEZfK5+AN9hfJocyBFCNiqyS48bpgzQ==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/postcss/"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "postcss-selector-parser": "^6.1.1"
      },
      "engines": {
        "node": ">=12.0"
      },
      "peerDependencies": {
        "postcss": "^8.2.14"
      }
    },
    "node_modules/postcss-selector-parser": {
      "version": "6.1.2",
      "resolved": "https://registry.npmjs.org/postcss-selector-parser/-/postcss-selector-parser-6.1.2.tgz",
      "integrity": "sha512-Q8qQfPiZ+THO/3ZrOrO0cJJKfpYCagtMUkXbnEfmgUjwXg6z/WBeOyS9APBBPCTSiDV+s4SwQGu8yFsiMRIudg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "cssesc": "^3.0.0",
        "util-deprecate": "^1.0.2"
      },
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/postcss-value-parser": {
      "version": "4.2.0",
      "resolved": "https://registry.npmjs.org/postcss-value-parser/-/postcss-value-parser-4.2.0.tgz",
      "integrity": "sha512-1NNCs6uurfkVbeXG4S8JFT9t19m45ICnif8zWLd5oPSZ50QnwMfK+H3jv408d4jw/7Bttv5axS5IiHoLaVNHeQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/prelude-ls": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/prelude-ls/-/prelude-ls-1.2.1.tgz",
      "integrity": "sha512-vkcDPrRZo1QZLbn5RLGPpg/WmIQ65qoWWhcGKf/b5eplkkarX0m9z8ppCat4mlOqUsWpyNuYgO3VRyrYHSzX5g==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/process-nextick-args": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/process-nextick-args/-/process-nextick-args-2.0.1.tgz",
      "integrity": "sha512-3ouUOpQhtgrbOa17J7+uxOTpITYWaGP7/AhoR3+A+/1e9skrzelGi/dXzEYyvbxubEF6Wn2ypscTKiKJFFn1ag==",
      "license": "MIT"
    },
    "node_modules/prop-types": {
      "version": "15.8.1",
      "resolved": "https://registry.npmjs.org/prop-types/-/prop-types-15.8.1.tgz",
      "integrity": "sha512-oj87CgZICdulUohogVAR7AjlC0327U4el4L6eAvOqCeudMDVU0NThNaV+b9Df4dXgSP1gXMTnPdhfe/2qDH5cg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "loose-envify": "^1.4.0",
        "object-assign": "^4.1.1",
        "react-is": "^16.13.1"
      }
    },
    "node_modules/punycode": {
      "version": "2.3.1",
      "resolved": "https://registry.npmjs.org/punycode/-/punycode-2.3.1.tgz",
      "integrity": "sha512-vYt7UD1U9Wg6138shLtLOvdAu+8DsC/ilFtEVHcH+wydcSpNE20AfSOduf6MkRFahL5FY7X1oU7nKVZFtfq8Fg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/queue-microtask": {
      "version": "1.2.3",
      "resolved": "https://registry.npmjs.org/queue-microtask/-/queue-microtask-1.2.3.tgz",
      "integrity": "sha512-NuaNSa6flKT5JaSYQzJok04JzTL1CA6aGhv5rfLW3PgqA+M2ChpZQnAC8h8i4ZFkBS8X5RqkDBHA7r4hej3K9A==",
      "dev": true,
      "funding": [
        {
          "type": "github",
          "url": "https://github.com/sponsors/feross"
        },
        {
          "type": "patreon",
          "url": "https://www.patreon.com/feross"
        },
        {
          "type": "consulting",
          "url": "https://feross.org/support"
        }
      ],
      "license": "MIT"
    },
    "node_modules/react": {
      "version": "18.3.1",
      "resolved": "https://registry.npmjs.org/react/-/react-18.3.1.tgz",
      "integrity": "sha512-wS+hAgJShR0KhEvPJArfuPVN1+Hz1t0Y6n5jLrGQbkb4urgPE/0Rve+1kMB1v/oWgHgm4WIcV+i7F2pTVj+2iQ==",
      "license": "MIT",
      "dependencies": {
        "loose-envify": "^1.1.0"
      },
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/react-dom": {
      "version": "18.3.1",
      "resolved": "https://registry.npmjs.org/react-dom/-/react-dom-18.3.1.tgz",
      "integrity": "sha512-5m4nQKp+rZRb09LNH59GM4BxTh9251/ylbKIbpe7TpGxfJ+9kv6BLkLBXIjjspbgbnIBNqlI23tRnTWT0snUIw==",
      "license": "MIT",
      "dependencies": {
        "loose-envify": "^1.1.0",
        "scheduler": "^0.23.2"
      },
      "peerDependencies": {
        "react": "^18.3.1"
      }
    },
    "node_modules/react-is": {
      "version": "16.13.1",
      "resolved": "https://registry.npmjs.org/react-is/-/react-is-16.13.1.tgz",
      "integrity": "sha512-24e6ynE2H+OKt4kqsOvNd8kBpV65zoxbA4BVsEOB3ARVWQki/DHzaUoC5KuON/BiccDaCCTZBuOcfZs70kR8bQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/read-cache": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/read-cache/-/read-cache-1.0.0.tgz",
      "integrity": "sha512-Owdv/Ft7IjOgm/i0xvNDZ1LrRANRfew4b2prF3OWMQLxLfu3bS8FVhCsrSCMK4lR56Y9ya+AThoTpDCTxCmpRA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "pify": "^2.3.0"
      }
    },
    "node_modules/readable-stream": {
      "version": "2.3.8",
      "resolved": "https://registry.npmjs.org/readable-stream/-/readable-stream-2.3.8.tgz",
      "integrity": "sha512-8p0AUk4XODgIewSi0l8Epjs+EVnWiK7NoDIEGU0HhE7+ZyY8D1IMY7odu5lRrFXGg71L15KG8QrPmum45RTtdA==",
      "license": "MIT",
      "dependencies": {
        "core-util-is": "~1.0.0",
        "inherits": "~2.0.3",
        "isarray": "~1.0.0",
        "process-nextick-args": "~2.0.0",
        "safe-buffer": "~5.1.1",
        "string_decoder": "~1.1.1",
        "util-deprecate": "~1.0.1"
      }
    },
    "node_modules/readable-stream/node_modules/isarray": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/isarray/-/isarray-1.0.0.tgz",
      "integrity": "sha512-VLghIWNM6ELQzo7zwmcg0NmTVyWKYjvIeM83yjp0wRDTmUnrM678fQbcKBo6n2CJEF0szoG//ytg+TKla89ALQ==",
      "license": "MIT"
    },
    "node_modules/readdirp": {
      "version": "3.6.0",
      "resolved": "https://registry.npmjs.org/readdirp/-/readdirp-3.6.0.tgz",
      "integrity": "sha512-hOS089on8RduqdbhvQ5Z37A0ESjsqz6qnRcffsMU3495FuTdqSm+7bhJ29JvIOsBDEEnan5DPu9t3To9VRlMzA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "picomatch": "^2.2.1"
      },
      "engines": {
        "node": ">=8.10.0"
      }
    },
    "node_modules/reflect.getprototypeof": {
      "version": "1.0.10",
      "resolved": "https://registry.npmjs.org/reflect.getprototypeof/-/reflect.getprototypeof-1.0.10.tgz",
      "integrity": "sha512-00o4I+DVrefhv+nX0ulyi3biSHCPDe+yLv5o/p6d/UVlirijB8E16FtfwSAi4g3tcqrQ4lRAqQSoFEZJehYEcw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.9",
        "es-errors": "^1.3.0",
        "es-object-atoms": "^1.0.0",
        "get-intrinsic": "^1.2.7",
        "get-proto": "^1.0.1",
        "which-builtin-type": "^1.2.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/regexp.prototype.flags": {
      "version": "1.5.4",
      "resolved": "https://registry.npmjs.org/regexp.prototype.flags/-/regexp.prototype.flags-1.5.4.tgz",
      "integrity": "sha512-dYqgNSZbDwkaJ2ceRd9ojCGjBq+mOm9LmtXnAnEGyHhN/5R7iDW2TRw3h+o/jCFxus3P2LfWIIiwowAjANm7IA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "define-properties": "^1.2.1",
        "es-errors": "^1.3.0",
        "get-proto": "^1.0.1",
        "gopd": "^1.2.0",
        "set-function-name": "^2.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/resolve": {
      "version": "1.22.10",
      "resolved": "https://registry.npmjs.org/resolve/-/resolve-1.22.10.tgz",
      "integrity": "sha512-NPRy+/ncIMeDlTAsuqwKIiferiawhefFJtkNSW0qZJEqMEb+qBt/77B/jGeeek+F0uOeN05CDa6HXbbIgtVX4w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-core-module": "^2.16.0",
        "path-parse": "^1.0.7",
        "supports-preserve-symlinks-flag": "^1.0.0"
      },
      "bin": {
        "resolve": "bin/resolve"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/resolve-from": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/resolve-from/-/resolve-from-4.0.0.tgz",
      "integrity": "sha512-pb/MYmXstAkysRFx8piNI1tGFNQIFA3vkE3Gq4EuA1dF6gHp/+vgZqsCGJapvy8N3Q+4o7FwvquPJcnZ7RYy4g==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/resolve-pkg-maps": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/resolve-pkg-maps/-/resolve-pkg-maps-1.0.0.tgz",
      "integrity": "sha512-seS2Tj26TBVOC2NIc2rOe2y2ZO7efxITtLZcGSOnHHNOQ7CkiUBfw0Iw2ck6xkIhPwLhKNLS8BO+hEpngQlqzw==",
      "dev": true,
      "license": "MIT",
      "funding": {
        "url": "https://github.com/privatenumber/resolve-pkg-maps?sponsor=1"
      }
    },
    "node_modules/reusify": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/reusify/-/reusify-1.1.0.tgz",
      "integrity": "sha512-g6QUff04oZpHs0eG5p83rFLhHeV00ug/Yf9nZM6fLeUrPguBTkTQOdpAWWspMh55TZfVQDPaN3NQJfbVRAxdIw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "iojs": ">=1.0.0",
        "node": ">=0.10.0"
      }
    },
    "node_modules/rimraf": {
      "version": "3.0.2",
      "resolved": "https://registry.npmjs.org/rimraf/-/rimraf-3.0.2.tgz",
      "integrity": "sha512-JZkJMZkAGFFPP2YqXZXPbMlMBgsxzE8ILs4lMIX/2o0L9UBw9O/Y3o6wFw/i9YLapcUJWwqbi3kdxIPdC62TIA==",
      "deprecated": "Rimraf versions prior to v4 are no longer supported",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "glob": "^7.1.3"
      },
      "bin": {
        "rimraf": "bin.js"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/run-parallel": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/run-parallel/-/run-parallel-1.2.0.tgz",
      "integrity": "sha512-5l4VyZR86LZ/lDxZTR6jqL8AFE2S0IFLMP26AbjsLVADxHdhB/c0GUsH+y39UfCi3dzz8OlQuPmnaJOMoDHQBA==",
      "dev": true,
      "funding": [
        {
          "type": "github",
          "url": "https://github.com/sponsors/feross"
        },
        {
          "type": "patreon",
          "url": "https://www.patreon.com/feross"
        },
        {
          "type": "consulting",
          "url": "https://feross.org/support"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "queue-microtask": "^1.2.2"
      }
    },
    "node_modules/safe-array-concat": {
      "version": "1.1.3",
      "resolved": "https://registry.npmjs.org/safe-array-concat/-/safe-array-concat-1.1.3.tgz",
      "integrity": "sha512-AURm5f0jYEOydBj7VQlVvDrjeFgthDdEF5H1dP+6mNpoXOMo1quQqJ4wvJDyRZ9+pO3kGWoOdmV08cSv2aJV6Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.2",
        "get-intrinsic": "^1.2.6",
        "has-symbols": "^1.1.0",
        "isarray": "^2.0.5"
      },
      "engines": {
        "node": ">=0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/safe-buffer": {
      "version": "5.1.2",
      "resolved": "https://registry.npmjs.org/safe-buffer/-/safe-buffer-5.1.2.tgz",
      "integrity": "sha512-Gd2UZBJDkXlY7GbJxfsE8/nvKkUEU1G38c1siN6QP6a9PT9MmHB8GnpscSmMJSoF8LOIrt8ud/wPtojys4G6+g==",
      "license": "MIT"
    },
    "node_modules/safe-push-apply": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/safe-push-apply/-/safe-push-apply-1.0.0.tgz",
      "integrity": "sha512-iKE9w/Z7xCzUMIZqdBsp6pEQvwuEebH4vdpjcDWnyzaI6yl6O9FHvVpmGelvEHNsoY6wGblkxR6Zty/h00WiSA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0",
        "isarray": "^2.0.5"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/safe-regex-test": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/safe-regex-test/-/safe-regex-test-1.1.0.tgz",
      "integrity": "sha512-x/+Cz4YrimQxQccJf5mKEbIa1NzeCRNI5Ecl/ekmlYaampdNLPalVyIcCZNNH3MvmqBugV5TMYZXv0ljslUlaw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.2",
        "es-errors": "^1.3.0",
        "is-regex": "^1.2.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/scheduler": {
      "version": "0.23.2",
      "resolved": "https://registry.npmjs.org/scheduler/-/scheduler-0.23.2.tgz",
      "integrity": "sha512-UOShsPwz7NrMUqhR6t0hWjFduvOzbtv7toDH1/hIrfRNIDBnnBWd0CwJTGvTpngVlmwGCdP9/Zl/tVrDqcuYzQ==",
      "license": "MIT",
      "dependencies": {
        "loose-envify": "^1.1.0"
      }
    },
    "node_modules/semver": {
      "version": "7.7.2",
      "resolved": "https://registry.npmjs.org/semver/-/semver-7.7.2.tgz",
      "integrity": "sha512-RF0Fw+rO5AMf9MAyaRXI4AV0Ulj5lMHqVxxdSgiVbixSCXoEmmX/jk0CuJw4+3SqroYO9VoUh+HcuJivvtJemA==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "semver": "bin/semver.js"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/set-function-length": {
      "version": "1.2.2",
      "resolved": "https://registry.npmjs.org/set-function-length/-/set-function-length-1.2.2.tgz",
      "integrity": "sha512-pgRc4hJ4/sNjWCSS9AmnS40x3bNMDTknHgL5UaMBTMyJnU90EgWh1Rz+MC9eFu4BuN/UwZjKQuY/1v3rM7HMfg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "define-data-property": "^1.1.4",
        "es-errors": "^1.3.0",
        "function-bind": "^1.1.2",
        "get-intrinsic": "^1.2.4",
        "gopd": "^1.0.1",
        "has-property-descriptors": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/set-function-name": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/set-function-name/-/set-function-name-2.0.2.tgz",
      "integrity": "sha512-7PGFlmtwsEADb0WYyvCMa1t+yke6daIG4Wirafur5kcf+MhUnPms1UeR0CKQdTZD81yESwMHbtn+TR+dMviakQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "define-data-property": "^1.1.4",
        "es-errors": "^1.3.0",
        "functions-have-names": "^1.2.3",
        "has-property-descriptors": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/set-proto": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/set-proto/-/set-proto-1.0.0.tgz",
      "integrity": "sha512-RJRdvCo6IAnPdsvP/7m6bsQqNnn1FCBX5ZNtFL98MmFF/4xAIJTIg1YbHW5DC2W5SKZanrC6i4HsJqlajw/dZw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "dunder-proto": "^1.0.1",
        "es-errors": "^1.3.0",
        "es-object-atoms": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/setimmediate": {
      "version": "1.0.5",
      "resolved": "https://registry.npmjs.org/setimmediate/-/setimmediate-1.0.5.tgz",
      "integrity": "sha512-MATJdZp8sLqDl/68LfQmbP8zKPLQNV6BIZoIgrscFDQ+RsvK/BxeDQOgyxKKoh0y/8h3BqVFnCqQ/gd+reiIXA==",
      "license": "MIT"
    },
    "node_modules/shebang-command": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/shebang-command/-/shebang-command-2.0.0.tgz",
      "integrity": "sha512-kHxr2zZpYtdmrN1qDjrrX/Z1rR1kG8Dx+gkpK1G4eXmvXswmcE1hTWBWYUzlraYw1/yZp6YuDY77YtvbN0dmDA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "shebang-regex": "^3.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/shebang-regex": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/shebang-regex/-/shebang-regex-3.0.0.tgz",
      "integrity": "sha512-7++dFhtcx3353uBaq8DDR4NuxBetBzC7ZQOhmTQInHEd6bSrXdiEyzCvG07Z44UYdLShWUyXt5M/yhz8ekcb1A==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/side-channel": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/side-channel/-/side-channel-1.1.0.tgz",
      "integrity": "sha512-ZX99e6tRweoUXqR+VBrslhda51Nh5MTQwou5tnUDgbtyM0dBgmhEDtWGP/xbKn6hqfPRHujUNwz5fy/wbbhnpw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0",
        "object-inspect": "^1.13.3",
        "side-channel-list": "^1.0.0",
        "side-channel-map": "^1.0.1",
        "side-channel-weakmap": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/side-channel-list": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/side-channel-list/-/side-channel-list-1.0.0.tgz",
      "integrity": "sha512-FCLHtRD/gnpCiCHEiJLOwdmFP+wzCmDEkc9y7NsYxeF4u7Btsn1ZuwgwJGxImImHicJArLP4R0yX4c2KCrMrTA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0",
        "object-inspect": "^1.13.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/side-channel-map": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/side-channel-map/-/side-channel-map-1.0.1.tgz",
      "integrity": "sha512-VCjCNfgMsby3tTdo02nbjtM/ewra6jPHmpThenkTYh8pG9ucZ/1P8So4u4FGBek/BjpOVsDCMoLA/iuBKIFXRA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.2",
        "es-errors": "^1.3.0",
        "get-intrinsic": "^1.2.5",
        "object-inspect": "^1.13.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/side-channel-weakmap": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/side-channel-weakmap/-/side-channel-weakmap-1.0.2.tgz",
      "integrity": "sha512-WPS/HvHQTYnHisLo9McqBHOJk2FkHO/tlpvldyrnem4aeQp4hai3gythswg6p01oSoTl58rcpiFAjF2br2Ak2A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.2",
        "es-errors": "^1.3.0",
        "get-intrinsic": "^1.2.5",
        "object-inspect": "^1.13.3",
        "side-channel-map": "^1.0.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/signal-exit": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/signal-exit/-/signal-exit-4.1.0.tgz",
      "integrity": "sha512-bzyZ1e88w9O1iNJbKnOlvYTrWPDl46O1bG0D3XInv+9tkPrxrN8jUUTiFlDkkmKWgn1M6CfIA13SuGqOa9Korw==",
      "dev": true,
      "license": "ISC",
      "engines": {
        "node": ">=14"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/slash": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/slash/-/slash-3.0.0.tgz",
      "integrity": "sha512-g9Q1haeby36OSStwb4ntCGGGaKsaVSjQ68fBxoQcutl5fS1vuY18H3wSt3jFyFtrkx+Kz0V1G85A4MyAdDMi2Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/source-map-js": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/source-map-js/-/source-map-js-1.2.1.tgz",
      "integrity": "sha512-UXWMKhLOwVKb728IUtQPXxfYU+usdybtUrK/8uGE8CQMvrhOpwvzDBwj0QhSL7MQc7vIsISBG8VQ8+IDQxpfQA==",
      "license": "BSD-3-Clause",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/stable-hash": {
      "version": "0.0.5",
      "resolved": "https://registry.npmjs.org/stable-hash/-/stable-hash-0.0.5.tgz",
      "integrity": "sha512-+L3ccpzibovGXFK+Ap/f8LOS0ahMrHTf3xu7mMLSpEGU0EO9ucaysSylKo9eRDFNhWve/y275iPmIZ4z39a9iA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/stop-iteration-iterator": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/stop-iteration-iterator/-/stop-iteration-iterator-1.1.0.tgz",
      "integrity": "sha512-eLoXW/DHyl62zxY4SCaIgnRhuMr6ri4juEYARS8E6sCEqzKpOiE521Ucofdx+KnDZl5xmvGYaaKCk5FEOxJCoQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0",
        "internal-slot": "^1.1.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/streamsearch": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/streamsearch/-/streamsearch-1.1.0.tgz",
      "integrity": "sha512-Mcc5wHehp9aXz1ax6bZUyY5afg9u2rv5cqQI3mRrYkGC8rW2hM02jWuwjtL++LS5qinSyhj2QfLyNsuc+VsExg==",
      "engines": {
        "node": ">=10.0.0"
      }
    },
    "node_modules/string_decoder": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/string_decoder/-/string_decoder-1.1.1.tgz",
      "integrity": "sha512-n/ShnvDi6FHbbVfviro+WojiFzv+s8MPMHBczVePfUpDJLwoLT0ht1l4YwBCbi8pJAveEEdnkHyPyTP/mzRfwg==",
      "license": "MIT",
      "dependencies": {
        "safe-buffer": "~5.1.0"
      }
    },
    "node_modules/string-width": {
      "version": "5.1.2",
      "resolved": "https://registry.npmjs.org/string-width/-/string-width-5.1.2.tgz",
      "integrity": "sha512-HnLOCR3vjcY8beoNLtcjZ5/nxn2afmME6lhrDrebokqMap+XbeW8n9TXpPDOqdGK5qcI3oT0GKTW6wC7EMiVqA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "eastasianwidth": "^0.2.0",
        "emoji-regex": "^9.2.2",
        "strip-ansi": "^7.0.1"
      },
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/string-width-cjs": {
      "name": "string-width",
      "version": "4.2.3",
      "resolved": "https://registry.npmjs.org/string-width/-/string-width-4.2.3.tgz",
      "integrity": "sha512-wKyQRQpjJ0sIp62ErSZdGsjMJWsap5oRNihHhu6G7JVO/9jIB6UyevL+tXuOqrng8j/cxKTWyWUwvSTriiZz/g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "emoji-regex": "^8.0.0",
        "is-fullwidth-code-point": "^3.0.0",
        "strip-ansi": "^6.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/string-width-cjs/node_modules/emoji-regex": {
      "version": "8.0.0",
      "resolved": "https://registry.npmjs.org/emoji-regex/-/emoji-regex-8.0.0.tgz",
      "integrity": "sha512-MSjYzcWNOA0ewAHpz0MxpYFvwg6yjy1NG3xteoqz644VCo/RPgnr1/GGt+ic3iJTzQ8Eu3TdM14SawnVUmGE6A==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/string-width/node_modules/ansi-regex": {
      "version": "6.1.0",
      "resolved": "https://registry.npmjs.org/ansi-regex/-/ansi-regex-6.1.0.tgz",
      "integrity": "sha512-7HSX4QQb4CspciLpVFwyRe79O3xsIZDDLER21kERQ71oaPodF8jL725AgJMFAYbooIqolJoRLuM81SpeUkpkvA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-regex?sponsor=1"
      }
    },
    "node_modules/string-width/node_modules/strip-ansi": {
      "version": "7.1.0",
      "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-7.1.0.tgz",
      "integrity": "sha512-iq6eVVI64nQQTRYq2KtEg2d2uU7LElhTJwsH4YzIHZshxlgZms/wIc4VoDQTlG/IvVIrBKG06CrZnp0qv7hkcQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-regex": "^6.0.1"
      },
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/strip-ansi?sponsor=1"
      }
    },
    "node_modules/string.prototype.includes": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/string.prototype.includes/-/string.prototype.includes-2.0.1.tgz",
      "integrity": "sha512-o7+c9bW6zpAdJHTtujeePODAhkuicdAryFsfVKwA+wGw89wJ4GTY484WTucM9hLtDEOpOvI+aHnzqnC5lHp4Rg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.7",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.3"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/string.prototype.matchall": {
      "version": "4.0.12",
      "resolved": "https://registry.npmjs.org/string.prototype.matchall/-/string.prototype.matchall-4.0.12.tgz",
      "integrity": "sha512-6CC9uyBL+/48dYizRf7H7VAYCMCNTBeM78x/VTUe9bFEaxBepPJDa1Ow99LqI/1yF7kuy7Q3cQsYMrcjGUcskA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.3",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.6",
        "es-errors": "^1.3.0",
        "es-object-atoms": "^1.0.0",
        "get-intrinsic": "^1.2.6",
        "gopd": "^1.2.0",
        "has-symbols": "^1.1.0",
        "internal-slot": "^1.1.0",
        "regexp.prototype.flags": "^1.5.3",
        "set-function-name": "^2.0.2",
        "side-channel": "^1.1.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/string.prototype.repeat": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/string.prototype.repeat/-/string.prototype.repeat-1.0.0.tgz",
      "integrity": "sha512-0u/TldDbKD8bFCQ/4f5+mNRrXwZ8hg2w7ZR8wa16e8z9XpePWl3eGEcUD0OXpEH/VJH/2G3gjUtR3ZOiBe2S/w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "define-properties": "^1.1.3",
        "es-abstract": "^1.17.5"
      }
    },
    "node_modules/string.prototype.trim": {
      "version": "1.2.10",
      "resolved": "https://registry.npmjs.org/string.prototype.trim/-/string.prototype.trim-1.2.10.tgz",
      "integrity": "sha512-Rs66F0P/1kedk5lyYyH9uBzuiI/kNRmwJAR9quK6VOtIpZ2G+hMZd+HQbbv25MgCA6gEffoMZYxlTod4WcdrKA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.2",
        "define-data-property": "^1.1.4",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.5",
        "es-object-atoms": "^1.0.0",
        "has-property-descriptors": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/string.prototype.trimend": {
      "version": "1.0.9",
      "resolved": "https://registry.npmjs.org/string.prototype.trimend/-/string.prototype.trimend-1.0.9.tgz",
      "integrity": "sha512-G7Ok5C6E/j4SGfyLCloXTrngQIQU3PWtXGst3yM7Bea9FRURf1S42ZHlZZtsNque2FN2PoUhfZXYLNWwEr4dLQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.2",
        "define-properties": "^1.2.1",
        "es-object-atoms": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/string.prototype.trimstart": {
      "version": "1.0.8",
      "resolved": "https://registry.npmjs.org/string.prototype.trimstart/-/string.prototype.trimstart-1.0.8.tgz",
      "integrity": "sha512-UXSH262CSZY1tfu3G3Secr6uGLCFVPMhIqHjlgCUtCCcgihYc/xKs9djMTMUOb2j1mVSeU8EU6NWc/iQKU6Gfg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.7",
        "define-properties": "^1.2.1",
        "es-object-atoms": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/strip-ansi": {
      "version": "6.0.1",
      "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-6.0.1.tgz",
      "integrity": "sha512-Y38VPSHcqkFrCpFnQ9vuSXmquuv5oXOKpGeT6aGrr3o3Gc9AlVa6JBfUSOCnbxGGZF+/0ooI7KrPuUSztUdU5A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-regex": "^5.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/strip-ansi-cjs": {
      "name": "strip-ansi",
      "version": "6.0.1",
      "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-6.0.1.tgz",
      "integrity": "sha512-Y38VPSHcqkFrCpFnQ9vuSXmquuv5oXOKpGeT6aGrr3o3Gc9AlVa6JBfUSOCnbxGGZF+/0ooI7KrPuUSztUdU5A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-regex": "^5.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/strip-bom": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/strip-bom/-/strip-bom-3.0.0.tgz",
      "integrity": "sha512-vavAMRXOgBVNF6nyEEmL3DBK19iRpDcoIwW+swQ+CbGiu7lju6t+JklA1MHweoWtadgt4ISVUsXLyDq34ddcwA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/strip-json-comments": {
      "version": "3.1.1",
      "resolved": "https://registry.npmjs.org/strip-json-comments/-/strip-json-comments-3.1.1.tgz",
      "integrity": "sha512-6fPc+R4ihwqP6N/aIv2f1gMH8lOVtWQHoqC4yK6oSDVVocumAsfCqjkXnqiYMhmMwS/mEHLp7Vehlt3ql6lEig==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/styled-jsx": {
      "version": "5.1.1",
      "resolved": "https://registry.npmjs.org/styled-jsx/-/styled-jsx-5.1.1.tgz",
      "integrity": "sha512-pW7uC1l4mBZ8ugbiZrcIsiIvVx1UmTfw7UkC3Um2tmfUq9Bhk8IiyEIPl6F8agHgjzku6j0xQEZbfA5uSgSaCw==",
      "license": "MIT",
      "dependencies": {
        "client-only": "0.0.1"
      },
      "engines": {
        "node": ">= 12.0.0"
      },
      "peerDependencies": {
        "react": ">= 16.8.0 || 17.x.x || ^18.0.0-0"
      },
      "peerDependenciesMeta": {
        "@babel/core": {
          "optional": true
        },
        "babel-plugin-macros": {
          "optional": true
        }
      }
    },
    "node_modules/sucrase": {
      "version": "3.35.0",
      "resolved": "https://registry.npmjs.org/sucrase/-/sucrase-3.35.0.tgz",
      "integrity": "sha512-8EbVDiu9iN/nESwxeSxDKe0dunta1GOlHufmSSXxMD2z2/tMZpDMpvXQGsc+ajGo8y2uYUmixaSRUc/QPoQ0GA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jridgewell/gen-mapping": "^0.3.2",
        "commander": "^4.0.0",
        "glob": "^10.3.10",
        "lines-and-columns": "^1.1.6",
        "mz": "^2.7.0",
        "pirates": "^4.0.1",
        "ts-interface-checker": "^0.1.9"
      },
      "bin": {
        "sucrase": "bin/sucrase",
        "sucrase-node": "bin/sucrase-node"
      },
      "engines": {
        "node": ">=16 || 14 >=14.17"
      }
    },
    "node_modules/sucrase/node_modules/brace-expansion": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/brace-expansion/-/brace-expansion-2.0.2.tgz",
      "integrity": "sha512-Jt0vHyM+jmUBqojB7E1NIYadt0vI0Qxjxd2TErW94wDz+E2LAm5vKMXXwg6ZZBTHPuUlDgQHKXvjGBdfcF1ZDQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "balanced-match": "^1.0.0"
      }
    },
    "node_modules/sucrase/node_modules/glob": {
      "version": "10.4.5",
      "resolved": "https://registry.npmjs.org/glob/-/glob-10.4.5.tgz",
      "integrity": "sha512-7Bv8RF0k6xjo7d4A/PxYLbUCfb6c+Vpd2/mB2yRDlew7Jb5hEXiCD9ibfO7wpk8i4sevK6DFny9h7EYbM3/sHg==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "foreground-child": "^3.1.0",
        "jackspeak": "^3.1.2",
        "minimatch": "^9.0.4",
        "minipass": "^7.1.2",
        "package-json-from-dist": "^1.0.0",
        "path-scurry": "^1.11.1"
      },
      "bin": {
        "glob": "dist/esm/bin.mjs"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/sucrase/node_modules/minimatch": {
      "version": "9.0.5",
      "resolved": "https://registry.npmjs.org/minimatch/-/minimatch-9.0.5.tgz",
      "integrity": "sha512-G6T0ZX48xgozx7587koeX9Ys2NYy6Gmv//P89sEte9V9whIapMNF4idKxnW2QtCcLiTWlb/wfCabAtAFWhhBow==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "brace-expansion": "^2.0.1"
      },
      "engines": {
        "node": ">=16 || 14 >=14.17"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/supports-color": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/supports-color/-/supports-color-7.2.0.tgz",
      "integrity": "sha512-qpCAvRl9stuOHveKsn7HncJRvv501qIacKzQlO/+Lwxc9+0q2wLyv4Dfvt80/DPn2pqOBsJdDiogXGR9+OvwRw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "has-flag": "^4.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/supports-preserve-symlinks-flag": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/supports-preserve-symlinks-flag/-/supports-preserve-symlinks-flag-1.0.0.tgz",
      "integrity": "sha512-ot0WnXS9fgdkgIcePe6RHNk1WA8+muPa6cSjeR3V8K27q9BB1rTE3R1p7Hv0z1ZyAc8s6Vvv8DIyWf681MAt0w==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/tailwindcss": {
      "version": "3.4.17",
      "resolved": "https://registry.npmjs.org/tailwindcss/-/tailwindcss-3.4.17.tgz",
      "integrity": "sha512-w33E2aCvSDP0tW9RZuNXadXlkHXqFzSkQew/aIa2i/Sj8fThxwovwlXHSPXTbAHwEIhBFXAedUhP2tueAKP8Og==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@alloc/quick-lru": "^5.2.0",
        "arg": "^5.0.2",
        "chokidar": "^3.6.0",
        "didyoumean": "^1.2.2",
        "dlv": "^1.1.3",
        "fast-glob": "^3.3.2",
        "glob-parent": "^6.0.2",
        "is-glob": "^4.0.3",
        "jiti": "^1.21.6",
        "lilconfig": "^3.1.3",
        "micromatch": "^4.0.8",
        "normalize-path": "^3.0.0",
        "object-hash": "^3.0.0",
        "picocolors": "^1.1.1",
        "postcss": "^8.4.47",
        "postcss-import": "^15.1.0",
        "postcss-js": "^4.0.1",
        "postcss-load-config": "^4.0.2",
        "postcss-nested": "^6.2.0",
        "postcss-selector-parser": "^6.1.2",
        "resolve": "^1.22.8",
        "sucrase": "^3.35.0"
      },
      "bin": {
        "tailwind": "lib/cli.js",
        "tailwindcss": "lib/cli.js"
      },
      "engines": {
        "node": ">=14.0.0"
      }
    },
    "node_modules/tailwindcss/node_modules/postcss-load-config": {
      "version": "4.0.2",
      "resolved": "https://registry.npmjs.org/postcss-load-config/-/postcss-load-config-4.0.2.tgz",
      "integrity": "sha512-bSVhyJGL00wMVoPUzAVAnbEoWyqRxkjv64tUl427SKnPrENtq6hJwUojroMz2VB+Q1edmi4IfrAPpami5VVgMQ==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/postcss/"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "lilconfig": "^3.0.0",
        "yaml": "^2.3.4"
      },
      "engines": {
        "node": ">= 14"
      },
      "peerDependencies": {
        "postcss": ">=8.0.9",
        "ts-node": ">=9.0.0"
      },
      "peerDependenciesMeta": {
        "postcss": {
          "optional": true
        },
        "ts-node": {
          "optional": true
        }
      }
    },
    "node_modules/text-table": {
      "version": "0.2.0",
      "resolved": "https://registry.npmjs.org/text-table/-/text-table-0.2.0.tgz",
      "integrity": "sha512-N+8UisAXDGk8PFXP4HAzVR9nbfmVJ3zYLAWiTIoqC5v5isinhr+r5uaO8+7r3BMfuNIufIsA7RdpVgacC2cSpw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/thenify": {
      "version": "3.3.1",
      "resolved": "https://registry.npmjs.org/thenify/-/thenify-3.3.1.tgz",
      "integrity": "sha512-RVZSIV5IG10Hk3enotrhvz0T9em6cyHBLkH/YAZuKqd8hRkKhSfCGIcP2KUY0EPxndzANBmNllzWPwak+bheSw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "any-promise": "^1.0.0"
      }
    },
    "node_modules/thenify-all": {
      "version": "1.6.0",
      "resolved": "https://registry.npmjs.org/thenify-all/-/thenify-all-1.6.0.tgz",
      "integrity": "sha512-RNxQH/qI8/t3thXJDwcstUO4zeqo64+Uy/+sNVRBx4Xn2OX+OZ9oP+iJnNFqplFra2ZUVeKCSa2oVWi3T4uVmA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "thenify": ">= 3.1.0 < 4"
      },
      "engines": {
        "node": ">=0.8"
      }
    },
    "node_modules/tinyglobby": {
      "version": "0.2.14",
      "resolved": "https://registry.npmjs.org/tinyglobby/-/tinyglobby-0.2.14.tgz",
      "integrity": "sha512-tX5e7OM1HnYr2+a2C/4V0htOcSQcoSTH9KgJnVvNm5zm/cyEWKJ7j7YutsH9CxMdtOkkLFy2AHrMci9IM8IPZQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "fdir": "^6.4.4",
        "picomatch": "^4.0.2"
      },
      "engines": {
        "node": ">=12.0.0"
      },
      "funding": {
        "url": "https://github.com/sponsors/SuperchupuDev"
      }
    },
    "node_modules/tinyglobby/node_modules/fdir": {
      "version": "6.5.0",
      "resolved": "https://registry.npmjs.org/fdir/-/fdir-6.5.0.tgz",
      "integrity": "sha512-tIbYtZbucOs0BRGqPJkshJUYdL+SDH7dVM8gjy+ERp3WAUjLEFJE+02kanyHtwjWOnwrKYBiwAmM0p4kLJAnXg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=12.0.0"
      },
      "peerDependencies": {
        "picomatch": "^3 || ^4"
      },
      "peerDependenciesMeta": {
        "picomatch": {
          "optional": true
        }
      }
    },
    "node_modules/tinyglobby/node_modules/picomatch": {
      "version": "4.0.3",
      "resolved": "https://registry.npmjs.org/picomatch/-/picomatch-4.0.3.tgz",
      "integrity": "sha512-5gTmgEY/sqK6gFXLIsQNH19lWb4ebPDLA4SdLP7dsWkIXHWlG66oPuVvXSGFPppYZz8ZDZq0dYYrbHfBCVUb1Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/sponsors/jonschlinkert"
      }
    },
    "node_modules/to-regex-range": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/to-regex-range/-/to-regex-range-5.0.1.tgz",
      "integrity": "sha512-65P7iz6X5yEr1cwcgvQxbbIw7Uk3gOy5dIdtZ4rDveLqhrdJP+Li/Hx6tyK0NEb+2GCyneCMJiGqrADCSNk8sQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-number": "^7.0.0"
      },
      "engines": {
        "node": ">=8.0"
      }
    },
    "node_modules/ts-api-utils": {
      "version": "1.4.3",
      "resolved": "https://registry.npmjs.org/ts-api-utils/-/ts-api-utils-1.4.3.tgz",
      "integrity": "sha512-i3eMG77UTMD0hZhgRS562pv83RC6ukSAC2GMNWc+9dieh/+jDM5u5YG+NHX6VNDRHQcHwmsTHctP9LhbC3WxVw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=16"
      },
      "peerDependencies": {
        "typescript": ">=4.2.0"
      }
    },
    "node_modules/ts-interface-checker": {
      "version": "0.1.13",
      "resolved": "https://registry.npmjs.org/ts-interface-checker/-/ts-interface-checker-0.1.13.tgz",
      "integrity": "sha512-Y/arvbn+rrz3JCKl9C4kVNfTfSm2/mEp5FSz5EsZSANGPSlQrpRI5M4PKF+mJnE52jOO90PnPSc3Ur3bTQw0gA==",
      "dev": true,
      "license": "Apache-2.0"
    },
    "node_modules/tsconfig-paths": {
      "version": "3.15.0",
      "resolved": "https://registry.npmjs.org/tsconfig-paths/-/tsconfig-paths-3.15.0.tgz",
      "integrity": "sha512-2Ac2RgzDe/cn48GvOe3M+o82pEFewD3UPbyoUHHdKasHwJKjds4fLXWf/Ux5kATBKN20oaFGu+jbElp1pos0mg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@types/json5": "^0.0.29",
        "json5": "^1.0.2",
        "minimist": "^1.2.6",
        "strip-bom": "^3.0.0"
      }
    },
    "node_modules/tslib": {
      "version": "2.8.1",
      "resolved": "https://registry.npmjs.org/tslib/-/tslib-2.8.1.tgz",
      "integrity": "sha512-oJFu94HQb+KVduSUQL7wnpmqnfmLsOA/nAh6b6EH0wCEoK0/mPeXU6c3wKDV83MkOuHPRHtSXKKU99IBazS/2w==",
      "license": "0BSD"
    },
    "node_modules/type-check": {
      "version": "0.4.0",
      "resolved": "https://registry.npmjs.org/type-check/-/type-check-0.4.0.tgz",
      "integrity": "sha512-XleUoc9uwGXqjWwXaUTZAmzMcFZ5858QA2vvx1Ur5xIcixXIP+8LnFDgRplU30us6teqdlskFfu+ae4K79Ooew==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "prelude-ls": "^1.2.1"
      },
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/type-fest": {
      "version": "0.20.2",
      "resolved": "https://registry.npmjs.org/type-fest/-/type-fest-0.20.2.tgz",
      "integrity": "sha512-Ne+eE4r0/iWnpAxD852z3A+N0Bt5RN//NjJwRd2VFHEmrywxf5vsZlh4R6lixl6B+wz/8d+maTSAkN1FIkI3LQ==",
      "dev": true,
      "license": "(MIT OR CC0-1.0)",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/typed-array-buffer": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/typed-array-buffer/-/typed-array-buffer-1.0.3.tgz",
      "integrity": "sha512-nAYYwfY3qnzX30IkA6AQZjVbtK6duGontcQm1WSG1MD94YLqK0515GNApXkoxKOWMusVssAHWLh9SeaoefYFGw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "es-errors": "^1.3.0",
        "is-typed-array": "^1.1.14"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/typed-array-byte-length": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/typed-array-byte-length/-/typed-array-byte-length-1.0.3.tgz",
      "integrity": "sha512-BaXgOuIxz8n8pIq3e7Atg/7s+DpiYrxn4vdot3w9KbnBhcRQq6o3xemQdIfynqSeXeDrF32x+WvfzmOjPiY9lg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "for-each": "^0.3.3",
        "gopd": "^1.2.0",
        "has-proto": "^1.2.0",
        "is-typed-array": "^1.1.14"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/typed-array-byte-offset": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/typed-array-byte-offset/-/typed-array-byte-offset-1.0.4.tgz",
      "integrity": "sha512-bTlAFB/FBYMcuX81gbL4OcpH5PmlFHqlCCpAl8AlEzMz5k53oNDvN8p1PNOWLEmI2x4orp3raOFB51tv9X+MFQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "available-typed-arrays": "^1.0.7",
        "call-bind": "^1.0.8",
        "for-each": "^0.3.3",
        "gopd": "^1.2.0",
        "has-proto": "^1.2.0",
        "is-typed-array": "^1.1.15",
        "reflect.getprototypeof": "^1.0.9"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/typed-array-length": {
      "version": "1.0.7",
      "resolved": "https://registry.npmjs.org/typed-array-length/-/typed-array-length-1.0.7.tgz",
      "integrity": "sha512-3KS2b+kL7fsuk/eJZ7EQdnEmQoaho/r6KUef7hxvltNA5DR8NAUM+8wJMbJyZ4G9/7i3v5zPBIMN5aybAh2/Jg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.7",
        "for-each": "^0.3.3",
        "gopd": "^1.0.1",
        "is-typed-array": "^1.1.13",
        "possible-typed-array-names": "^1.0.0",
        "reflect.getprototypeof": "^1.0.6"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/typescript": {
      "version": "5.9.2",
      "resolved": "https://registry.npmjs.org/typescript/-/typescript-5.9.2.tgz",
      "integrity": "sha512-CWBzXQrc/qOkhidw1OzBTQuYRbfyxDXJMVJ1XNwUHGROVmuaeiEm3OslpZ1RV96d7SKKjZKrSJu3+t/xlw3R9A==",
      "license": "Apache-2.0",
      "bin": {
        "tsc": "bin/tsc",
        "tsserver": "bin/tsserver"
      },
      "engines": {
        "node": ">=14.17"
      }
    },
    "node_modules/unbox-primitive": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/unbox-primitive/-/unbox-primitive-1.1.0.tgz",
      "integrity": "sha512-nWJ91DjeOkej/TA8pXQ3myruKpKEYgqvpw9lz4OPHj/NWFNluYrjbz9j01CJ8yKQd2g4jFoOkINCTW2I5LEEyw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "has-bigints": "^1.0.2",
        "has-symbols": "^1.1.0",
        "which-boxed-primitive": "^1.1.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/undici-types": {
      "version": "6.21.0",
      "resolved": "https://registry.npmjs.org/undici-types/-/undici-types-6.21.0.tgz",
      "integrity": "sha512-iwDZqg0QAGrg9Rav5H4n0M64c3mkR59cJ6wQp+7C4nI0gsmExaedaYLNO44eT4AtBBwjbTiGPMlt2Md0T9H9JQ==",
      "license": "MIT"
    },
    "node_modules/unrs-resolver": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/unrs-resolver/-/unrs-resolver-1.11.1.tgz",
      "integrity": "sha512-bSjt9pjaEBnNiGgc9rUiHGKv5l4/TGzDmYw3RhnkJGtLhbnnA/5qJj7x3dNDCRx/PJxu774LlH8lCOlB4hEfKg==",
      "dev": true,
      "hasInstallScript": true,
      "license": "MIT",
      "dependencies": {
        "napi-postinstall": "^0.3.0"
      },
      "funding": {
        "url": "https://opencollective.com/unrs-resolver"
      },
      "optionalDependencies": {
        "@unrs/resolver-binding-android-arm-eabi": "1.11.1",
        "@unrs/resolver-binding-android-arm64": "1.11.1",
        "@unrs/resolver-binding-darwin-arm64": "1.11.1",
        "@unrs/resolver-binding-darwin-x64": "1.11.1",
        "@unrs/resolver-binding-freebsd-x64": "1.11.1",
        "@unrs/resolver-binding-linux-arm-gnueabihf": "1.11.1",
        "@unrs/resolver-binding-linux-arm-musleabihf": "1.11.1",
        "@unrs/resolver-binding-linux-arm64-gnu": "1.11.1",
        "@unrs/resolver-binding-linux-arm64-musl": "1.11.1",
        "@unrs/resolver-binding-linux-ppc64-gnu": "1.11.1",
        "@unrs/resolver-binding-linux-riscv64-gnu": "1.11.1",
        "@unrs/resolver-binding-linux-riscv64-musl": "1.11.1",
        "@unrs/resolver-binding-linux-s390x-gnu": "1.11.1",
        "@unrs/resolver-binding-linux-x64-gnu": "1.11.1",
        "@unrs/resolver-binding-linux-x64-musl": "1.11.1",
        "@unrs/resolver-binding-wasm32-wasi": "1.11.1",
        "@unrs/resolver-binding-win32-arm64-msvc": "1.11.1",
        "@unrs/resolver-binding-win32-ia32-msvc": "1.11.1",
        "@unrs/resolver-binding-win32-x64-msvc": "1.11.1"
      }
    },
    "node_modules/update-browserslist-db": {
      "version": "1.1.3",
      "resolved": "https://registry.npmjs.org/update-browserslist-db/-/update-browserslist-db-1.1.3.tgz",
      "integrity": "sha512-UxhIZQ+QInVdunkDAaiazvvT/+fXL5Osr0JZlJulepYu6Jd7qJtDZjlur0emRlT71EN3ScPoE7gvsuIKKNavKw==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/browserslist"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/browserslist"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "escalade": "^3.2.0",
        "picocolors": "^1.1.1"
      },
      "bin": {
        "update-browserslist-db": "cli.js"
      },
      "peerDependencies": {
        "browserslist": ">= 4.21.0"
      }
    },
    "node_modules/uri-js": {
      "version": "4.4.1",
      "resolved": "https://registry.npmjs.org/uri-js/-/uri-js-4.4.1.tgz",
      "integrity": "sha512-7rKUyy33Q1yc98pQ1DAmLtwX109F7TIfWlW1Ydo8Wl1ii1SeHieeh0HHfPeL2fMXK6z0s8ecKs9frCuLJvndBg==",
      "dev": true,
      "license": "BSD-2-Clause",
      "dependencies": {
        "punycode": "^2.1.0"
      }
    },
    "node_modules/util-deprecate": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/util-deprecate/-/util-deprecate-1.0.2.tgz",
      "integrity": "sha512-EPD5q1uXyFxJpCrLnCc1nHnq3gOa6DZBocAIiI2TaSCA7VCJ1UJDMagCzIkXNsUYfD1daK//LTEQ8xiIbrHtcw==",
      "license": "MIT"
    },
    "node_modules/watchpack": {
      "version": "2.4.0",
      "resolved": "https://registry.npmjs.org/watchpack/-/watchpack-2.4.0.tgz",
      "integrity": "sha512-Lcvm7MGST/4fup+ifyKi2hjyIAwcdI4HRgtvTpIUxBRhB+RFtUh8XtDOxUfctVCnhVi+QQj49i91OyvzkJl6cg==",
      "license": "MIT",
      "dependencies": {
        "glob-to-regexp": "^0.4.1",
        "graceful-fs": "^4.1.2"
      },
      "engines": {
        "node": ">=10.13.0"
      }
    },
    "node_modules/wavesurfer.js": {
      "version": "7.12.1",
      "resolved": "https://registry.npmjs.org/wavesurfer.js/-/wavesurfer.js-7.12.1.tgz",
      "integrity": "sha512-NswPjVHxk0Q1F/VMRemCPUzSojjuHHisQrBqQiRXg7MVbe3f5vQ6r0rTTXA/a/neC/4hnOEC4YpXca4LpH0SUg==",
      "license": "BSD-3-Clause"
    },
    "node_modules/which": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/which/-/which-2.0.2.tgz",
      "integrity": "sha512-BLI3Tl1TW3Pvl70l3yq3Y64i+awpwXqsGBYWkkqMtnbXgrMD+yj7rhW0kuEDxzJaYXGjEW5ogapKNMEKNMjibA==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "isexe": "^2.0.0"
      },
      "bin": {
        "node-which": "bin/node-which"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/which-boxed-primitive": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/which-boxed-primitive/-/which-boxed-primitive-1.1.1.tgz",
      "integrity": "sha512-TbX3mj8n0odCBFVlY8AxkqcHASw3L60jIuF8jFP78az3C2YhmGvqbHBpAjTRH2/xqYunrJ9g1jSyjCjpoWzIAA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-bigint": "^1.1.0",
        "is-boolean-object": "^1.2.1",
        "is-number-object": "^1.1.1",
        "is-string": "^1.1.1",
        "is-symbol": "^1.1.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/which-builtin-type": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/which-builtin-type/-/which-builtin-type-1.2.1.tgz",
      "integrity": "sha512-6iBczoX+kDQ7a3+YJBnh3T+KZRxM/iYNPXicqk66/Qfm1b93iu+yOImkg0zHbj5LNOcNv1TEADiZ0xa34B4q6Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.2",
        "function.prototype.name": "^1.1.6",
        "has-tostringtag": "^1.0.2",
        "is-async-function": "^2.0.0",
        "is-date-object": "^1.1.0",
        "is-finalizationregistry": "^1.1.0",
        "is-generator-function": "^1.0.10",
        "is-regex": "^1.2.1",
        "is-weakref": "^1.0.2",
        "isarray": "^2.0.5",
        "which-boxed-primitive": "^1.1.0",
        "which-collection": "^1.0.2",
        "which-typed-array": "^1.1.16"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/which-collection": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/which-collection/-/which-collection-1.0.2.tgz",
      "integrity": "sha512-K4jVyjnBdgvc86Y6BkaLZEN933SwYOuBFkdmBu9ZfkcAbdVbpITnDmjvZ/aQjRXQrv5EPkTnD1s39GiiqbngCw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-map": "^2.0.3",
        "is-set": "^2.0.3",
        "is-weakmap": "^2.0.2",
        "is-weakset": "^2.0.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/which-typed-array": {
      "version": "1.1.19",
      "resolved": "https://registry.npmjs.org/which-typed-array/-/which-typed-array-1.1.19.tgz",
      "integrity": "sha512-rEvr90Bck4WZt9HHFC4DJMsjvu7x+r6bImz0/BrbWb7A2djJ8hnZMrWnHo9F8ssv0OMErasDhftrfROTyqSDrw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "available-typed-arrays": "^1.0.7",
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.4",
        "for-each": "^0.3.5",
        "get-proto": "^1.0.1",
        "gopd": "^1.2.0",
        "has-tostringtag": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/word-wrap": {
      "version": "1.2.5",
      "resolved": "https://registry.npmjs.org/word-wrap/-/word-wrap-1.2.5.tgz",
      "integrity": "sha512-BN22B5eaMMI9UMtjrGd5g5eCYPpCPDUy0FJXbYsaT5zYxjFOckS53SQDE3pWkVoWpHXVb3BrYcEN4Twa55B5cA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/wrap-ansi": {
      "version": "8.1.0",
      "resolved": "https://registry.npmjs.org/wrap-ansi/-/wrap-ansi-8.1.0.tgz",
      "integrity": "sha512-si7QWI6zUMq56bESFvagtmzMdGOtoxfR+Sez11Mobfc7tm+VkUckk9bW2UeffTGVUbOksxmSw0AA2gs8g71NCQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-styles": "^6.1.0",
        "string-width": "^5.0.1",
        "strip-ansi": "^7.0.1"
      },
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/wrap-ansi?sponsor=1"
      }
    },
    "node_modules/wrap-ansi-cjs": {
      "name": "wrap-ansi",
      "version": "7.0.0",
      "resolved": "https://registry.npmjs.org/wrap-ansi/-/wrap-ansi-7.0.0.tgz",
      "integrity": "sha512-YVGIj2kamLSTxw6NsZjoBxfSwsn0ycdesmc4p+Q21c5zPuZ1pl+NfxVdxPtdHvmNVOQ6XSYG4AUtyt/Fi7D16Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-styles": "^4.0.0",
        "string-width": "^4.1.0",
        "strip-ansi": "^6.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/chalk/wrap-ansi?sponsor=1"
      }
    },
    "node_modules/wrap-ansi-cjs/node_modules/emoji-regex": {
      "version": "8.0.0",
      "resolved": "https://registry.npmjs.org/emoji-regex/-/emoji-regex-8.0.0.tgz",
      "integrity": "sha512-MSjYzcWNOA0ewAHpz0MxpYFvwg6yjy1NG3xteoqz644VCo/RPgnr1/GGt+ic3iJTzQ8Eu3TdM14SawnVUmGE6A==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/wrap-ansi-cjs/node_modules/string-width": {
      "version": "4.2.3",
      "resolved": "https://registry.npmjs.org/string-width/-/string-width-4.2.3.tgz",
      "integrity": "sha512-wKyQRQpjJ0sIp62ErSZdGsjMJWsap5oRNihHhu6G7JVO/9jIB6UyevL+tXuOqrng8j/cxKTWyWUwvSTriiZz/g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "emoji-regex": "^8.0.0",
        "is-fullwidth-code-point": "^3.0.0",
        "strip-ansi": "^6.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/wrap-ansi/node_modules/ansi-regex": {
      "version": "6.1.0",
      "resolved": "https://registry.npmjs.org/ansi-regex/-/ansi-regex-6.1.0.tgz",
      "integrity": "sha512-7HSX4QQb4CspciLpVFwyRe79O3xsIZDDLER21kERQ71oaPodF8jL725AgJMFAYbooIqolJoRLuM81SpeUkpkvA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-regex?sponsor=1"
      }
    },
    "node_modules/wrap-ansi/node_modules/ansi-styles": {
      "version": "6.2.1",
      "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-6.2.1.tgz",
      "integrity": "sha512-bN798gFfQX+viw3R7yrGWRqnrN2oRkEkUjjl4JNn4E8GxxbjtG3FbrEIIY3l8/hrwUwIeCZvi4QuOTP4MErVug==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-styles?sponsor=1"
      }
    },
    "node_modules/wrap-ansi/node_modules/strip-ansi": {
      "version": "7.1.0",
      "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-7.1.0.tgz",
      "integrity": "sha512-iq6eVVI64nQQTRYq2KtEg2d2uU7LElhTJwsH4YzIHZshxlgZms/wIc4VoDQTlG/IvVIrBKG06CrZnp0qv7hkcQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-regex": "^6.0.1"
      },
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/strip-ansi?sponsor=1"
      }
    },
    "node_modules/wrappy": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/wrappy/-/wrappy-1.0.2.tgz",
      "integrity": "sha512-l4Sp/DRseor9wL6EvV2+TuQn63dMkPjZ/sp9XkghTEbV9KlPS1xUsZ3u7/IQO4wxtcFB4bgpQPRcR3QCvezPcQ==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/yaml": {
      "version": "2.8.1",
      "resolved": "https://registry.npmjs.org/yaml/-/yaml-2.8.1.tgz",
      "integrity": "sha512-lcYcMxX2PO9XMGvAJkJ3OsNMw+/7FKes7/hgerGUYWIoWu5j/+YQqcZr5JnPZWzOsEBgMbSbiSTn/dv/69Mkpw==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "yaml": "bin.mjs"
      },
      "engines": {
        "node": ">= 14.6"
      }
    },
    "node_modules/yocto-queue": {
      "version": "0.1.0",
      "resolved": "https://registry.npmjs.org/yocto-queue/-/yocto-queue-0.1.0.tgz",
      "integrity": "sha512-rVksvsnNCdJ/ohGc6xgPwyN8eheCxsiLM8mxuE/t/mOVqJewPuO1miLpTHQiRgTKCLexL4MeAFVagts7HmNZ2Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    }
  }
}
===== END FILE =====

===== FILE: frontend-next/package.json =====
{
  "name": "transcribealpha-frontend",
  "version": "1.0.0",
  "private": true,
  "scripts": {
    "dev": "next dev",
    "copy:ffmpeg-core": "node scripts/copy-ffmpeg-core.mjs",
    "prebuild": "npm run copy:ffmpeg-core",
    "build": "next build",
    "start": "next start",
    "lint": "next lint",
    "postinstall": "npm run copy:ffmpeg-core || true"
  },
  "dependencies": {
    "@ffmpeg/core": "^0.12.10",
    "@ffmpeg/ffmpeg": "^0.12.15",
    "@ffmpeg/util": "^0.12.2",
    "@types/node": "^20.0.0",
    "@types/react": "^18.2.0",
    "@types/react-dom": "^18.2.0",
    "jszip": "^3.10.1",
    "next": "14.0.0",
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "typescript": "^5.0.0",
    "wavesurfer.js": "^7.12.1"
  },
  "devDependencies": {
    "autoprefixer": "^10.4.0",
    "eslint": "^8.0.0",
    "eslint-config-next": "14.0.0",
    "postcss": "^8.4.0",
    "tailwindcss": "^3.3.0"
  }
}
===== END FILE =====

===== FILE: frontend-next/postcss.config.js =====
module.exports = {
  plugins: {
    tailwindcss: {},
    autoprefixer: {},
  },
}
===== END FILE =====

===== FILE: frontend-next/public/manifest.json =====
{
  "name": "TranscribeAlpha",
  "short_name": "TranscribeAlpha",
  "description": "Legal transcript generation",
  "start_url": "/",
  "display": "standalone",
  "background_color": "#0f172a",
  "theme_color": "#0f172a",
  "icons": [
    { "src": "/icon-192.png", "sizes": "192x192", "type": "image/png" },
    { "src": "/icon-512.png", "sizes": "512x512", "type": "image/png" }
  ]
}
===== END FILE =====

===== FILE: frontend-next/public/sw.js =====
const CACHE_NAME = 'ta-shell-v3'
const FFMPEG_CORE_FILES = new Set([
  '/ffmpeg-core.js',
  '/ffmpeg-core.wasm',
  '/ffmpeg-core.worker.js',
])

function putInCache(request, response) {
  return caches
    .open(CACHE_NAME)
    .then((cache) => cache.put(request, response))
    .catch(() => undefined)
}

self.addEventListener('install', (event) => {
  self.skipWaiting()
})

self.addEventListener('activate', (event) => {
  event.waitUntil(
    caches.keys().then((keys) =>
      Promise.all(
        keys
          .filter((key) => key !== CACHE_NAME)
          .map((key) => caches.delete(key))
      )
    )
  )
  self.clients.claim()
})

self.addEventListener('fetch', (event) => {
  const url = new URL(event.request.url)

  if (FFMPEG_CORE_FILES.has(url.pathname)) {
    event.respondWith(
      caches.match(event.request).then(async (cached) => {
        try {
          const response = await fetch(event.request)
          if (response.ok) {
            const clone = response.clone()
            void putInCache(event.request, clone)
          }
          return response
        } catch {
          return cached || Response.error()
        }
      })
    )
    return
  }

  // Keep uploads/mutations off SW cache logic; stream straight to the network.
  if (url.pathname.startsWith('/api/') && event.request.method !== 'GET') {
    return
  }

  // Network-first for API GET calls
  if (url.pathname.startsWith('/api/')) {
    event.respondWith(
      fetch(event.request).catch(async () => {
        const cached = await caches.match(event.request)
        return cached || Response.error()
      })
    )
    return
  }

  // Cache-first for app shell (HTML, JS, CSS, images)
  if (
    event.request.destination === 'document' ||
    event.request.destination === 'script' ||
    event.request.destination === 'style' ||
    event.request.destination === 'image' ||
    event.request.destination === 'font'
  ) {
    event.respondWith(
      caches.match(event.request).then(async (cached) => {
        try {
          const response = await fetch(event.request)
          if (response.ok) {
            const clone = response.clone()
            void putInCache(event.request, clone)
          }
          return response
        } catch {
          return cached || Response.error()
        }
      })
    )
    return
  }

  // Pass through everything else
  event.respondWith(fetch(event.request))
})
===== END FILE =====

===== FILE: frontend-next/scripts/copy-ffmpeg-core.mjs =====
import { copyFile, mkdir, stat } from 'node:fs/promises'
import path from 'node:path'
import process from 'node:process'

const ROOT = process.cwd()
const srcDir = path.join(ROOT, 'node_modules', '@ffmpeg', 'core', 'dist', 'umd')
const publicDir = path.join(ROOT, 'public')

const requiredAssets = [
  'ffmpeg-core.js',
  'ffmpeg-core.wasm',
]

const optionalAssets = [
  'ffmpeg-core.worker.js',
]

async function ensureSourceDir() {
  try {
    await stat(srcDir)
  } catch {
    throw new Error(`Missing source directory: ${srcDir}`)
  }
}

async function copyRequiredAsset(name) {
  const srcPath = path.join(srcDir, name)
  const destPath = path.join(publicDir, name)
  await copyFile(srcPath, destPath)
}

async function copyOptionalAsset(name) {
  const srcPath = path.join(srcDir, name)
  const destPath = path.join(publicDir, name)
  try {
    await copyFile(srcPath, destPath)
  } catch (error) {
    if ((error && typeof error === 'object' && 'code' in error && error.code === 'ENOENT')) {
      return
    }
    throw error
  }
}

async function main() {
  await ensureSourceDir()
  await mkdir(publicDir, { recursive: true })
  await Promise.all(requiredAssets.map(copyRequiredAsset))
  await Promise.all(optionalAssets.map(copyOptionalAsset))
  console.log('Copied ffmpeg core assets into public/')
}

main().catch((error) => {
  console.error(error instanceof Error ? error.message : String(error))
  process.exit(1)
})
===== END FILE =====

===== FILE: frontend-next/src/app/(dashboard)/case-detail/page.tsx =====
'use client'

import { useCallback, useEffect, useState } from 'react'
import { useSearchParams, useRouter } from 'next/navigation'
import Link from 'next/link'
import { useDashboard } from '@/context/DashboardContext'
import { authenticatedFetch } from '@/utils/auth'
import { routes } from '@/utils/routes'
import { guardedPush } from '@/utils/navigationGuard'
import {
  getCase as localGetCase,
  updateCase as localUpdateCase,
  deleteCase as localDeleteCase,
  moveTranscriptToCase as localMoveTranscriptToCase,
  deleteTranscript as localDeleteTranscript,
  searchCaseTranscripts as localSearchCaseTranscripts,
  listTranscriptsInCase as localListTranscriptsInCase,
} from '@/lib/storage'

interface CaseMeta {
  case_id: string
  name: string
  description?: string
  created_at: string
  updated_at: string
  transcript_count: number
}

interface TranscriptItem {
  media_key: string
  title_label: string
  added_at?: string
  updated_at?: string | null
  line_count?: number
  audio_duration?: number
}

interface SearchMatch {
  line_id: string
  page: number
  line: number
  text: string
  speaker: string
  match_type: string
}

interface SearchResult {
  media_key: string
  title_label: string
  matches: SearchMatch[]
}

export default function CaseDetailPage() {
  const searchParams = useSearchParams()
  const router = useRouter()
  const caseId = searchParams.get('id') ?? ''
  const { cases, refreshCases, setActiveMediaKey, appVariant } = useDashboard()

  const [caseMeta, setCaseMeta] = useState<CaseMeta | null>(null)
  const [transcripts, setTranscripts] = useState<TranscriptItem[]>([])
  const [isLoading, setIsLoading] = useState(true)
  const [error, setError] = useState('')

  // Edit mode
  const [isEditing, setIsEditing] = useState(false)
  const [editName, setEditName] = useState('')
  const [editDescription, setEditDescription] = useState('')
  const [saving, setSaving] = useState(false)

  // Delete modal
  const [showDeleteModal, setShowDeleteModal] = useState(false)
  const [deleteTranscripts, setDeleteTranscripts] = useState(false)
  const [deleting, setDeleting] = useState(false)

  // Search
  const [searchQuery, setSearchQuery] = useState('')
  const [searchResults, setSearchResults] = useState<SearchResult[]>([])
  const [searching, setSearching] = useState(false)
  const [showSearchResults, setShowSearchResults] = useState(false)

  // Reassign transcripts (edit mode)
  const [reassignTargets, setReassignTargets] = useState<Record<string, string>>({})
  const [reassigningTranscript, setReassigningTranscript] = useState<string | null>(null)
  const [transcriptDeleteTarget, setTranscriptDeleteTarget] = useState<TranscriptItem | null>(null)
  const [deletingStoredTranscript, setDeletingStoredTranscript] = useState(false)

  const loadCase = useCallback(async () => {
    if (!caseId) {
      setError('No case selected')
      setIsLoading(false)
      return
    }
    setIsLoading(true)
    setError('')
    try {
      if (appVariant === 'criminal') {
        const caseDetail = await localGetCase(caseId)
        if (!caseDetail) throw new Error('Case not found')
        setCaseMeta({
          case_id: caseDetail.case_id,
          name: caseDetail.name,
          description: caseDetail.description,
          created_at: caseDetail.created_at,
          updated_at: caseDetail.updated_at,
          transcript_count: caseDetail.transcript_count,
        })
        const caseTranscripts = await localListTranscriptsInCase(caseId)
        setTranscripts(
          caseTranscripts.map((t) => ({
            media_key: t.media_key,
            title_label: t.title_label,
            updated_at: t.updated_at,
            line_count: t.line_count,
            audio_duration: t.audio_duration,
          })),
        )
        setEditName(caseDetail.name)
        setEditDescription(caseDetail.description || '')
      } else {
        const response = await authenticatedFetch(`/api/cases/${caseId}`)
        if (!response.ok) {
          if (response.status === 404) {
            throw new Error('Case not found')
          }
          throw new Error('Failed to load case')
        }
        const data = await response.json()
        setCaseMeta(data.case)
        setTranscripts(data.transcripts || [])
        setEditName(data.case.name)
        setEditDescription(data.case.description || '')
      }
    } catch (err: any) {
      setError(err?.message || 'Failed to load case')
    } finally {
      setIsLoading(false)
    }
  }, [caseId, appVariant])

  useEffect(() => {
    loadCase()
  }, [loadCase])

  useEffect(() => {
    if (!isEditing) {
      setReassignTargets({})
      setReassigningTranscript(null)
    }
  }, [isEditing])

  const handleSaveEdit = async () => {
    if (!editName.trim() || !caseId) return
    setSaving(true)
    try {
      if (appVariant === 'criminal') {
        await localUpdateCase(caseId, { name: editName.trim(), description: editDescription.trim() })
        setCaseMeta((prev) =>
          prev ? { ...prev, name: editName.trim(), description: editDescription.trim(), updated_at: new Date().toISOString() } : prev,
        )
        setIsEditing(false)
        refreshCases()
      } else {
        const response = await authenticatedFetch(`/api/cases/${caseId}`, {
          method: 'PUT',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ name: editName.trim(), description: editDescription.trim() }),
        })
        if (!response.ok) throw new Error('Failed to update case')
        const data = await response.json()
        setCaseMeta(data.case)
        setIsEditing(false)
        refreshCases()
      }
    } catch (err) {
      setError('Failed to update case')
    } finally {
      setSaving(false)
    }
  }

  const handleDeleteCase = async () => {
    if (!caseId) return
    setDeleting(true)
    try {
      if (appVariant === 'criminal') {
        await localDeleteCase(caseId, deleteTranscripts)
      } else {
        const response = await authenticatedFetch(
          `/api/cases/${caseId}?delete_transcripts=${deleteTranscripts}`,
          { method: 'DELETE' }
        )
        if (!response.ok) throw new Error('Failed to delete case')
      }
      await refreshCases()
      guardedPush(router, routes.cases())
    } catch (err) {
      setError('Failed to delete case')
      setDeleting(false)
    }
  }

  const getReassignTarget = (mediaKey: string) => {
    return reassignTargets[mediaKey] ?? 'uncategorized'
  }

  const handleReassignTranscript = async (mediaKey: string) => {
    if (!caseId) return
    const target = getReassignTarget(mediaKey)

    if (!target || target === caseId) {
      return
    }

    setReassigningTranscript(mediaKey)
    setError('')
    try {
      if (appVariant === 'criminal') {
        if (target === 'uncategorized') {
          await localMoveTranscriptToCase(mediaKey, 'uncategorized')
        } else {
          await localMoveTranscriptToCase(mediaKey, target)
        }
      } else {
        if (target === 'uncategorized') {
          const response = await authenticatedFetch(
            `/api/cases/${caseId}/transcripts/${encodeURIComponent(mediaKey)}`,
            { method: 'DELETE' }
          )
          if (!response.ok) {
            const detail = await response.json().catch(() => ({}))
            throw new Error(detail?.detail || 'Failed to move transcript to uncategorized')
          }
        } else {
          const response = await authenticatedFetch(`/api/cases/${target}/transcripts`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ media_key: mediaKey }),
          })
          if (!response.ok) {
            const detail = await response.json().catch(() => ({}))
            throw new Error(detail?.detail || 'Failed to reassign transcript')
          }
        }
      }

      await loadCase()
      await refreshCases()
    } catch (err: any) {
      setError(err?.message || 'Failed to reassign transcript')
    } finally {
      setReassigningTranscript(null)
    }
  }

  const handleDeleteStoredTranscript = async () => {
    if (!transcriptDeleteTarget) return
    setDeletingStoredTranscript(true)
    try {
      if (appVariant === 'criminal') {
        await localDeleteTranscript(transcriptDeleteTarget.media_key)
      } else {
        const response = await authenticatedFetch(
          `/api/transcripts/by-key/${encodeURIComponent(transcriptDeleteTarget.media_key)}`,
          { method: 'DELETE' }
        )
        if (!response.ok) {
          const detail = await response.json().catch(() => ({}))
          throw new Error(detail?.detail || 'Failed to delete transcript')
        }
      }
      setTranscriptDeleteTarget(null)
      await loadCase()
      refreshCases()
    } catch (err: any) {
      setError(err?.message || 'Failed to delete transcript')
    } finally {
      setDeletingStoredTranscript(false)
    }
  }

  const handleSearch = async () => {
    if (!searchQuery.trim() || searchQuery.length < 2 || !caseId) return
    setSearching(true)
    setShowSearchResults(true)
    try {
      if (appVariant === 'criminal') {
        const results = await localSearchCaseTranscripts(caseId, searchQuery)
        setSearchResults(results)
      } else {
        const response = await authenticatedFetch(
          `/api/cases/${caseId}/search?q=${encodeURIComponent(searchQuery)}`
        )
        if (!response.ok) throw new Error('Search failed')
        const data = await response.json()
        setSearchResults(data.results || [])
      }
    } catch (err) {
      setSearchResults([])
    } finally {
      setSearching(false)
    }
  }

  const formatDuration = (seconds?: number) => {
    if (!seconds) return '-'
    const mins = Math.floor(seconds / 60)
    const secs = Math.floor(seconds % 60)
    return `${mins}:${secs.toString().padStart(2, '0')}`
  }

  const formatDate = (dateStr?: string | null) => {
    if (!dateStr) return '-'
    return new Date(dateStr).toLocaleDateString()
  }

  if (isLoading) {
    return (
      <div className="p-8 flex items-center justify-center min-h-[60vh]">
        <div className="text-center">
          <div className="w-12 h-12 mx-auto mb-4 relative">
            <div className="absolute inset-0 border-4 border-primary-200 rounded-full"></div>
            <div className="absolute inset-0 border-4 border-primary-600 rounded-full border-t-transparent animate-spin"></div>
          </div>
          <p className="text-gray-500">Loading case...</p>
        </div>
      </div>
    )
  }

  if (error && !caseMeta) {
    return (
      <div className="p-8 max-w-4xl mx-auto">
        <div className="bg-red-50 border border-red-200 rounded-xl p-8 text-center">
          <h2 className="text-xl font-semibold text-gray-900 mb-2">Error</h2>
          <p className="text-gray-600 mb-6">{error}</p>
          <Link href={routes.cases()} className="btn-primary px-6 py-3">
            Back to Cases
          </Link>
        </div>
      </div>
    )
  }

  return (
    <div className="p-8 max-w-6xl mx-auto">
      {/* Breadcrumb */}
      <div className="flex items-center gap-2 text-sm text-gray-500 mb-6">
        <Link href={routes.cases()} className="hover:text-primary-600">Cases</Link>
        <span>/</span>
        <span className="text-gray-900">{caseMeta?.name}</span>
      </div>

      {/* Header */}
      <div className="bg-white rounded-xl shadow-sm border border-gray-100 p-6 mb-6">
        {isEditing ? (
          <div className="space-y-4">
            <div>
              <label className="block text-sm font-medium text-gray-700 mb-1">Case Name</label>
              <input
                type="text"
                value={editName}
                onChange={(e) => setEditName(e.target.value)}
                className="input-field"
                autoFocus
              />
            </div>
            <div>
              <label className="block text-sm font-medium text-gray-700 mb-1">Description</label>
              <textarea
                value={editDescription}
                onChange={(e) => setEditDescription(e.target.value)}
                className="input-field"
                rows={3}
              />
            </div>
            <div className="flex gap-3">
              <button onClick={handleSaveEdit} disabled={saving || !editName.trim()} className="btn-primary px-4 py-2">
                {saving ? 'Saving...' : 'Save Changes'}
              </button>
              <button onClick={() => setIsEditing(false)} className="btn-outline px-4 py-2">
                Cancel
              </button>
            </div>
          </div>
        ) : (
          <div className="flex items-start justify-between">
            <div>
              <h1 className="text-2xl font-semibold text-gray-900 mb-1">{caseMeta?.name}</h1>
              {caseMeta?.description && (
                <p className="text-gray-500 mb-3">{caseMeta.description}</p>
              )}
              <div className="flex items-center gap-4 text-sm text-gray-400">
                <span>{transcripts.length} transcript{transcripts.length !== 1 ? 's' : ''}</span>
                <span>Created {formatDate(caseMeta?.created_at)}</span>
              </div>
            </div>
            <div className="flex gap-2">
              <button onClick={() => setIsEditing(true)} className="btn-outline px-3 py-2">
                Edit
              </button>
              <button
                onClick={() => setShowDeleteModal(true)}
                className="px-3 py-2 text-red-600 hover:bg-red-50 rounded-lg transition-colors"
              >
                Delete
              </button>
            </div>
          </div>
        )}
      </div>

      {error && (
        <div className="bg-red-50 border border-red-200 rounded-lg p-4 mb-6 text-red-700">
          {error}
        </div>
      )}

      {/* Search */}
      <div className="bg-white rounded-xl shadow-sm border border-gray-100 p-4 mb-6">
        <div className="flex gap-3">
          <div className="relative flex-1">
            <input
              type="text"
              value={searchQuery}
              onChange={(e) => setSearchQuery(e.target.value)}
              onKeyDown={(e) => e.key === 'Enter' && handleSearch()}
              placeholder="Search transcripts in this case..."
              className="input-field pl-10"
            />
            <svg className="absolute left-3 top-1/2 -translate-y-1/2 w-5 h-5 text-gray-400" fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24">
              <path d="M21 21l-6-6m2-5a7 7 0 11-14 0 7 7 0 0114 0z" />
            </svg>
          </div>
          <button
            onClick={handleSearch}
            disabled={searching || searchQuery.length < 2}
            className="btn-primary px-4 py-2"
          >
            {searching ? 'Searching...' : 'Search'}
          </button>
          {showSearchResults && (
            <button
              onClick={() => {
                setShowSearchResults(false)
                setSearchQuery('')
                setSearchResults([])
              }}
              className="btn-outline px-4 py-2"
            >
              Clear
            </button>
          )}
        </div>
      </div>

      {/* Search Results */}
      {showSearchResults && (
        <div className="bg-white rounded-xl shadow-sm border border-gray-100 mb-6">
          <div className="p-4 border-b border-gray-100">
            <h3 className="font-semibold text-gray-900">
              Search Results for &quot;{searchQuery}&quot;
            </h3>
          </div>
          {searchResults.length === 0 ? (
            <div className="p-6 text-center text-gray-500">
              No matches found
            </div>
          ) : (
            <div className="divide-y divide-gray-100 max-h-96 overflow-y-auto">
              {searchResults.map((result) => (
                <div key={result.media_key} className="p-4">
                  <button
                    onClick={() => {
                      setActiveMediaKey(result.media_key)
                      guardedPush(router, routes.editor(result.media_key))
                    }}
                    className="font-medium text-primary-600 hover:text-primary-700 mb-2 text-left"
                  >
                    {result.title_label}
                  </button>
                  <div className="space-y-2">
                    {result.matches.slice(0, 5).map((match, i) => (
                      <div key={i} className="text-sm bg-gray-50 rounded p-2">
                        <span className="text-gray-500">Page {match.page}, Line {match.line}</span>
                        <span className="mx-2 text-gray-400">|</span>
                        <span className="font-medium text-gray-700">{match.speaker}:</span>
                        <span className="text-gray-600 ml-1">{match.text}</span>
                      </div>
                    ))}
                    {result.matches.length > 5 && (
                      <p className="text-sm text-gray-500">
                        ... and {result.matches.length - 5} more matches
                      </p>
                    )}
                  </div>
                </div>
              ))}
            </div>
          )}
        </div>
      )}

      {/* Transcripts */}
      <div className="bg-white rounded-xl shadow-sm border border-gray-100">
        <div className="p-4 border-b border-gray-100 flex items-center justify-between">
          <h2 className="text-lg font-semibold text-gray-900">Transcripts</h2>
          <Link
            href={routes.transcribe(caseId)}
            className="btn-primary px-4 py-2 text-sm flex items-center gap-2"
          >
            <svg className="w-4 h-4" fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24">
              <path d="M12 4v16m8-8H4" />
            </svg>
            Add Transcript
          </Link>
        </div>
        {isEditing && (
          <div className="px-4 py-3 border-b border-gray-100 bg-primary-50 text-sm text-primary-800">
            Reassign transcripts to another case or to uncategorized.
          </div>
        )}

        {transcripts.length === 0 ? (
          <div className="p-8 text-center">
            <div className="w-16 h-16 bg-gray-100 rounded-full flex items-center justify-center mx-auto mb-4">
              <svg className="w-8 h-8 text-gray-400" fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24">
                <path d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z" />
              </svg>
            </div>
            <h3 className="text-lg font-medium text-gray-900 mb-2">No transcripts yet</h3>
            <p className="text-gray-500 mb-4">Create your first transcript for this case</p>
            <Link href={routes.transcribe(caseId)} className="btn-primary px-4 py-2">
              Create Transcript
            </Link>
          </div>
        ) : (
          <div className="divide-y divide-gray-100">
            {transcripts.map((transcript) => (
              <div
                key={transcript.media_key}
                className="p-4 flex items-center justify-between hover:bg-gray-50"
              >
                <div className="flex items-center gap-4 flex-1 min-w-0">
                  <div className="w-10 h-10 bg-primary-100 rounded-lg flex items-center justify-center flex-shrink-0">
                    <svg className="w-5 h-5 text-primary-600" fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24">
                      <path d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z" />
                    </svg>
                  </div>
                  <div className="flex-1 min-w-0">
                    <p className="font-medium text-gray-900 truncate">{transcript.title_label}</p>
                    <p className="text-sm text-gray-500">
                      {transcript.line_count || 0} lines • {formatDuration(transcript.audio_duration)} • Updated {formatDate(transcript.updated_at)}
                    </p>
                  </div>
                </div>
                <div className="flex items-center gap-3 flex-wrap justify-end">
                  {isEditing && (
                    <>
                      <select
                        value={getReassignTarget(transcript.media_key)}
                        onChange={(e) =>
                          setReassignTargets((prev) => ({
                            ...prev,
                            [transcript.media_key]: e.target.value,
                          }))
                        }
                        className="input-field h-9 w-[16rem] md:w-[22rem] min-w-[220px] text-sm"
                      >
                        <option value="uncategorized">Uncategorized</option>
                        {cases
                          .filter((caseItem) => caseItem.case_id !== caseId)
                          .map((caseItem) => (
                            <option key={caseItem.case_id} value={caseItem.case_id}>
                              {caseItem.name}
                            </option>
                          ))}
                      </select>
                      <button
                        onClick={() => handleReassignTranscript(transcript.media_key)}
                        disabled={reassigningTranscript === transcript.media_key}
                        className="btn-outline text-sm px-3 py-1 disabled:opacity-50 disabled:cursor-not-allowed"
                      >
                        {reassigningTranscript === transcript.media_key ? 'Applying...' : 'Apply'}
                      </button>
                    </>
                  )}
                  <button
                    onClick={() => {
                      setActiveMediaKey(transcript.media_key)
                      guardedPush(router, routes.viewer(transcript.media_key, caseId))
                    }}
                    className="btn-primary text-sm px-3 py-1"
                  >
                    View
                  </button>
                  <button
                    onClick={() => {
                      setActiveMediaKey(transcript.media_key)
                      guardedPush(router, routes.editor(transcript.media_key))
                    }}
                    className="btn-outline text-sm px-3 py-1"
                  >
                    Edit
                  </button>
                  <button
                    onClick={() => setTranscriptDeleteTarget(transcript)}
                    disabled={deletingStoredTranscript}
                    className="p-2 text-gray-400 hover:text-red-600 hover:bg-red-50 rounded-lg transition-colors disabled:opacity-50 disabled:cursor-not-allowed"
                    title="Delete transcript permanently"
                  >
                    <svg className="w-5 h-5" fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24">
                      <path d="M19 7l-.867 12.142A2 2 0 0116.138 21H7.862a2 2 0 01-1.995-1.858L5 7m5 4v6m4-6v6m1-10V4a1 1 0 00-1-1h-4a1 1 0 00-1 1v3M4 7h16" />
                    </svg>
                  </button>
                </div>
              </div>
            ))}
          </div>
        )}
      </div>

      {/* Transcript Delete Modal */}
      {transcriptDeleteTarget && (
        <div className="fixed inset-0 z-50 flex items-center justify-center bg-slate-900/60 backdrop-blur-sm p-4">
          <div className="w-full max-w-lg rounded-2xl border border-gray-100 bg-white shadow-2xl">
            <div className="p-6 border-b border-gray-100">
              <div className="flex items-start gap-4">
                <div className="h-10 w-10 rounded-full bg-red-100 text-red-600 flex items-center justify-center flex-shrink-0">
                  <svg className="w-5 h-5" fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24">
                    <path d="M12 9v4m0 4h.01M5.07 19h13.86c1.54 0 2.5-1.67 1.73-3L13.73 4c-.77-1.33-2.69-1.33-3.46 0L3.34 16c-.77 1.33.19 3 1.73 3z" />
                  </svg>
                </div>
                <div>
                  <h3 className="text-lg font-semibold text-gray-900">Delete Transcript Permanently?</h3>
                  <p className="mt-2 text-sm text-gray-600">
                    This will permanently remove <span className="font-medium text-gray-900">&quot;{transcriptDeleteTarget.title_label}&quot;</span>.
                    This action cannot be undone.
                  </p>
                </div>
              </div>
            </div>
            <div className="p-6 flex justify-end gap-3">
              <button
                onClick={() => {
                  if (deletingStoredTranscript) return
                  setTranscriptDeleteTarget(null)
                }}
                className="btn-outline px-4 py-2"
              >
                Cancel
              </button>
              <button
                onClick={handleDeleteStoredTranscript}
                disabled={deletingStoredTranscript}
                className="px-4 py-2 bg-red-600 hover:bg-red-700 text-white rounded-lg font-medium transition-colors disabled:opacity-70"
              >
                {deletingStoredTranscript ? 'Deleting...' : 'Delete Transcript'}
              </button>
            </div>
          </div>
        </div>
      )}

      {/* Delete Modal */}
      {showDeleteModal && (
        <div className="fixed inset-0 z-50 flex items-center justify-center bg-black/50 p-4">
          <div className="bg-white rounded-xl shadow-xl w-full max-w-md p-6">
            <h3 className="text-lg font-semibold text-gray-900 mb-2">Delete Case</h3>
            <p className="text-gray-600 mb-4">
              Are you sure you want to delete &quot;{caseMeta?.name}&quot;?
            </p>
            {transcripts.length > 0 && (
              <div className="bg-amber-50 border border-amber-200 rounded-lg p-4 mb-4">
                <label className="flex items-start gap-3 cursor-pointer">
                  <input
                    type="checkbox"
                    checked={deleteTranscripts}
                    onChange={(e) => setDeleteTranscripts(e.target.checked)}
                    className="mt-1"
                  />
                  <div>
                    <p className="font-medium text-amber-800">
                      Also delete {transcripts.length} transcript{transcripts.length !== 1 ? 's' : ''}
                    </p>
                    <p className="text-sm text-amber-700">
                      {deleteTranscripts
                        ? 'Transcripts will be permanently deleted'
                        : 'Transcripts will be moved to uncategorized (30-day expiry)'}
                    </p>
                  </div>
                </label>
              </div>
            )}
            <div className="flex justify-end gap-3">
              <button
                onClick={() => {
                  setShowDeleteModal(false)
                  setDeleteTranscripts(false)
                }}
                className="btn-outline px-4 py-2"
              >
                Cancel
              </button>
              <button
                onClick={handleDeleteCase}
                disabled={deleting}
                className="px-4 py-2 bg-red-600 hover:bg-red-700 text-white rounded-lg font-medium transition-colors"
              >
                {deleting ? 'Deleting...' : 'Delete Case'}
              </button>
            </div>
          </div>
        </div>
      )}
    </div>
  )
}
===== END FILE =====

===== FILE: frontend-next/src/app/(dashboard)/cases/page.tsx =====
'use client'

import { useCallback, useEffect, useState } from 'react'
import Link from 'next/link'
import { useSearchParams, useRouter } from 'next/navigation'
import { useDashboard } from '@/context/DashboardContext'
import { authenticatedFetch } from '@/utils/auth'
import { routes } from '@/utils/routes'
import { guardedPush } from '@/utils/navigationGuard'
import {
  createCase as localCreateCase,
  listUncategorizedTranscripts as localListUncategorized,
  deleteTranscript as localDeleteTranscript,
  moveTranscriptToCase as localMoveTranscriptToCase,
  type TranscriptSummary,
} from '@/lib/storage'

interface TranscriptListItem {
  media_key: string
  title_label: string
  updated_at?: string | null
  line_count?: number
  expires_at?: string | null
}

export default function CasesPage() {
  const router = useRouter()
  const searchParams = useSearchParams()
  const { cases, uncategorizedCount, refreshCases, setActiveMediaKey, appVariant } = useDashboard()

  const [activeTab, setActiveTab] = useState<'cases' | 'uncategorized'>('cases')
  const [uncategorizedTranscripts, setUncategorizedTranscripts] = useState<TranscriptListItem[]>([])
  const [loadingUncategorized, setLoadingUncategorized] = useState(false)
  const [showNewCaseModal, setShowNewCaseModal] = useState(false)
  const [newCaseName, setNewCaseName] = useState('')
  const [newCaseDescription, setNewCaseDescription] = useState('')
  const [creatingCase, setCreatingCase] = useState(false)
  const [error, setError] = useState('')
  const [uncategorizedDeleteTarget, setUncategorizedDeleteTarget] = useState<TranscriptListItem | null>(null)
  const [deletingUncategorizedTranscript, setDeletingUncategorizedTranscript] = useState(false)
  const [assignModeEnabled, setAssignModeEnabled] = useState(false)
  const [assignmentTargets, setAssignmentTargets] = useState<Record<string, string>>({})
  const [assigningTranscript, setAssigningTranscript] = useState<string | null>(null)

  useEffect(() => {
    if (searchParams.get('tab') === 'uncategorized') {
      setActiveTab('uncategorized')
    }
  }, [searchParams])

  const loadUncategorized = useCallback(async () => {
    setLoadingUncategorized(true)
    try {
      if (appVariant === 'criminal') {
        const items = await localListUncategorized()
        setUncategorizedTranscripts(
          items.map((t: TranscriptSummary) => ({
            media_key: t.media_key,
            title_label: t.title_label,
            updated_at: t.updated_at,
            line_count: t.line_count,
          })),
        )
      } else {
        const response = await authenticatedFetch('/api/transcripts/uncategorized')
        if (response.ok) {
          const data = await response.json()
          setUncategorizedTranscripts(data.transcripts || [])
        }
      }
    } catch (err) {
      console.error('Failed to load uncategorized transcripts:', err)
    } finally {
      setLoadingUncategorized(false)
    }
  }, [appVariant])

  useEffect(() => {
    if (activeTab === 'uncategorized') {
      loadUncategorized()
    }
  }, [activeTab, loadUncategorized])

  useEffect(() => {
    if (activeTab !== 'uncategorized') {
      setAssignModeEnabled(false)
      setAssignmentTargets({})
      setAssigningTranscript(null)
    }
  }, [activeTab])

  const handleCreateCase = async () => {
    if (!newCaseName.trim()) return
    setCreatingCase(true)
    setError('')
    try {
      if (appVariant === 'criminal') {
        const caseId = crypto.randomUUID()
        const now = new Date().toISOString()
        await localCreateCase({
          case_id: caseId,
          name: newCaseName.trim(),
          description: newCaseDescription.trim(),
          created_at: now,
          updated_at: now,
        })
      } else {
        const response = await authenticatedFetch('/api/cases', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ name: newCaseName.trim(), description: newCaseDescription.trim() }),
        })
        if (!response.ok) throw new Error('Failed to create case')
      }
      await refreshCases()
      setShowNewCaseModal(false)
      setNewCaseName('')
      setNewCaseDescription('')
    } catch (err) {
      setError('Failed to create case')
    } finally {
      setCreatingCase(false)
    }
  }

  const handleDeleteUncategorizedTranscript = async () => {
    if (!uncategorizedDeleteTarget) return
    setDeletingUncategorizedTranscript(true)
    setError('')
    try {
      if (appVariant === 'criminal') {
        await localDeleteTranscript(uncategorizedDeleteTarget.media_key)
      } else {
        const response = await authenticatedFetch(
          `/api/transcripts/by-key/${encodeURIComponent(uncategorizedDeleteTarget.media_key)}`,
          { method: 'DELETE' }
        )
        if (!response.ok) {
          const detail = await response.json().catch(() => ({}))
          throw new Error(detail?.detail || 'Failed to delete transcript')
        }
      }
      setUncategorizedDeleteTarget(null)
      await loadUncategorized()
      await refreshCases()
    } catch (err: any) {
      setError(err?.message || 'Failed to delete transcript')
    } finally {
      setDeletingUncategorizedTranscript(false)
    }
  }

  const getAssignmentTarget = (mediaKey: string) => {
    return assignmentTargets[mediaKey] ?? (cases[0]?.case_id || '')
  }

  const handleAssignToCase = async (mediaKey: string) => {
    const targetCaseId = getAssignmentTarget(mediaKey)
    if (!targetCaseId) {
      setError('Create a case before assigning transcripts.')
      return
    }

    setAssigningTranscript(mediaKey)
    setError('')
    try {
      if (appVariant === 'criminal') {
        await localMoveTranscriptToCase(mediaKey, targetCaseId)
      } else {
        const response = await authenticatedFetch(`/api/cases/${targetCaseId}/transcripts`, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ media_key: mediaKey }),
        })
        if (!response.ok) {
          const detail = await response.json().catch(() => ({}))
          throw new Error(detail?.detail || 'Failed to assign transcript to case')
        }
      }

      await loadUncategorized()
      await refreshCases()
    } catch (err: any) {
      setError(err?.message || 'Failed to assign transcript to case')
    } finally {
      setAssigningTranscript(null)
    }
  }

  const formatDate = (dateStr?: string | null) => {
    if (!dateStr) return '-'
    return new Date(dateStr).toLocaleDateString()
  }

  const getDaysUntilExpiry = (expiresAt?: string | null) => {
    if (!expiresAt) return null
    const now = new Date()
    const expiry = new Date(expiresAt)
    const diff = Math.ceil((expiry.getTime() - now.getTime()) / (1000 * 60 * 60 * 24))
    return diff > 0 ? diff : 0
  }

  return (
    <div className="p-8 max-w-6xl mx-auto">
      {/* Header */}
      <div className="flex items-center justify-between mb-8">
        <div>
          <h1 className="text-2xl font-semibold text-gray-900">Cases</h1>
          <p className="text-gray-500 mt-1">Organize your transcripts into cases</p>
        </div>
        <button
          onClick={() => setShowNewCaseModal(true)}
          className="btn-primary px-4 py-2 flex items-center gap-2"
        >
          <svg className="w-5 h-5" fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24">
            <path d="M12 4v16m8-8H4" />
          </svg>
          New Case
        </button>
      </div>

      {/* Tabs */}
      <div className="flex gap-2 mb-6 border-b border-gray-200">
        <button
          onClick={() => {
            setActiveTab('cases')
            guardedPush(router, routes.cases())
          }}
          className={`px-4 py-3 font-medium text-sm border-b-2 -mb-px transition-colors ${
            activeTab === 'cases'
              ? 'border-primary-600 text-primary-600'
              : 'border-transparent text-gray-500 hover:text-gray-700'
          }`}
        >
          Cases ({cases.length})
        </button>
        <button
          onClick={() => {
            setActiveTab('uncategorized')
            guardedPush(router, routes.casesTab('uncategorized'))
          }}
          className={`px-4 py-3 font-medium text-sm border-b-2 -mb-px transition-colors ${
            activeTab === 'uncategorized'
              ? 'border-primary-600 text-primary-600'
              : 'border-transparent text-gray-500 hover:text-gray-700'
          }`}
        >
          Uncategorized ({uncategorizedCount})
        </button>
      </div>

      {/* Cases Grid */}
      {activeTab === 'cases' && (
        <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-4">
          {cases.length === 0 ? (
            <div className="col-span-full bg-white rounded-xl shadow-sm border border-gray-100 p-8 text-center">
              <div className="w-16 h-16 bg-gray-100 rounded-full flex items-center justify-center mx-auto mb-4">
                <svg className="w-8 h-8 text-gray-400" fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24">
                  <path d="M3 7v10a2 2 0 002 2h14a2 2 0 002-2V9a2 2 0 00-2-2h-6l-2-2H5a2 2 0 00-2 2z" />
                </svg>
              </div>
              <h3 className="text-lg font-medium text-gray-900 mb-2">No cases yet</h3>
              <p className="text-gray-500 mb-4">Create your first case to organize transcripts</p>
              <button onClick={() => setShowNewCaseModal(true)} className="btn-primary px-4 py-2">
                Create Case
              </button>
            </div>
          ) : (
            cases.map((caseItem) => (
              <Link
                key={caseItem.case_id}
                href={routes.caseDetail(caseItem.case_id)}
                className="bg-white rounded-xl shadow-sm border border-gray-100 p-6 hover:shadow-md hover:border-primary-200 transition-all"
              >
                <div className="flex items-start justify-between mb-3">
                  <div className="w-12 h-12 bg-primary-100 rounded-lg flex items-center justify-center">
                    <span className="text-lg font-semibold text-primary-700">{caseItem.transcript_count}</span>
                  </div>
                  <svg className="w-5 h-5 text-gray-400" fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24">
                    <path d="M9 5l7 7-7 7" />
                  </svg>
                </div>
                <h3 className="font-semibold text-gray-900 mb-1 truncate">{caseItem.name}</h3>
                <p className="text-sm text-gray-500">
                  {caseItem.transcript_count} transcript{caseItem.transcript_count !== 1 ? 's' : ''}
                </p>
                {caseItem.description && (
                  <p className="text-sm text-gray-400 mt-2 line-clamp-2">{caseItem.description}</p>
                )}
                <p className="text-xs text-gray-400 mt-3">
                  Updated {formatDate(caseItem.updated_at)}
                </p>
              </Link>
            ))
          )}
        </div>
      )}

      {/* Uncategorized Transcripts */}
      {activeTab === 'uncategorized' && (
        <div className="bg-white rounded-xl shadow-sm border border-gray-100">
          {loadingUncategorized ? (
            <div className="p-8 text-center text-gray-500">Loading...</div>
          ) : uncategorizedTranscripts.length === 0 ? (
            <div className="p-8 text-center">
              <div className="w-16 h-16 bg-gray-100 rounded-full flex items-center justify-center mx-auto mb-4">
                <svg className="w-8 h-8 text-gray-400" fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24">
                  <path d="M5 13l4 4L19 7" />
                </svg>
              </div>
              <h3 className="text-lg font-medium text-gray-900 mb-2">All organized!</h3>
              <p className="text-gray-500">No uncategorized transcripts</p>
            </div>
          ) : (
            <div className="divide-y divide-gray-100">
              <div className="p-4 bg-amber-50 border-b border-amber-100 flex items-center justify-between gap-3">
                {appVariant !== 'criminal' && (
                  <p className="text-sm text-amber-800">
                    <strong>Note:</strong> Uncategorized transcripts expire after 30 days.
                  </p>
                )}
                {appVariant === 'criminal' && (
                  <p className="text-sm text-amber-800">
                    Assign transcripts to a case for better organization.
                  </p>
                )}
                <button
                  onClick={() => setAssignModeEnabled((prev) => !prev)}
                  disabled={cases.length === 0}
                  className="btn-outline text-sm px-3 py-1 disabled:opacity-50 disabled:cursor-not-allowed"
                  title={cases.length === 0 ? 'Create a case first' : 'Assign transcripts to a case'}
                >
                  {assignModeEnabled ? 'Done' : 'Assign to Case'}
                </button>
              </div>
              {uncategorizedTranscripts.map((transcript) => {
                const daysLeft = getDaysUntilExpiry(transcript.expires_at)
                return (
                  <div
                    key={transcript.media_key}
                    className="p-4 flex items-center justify-between hover:bg-gray-50"
                  >
                    <div className="flex items-center gap-4 flex-1 min-w-0">
                      <div className="w-10 h-10 bg-gray-100 rounded-lg flex items-center justify-center flex-shrink-0">
                        <svg className="w-5 h-5 text-gray-500" fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24">
                          <path d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z" />
                        </svg>
                      </div>
                      <div className="flex-1 min-w-0">
                        <p className="font-medium text-gray-900 truncate">{transcript.title_label}</p>
                        <p className="text-sm text-gray-500">
                          {transcript.line_count || 0} lines • Updated {formatDate(transcript.updated_at)}
                        </p>
                      </div>
                    </div>
                    <div className="flex items-center gap-3 flex-wrap justify-end">
                      {assignModeEnabled && (
                        <>
                          <select
                            value={getAssignmentTarget(transcript.media_key)}
                            onChange={(e) =>
                              setAssignmentTargets((prev) => ({
                                ...prev,
                                [transcript.media_key]: e.target.value,
                              }))
                            }
                            className="input-field h-9 w-[16rem] md:w-[22rem] min-w-[220px] text-sm"
                          >
                            {cases.map((caseItem) => (
                              <option key={caseItem.case_id} value={caseItem.case_id}>
                                {caseItem.name}
                              </option>
                            ))}
                          </select>
                          <button
                            onClick={() => handleAssignToCase(transcript.media_key)}
                            disabled={assigningTranscript === transcript.media_key || cases.length === 0}
                            className="btn-primary text-sm px-3 py-1 disabled:opacity-50 disabled:cursor-not-allowed"
                          >
                            {assigningTranscript === transcript.media_key ? 'Assigning...' : 'Assign'}
                          </button>
                        </>
                      )}
                      {appVariant !== 'criminal' && daysLeft !== null && (
                        <span className={`text-sm px-2 py-1 rounded ${
                          daysLeft <= 7 ? 'bg-red-100 text-red-700' : 'bg-amber-100 text-amber-700'
                        }`}>
                          {daysLeft} days left
                        </span>
                      )}
                      <button
                        onClick={() => {
                          setActiveMediaKey(transcript.media_key)
                          guardedPush(router, routes.editor(transcript.media_key))
                        }}
                        className="btn-outline text-sm px-3 py-1"
                      >
                        Open
                      </button>
                      <button
                        onClick={() => setUncategorizedDeleteTarget(transcript)}
                        disabled={deletingUncategorizedTranscript}
                        className="p-2 text-gray-400 hover:text-red-600 hover:bg-red-50 rounded-lg transition-colors disabled:opacity-50 disabled:cursor-not-allowed"
                        title="Delete transcript permanently"
                      >
                        <svg className="w-5 h-5" fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24">
                          <path d="M19 7l-.867 12.142A2 2 0 0116.138 21H7.862a2 2 0 01-1.995-1.858L5 7m5 4v6m4-6v6m1-10V4a1 1 0 00-1-1h-4a1 1 0 00-1 1v3M4 7h16" />
                        </svg>
                      </button>
                    </div>
                  </div>
                )
              })}
            </div>
          )}
        </div>
      )}

      {/* Uncategorized Transcript Delete Modal */}
      {uncategorizedDeleteTarget && (
        <div className="fixed inset-0 z-50 flex items-center justify-center bg-slate-900/60 backdrop-blur-sm p-4">
          <div className="w-full max-w-lg rounded-2xl border border-gray-100 bg-white shadow-2xl">
            <div className="p-6 border-b border-gray-100">
              <div className="flex items-start gap-4">
                <div className="h-10 w-10 rounded-full bg-red-100 text-red-600 flex items-center justify-center flex-shrink-0">
                  <svg className="w-5 h-5" fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24">
                    <path d="M12 9v4m0 4h.01M5.07 19h13.86c1.54 0 2.5-1.67 1.73-3L13.73 4c-.77-1.33-2.69-1.33-3.46 0L3.34 16c-.77 1.33.19 3 1.73 3z" />
                  </svg>
                </div>
                <div>
                  <h3 className="text-lg font-semibold text-gray-900">Delete Transcript Permanently?</h3>
                  <p className="mt-2 text-sm text-gray-600">
                    This will permanently remove <span className="font-medium text-gray-900">&quot;{uncategorizedDeleteTarget.title_label}&quot;</span>.
                    This action cannot be undone.
                  </p>
                </div>
              </div>
            </div>
            <div className="p-6 flex justify-end gap-3">
              <button
                onClick={() => {
                  if (deletingUncategorizedTranscript) return
                  setUncategorizedDeleteTarget(null)
                }}
                className="btn-outline px-4 py-2"
              >
                Cancel
              </button>
              <button
                onClick={handleDeleteUncategorizedTranscript}
                disabled={deletingUncategorizedTranscript}
                className="px-4 py-2 bg-red-600 hover:bg-red-700 text-white rounded-lg font-medium transition-colors disabled:opacity-70"
              >
                {deletingUncategorizedTranscript ? 'Deleting...' : 'Delete Transcript'}
              </button>
            </div>
          </div>
        </div>
      )}

      {/* New Case Modal */}
      {showNewCaseModal && (
        <div className="fixed inset-0 z-50 flex items-center justify-center bg-black/50 p-4">
          <div className="bg-white rounded-xl shadow-xl w-full max-w-md p-6">
            <h3 className="text-lg font-semibold text-gray-900 mb-4">Create New Case</h3>
            <div className="space-y-4">
              <div>
                <label className="block text-sm font-medium text-gray-700 mb-1">Case Name</label>
                <input
                  type="text"
                  value={newCaseName}
                  onChange={(e) => setNewCaseName(e.target.value)}
                  className="input-field"
                  placeholder="e.g., Smith vs. Johnson"
                  autoFocus
                />
              </div>
              <div>
                <label className="block text-sm font-medium text-gray-700 mb-1">Description (optional)</label>
                <textarea
                  value={newCaseDescription}
                  onChange={(e) => setNewCaseDescription(e.target.value)}
                  className="input-field"
                  rows={3}
                  placeholder="Brief description..."
                />
              </div>
            </div>
            {error && (
              <div className="mt-4 bg-red-50 border border-red-200 rounded-lg p-3 text-sm text-red-700">
                {error}
              </div>
            )}
            <div className="flex justify-end gap-3 mt-6">
              <button
                onClick={() => {
                  setShowNewCaseModal(false)
                  setNewCaseName('')
                  setNewCaseDescription('')
                  setError('')
                }}
                className="btn-outline px-4 py-2"
              >
                Cancel
              </button>
              <button
                onClick={handleCreateCase}
                disabled={!newCaseName.trim() || creatingCase}
                className="btn-primary px-4 py-2"
              >
                {creatingCase ? 'Creating...' : 'Create Case'}
              </button>
            </div>
          </div>
        </div>
      )}
    </div>
  )
}
===== END FILE =====

===== FILE: frontend-next/src/app/(dashboard)/converter/page.tsx =====
'use client'

import JSZip from 'jszip'
import { useCallback, useEffect, useMemo, useRef, useState } from 'react'
import { useDashboard } from '@/context/DashboardContext'
import {
  FFmpegCanceledError,
  cancelActiveFFmpegJob,
  convertToPlayable,
  detectCodec,
  readConvertedFromCache,
  writeConvertedToCache,
  type CodecInfo,
} from '@/lib/ffmpegWorker'

type ConverterStatus =
  | 'detecting'
  | 'ready'
  | 'already-playable'
  | 'skipped'
  | 'converting'
  | 'converted'
  | 'failed'

interface ConverterItem {
  id: string
  file: File
  codec: CodecInfo | null
  status: ConverterStatus
  progress: number
  error: string
  convertedFile: File | null
}

const buildId = () => `${Date.now()}_${Math.random().toString(16).slice(2)}`
const LARGE_FILE_WARNING_BYTES = 500 * 1024 * 1024
const LARGE_ZIP_WARNING_BYTES = 750 * 1024 * 1024

function statusLabel(status: ConverterStatus): string {
  if (status === 'detecting') return 'Detecting'
  if (status === 'ready') return 'Ready'
  if (status === 'already-playable') return 'Already OK'
  if (status === 'skipped') return 'Skipped'
  if (status === 'converting') return 'Converting'
  if (status === 'converted') return 'Converted'
  return 'Failed'
}

function statusClass(status: ConverterStatus): string {
  if (status === 'converted') return 'bg-green-100 text-green-700'
  if (status === 'ready') return 'bg-blue-100 text-blue-700'
  if (status === 'already-playable') return 'bg-gray-100 text-gray-700'
  if (status === 'converting') return 'bg-primary-100 text-primary-700'
  if (status === 'failed') return 'bg-red-100 text-red-700'
  return 'bg-amber-100 text-amber-800'
}

function downloadFile(file: File) {
  const url = URL.createObjectURL(file)
  const link = document.createElement('a')
  link.href = url
  link.download = file.name
  document.body.appendChild(link)
  link.click()
  document.body.removeChild(link)
  URL.revokeObjectURL(url)
}

function formatBytes(bytes: number): string {
  if (!Number.isFinite(bytes) || bytes <= 0) return '0 B'
  if (bytes < 1024) return `${bytes} B`
  if (bytes < 1024 * 1024) return `${(bytes / 1024).toFixed(1)} KB`
  if (bytes < 1024 * 1024 * 1024) return `${(bytes / (1024 * 1024)).toFixed(1)} MB`
  return `${(bytes / (1024 * 1024 * 1024)).toFixed(1)} GB`
}

export default function ConverterPage() {
  const { appVariant } = useDashboard()
  const [items, setItems] = useState<ConverterItem[]>([])
  const [pageError, setPageError] = useState('')
  const [pageNotice, setPageNotice] = useState('')
  const [isConverting, setIsConverting] = useState(false)
  const [zipBusy, setZipBusy] = useState(false)
  const [dragOver, setDragOver] = useState(false)
  const [batchProgress, setBatchProgress] = useState<{ current: number; total: number } | null>(null)

  const fileInputRef = useRef<HTMLInputElement>(null)
  const stopRequestedRef = useRef(false)
  const itemsRef = useRef<ConverterItem[]>([])
  const dragDepthRef = useRef(0)

  useEffect(() => {
    itemsRef.current = items
  }, [items])

  const updateItem = useCallback((id: string, updater: Partial<ConverterItem> | ((item: ConverterItem) => ConverterItem)) => {
    setItems((prev) =>
      prev.map((item) => {
        if (item.id !== id) return item
        if (typeof updater === 'function') {
          return updater(item)
        }
        return { ...item, ...updater }
      }),
    )
  }, [])

  const detectForItem = useCallback(async (id: string, file: File) => {
    try {
      const codec = await detectCodec(file)
      if (codec.needsConversion) {
        updateItem(id, {
          codec,
          status: 'ready',
          error: '',
        })
        return
      }

      updateItem(id, {
        codec,
        status: 'already-playable',
        error: '',
      })
    } catch {
      updateItem(id, {
        codec: null,
        status: 'skipped',
        error: 'Could not detect format.',
      })
    }
  }, [updateItem])

  const addFiles = useCallback(async (incoming: File[]) => {
    if (!incoming.length) return
    setPageError('')
    setPageNotice('')

    const newItems: ConverterItem[] = incoming.map((file) => ({
      id: buildId(),
      file,
      codec: null,
      status: 'detecting',
      progress: 0,
      error: '',
      convertedFile: null,
    }))

    setItems((prev) => [...prev, ...newItems])

    await Promise.allSettled(newItems.map((item) => detectForItem(item.id, item.file)))
  }, [detectForItem])

  const handleFileInputChange = useCallback(async (event: React.ChangeEvent<HTMLInputElement>) => {
    const files = event.target.files
    if (!files || !files.length) return
    await addFiles(Array.from(files))
    event.target.value = ''
  }, [addFiles])

  const handleDrop = useCallback(async (event: React.DragEvent<HTMLLabelElement>) => {
    event.preventDefault()
    dragDepthRef.current = 0
    setDragOver(false)
    const files = event.dataTransfer.files
    if (!files || !files.length) return
    await addFiles(Array.from(files))
  }, [addFiles])

  const handleDragEnter = useCallback((event: React.DragEvent<HTMLLabelElement>) => {
    event.preventDefault()
    dragDepthRef.current += 1
    setDragOver(true)
  }, [])

  const handleDragLeave = useCallback((event: React.DragEvent<HTMLLabelElement>) => {
    event.preventDefault()
    dragDepthRef.current = Math.max(0, dragDepthRef.current - 1)
    if (dragDepthRef.current === 0) {
      setDragOver(false)
    }
  }, [])

  const handleDragOver = useCallback((event: React.DragEvent<HTMLLabelElement>) => {
    event.preventDefault()
    setDragOver(true)
  }, [])

  const convertReadyFiles = useCallback(async () => {
    if (isConverting) return

    const readyItems = itemsRef.current.filter((item) => item.status === 'ready')
    if (!readyItems.length) {
      setPageError('No files are ready to convert.')
      return
    }

    const itemsToConvert: ConverterItem[] = []
    for (const item of readyItems) {
      if (item.file.size <= LARGE_FILE_WARNING_BYTES) {
        itemsToConvert.push(item)
        continue
      }

      const shouldContinue = window.confirm(
        `This file is very large (${formatBytes(item.file.size)}). In-browser conversion may fail. Continue?\n\n${item.file.name}`,
      )
      if (shouldContinue) {
        updateItem(item.id, { error: '' })
        itemsToConvert.push(item)
      } else {
        updateItem(item.id, {
          status: 'ready',
          progress: 0,
          error: 'Skipped in this batch due to large file size.',
        })
      }
    }

    if (!itemsToConvert.length) {
      setPageError('')
      setPageNotice('No files selected for conversion after large-file warnings.')
      return
    }

    stopRequestedRef.current = false
    setIsConverting(true)
    setBatchProgress({ current: 1, total: itemsToConvert.length })
    setPageError('')
    setPageNotice('')

    try {
      for (let index = 0; index < itemsToConvert.length; index += 1) {
        const item = itemsToConvert[index]
        if (stopRequestedRef.current) break

        setBatchProgress({ current: index + 1, total: itemsToConvert.length })
        updateItem(item.id, {
          status: 'converting',
          progress: 0,
          error: '',
        })

        try {
          let cached: File | null = null
          try {
            cached = await readConvertedFromCache(item.file)
          } catch (cacheReadError) {
            console.warn('Converter cache read failed, continuing with conversion.', cacheReadError)
          }

          if (cached) {
            updateItem(item.id, {
              status: 'converted',
              convertedFile: cached,
              progress: 1,
            })
            continue
          }

          let converted: File | null = null

          try {
            converted = await convertToPlayable(item.file, (ratio) => {
              updateItem(item.id, {
                status: 'converting',
                progress: ratio,
              })
            })
          } catch (clientError) {
            if (clientError instanceof FFmpegCanceledError || stopRequestedRef.current) {
              updateItem(item.id, {
                status: 'failed',
                error: 'Conversion canceled.',
              })
              break
            }
            const message = clientError instanceof Error ? clientError.message : 'In-browser conversion failed.'
            updateItem(item.id, {
              status: 'failed',
              error: message,
            })
            continue
          }

          if (!converted) continue

          try {
            await writeConvertedToCache(item.file, converted)
          } catch (cacheWriteError) {
            console.warn('Converter cache write failed, continuing without cache.', cacheWriteError)
          }

          updateItem(item.id, {
            status: 'converted',
            convertedFile: converted,
            progress: 1,
          })
        } catch (error) {
          const message = error instanceof Error ? error.message : 'Conversion failed.'
          updateItem(item.id, {
            status: 'failed',
            error: message,
          })
        }
      }
    } finally {
      setIsConverting(false)
      setBatchProgress(null)
      if (stopRequestedRef.current) {
        setPageNotice('Conversion stopped. Completed files were kept.')
      }
      stopRequestedRef.current = false
    }
  }, [isConverting, updateItem])

  const handleStop = useCallback(() => {
    stopRequestedRef.current = true
    cancelActiveFFmpegJob()
  }, [])

  const removeItem = useCallback((id: string) => {
    if (isConverting) return
    setItems((prev) => prev.filter((item) => item.id !== id))
  }, [isConverting])

  const retryItem = useCallback((id: string) => {
    if (isConverting) return
    updateItem(id, {
      status: 'ready',
      progress: 0,
      error: '',
      convertedFile: null,
    })
  }, [isConverting, updateItem])

  const downloadAllZip = useCallback(async () => {
    const converted = itemsRef.current.filter((item) => item.convertedFile).map((item) => item.convertedFile as File)
    if (!converted.length) {
      setPageError('No converted files are available to download.')
      return
    }

    const totalBytes = converted.reduce((sum, file) => sum + file.size, 0)
    if (totalBytes > LARGE_ZIP_WARNING_BYTES) {
      const shouldContinue = window.confirm(
        `This ZIP is very large (${formatBytes(totalBytes)} across ${converted.length} files). Building it in-browser may fail. Continue?`,
      )
      if (!shouldContinue) {
        return
      }
    }

    setZipBusy(true)
    setPageError('')
    try {
      const zip = new JSZip()
      const usedNames = new Set<string>()

      for (const file of converted) {
        let name = file.name
        let suffix = 2
        while (usedNames.has(name)) {
          const dot = file.name.lastIndexOf('.')
          const stem = dot > -1 ? file.name.slice(0, dot) : file.name
          const ext = dot > -1 ? file.name.slice(dot) : ''
          name = `${stem}-${suffix}${ext}`
          suffix += 1
        }
        usedNames.add(name)
        zip.file(name, file)
      }

      const blob = await zip.generateAsync({ type: 'blob', streamFiles: true })
      const url = URL.createObjectURL(blob)
      const link = document.createElement('a')
      link.href = url
      link.download = `converted-media-${new Date().toISOString().slice(0, 10)}.zip`
      document.body.appendChild(link)
      link.click()
      document.body.removeChild(link)
      URL.revokeObjectURL(url)
    } catch {
      setPageError('Failed to generate ZIP file.')
    } finally {
      setZipBusy(false)
    }
  }, [])

  const totals = useMemo(() => {
    const totalSize = items.reduce((sum, item) => sum + item.file.size, 0)
    const convertedCount = items.filter((item) => item.status === 'converted').length
    const readyCount = items.filter((item) => item.status === 'ready').length
    return { totalSize, convertedCount, readyCount }
  }, [items])

  if (appVariant !== 'criminal') {
    return (
      <div className="p-8 max-w-4xl mx-auto">
        <div className="bg-white rounded-xl shadow-sm border border-gray-100 p-8">
          <h1 className="text-2xl font-semibold text-gray-900 mb-2">Media Converter</h1>
          <p className="text-gray-600">The converter is available only in the criminal variant.</p>
        </div>
      </div>
    )
  }

  return (
    <div className="p-8 max-w-6xl mx-auto space-y-6">
      <div>
        <h1 className="text-2xl font-semibold text-gray-900">Media Converter</h1>
        <p className="text-gray-600 mt-1">
          Convert proprietary audio/video files into browser-playable formats.
        </p>
      </div>

      {(pageError || pageNotice) && (
        <div className="space-y-3">
          {pageError && <div className="bg-red-50 border border-red-200 rounded-lg p-4 text-red-700">{pageError}</div>}
          {pageNotice && <div className="bg-amber-50 border border-amber-200 rounded-lg p-4 text-amber-800">{pageNotice}</div>}
        </div>
      )}

      <div className="bg-white rounded-xl shadow-sm border border-gray-100 p-6">
        <label
          htmlFor="converter-file-picker"
          onDrop={handleDrop}
          onDragEnter={handleDragEnter}
          onDragLeave={handleDragLeave}
          onDragOver={handleDragOver}
          className={`block border-2 border-dashed rounded-xl p-10 text-center cursor-pointer transition-colors ${
            dragOver
              ? 'border-primary-500 bg-primary-50'
              : 'border-gray-300 hover:border-primary-400 hover:bg-primary-50'
          }`}
        >
          <input
            id="converter-file-picker"
            ref={fileInputRef}
            type="file"
            multiple
            onChange={handleFileInputChange}
            accept="audio/*,video/*,.wav,.mp3,.m4a,.flac,.ogg,.aac,.wma,.mp4,.mov,.avi,.mkv,.webm"
            className="sr-only"
          />
          <div className="space-y-3">
            <div className="w-16 h-16 bg-gray-100 rounded-full flex items-center justify-center mx-auto">
              <svg className="w-8 h-8 text-gray-400" fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24">
                <path d="M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12" />
              </svg>
            </div>
            <p className="font-medium text-gray-900">Drop files here or click to browse</p>
            <p className="text-sm text-gray-500">Batch conversion is processed serially in-browser.</p>
          </div>
        </label>
      </div>

      <div className="bg-white rounded-xl shadow-sm border border-gray-100 overflow-hidden">
        <div className="p-4 border-b border-gray-100 flex flex-wrap items-center justify-between gap-3">
          <div>
            <h2 className="font-semibold text-gray-900">Files ({items.length})</h2>
            <p className="text-sm text-gray-500">
              {formatBytes(totals.totalSize)} total, {totals.readyCount} ready, {totals.convertedCount} converted
            </p>
            {isConverting && batchProgress && (
              <p className="text-sm font-medium text-primary-700 mt-1">
                Converting {batchProgress.current} of {batchProgress.total}
              </p>
            )}
          </div>
          <div className="flex flex-wrap gap-2">
            <button
              type="button"
              onClick={convertReadyFiles}
              disabled={isConverting || totals.readyCount === 0}
              className="btn-primary px-4 py-2 disabled:opacity-50 disabled:cursor-not-allowed"
            >
              Convert All
            </button>
            <button
              type="button"
              onClick={handleStop}
              disabled={!isConverting}
              className="btn-outline px-4 py-2 disabled:opacity-50 disabled:cursor-not-allowed"
            >
              Stop
            </button>
            <button
              type="button"
              onClick={downloadAllZip}
              disabled={zipBusy || totals.convertedCount === 0}
              className="btn-outline px-4 py-2 disabled:opacity-50 disabled:cursor-not-allowed"
            >
              {zipBusy ? 'Building ZIP…' : 'Download Converted ZIP'}
            </button>
            <button
              type="button"
              onClick={() => {
                if (isConverting) return
                setItems([])
              }}
              disabled={isConverting || items.length === 0}
              className="btn-outline px-4 py-2 disabled:opacity-50 disabled:cursor-not-allowed"
            >
              Clear
            </button>
          </div>
        </div>

        <div className="divide-y divide-gray-100">
          {items.map((item) => (
            <div key={item.id} className="p-4 flex flex-wrap items-center gap-4">
              <div className="flex-1 min-w-0">
                <p className="font-medium text-gray-900 truncate">{item.file.name}</p>
                <p className="text-sm text-gray-500">
                  {(item.codec?.codecName || 'Unknown')} • {formatBytes(item.file.size)}
                </p>
                {item.error && <p className="text-sm text-red-600 mt-1">{item.error}</p>}
              </div>

              {item.status === 'converting' ? (
                <div className="w-40">
                  <div className="h-2 bg-gray-200 rounded-full overflow-hidden">
                    <div className="h-full bg-primary-600 transition-all" style={{ width: `${Math.round(item.progress * 100)}%` }} />
                  </div>
                  <p className="text-xs text-gray-500 mt-1">{Math.round(item.progress * 100)}%</p>
                </div>
              ) : (
                <div className="w-40" />
              )}

              <span className={`px-2.5 py-1 rounded-full text-xs font-medium ${statusClass(item.status)}`}>
                {statusLabel(item.status)}
              </span>

              {item.status === 'failed' && (
                <button
                  type="button"
                  onClick={() => retryItem(item.id)}
                  disabled={isConverting}
                  className="btn-outline px-3 py-1.5 text-sm disabled:opacity-50 disabled:cursor-not-allowed"
                >
                  Retry
                </button>
              )}

              <button
                type="button"
                onClick={() => {
                  if (!item.convertedFile) return
                  downloadFile(item.convertedFile)
                }}
                disabled={!item.convertedFile}
                className="btn-outline px-3 py-1.5 text-sm disabled:opacity-50 disabled:cursor-not-allowed"
              >
                Download
              </button>

              <button
                type="button"
                onClick={() => removeItem(item.id)}
                disabled={isConverting}
                className="btn-outline px-3 py-1.5 text-sm text-red-700 border-red-300 hover:bg-red-50 disabled:opacity-50 disabled:cursor-not-allowed"
                aria-label={`Remove ${item.file.name}`}
              >
                X
              </button>
            </div>
          ))}

          {items.length === 0 && (
            <div className="p-8 text-center text-gray-500">No files selected yet.</div>
          )}
        </div>
      </div>
    </div>
  )
}
===== END FILE =====

===== FILE: frontend-next/src/app/(dashboard)/editor/page.tsx =====
'use client'

import { useCallback, useEffect, useRef, useState } from 'react'
import { useSearchParams } from 'next/navigation'
import Link from 'next/link'
import { useDashboard } from '@/context/DashboardContext'
import { authenticatedFetch } from '@/utils/auth'
import TranscriptEditor, { EditorSessionResponse, EditorSaveResponse } from '@/components/TranscriptEditor'
import MediaMissingBanner from '@/components/MediaMissingBanner'
import { routes } from '@/utils/routes'
import { getTranscript as localGetTranscript, saveTranscript as localSaveTranscript } from '@/lib/storage'
import { getMediaObjectURL, promptRelinkMedia } from '@/lib/mediaHandles'

type TranscriptData = EditorSessionResponse & {
  transcript?: string | null
  transcript_text?: string | null
}

interface SnapshotListItem {
  snapshot_id: string
  created_at?: string
  is_manual_save?: boolean
  line_count?: number
  title_label?: string
}

export default function EditorPage() {
  const searchParams = useSearchParams()
  const { activeMediaKey, setActiveMediaKey, refreshRecentTranscripts, appVariant } = useDashboard()

  const [mediaKey, setMediaKey] = useState<string | null>(null)
  const [transcriptData, setTranscriptData] = useState<TranscriptData | null>(null)
  const [mediaUrl, setMediaUrl] = useState<string>('')
  const [mediaContentType, setMediaContentType] = useState<string | undefined>(undefined)
  const [isLoading, setIsLoading] = useState(true)
  const [error, setError] = useState<string>('')
  const [mediaAvailable, setMediaAvailable] = useState(true)
  const [showReimportModal, setShowReimportModal] = useState(false)
  const [showHistoryModal, setShowHistoryModal] = useState(false)
  const [historyLoading, setHistoryLoading] = useState(false)
  const [historyError, setHistoryError] = useState('')
  const [historySnapshots, setHistorySnapshots] = useState<SnapshotListItem[]>([])
  const [selectedSnapshotId, setSelectedSnapshotId] = useState<string | null>(null)
  const [isLoadingSnapshot, setIsLoadingSnapshot] = useState(false)
  const [mediaFilename, setMediaFilename] = useState<string>('')
  const blobUrlRef = useRef<string | null>(null)

  // Revoke blob URL on unmount
  useEffect(() => {
    return () => {
      if (blobUrlRef.current) {
        URL.revokeObjectURL(blobUrlRef.current)
        blobUrlRef.current = null
      }
    }
  }, [])

  // Get media_key from URL or context
  useEffect(() => {
    const urlKey = searchParams.get('key')
    if (urlKey) {
      setMediaKey(urlKey)
      setActiveMediaKey(urlKey)
    } else if (activeMediaKey) {
      setMediaKey(activeMediaKey)
    }
  }, [searchParams, activeMediaKey, setActiveMediaKey])

  // Load transcript data
  const loadTranscript = useCallback(async (key: string) => {
    setIsLoading(true)
    setError('')
    try {
      if (appVariant === 'criminal') {
        const data = await localGetTranscript(key)
        if (!data) throw new Error('Transcript not found')
        setTranscriptData(data as unknown as TranscriptData)
        setMediaFilename((data as Record<string, unknown>).media_filename as string || '')
        setMediaContentType((data as Record<string, unknown>).media_content_type as string || undefined)

        // Try to get media from IndexedDB handle
        if (blobUrlRef.current) {
          URL.revokeObjectURL(blobUrlRef.current)
          blobUrlRef.current = null
        }
        const mediaSourceId = ((data as Record<string, unknown>).media_handle_id as string) || key
        const url = await getMediaObjectURL(mediaSourceId)
        if (url) {
          blobUrlRef.current = url
          setMediaUrl(url)
          setMediaAvailable(true)
        } else {
          setMediaUrl('')
          setMediaAvailable(false)
        }
      } else {
        const response = await authenticatedFetch(`/api/transcripts/by-key/${encodeURIComponent(key)}`)
        if (!response.ok) {
          const detail = await response.json().catch(() => ({}))
          throw new Error(detail?.detail || 'Failed to load transcript')
        }
        const data: TranscriptData = await response.json()
        setTranscriptData(data)

        if (data.media_blob_name) {
          setMediaUrl(`/api/media/${data.media_blob_name}`)
          setMediaContentType(data.media_content_type ?? undefined)
        } else {
          setMediaUrl('')
          setMediaContentType(undefined)
        }
      }
    } catch (err: any) {
      setError(err?.message || 'Failed to load transcript')
    } finally {
      setIsLoading(false)
    }
  }, [appVariant])

  // Check media availability
  const checkMediaStatus = useCallback(async (key: string) => {
    if (appVariant === 'criminal') {
      // Already checked in loadTranscript for criminal
      return
    }
    try {
      const response = await authenticatedFetch(`/api/transcripts/by-key/${encodeURIComponent(key)}/media-status`)
      if (!response.ok) {
        if (response.status === 404) {
          setMediaAvailable(false)
        }
        return
      }
      const data = await response.json()
      setMediaAvailable(data.media_available ?? data.available ?? true)
    } catch {
      // Assume available if check fails
      setMediaAvailable(true)
    }
  }, [appVariant])

  useEffect(() => {
    if (mediaKey) {
      loadTranscript(mediaKey)
      checkMediaStatus(mediaKey)
    }
  }, [mediaKey, loadTranscript, checkMediaStatus])

  const handleSessionChange = useCallback((session: EditorSessionResponse) => {
    setTranscriptData(prev => ({
      ...prev,
      ...session,
    }))
    if (appVariant !== 'criminal' && session.media_blob_name) {
      setMediaUrl(`/api/media/${session.media_blob_name}`)
      setMediaContentType(session.media_content_type ?? undefined)
    }
  }, [appVariant])

  const handleSaveComplete = useCallback((data: EditorSaveResponse) => {
    setTranscriptData(prev => ({
      ...prev,
      ...data,
    }))
    refreshRecentTranscripts()
  }, [refreshRecentTranscripts])

  const handleMediaReimported = useCallback(() => {
    if (mediaKey) {
      loadTranscript(mediaKey)
      setMediaAvailable(true)
    }
    setShowReimportModal(false)
  }, [mediaKey, loadTranscript])

  const handleRelinkMedia = useCallback(async () => {
    if (!mediaKey) return
    try {
      const result = await promptRelinkMedia(mediaFilename || 'media file')
      if (!result) return

      const relinkedFile = await result.handle.getFile()
      const nextMediaSourceId = result.handleId
      const existing = await localGetTranscript(mediaKey)
      if (existing) {
        const existingRecord = existing as Record<string, unknown>
        const caseId = typeof existingRecord.case_id === 'string' && existingRecord.case_id
          ? existingRecord.case_id
          : undefined
        const updated = {
          ...existingRecord,
          media_handle_id: nextMediaSourceId,
          media_filename: relinkedFile.name || (existingRecord.media_filename as string | undefined),
          media_content_type: relinkedFile.type || (existingRecord.media_content_type as string | undefined),
        } as Record<string, unknown>
        await localSaveTranscript(mediaKey, updated, caseId)
        setTranscriptData(updated as unknown as TranscriptData)
        refreshRecentTranscripts()
      }

      setMediaFilename(relinkedFile.name || mediaFilename)
      setMediaContentType(relinkedFile.type || mediaContentType)

      // Refresh media URL
      if (blobUrlRef.current) {
        URL.revokeObjectURL(blobUrlRef.current)
        blobUrlRef.current = null
      }
      const url = await getMediaObjectURL(nextMediaSourceId)
      if (url) {
        blobUrlRef.current = url
        setMediaUrl(url)
        setMediaAvailable(true)
      }
    } catch (err: any) {
      setError(err?.message || 'Failed to relink media')
    }
  }, [mediaContentType, mediaFilename, mediaKey, refreshRecentTranscripts])

  const openHistoryModal = useCallback(async () => {
    if (!mediaKey) return

    setShowHistoryModal(true)
    setHistoryLoading(true)
    setHistoryError('')
    setSelectedSnapshotId(null)

    try {
      const response = await authenticatedFetch(
        `/api/transcripts/by-key/${encodeURIComponent(mediaKey)}/history`,
      )
      if (!response.ok) {
        const detail = await response.json().catch(() => ({}))
        throw new Error(detail?.detail || 'Failed to load edit history')
      }

      const data = await response.json()
      const snapshots: SnapshotListItem[] = (data.snapshots || [])
        .sort((a: SnapshotListItem, b: SnapshotListItem) => {
          const aTime = a.created_at ? new Date(a.created_at).getTime() : 0
          const bTime = b.created_at ? new Date(b.created_at).getTime() : 0
          return bTime - aTime
        })
        .slice(0, 10)
      setHistorySnapshots(snapshots)
    } catch (err: any) {
      setHistoryError(err?.message || 'Failed to load edit history')
      setHistorySnapshots([])
    } finally {
      setHistoryLoading(false)
    }
  }, [mediaKey])

  const handleLoadSnapshot = useCallback(async () => {
    if (!mediaKey || !selectedSnapshotId) return

    setIsLoadingSnapshot(true)
    setHistoryError('')

    try {
      const response = await authenticatedFetch(
        `/api/transcripts/by-key/${encodeURIComponent(mediaKey)}/restore/${selectedSnapshotId}`,
        { method: 'POST' },
      )
      if (!response.ok) {
        const detail = await response.json().catch(() => ({}))
        throw new Error(detail?.detail || 'Failed to load snapshot')
      }

      const data: TranscriptData = await response.json()
      handleSessionChange(data)
      refreshRecentTranscripts()
      setShowHistoryModal(false)
      setSelectedSnapshotId(null)
    } catch (err: any) {
      setHistoryError(err?.message || 'Failed to load snapshot')
    } finally {
      setIsLoadingSnapshot(false)
    }
  }, [handleSessionChange, mediaKey, refreshRecentTranscripts, selectedSnapshotId])

  const downloadFile = (base64Data: string, filename: string, mimeType: string) => {
    const byteCharacters = atob(base64Data)
    const byteNumbers = new Array(byteCharacters.length)
    for (let i = 0; i < byteCharacters.length; i++) {
      byteNumbers[i] = byteCharacters.charCodeAt(i)
    }
    const byteArray = new Uint8Array(byteNumbers)
    const blob = new Blob([byteArray], { type: mimeType })

    const link = document.createElement('a')
    link.href = URL.createObjectURL(blob)
    link.download = filename
    document.body.appendChild(link)
    link.click()
    document.body.removeChild(link)
    URL.revokeObjectURL(link.href)
  }

  const generateFilename = (baseName: string, extension: string) => {
    const caseName = transcriptData?.title_data?.CASE_NAME || ''
    const date = transcriptData?.title_data?.DATE || ''
    let filename = ''
    if (caseName) {
      const sanitized = caseName.replace(/[^a-zA-Z0-9\s-]/g, '').replace(/\s+/g, '-')
      filename += sanitized + '-'
    }
    filename += baseName
    if (date) filename += '-' + date
    return filename + extension
  }

  if (!mediaKey) {
    return (
      <div className="p-8 max-w-4xl mx-auto">
        <div className="bg-white rounded-xl shadow-sm border border-gray-100 p-8 text-center">
          <div className="w-16 h-16 bg-gray-100 rounded-full flex items-center justify-center mx-auto mb-4">
            <svg className="w-8 h-8 text-gray-400" fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24">
              <path d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z" />
            </svg>
          </div>
          <h2 className="text-xl font-semibold text-gray-900 mb-2">No Transcript Selected</h2>
          <p className="text-gray-500 mb-6">Select a transcript from the sidebar or create a new one.</p>
          <Link href={routes.transcribe()} className="btn-primary px-6 py-3 inline-block">
            Create New Transcript
          </Link>
        </div>
      </div>
    )
  }

  if (isLoading) {
    return (
      <div className="p-8 flex items-center justify-center min-h-[60vh]">
        <div className="text-center">
          <div className="w-12 h-12 mx-auto mb-4 relative">
            <div className="absolute inset-0 border-4 border-primary-200 rounded-full"></div>
            <div className="absolute inset-0 border-4 border-primary-600 rounded-full border-t-transparent animate-spin"></div>
          </div>
          <p className="text-gray-500">Loading transcript...</p>
        </div>
      </div>
    )
  }

  if (error) {
    return (
      <div className="p-8 max-w-4xl mx-auto">
        <div className="bg-red-50 border border-red-200 rounded-xl p-8 text-center">
          <div className="w-16 h-16 bg-red-100 rounded-full flex items-center justify-center mx-auto mb-4">
            <svg className="w-8 h-8 text-red-600" fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24">
              <path d="M12 9v2m0 4h.01m-6.938 4h13.856c1.54 0 2.502-1.667 1.732-3L13.732 4c-.77-1.333-2.694-1.333-3.464 0L3.34 16c-.77 1.333.192 3 1.732 3z" />
            </svg>
          </div>
          <h2 className="text-xl font-semibold text-gray-900 mb-2">Error Loading Transcript</h2>
          <p className="text-gray-600 mb-6">{error}</p>
          <button onClick={() => loadTranscript(mediaKey)} className="btn-primary px-6 py-3">
            Retry
          </button>
        </div>
      </div>
    )
  }

  return (
    <div className="h-full flex flex-col">
      {mediaKey && (
        <div className="px-6 pt-4">
          <Link
            href={routes.viewer(mediaKey)}
            className="inline-flex items-center gap-2 rounded-lg border border-primary-200 bg-primary-50 px-3 py-1.5 text-sm font-medium text-primary-700 hover:bg-primary-100"
          >
            <svg className="h-4 w-4" fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24">
              <path d="M2 12s3.5-6 10-6 10 6 10 6-3.5 6-10 6-10-6-10-6z" />
              <circle cx="12" cy="12" r="3" />
            </svg>
            View in Viewer
          </Link>
        </div>
      )}

      {!mediaAvailable && (
        <MediaMissingBanner
          mediaKey={mediaKey}
          appVariant={appVariant}
          mediaFilename={mediaFilename}
          onReimport={appVariant === 'criminal' ? handleRelinkMedia : () => setShowReimportModal(true)}
        />
      )}

      <TranscriptEditor
        mediaKey={mediaKey}
        initialData={transcriptData}
        mediaUrl={mediaAvailable ? mediaUrl : undefined}
        mediaType={mediaContentType}
        pdfBase64={transcriptData?.pdf_base64 ?? transcriptData?.docx_base64}
        docxBase64={transcriptData?.docx_base64}
        xmlBase64={transcriptData?.oncue_xml_base64}
        viewerHtmlBase64={transcriptData?.viewer_html_base64}
        appVariant={appVariant}
        onDownload={downloadFile}
        buildFilename={generateFilename}
        onSessionChange={handleSessionChange}
        onSaveComplete={handleSaveComplete}
        onRequestMediaImport={appVariant === 'criminal' ? handleRelinkMedia : () => setShowReimportModal(true)}
        onOpenHistory={appVariant === 'criminal' ? undefined : openHistoryModal}
      />

      {/* Reimport Modal */}
      {showReimportModal && (
        <ReimportMediaModal
          mediaKey={mediaKey}
          onClose={() => setShowReimportModal(false)}
          onSuccess={handleMediaReimported}
        />
      )}

      {showHistoryModal && (
        <div className="fixed inset-0 z-50 flex items-center justify-center bg-black/60 p-4">
          <div className="w-full max-w-3xl rounded-lg bg-white p-6 shadow-2xl">
            <div className="flex items-center justify-between gap-3">
              <div>
                <h3 className="text-xl font-semibold text-primary-900">Edit History</h3>
                <p className="text-sm text-primary-600">
                  Showing the ten most recent snapshots for this transcript.
                </p>
              </div>
              <button
                className="rounded border border-primary-300 px-3 py-1 text-sm text-primary-700 hover:bg-primary-100"
                onClick={() => setShowHistoryModal(false)}
              >
                Close
              </button>
            </div>

            {historyError && (
              <div className="mt-3 rounded border border-red-200 bg-red-50 px-3 py-2 text-sm text-red-700">
                {historyError}
              </div>
            )}

            <div className="mt-4 max-h-[60vh] overflow-y-auto rounded border border-primary-100">
              {historyLoading ? (
                <div className="p-4 text-sm text-primary-600">Loading snapshots...</div>
              ) : historySnapshots.length === 0 ? (
                <div className="p-4 text-sm text-primary-700">
                  No saved snapshots yet for this transcript.
                </div>
              ) : (
                <ul>
                  {historySnapshots.map((snapshot) => {
                    const isSelected = selectedSnapshotId === snapshot.snapshot_id
                    const itemClasses = [
                      'w-full border-b border-primary-100 px-4 py-3 text-left transition-colors',
                      isSelected ? 'bg-primary-100 hover:bg-primary-100 ring-2 ring-inset ring-primary-500 border-l-4 border-l-primary-600' : 'hover:bg-primary-50',
                    ]
                    return (
                      <li key={snapshot.snapshot_id}>
                        <button
                          type="button"
                          className={itemClasses.join(' ')}
                          onClick={() => setSelectedSnapshotId(snapshot.snapshot_id)}
                        >
                          <div className="font-semibold text-primary-900">
                            {snapshot.title_label || transcriptData?.title_data?.CASE_NAME || mediaKey}
                          </div>
                          <div className="text-xs text-primary-600">
                            {snapshot.created_at ? new Date(snapshot.created_at).toLocaleString() : 'Unknown time'}
                          </div>
                          <div className="text-xs text-primary-500">
                            {snapshot.is_manual_save ? 'Manual save' : 'Autosave'} - {snapshot.line_count ?? 0} lines
                          </div>
                        </button>
                      </li>
                    )
                  })}
                </ul>
              )}
            </div>

            <div className="mt-4 flex justify-end gap-3">
              <button
                className="rounded border border-primary-300 px-4 py-2 text-sm text-primary-700 hover:bg-primary-100"
                onClick={() => setShowHistoryModal(false)}
              >
                Cancel
              </button>
              <button
                className="rounded px-4 py-2 text-sm font-medium text-white disabled:cursor-not-allowed disabled:bg-gray-300 disabled:text-gray-500 bg-primary-600 hover:bg-primary-700"
                onClick={handleLoadSnapshot}
                disabled={!selectedSnapshotId || historyLoading || isLoadingSnapshot}
              >
                {isLoadingSnapshot ? 'Loading...' : 'Load Snapshot'}
              </button>
            </div>
          </div>
        </div>
      )}
    </div>
  )
}

function ReimportMediaModal({
  mediaKey,
  onClose,
  onSuccess,
}: {
  mediaKey: string
  onClose: () => void
  onSuccess: () => void
}) {
  const [file, setFile] = useState<File | null>(null)
  const [uploading, setUploading] = useState(false)
  const [error, setError] = useState('')

  const handleUpload = async () => {
    if (!file) return
    setUploading(true)
    setError('')
    try {
      const formData = new FormData()
      formData.append('file', file)

      const response = await authenticatedFetch(
        `/api/transcripts/by-key/${encodeURIComponent(mediaKey)}/reattach-media`,
        { method: 'POST', body: formData }
      )
      if (!response.ok) {
        const detail = await response.json().catch(() => ({}))
        throw new Error(detail?.detail || 'Failed to upload media')
      }
      onSuccess()
    } catch (err: any) {
      setError(err?.message || 'Failed to upload media')
    } finally {
      setUploading(false)
    }
  }

  return (
    <div className="fixed inset-0 z-50 flex items-center justify-center bg-black/50 p-4">
      <div className="bg-white rounded-xl shadow-xl w-full max-w-md p-6">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Re-import Media File</h3>
        <p className="text-sm text-gray-500 mb-4">
          The original media file has expired. Upload the same or updated file to enable playback and clip creation.
        </p>

        <label className={`block border-2 border-dashed rounded-lg p-8 text-center cursor-pointer transition-colors ${
          file ? 'border-green-300 bg-green-50' : 'border-gray-300 hover:border-primary-400'
        }`}>
          <input
            type="file"
            onChange={(e) => setFile(e.target.files?.[0] || null)}
            accept="audio/*,video/*"
            className="sr-only"
          />
          {file ? (
            <div>
              <p className="font-medium text-gray-900">{file.name}</p>
              <p className="text-sm text-gray-500">{(file.size / (1024 * 1024)).toFixed(1)} MB</p>
            </div>
          ) : (
            <div>
              <p className="font-medium text-gray-700">Click to select file</p>
              <p className="text-sm text-gray-500">Audio or video file</p>
            </div>
          )}
        </label>

        {error && (
          <div className="mt-4 bg-red-50 border border-red-200 rounded-lg p-3 text-sm text-red-700">
            {error}
          </div>
        )}

        <div className="flex justify-end gap-3 mt-6">
          <button onClick={onClose} className="btn-outline px-4 py-2">
            Cancel
          </button>
          <button
            onClick={handleUpload}
            disabled={!file || uploading}
            className="btn-primary px-4 py-2"
          >
            {uploading ? 'Uploading...' : 'Upload'}
          </button>
        </div>
      </div>
    </div>
  )
}
===== END FILE =====

===== FILE: frontend-next/src/app/(dashboard)/layout.tsx =====
'use client'

import { useCallback, useEffect, useState } from 'react'
import { DashboardProvider, useDashboard } from '@/context/DashboardContext'
import Sidebar from '@/components/layout/Sidebar'
import WorkspaceSetup from '@/components/WorkspaceSetup'
import { isWorkspaceConfigured, initWorkspace, setupMultiTabDetection } from '@/lib/storage'
import { confirmQueueNavigation, isQueueNavigationGuardActive } from '@/utils/navigationGuard'

const SIDEBAR_COLLAPSED_KEY = 'dashboard_sidebar_collapsed'

function WorkspaceGate({ children }: { children: React.ReactNode }) {
  const { appVariant, variantResolved, refreshCases, refreshRecentTranscripts } = useDashboard()
  const [ready, setReady] = useState(false)
  const [checking, setChecking] = useState(true)
  const [showSetup, setShowSetup] = useState(false)
  const [multiTabWarning, setMultiTabWarning] = useState(false)

  // Multi-tab detection for criminal variant
  useEffect(() => {
    if (appVariant !== 'criminal') return
    const cleanup = setupMultiTabDetection(() => setMultiTabWarning(true))
    return cleanup
  }, [appVariant])

  const checkWorkspace = useCallback(async () => {
    // Don't make any decisions until we know the real variant
    if (!variantResolved) return

    if (appVariant !== 'criminal') {
      setReady(true)
      setChecking(false)
      return
    }

    const configured = await isWorkspaceConfigured()
    if (configured) {
      const handle = await initWorkspace()
      if (handle) {
        setReady(true)
        setChecking(false)
        void Promise.allSettled([refreshCases(), refreshRecentTranscripts()])
        return
      }
    }
    setShowSetup(true)
    setChecking(false)
  }, [appVariant, refreshCases, refreshRecentTranscripts, variantResolved])

  useEffect(() => {
    checkWorkspace()
  }, [checkWorkspace])

  if (!variantResolved || (appVariant !== 'criminal' && !variantResolved)) {
    // Still loading config — show spinner
    return (
      <div className="flex items-center justify-center min-h-screen bg-gray-50">
        <div className="text-center">
          <div className="w-12 h-12 mx-auto mb-4 relative">
            <div className="absolute inset-0 border-4 border-primary-200 rounded-full" />
            <div className="absolute inset-0 border-4 border-primary-600 rounded-full border-t-transparent animate-spin" />
          </div>
          <p className="text-gray-500">Loading...</p>
        </div>
      </div>
    )
  }

  if (appVariant !== 'criminal') return <>{children}</>

  if (checking) {
    return (
      <div className="flex items-center justify-center min-h-screen bg-gray-50">
        <div className="text-center">
          <div className="w-12 h-12 mx-auto mb-4 relative">
            <div className="absolute inset-0 border-4 border-primary-200 rounded-full" />
            <div className="absolute inset-0 border-4 border-primary-600 rounded-full border-t-transparent animate-spin" />
          </div>
          <p className="text-gray-500">Connecting to workspace...</p>
        </div>
      </div>
    )
  }

  if (showSetup && !ready) {
    return (
      <WorkspaceSetup
        onComplete={() => {
          setReady(true)
          setShowSetup(false)
          void Promise.allSettled([refreshCases(), refreshRecentTranscripts()])
        }}
      />
    )
  }

  return (
    <>
      {multiTabWarning && (
        <div className="fixed top-0 left-0 right-0 z-50 bg-amber-500 text-amber-950 text-center py-2 px-4 text-sm font-medium">
          TranscribeAlpha is open in another tab. Please close other tabs to avoid data conflicts.
          <button onClick={() => setMultiTabWarning(false)} className="ml-3 underline">Dismiss</button>
        </div>
      )}
      {children}
    </>
  )
}

function PWAInstallPrompt() {
  const [deferredPrompt, setDeferredPrompt] = useState<any>(null)
  const [dismissed, setDismissed] = useState(false)

  useEffect(() => {
    try {
      if (localStorage.getItem('pwa_install_dismissed') === 'true') {
        setDismissed(true)
      }
    } catch {}

    const handler = (e: Event) => {
      e.preventDefault()
      setDeferredPrompt(e)
    }
    window.addEventListener('beforeinstallprompt', handler)
    return () => window.removeEventListener('beforeinstallprompt', handler)
  }, [])

  if (!deferredPrompt || dismissed) return null

  return (
    <div className="fixed bottom-4 right-4 z-40 bg-white border border-gray-200 rounded-xl shadow-lg p-4 max-w-sm">
      <p className="text-sm font-medium text-gray-900 mb-1">Install TranscribeAlpha</p>
      <p className="text-xs text-gray-500 mb-3">Install for the best experience: faster loading, offline access, and reliable file permissions.</p>
      <div className="flex gap-2">
        <button
          onClick={async () => {
            deferredPrompt.prompt()
            await deferredPrompt.userChoice
            setDeferredPrompt(null)
          }}
          className="px-3 py-1.5 bg-primary-600 text-white text-sm rounded-lg hover:bg-primary-500"
        >
          Install
        </button>
        <button
          onClick={() => {
            setDismissed(true)
            try { localStorage.setItem('pwa_install_dismissed', 'true') } catch {}
          }}
          className="px-3 py-1.5 text-gray-500 text-sm hover:text-gray-700"
        >
          Not now
        </button>
      </div>
    </div>
  )
}

export default function DashboardLayout({
  children,
}: {
  children: React.ReactNode
}) {
  const [sidebarCollapsed, setSidebarCollapsed] = useState(false)

  useEffect(() => {
    try {
      const stored = localStorage.getItem(SIDEBAR_COLLAPSED_KEY)
      if (stored === 'true') {
        setSidebarCollapsed(true)
      }
    } catch {
      // Ignore localStorage failures
    }
  }, [])

  useEffect(() => {
    try {
      localStorage.setItem(SIDEBAR_COLLAPSED_KEY, sidebarCollapsed ? 'true' : 'false')
    } catch {
      // Ignore localStorage failures
    }
  }, [sidebarCollapsed])

  useEffect(() => {
    const handleLinkNavigation = (event: MouseEvent) => {
      if (!isQueueNavigationGuardActive()) return
      if (event.defaultPrevented) return
      if (event.button !== 0) return
      if (event.metaKey || event.ctrlKey || event.shiftKey || event.altKey) return

      const target = event.target as Element | null
      const anchor = target?.closest('a[href]') as HTMLAnchorElement | null
      if (!anchor) return
      if (anchor.target && anchor.target !== '_self') return
      if (anchor.hasAttribute('download')) return

      const href = anchor.getAttribute('href')
      if (!href || href.startsWith('#') || href.startsWith('javascript:')) return

      let destination: URL
      try {
        destination = new URL(anchor.href, window.location.href)
      } catch {
        return
      }

      if (destination.origin !== window.location.origin) return

      const currentPath = `${window.location.pathname}${window.location.search}${window.location.hash}`
      const nextPath = `${destination.pathname}${destination.search}${destination.hash}`
      if (currentPath === nextPath) return

      if (!confirmQueueNavigation()) {
        event.preventDefault()
        event.stopPropagation()
      }
    }

    document.addEventListener('click', handleLinkNavigation, true)
    return () => {
      document.removeEventListener('click', handleLinkNavigation, true)
    }
  }, [])

  return (
    <DashboardProvider>
      <WorkspaceGate>
        <div className="flex min-h-screen bg-gray-50">
          <Sidebar
            collapsed={sidebarCollapsed}
            onToggle={() => setSidebarCollapsed((prev) => !prev)}
          />
          <main className="flex-1 overflow-y-auto">
            {children}
          </main>
        </div>
        <PWAInstallPrompt />
      </WorkspaceGate>
    </DashboardProvider>
  )
}
===== END FILE =====

===== FILE: frontend-next/src/app/(dashboard)/page.tsx =====
'use client'

import Link from 'next/link'
import { useRouter } from 'next/navigation'
import { useDashboard } from '@/context/DashboardContext'
import { routes } from '@/utils/routes'
import { guardedPush } from '@/utils/navigationGuard'

export default function DashboardHome() {
  const router = useRouter()
  const { cases, recentTranscripts, setActiveMediaKey } = useDashboard()

  return (
    <div className="p-8 max-w-5xl mx-auto">
      {/* Quick Start Hero */}
      <div className="bg-gradient-to-br from-primary-600 to-primary-700 rounded-2xl p-10 mb-8 text-white">
        <h1 className="text-3xl font-semibold mb-3">Welcome to TranscribeAlpha</h1>
        <p className="text-primary-100 mb-8 text-lg">
          Generate professional legal transcripts from audio and video files
        </p>
        <Link
          href={routes.transcribe()}
          className="inline-flex items-center gap-3 bg-white text-primary-700 px-8 py-4 rounded-xl font-semibold text-lg hover:bg-primary-50 transition-colors shadow-lg"
        >
          <svg className="w-6 h-6" fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24">
            <path d="M12 4v16m8-8H4" />
          </svg>
          New Transcript
        </Link>
      </div>

      <div className="grid grid-cols-1 lg:grid-cols-2 gap-8">
        {/* Recent Transcripts */}
        <div className="bg-white rounded-xl shadow-sm border border-gray-100">
          <div className="p-5 border-b border-gray-100">
            <h2 className="text-lg font-semibold text-gray-900">Recent Transcripts</h2>
          </div>
          <div className="divide-y divide-gray-100">
            {recentTranscripts.length === 0 ? (
              <div className="p-8 text-center">
                <div className="w-14 h-14 bg-gray-100 rounded-full flex items-center justify-center mx-auto mb-4">
                  <svg className="w-7 h-7 text-gray-400" fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24">
                    <path d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z" />
                  </svg>
                </div>
                <p className="text-gray-500 mb-4">No transcripts yet</p>
                <Link href={routes.transcribe()} className="text-primary-600 hover:text-primary-700 font-medium text-sm">
                  Create your first transcript →
                </Link>
              </div>
            ) : (
              recentTranscripts.map((transcript) => (
                <button
                  key={transcript.media_key}
                  onClick={() => {
                    setActiveMediaKey(transcript.media_key)
                    guardedPush(router, routes.editor(transcript.media_key))
                  }}
                  className="w-full p-4 text-left hover:bg-gray-50 transition-colors flex items-center gap-4"
                >
                  <div className="w-10 h-10 bg-primary-100 rounded-lg flex items-center justify-center flex-shrink-0">
                    <svg className="w-5 h-5 text-primary-600" fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24">
                      <path d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z" />
                    </svg>
                  </div>
                  <div className="flex-1 min-w-0">
                    <p className="font-medium text-gray-900 truncate">{transcript.title_label}</p>
                    <p className="text-sm text-gray-500">
                      {transcript.line_count ? `${transcript.line_count} lines` : 'Processing...'}
                    </p>
                  </div>
                  <svg className="w-5 h-5 text-gray-400" fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24">
                    <path d="M9 5l7 7-7 7" />
                  </svg>
                </button>
              ))
            )}
          </div>
          {recentTranscripts.length > 0 && (
            <div className="p-4 border-t border-gray-100">
              <Link href={routes.cases()} className="text-sm text-primary-600 hover:text-primary-700 font-medium">
                View all transcripts →
              </Link>
            </div>
          )}
        </div>

        {/* Cases */}
        <div className="bg-white rounded-xl shadow-sm border border-gray-100">
          <div className="p-5 border-b border-gray-100 flex items-center justify-between">
            <h2 className="text-lg font-semibold text-gray-900">Your Cases</h2>
            <Link
              href={routes.cases()}
              className="text-sm text-primary-600 hover:text-primary-700 font-medium"
            >
              Manage
            </Link>
          </div>
          <div className="divide-y divide-gray-100">
            {cases.length === 0 ? (
              <div className="p-8 text-center">
                <div className="w-14 h-14 bg-gray-100 rounded-full flex items-center justify-center mx-auto mb-4">
                  <svg className="w-7 h-7 text-gray-400" fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24">
                    <path d="M3 7v10a2 2 0 002 2h14a2 2 0 002-2V9a2 2 0 00-2-2h-6l-2-2H5a2 2 0 00-2 2z" />
                  </svg>
                </div>
                <p className="text-gray-500 mb-4">No cases yet</p>
                <Link href={routes.cases()} className="text-primary-600 hover:text-primary-700 font-medium text-sm">
                  Create a case to organize transcripts →
                </Link>
              </div>
            ) : (
              cases.slice(0, 5).map((caseItem) => (
                <Link
                  key={caseItem.case_id}
                  href={routes.caseDetail(caseItem.case_id)}
                  className="p-4 hover:bg-gray-50 transition-colors flex items-center gap-4"
                >
                  <div className="w-10 h-10 bg-primary-100 rounded-lg flex items-center justify-center flex-shrink-0">
                    <span className="text-sm font-semibold text-primary-700">{caseItem.transcript_count}</span>
                  </div>
                  <div className="flex-1 min-w-0">
                    <p className="font-medium text-gray-900 truncate">{caseItem.name}</p>
                    <p className="text-sm text-gray-500">
                      {caseItem.transcript_count} transcript{caseItem.transcript_count !== 1 ? 's' : ''}
                    </p>
                  </div>
                  <svg className="w-5 h-5 text-gray-400" fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24">
                    <path d="M9 5l7 7-7 7" />
                  </svg>
                </Link>
              ))
            )}
          </div>
        </div>
      </div>

      {/* Quick Actions */}
      <div className="mt-8 grid grid-cols-1 md:grid-cols-3 gap-4">
        <Link
          href={routes.transcribe()}
          className="bg-white rounded-xl p-5 border border-gray-100 hover:border-primary-200 hover:shadow-md transition-all flex items-center gap-4"
        >
          <div className="w-12 h-12 bg-primary-100 rounded-xl flex items-center justify-center">
            <svg className="w-6 h-6 text-primary-600" fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24">
              <path d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z" />
            </svg>
          </div>
          <div>
            <p className="font-semibold text-gray-900">Transcribe</p>
            <p className="text-sm text-gray-500">Upload audio/video</p>
          </div>
        </Link>

        <Link
          href={routes.editor()}
          className="bg-white rounded-xl p-5 border border-gray-100 hover:border-primary-200 hover:shadow-md transition-all flex items-center gap-4"
        >
          <div className="w-12 h-12 bg-green-100 rounded-xl flex items-center justify-center">
            <svg className="w-6 h-6 text-green-600" fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24">
              <path d="M11 5H6a2 2 0 00-2 2v11a2 2 0 002 2h11a2 2 0 002-2v-5m-1.414-9.414a2 2 0 112.828 2.828L11.828 15H9v-2.828l8.586-8.586z" />
            </svg>
          </div>
          <div>
            <p className="font-semibold text-gray-900">Editor</p>
            <p className="text-sm text-gray-500">Edit & sync timing</p>
          </div>
        </Link>

        <Link
          href={routes.viewer()}
          className="bg-white rounded-xl p-5 border border-gray-100 hover:border-primary-200 hover:shadow-md transition-all flex items-center gap-4"
        >
          <div className="w-12 h-12 bg-purple-100 rounded-xl flex items-center justify-center">
            <svg className="w-6 h-6 text-purple-600" fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24">
              <path d="M2 12s3.5-6 10-6 10 6 10 6-3.5 6-10 6-10-6-10-6z" />
              <circle cx="12" cy="12" r="3" />
            </svg>
          </div>
          <div>
            <p className="font-semibold text-gray-900">Viewer</p>
            <p className="text-sm text-gray-500">Play, present, and clip</p>
          </div>
        </Link>
      </div>
    </div>
  )
}
===== END FILE =====

===== FILE: frontend-next/src/app/(dashboard)/settings/page.tsx =====
'use client'

import { useCallback, useEffect, useState } from 'react'
import { useDashboard } from '@/context/DashboardContext'
import { getWorkspaceName, getStorageEstimate, clearWorkspace, pickAndInitWorkspace } from '@/lib/storage'

function formatBytes(bytes: number): string {
  if (bytes === 0) return '0 B'
  const k = 1024
  const sizes = ['B', 'KB', 'MB', 'GB']
  const i = Math.floor(Math.log(bytes) / Math.log(k))
  return `${parseFloat((bytes / Math.pow(k, i)).toFixed(1))} ${sizes[i]}`
}

export default function SettingsPage() {
  const { appVariant } = useDashboard()
  const isCriminal = appVariant === 'criminal'

  const [workspaceName, setWorkspaceName] = useState<string | null>(null)
  const [storageEstimate, setStorageEstimate] = useState<{ fileCount: number; totalSize: number } | null>(null)
  const [changingWorkspace, setChangingWorkspace] = useState(false)

  const loadWorkspaceInfo = useCallback(async () => {
    if (!isCriminal) return
    const name = getWorkspaceName()
    setWorkspaceName(name)
    try {
      const estimate = await getStorageEstimate()
      setStorageEstimate(estimate)
    } catch {
      // Workspace may not be accessible
    }
  }, [isCriminal])

  useEffect(() => {
    loadWorkspaceInfo()
  }, [loadWorkspaceInfo])

  const handleChangeWorkspace = async () => {
    setChangingWorkspace(true)
    try {
      await clearWorkspace()
      await pickAndInitWorkspace() // returns { handle, isExisting } but we don't need it here
      await loadWorkspaceInfo()
    } catch {
      // User cancelled picker
    } finally {
      setChangingWorkspace(false)
    }
  }

  return (
    <div className="p-8 max-w-4xl mx-auto">
      {/* Header */}
      <div className="mb-8">
        <h1 className="text-2xl font-semibold text-gray-900">Settings</h1>
        <p className="text-gray-500 mt-1">Configure your TranscribeAlpha preferences</p>
      </div>

      <div className="space-y-6">
        {/* App Info */}
        <div className="bg-white rounded-xl shadow-sm border border-gray-100 p-6">
          <h2 className="text-lg font-semibold text-gray-900 mb-4">Application</h2>
          <div className="space-y-4">
            <div className="flex items-center justify-between py-3 border-b border-gray-100">
              <div>
                <p className="font-medium text-gray-900">App Variant</p>
                <p className="text-sm text-gray-500">Current application mode</p>
              </div>
              <span className="px-3 py-1 bg-primary-100 text-primary-700 rounded-full text-sm font-medium capitalize">
                {appVariant}
              </span>
            </div>
            <div className="flex items-center justify-between py-3 border-b border-gray-100">
              <div>
                <p className="font-medium text-gray-900">Version</p>
                <p className="text-sm text-gray-500">TranscribeAlpha version</p>
              </div>
              <span className="text-gray-600">2.0.0</span>
            </div>
          </div>
        </div>

        {/* Storage Info */}
        <div className="bg-white rounded-xl shadow-sm border border-gray-100 p-6">
          <h2 className="text-lg font-semibold text-gray-900 mb-4">Storage</h2>
          <div className="space-y-4">
            {isCriminal ? (
              <>
                <div className="flex items-center justify-between py-3 border-b border-gray-100">
                  <div>
                    <p className="font-medium text-gray-900">Workspace Folder</p>
                    <p className="text-sm text-gray-500">
                      {workspaceName || 'Not configured'}
                    </p>
                  </div>
                  <button
                    onClick={handleChangeWorkspace}
                    disabled={changingWorkspace}
                    className="px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-700 font-medium text-sm rounded-lg transition-colors disabled:opacity-50"
                  >
                    {changingWorkspace ? 'Changing...' : 'Change Workspace'}
                  </button>
                </div>
                <div className="py-3 border-b border-gray-100">
                  <p className="font-medium text-gray-900 mb-1">Storage Usage</p>
                  {storageEstimate ? (
                    <p className="text-sm text-gray-500">
                      {storageEstimate.fileCount} files &middot; {formatBytes(storageEstimate.totalSize)}
                    </p>
                  ) : (
                    <p className="text-sm text-gray-500">Calculating...</p>
                  )}
                </div>
                <div className="py-3">
                  <p className="font-medium text-gray-900 mb-1">Data Storage</p>
                  <p className="text-sm text-gray-500">
                    All transcripts and case data are stored locally in your workspace folder. Media files remain on your computer and are referenced by file location.
                  </p>
                </div>
              </>
            ) : (
              <>
                <div className="py-3 border-b border-gray-100">
                  <p className="font-medium text-gray-900 mb-1">Transcript Storage</p>
                  <p className="text-sm text-gray-500">
                    Transcripts assigned to cases are stored permanently. Uncategorized transcripts expire after 30 days.
                  </p>
                </div>
                <div className="py-3">
                  <p className="font-medium text-gray-900 mb-1">Media Files</p>
                  <p className="text-sm text-gray-500">
                    Media files are stored temporarily and may expire. You can re-import media files at any time to restore playback.
                  </p>
                </div>
              </>
            )}
          </div>
        </div>

        {/* Export Options */}
        <div className="bg-white rounded-xl shadow-sm border border-gray-100 p-6">
          <h2 className="text-lg font-semibold text-gray-900 mb-4">Export Formats</h2>
          <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
            <div className="p-4 bg-gray-50 rounded-lg">
              <div className="flex items-center gap-3 mb-2">
                <div className="w-10 h-10 bg-blue-100 rounded-lg flex items-center justify-center">
                  <span className="text-blue-600 font-bold text-sm">PDF</span>
                </div>
                <p className="font-medium text-gray-900">Transcript PDF</p>
              </div>
              <p className="text-sm text-gray-500">
                Canonical transcript layout for printing and page/line references
              </p>
            </div>
            {appVariant === 'oncue' ? (
              <div className="p-4 bg-gray-50 rounded-lg">
                <div className="flex items-center gap-3 mb-2">
                  <div className="w-10 h-10 bg-green-100 rounded-lg flex items-center justify-center">
                    <span className="text-green-600 font-bold text-sm">XML</span>
                  </div>
                  <p className="font-medium text-gray-900">OnCue XML</p>
                </div>
                <p className="text-sm text-gray-500">
                  Compatible with OnCue trial presentation software
                </p>
              </div>
            ) : (
              <div className="p-4 bg-gray-50 rounded-lg">
                <div className="flex items-center gap-3 mb-2">
                  <div className="w-10 h-10 bg-purple-100 rounded-lg flex items-center justify-center">
                    <span className="text-purple-600 font-bold text-sm">HTML</span>
                  </div>
                  <p className="font-medium text-gray-900">HTML Viewer</p>
                </div>
                <p className="text-sm text-gray-500">
                  Interactive web-based transcript viewer
                </p>
              </div>
            )}
          </div>
        </div>

        {/* Keyboard Shortcuts */}
        <div className="bg-white rounded-xl shadow-sm border border-gray-100 p-6">
          <h2 className="text-lg font-semibold text-gray-900 mb-4">Editor Keyboard Shortcuts</h2>
          <div className="grid grid-cols-1 md:grid-cols-2 gap-x-8 gap-y-3">
            <div className="flex items-center justify-between py-2">
              <span className="text-gray-600">Save transcript</span>
              <kbd className="px-2 py-1 bg-gray-100 rounded text-sm font-mono text-gray-700">Ctrl/Cmd+S</kbd>
            </div>
            <div className="flex items-center justify-between py-2">
              <span className="text-gray-600">Play/pause media (outside text fields)</span>
              <kbd className="px-2 py-1 bg-gray-100 rounded text-sm font-mono text-gray-700">Space</kbd>
            </div>
            <div className="flex items-center justify-between py-2">
              <span className="text-gray-600">Skip backward 5s</span>
              <kbd className="px-2 py-1 bg-gray-100 rounded text-sm font-mono text-gray-700">Left</kbd>
            </div>
            <div className="flex items-center justify-between py-2">
              <span className="text-gray-600">Skip forward 5s</span>
              <kbd className="px-2 py-1 bg-gray-100 rounded text-sm font-mono text-gray-700">Right</kbd>
            </div>
          </div>
        </div>
      </div>
    </div>
  )
}
===== END FILE =====

===== FILE: frontend-next/src/app/(dashboard)/transcribe/page.tsx =====
'use client'

import JSZip from 'jszip'
import Link from 'next/link'
import { useCallback, useEffect, useMemo, useRef, useState } from 'react'
import { useRouter, useSearchParams } from 'next/navigation'
import { authenticatedFetch, getAuthHeaders } from '@/utils/auth'
import { useDashboard } from '@/context/DashboardContext'
import { routes } from '@/utils/routes'
import {
  confirmQueueNavigation,
  guardedPush,
  setQueueNavigationGuardActive,
} from '@/utils/navigationGuard'
import {
  createCase as localCreateCase,
  saveTranscript as localSaveTranscript,
  type TranscriptData,
} from '@/lib/storage'
import { storeMediaBlob, storeMediaHandle } from '@/lib/mediaHandles'
import {
  cancelActiveFFmpegJob,
  FFmpegCanceledError,
  extractAudio,
} from '@/lib/ffmpegWorker'

interface FormData {
  case_name: string
  case_number: string
  firm_name: string
  input_date: string
  location: string
  transcription_model: 'assemblyai' | 'gemini'
  case_id: string
}

type WizardStep = 'upload' | 'configure' | 'transcribe'
type QueueItemStatus = 'queued' | 'uploading' | 'transcribing' | 'building' | 'done' | 'failed' | 'canceled'

interface TranscriptResponse {
  media_key: string
  lines?: Array<unknown>
  pdf_base64?: string
  docx_base64?: string
  oncue_xml_base64?: string
  viewer_html_base64?: string
  title_data?: Record<string, string>
}

interface QueueItem {
  id: string
  file: File
  originalFileName: string
  fileHandle?: FileSystemFileHandle | null
  status: QueueItemStatus
  stageText: string
  error: string
  result: TranscriptResponse | null
  attemptCount: number
  speaker_names: string
  speakers_expected: string
  case_target: string
}

interface RequestFailure {
  message: string
  retryable: boolean
}

const wizardSteps: Array<{ key: WizardStep; label: string }> = [
  { key: 'upload', label: 'Upload' },
  { key: 'configure', label: 'Configure' },
  { key: 'transcribe', label: 'Results' },
]

const MAX_BATCH_FILES = 50
const RESULTS_PREVIEW_LIMIT = 10
const CRIMINAL_AUDIO_EXTRACTION_TIMEOUT_MS = 7 * 60 * 1000
const CRIMINAL_DIRECT_UPLOAD_FALLBACK_MAX_BYTES = 512 * 1024 * 1024
const CRIMINAL_TRANSCRIBE_REQUEST_TIMEOUT_MS = 16 * 60 * 1000
const CASE_USE_BATCH = '__batch__'
const CASE_UNCATEGORIZED = '__uncategorized__'
const VIDEO_EXTENSIONS = new Set(['mp4', 'mov', 'avi', 'mkv', 'm4v', 'webm'])
const COMPRESSED_AUDIO_EXTENSIONS = new Set(['mp3', 'm4a', 'aac', 'ogg', 'opus', 'wma'])

const buildQueueId = () => `${Date.now()}_${Math.random().toString(16).slice(2)}`

const sanitizeFilenamePart = (value: string) => {
  const sanitized = value
    .replace(/[^a-zA-Z0-9\s-]/g, '')
    .trim()
    .replace(/\s+/g, '-')
    .replace(/-+/g, '-')
    .replace(/^-|-$/g, '')
  return sanitized || 'transcript'
}

const sanitizeDownloadStem = (value: string) => {
  const sanitized = value
    .replace(/[\\/:*?"<>|]/g, ' ')
    .replace(/\s+/g, ' ')
    .trim()
  return sanitized || 'transcript'
}

const stripExtension = (filename: string) => filename.replace(/\.[^.]+$/, '')

const buildFileSignature = (file: File) => `${file.name}::${file.size}::${file.lastModified}`
const getFileExtension = (filename: string) => {
  const dot = filename.lastIndexOf('.')
  if (dot === -1) return ''
  return filename.slice(dot + 1).toLowerCase()
}
const isLikelyVideoSource = (file: File) => {
  if ((file.type || '').startsWith('video/')) return true
  return VIDEO_EXTENSIONS.has(getFileExtension(file.name))
}
const isLikelyCompressedAudioSource = (file: File) => {
  if ((file.type || '').startsWith('audio/')) {
    const extension = getFileExtension(file.name)
    if (!extension) return false
    return COMPRESSED_AUDIO_EXTENSIONS.has(extension)
  }
  return COMPRESSED_AUDIO_EXTENSIONS.has(getFileExtension(file.name))
}

const statusLabel = (status: QueueItemStatus) => {
  if (status === 'queued') return 'Queued'
  if (status === 'uploading') return 'Uploading'
  if (status === 'transcribing') return 'Transcribing'
  if (status === 'building') return 'Building'
  if (status === 'done') return 'Complete'
  if (status === 'failed') return 'Failed'
  return 'Canceled'
}

const statusBadgeClass = (status: QueueItemStatus) => {
  if (status === 'done') return 'bg-green-100 text-green-700'
  if (status === 'failed') return 'bg-red-100 text-red-700'
  if (status === 'canceled') return 'bg-amber-100 text-amber-800'
  if (status === 'queued') return 'bg-gray-100 text-gray-600'
  return 'bg-primary-100 text-primary-700'
}

const isRetryableStatus = (status: number) => status === 429 || (status >= 500 && status <= 599)

export default function TranscribePage() {
  const router = useRouter()
  const searchParams = useSearchParams()
  const { cases, refreshCases, refreshRecentTranscripts, setActiveMediaKey, appVariant } = useDashboard()

  const [step, setStep] = useState<WizardStep>('upload')
  const [formData, setFormData] = useState<FormData>({
    case_name: '',
    case_number: '',
    firm_name: '',
    input_date: '',
    location: '',
    transcription_model: 'assemblyai',
    case_id: '',
  })

  const [queue, setQueue] = useState<QueueItem[]>([])
  const [isProcessing, setIsProcessing] = useState(false)
  const [stopAfterCurrent, setStopAfterCurrent] = useState(false)
  const [pageError, setPageError] = useState('')
  const [pageNotice, setPageNotice] = useState('')
  const [showAllResults, setShowAllResults] = useState(false)
  const [zipBusy, setZipBusy] = useState<'pdf' | 'variant' | null>(null)

  const [showNewCaseModal, setShowNewCaseModal] = useState(false)
  const [newCaseName, setNewCaseName] = useState('')
  const [newCaseDescription, setNewCaseDescription] = useState('')
  const [creatingCase, setCreatingCase] = useState(false)

  const [draggingId, setDraggingId] = useState<string | null>(null)
  const [dragOverId, setDragOverId] = useState<string | null>(null)

  const fileInputRef = useRef<HTMLInputElement>(null)
  const queueRef = useRef<QueueItem[]>([])
  const stopAfterCurrentRef = useRef(false)
  const skipNextPopstateRef = useRef(false)
  const preparedAudioByItemRef = useRef<Map<string, File>>(new Map())

  useEffect(() => {
    queueRef.current = queue
  }, [queue])

  useEffect(() => {
    stopAfterCurrentRef.current = stopAfterCurrent
  }, [stopAfterCurrent])

  useEffect(() => {
    const caseIdParam = searchParams.get('case_id')
    if (caseIdParam) {
      setFormData((prev) => ({ ...prev, case_id: caseIdParam }))
    }
  }, [searchParams])

  useEffect(() => {
    if (!isProcessing) return
    const handler = (event: BeforeUnloadEvent) => {
      event.preventDefault()
      event.returnValue = ''
    }
    window.addEventListener('beforeunload', handler)
    return () => window.removeEventListener('beforeunload', handler)
  }, [isProcessing])

  useEffect(() => {
    if (!isProcessing) return

    const handlePopstate = () => {
      if (skipNextPopstateRef.current) {
        skipNextPopstateRef.current = false
        return
      }

      if (confirmQueueNavigation()) {
        return
      }

      skipNextPopstateRef.current = true
      window.history.go(1)
    }

    window.addEventListener('popstate', handlePopstate)
    return () => {
      window.removeEventListener('popstate', handlePopstate)
      skipNextPopstateRef.current = false
    }
  }, [isProcessing])

  useEffect(() => {
    setQueueNavigationGuardActive(isProcessing)
    return () => {
      setQueueNavigationGuardActive(false)
    }
  }, [isProcessing])

  const caseNameById = useMemo(() => {
    const map = new Map<string, string>()
    for (const c of cases) {
      map.set(c.case_id, c.name)
    }
    return map
  }, [cases])

  const queuedCount = useMemo(() => queue.filter((item) => item.status === 'queued').length, [queue])
  const doneCount = useMemo(() => queue.filter((item) => item.status === 'done').length, [queue])
  const failedCount = useMemo(() => queue.filter((item) => item.status === 'failed').length, [queue])
  const canceledCount = useMemo(() => queue.filter((item) => item.status === 'canceled').length, [queue])
  const inProgressCount = useMemo(
    () => queue.filter((item) => item.status === 'uploading' || item.status === 'transcribing' || item.status === 'building').length,
    [queue],
  )

  const processedItems = useMemo(
    () => queue.filter((item) => item.status === 'done' || item.status === 'failed' || item.status === 'canceled'),
    [queue],
  )

  const visibleProcessedItems = useMemo(() => {
    if (showAllResults) return processedItems
    return processedItems.slice(0, RESULTS_PREVIEW_LIMIT)
  }, [processedItems, showAllResults])

  const updateQueueItem = useCallback((itemId: string, updater: Partial<QueueItem> | ((current: QueueItem) => QueueItem)) => {
    setQueue((prev) =>
      prev.map((item) => {
        if (item.id !== itemId) return item
        if (typeof updater === 'function') {
          return updater(item)
        }
        return { ...item, ...updater }
      }),
    )
  }, [])

  const reorderQueue = useCallback((sourceId: string, targetId: string) => {
    if (sourceId === targetId) return
    setQueue((prev) => {
      const sourceIndex = prev.findIndex((item) => item.id === sourceId)
      const targetIndex = prev.findIndex((item) => item.id === targetId)
      if (sourceIndex === -1 || targetIndex === -1) return prev
      const next = [...prev]
      const [moved] = next.splice(sourceIndex, 1)
      next.splice(targetIndex, 0, moved)
      return next
    })
  }, [])

  const createQueueItem = useCallback((file: File, fileHandle?: FileSystemFileHandle | null): QueueItem => {
    return {
      id: buildQueueId(),
      file,
      originalFileName: file.name,
      fileHandle: fileHandle ?? null,
      status: 'queued',
      stageText: 'Queued',
      error: '',
      result: null,
      attemptCount: 0,
      speaker_names: '',
      speakers_expected: '',
      case_target: CASE_USE_BATCH,
    }
  }, [])

  const addFilesToQueue = useCallback(
    (incoming: File[]) => {
      if (!incoming.length) return

      setPageError('')
      setPageNotice('')
      setShowAllResults(false)

      const current = queueRef.current
      const currentHasProcessed = current.some((item) => item.status !== 'queued')
      const currentHasQueued = current.some((item) => item.status === 'queued')
      const baseQueue = currentHasProcessed && !currentHasQueued ? [] : current
      if (baseQueue.length === 0) {
        preparedAudioByItemRef.current.clear()
      }

      const existingSignatures = new Set(baseQueue.map((item) => buildFileSignature(item.file)))
      let duplicateCount = 0
      const dedupedIncoming: File[] = []

      for (const file of incoming) {
        const signature = buildFileSignature(file)
        if (existingSignatures.has(signature)) {
          duplicateCount += 1
        }
        dedupedIncoming.push(file)
        existingSignatures.add(signature)
      }

      const remainingSlots = Math.max(MAX_BATCH_FILES - baseQueue.length, 0)
      if (remainingSlots <= 0) {
        setPageError(`Batch limit reached. Maximum ${MAX_BATCH_FILES} files per run.`)
        return
      }

      const accepted = dedupedIncoming.slice(0, remainingSlots)
      const dropped = dedupedIncoming.length - accepted.length

      const nextItems = accepted.map((file) => createQueueItem(file))
      setQueue([...baseQueue, ...nextItems])

      if (duplicateCount > 0) {
        setPageNotice(`${duplicateCount} duplicate file(s) were added. Duplicates are allowed and will be processed.`)
      }
      if (dropped > 0) {
        setPageError(`Added ${accepted.length} file(s). ${dropped} file(s) were not added because of the ${MAX_BATCH_FILES}-file limit.`)
      }
    },
    [createQueueItem],
  )

  const handleFileInputChange = (event: React.ChangeEvent<HTMLInputElement>) => {
    const files = event.target.files
    if (!files || files.length === 0) return
    addFilesToQueue(Array.from(files))
    event.target.value = ''
  }

  const handleDrop = useCallback(
    (event: React.DragEvent) => {
      event.preventDefault()
      const files = event.dataTransfer.files
      if (!files || files.length === 0) return
      addFilesToQueue(Array.from(files))
    },
    [addFilesToQueue],
  )

  const handleDragOver = useCallback((event: React.DragEvent) => {
    event.preventDefault()
  }, [])

  const handleOpenFilePicker = useCallback(async () => {
    if (appVariant !== 'criminal') return
    try {
      const handles: FileSystemFileHandle[] = await (window as any).showOpenFilePicker({
        multiple: true,
        types: [
          {
            description: 'Audio/Video files',
            accept: {
              'audio/*': ['.wav', '.mp3', '.m4a', '.flac', '.ogg', '.aac', '.wma'],
              'video/*': ['.mp4', '.mov', '.avi', '.mkv'],
            },
          },
        ],
      })
      if (!handles.length) return

      setPageError('')
      setPageNotice('')
      setShowAllResults(false)

      const current = queueRef.current
      const currentHasProcessed = current.some((item) => item.status !== 'queued')
      const currentHasQueued = current.some((item) => item.status === 'queued')
      const baseQueue = currentHasProcessed && !currentHasQueued ? [] : current
      if (baseQueue.length === 0) {
        preparedAudioByItemRef.current.clear()
      }

      const remainingSlots = Math.max(MAX_BATCH_FILES - baseQueue.length, 0)
      if (remainingSlots <= 0) {
        setPageError(`Batch limit reached. Maximum ${MAX_BATCH_FILES} files per run.`)
        return
      }

      const accepted = handles.slice(0, remainingSlots)
      const dropped = handles.length - accepted.length

      const nextItems: QueueItem[] = []
      for (const handle of accepted) {
        const file = await handle.getFile()
        nextItems.push(createQueueItem(file, handle))
      }
      setQueue([...baseQueue, ...nextItems])

      if (dropped > 0) {
        setPageError(`Added ${accepted.length} file(s). ${dropped} file(s) were not added because of the ${MAX_BATCH_FILES}-file limit.`)
      }
    } catch {
      // User cancelled the file picker
    }
  }, [appVariant, createQueueItem])

  const handleCreateCase = async () => {
    if (!newCaseName.trim()) return
    setCreatingCase(true)
    setPageError('')

    try {
      if (appVariant === 'criminal') {
        const newCaseId = crypto.randomUUID()
        const now = new Date().toISOString()
        await localCreateCase({
          case_id: newCaseId,
          name: newCaseName.trim(),
          description: newCaseDescription.trim(),
          created_at: now,
          updated_at: now,
        })
        await refreshCases()
        setFormData((prev) => ({ ...prev, case_id: newCaseId }))
      } else {
        const response = await authenticatedFetch('/api/cases', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ name: newCaseName.trim(), description: newCaseDescription.trim() }),
        })
        if (!response.ok) throw new Error('Failed to create case')
        const data = await response.json()
        await refreshCases()
        setFormData((prev) => ({ ...prev, case_id: data.case.case_id }))
      }
      setShowNewCaseModal(false)
      setNewCaseName('')
      setNewCaseDescription('')
    } catch {
      setPageError('Failed to create case')
    } finally {
      setCreatingCase(false)
    }
  }

  const getEffectiveCaseId = useCallback(
    (item: QueueItem) => {
      if (item.case_target === CASE_USE_BATCH) {
        return formData.case_id
      }
      if (item.case_target === CASE_UNCATEGORIZED) {
        return ''
      }
      return item.case_target
    },
    [formData.case_id],
  )

  const buildRequestFormData = useCallback(
    (item: QueueItem) => {
      const submitFormData = new FormData()
      submitFormData.append('file', item.file)
      submitFormData.append('transcription_model', formData.transcription_model)
      if (appVariant === 'criminal' && item.originalFileName) {
        submitFormData.append('source_filename', item.originalFileName)
      }

      if (formData.case_name.trim()) submitFormData.append('case_name', formData.case_name.trim())
      if (formData.case_number.trim()) submitFormData.append('case_number', formData.case_number.trim())
      if (formData.firm_name.trim()) submitFormData.append('firm_name', formData.firm_name.trim())
      if (formData.input_date) submitFormData.append('input_date', formData.input_date)
      if (formData.location.trim()) submitFormData.append('location', formData.location.trim())

      const effectiveCaseId = getEffectiveCaseId(item)
      // Criminal variant: don't send case_id to backend (backend doesn't persist)
      if (effectiveCaseId && appVariant !== 'criminal') {
        submitFormData.append('case_id', effectiveCaseId)
      }

      if (item.speaker_names.trim()) {
        submitFormData.append('speaker_names', item.speaker_names.trim())
      }

      const expectedSpeakers = Number(item.speakers_expected)
      if (Number.isInteger(expectedSpeakers) && expectedSpeakers > 0) {
        submitFormData.append('speakers_expected', String(expectedSpeakers))
      }

      return submitFormData
    },
    [appVariant, formData, getEffectiveCaseId],
  )

  const transcribeOneItem = useCallback(
    async (item: QueueItem): Promise<TranscriptResponse> => {
      const submitFormData = buildRequestFormData(item)

      return new Promise<TranscriptResponse>((resolve, reject) => {
        const request = new XMLHttpRequest()
        request.open('POST', '/api/transcribe', true)
        request.responseType = 'json'
        request.timeout = CRIMINAL_TRANSCRIBE_REQUEST_TIMEOUT_MS

        const authHeaders = getAuthHeaders()
        Object.entries(authHeaders).forEach(([key, value]) => {
          request.setRequestHeader(key, String(value))
        })

        const isVideoFile =
          (item.file.type || '').startsWith('video/') || /\.(mp4|mov|avi|mkv)$/i.test(item.file.name)

        let stageTimer: number | null = null
        const clearStageTimer = () => {
          if (stageTimer) {
            window.clearTimeout(stageTimer)
            stageTimer = null
          }
        }

        updateQueueItem(item.id, {
          status: 'uploading',
          stageText: 'Uploading media...',
          error: '',
        })

        request.upload.onprogress = () => {
          updateQueueItem(item.id, {
            status: 'uploading',
            stageText: 'Uploading media...',
          })
        }

        request.upload.onload = () => {
          clearStageTimer()
          if (isVideoFile) {
            updateQueueItem(item.id, {
              status: 'transcribing',
              stageText: 'Converting to audio...',
            })
            stageTimer = window.setTimeout(() => {
              updateQueueItem(item.id, {
                status: 'transcribing',
                stageText: 'Transcribing (this may take a few minutes)...',
              })
              stageTimer = null
            }, 1200)
          } else {
            updateQueueItem(item.id, {
              status: 'transcribing',
              stageText: 'Transcribing (this may take a few minutes)...',
            })
          }
        }

        request.onload = () => {
          clearStageTimer()
          const responseData =
            request.response
            ?? (() => {
              try {
                return JSON.parse(request.responseText)
              } catch {
                return null
              }
            })()

          if (request.status >= 200 && request.status < 300) {
            updateQueueItem(item.id, {
              status: 'building',
              stageText: 'Producing transcript...',
            })
            resolve(responseData as TranscriptResponse)
            return
          }

          let detail = responseData?.detail || 'Transcription failed'
          if (request.status === 408) {
            detail = 'Request timed out while uploading or processing media. This usually means the source file is too large for direct upload.'
          }
          const failure: RequestFailure = {
            message: detail,
            retryable: isRetryableStatus(request.status),
          }
          reject(failure)
        }

        request.onerror = () => {
          clearStageTimer()
          reject({
            message: 'Upload failed. Please try again.',
            retryable: true,
          } satisfies RequestFailure)
        }

        request.ontimeout = () => {
          clearStageTimer()
          reject({
            message:
              'Transcription request timed out. For large media, convert to MP3 first (Converter page or desktop FFmpeg) and retry.',
            retryable: false,
          } satisfies RequestFailure)
        }

        request.send(submitFormData)
      })
    },
    [buildRequestFormData, updateQueueItem],
  )

  const prepareUploadFile = useCallback(
    async (item: QueueItem): Promise<File> => {
      if (appVariant !== 'criminal') return item.file

      if (!isLikelyVideoSource(item.file) && isLikelyCompressedAudioSource(item.file)) {
        updateQueueItem(item.id, {
          status: 'transcribing',
          stageText: 'Using source audio upload...',
          error: '',
        })
        return item.file
      }

      const cachedAudio = preparedAudioByItemRef.current.get(item.id)
      if (cachedAudio) {
        updateQueueItem(item.id, {
          status: 'transcribing',
          stageText: 'Using prepared audio upload...',
          error: '',
        })
        return cachedAudio
      }

      updateQueueItem(item.id, {
        status: 'transcribing',
        stageText: 'Extracting compressed mono audio for upload...',
        error: '',
      })

      let extractionTimedOut = false
      try {
        let timeoutId: number | null = null
        try {
          const extractionPromise = extractAudio(item.file, (ratio) => {
            updateQueueItem(item.id, {
              status: 'transcribing',
              stageText: `Extracting compressed mono audio for upload... ${Math.round(ratio * 100)}%`,
            })
          })
          const timeoutPromise = new Promise<never>((_, reject) => {
            timeoutId = window.setTimeout(() => {
              extractionTimedOut = true
              cancelActiveFFmpegJob()
              reject(new Error('Audio extraction timed out in browser'))
            }, CRIMINAL_AUDIO_EXTRACTION_TIMEOUT_MS)
          })
          const extractedAudio = await Promise.race([extractionPromise, timeoutPromise])
          preparedAudioByItemRef.current.set(item.id, extractedAudio)
          updateQueueItem(item.id, {
            status: 'transcribing',
            stageText: 'Audio extraction complete. Preparing upload...',
          })
          return extractedAudio
        } finally {
          if (timeoutId) {
            window.clearTimeout(timeoutId)
          }
        }
      } catch (error) {
        if (error instanceof FFmpegCanceledError && !extractionTimedOut) {
          throw {
            message: 'Audio extraction canceled.',
            retryable: false,
          } satisfies RequestFailure
        }

        if (item.file.size > CRIMINAL_DIRECT_UPLOAD_FALLBACK_MAX_BYTES) {
          const sizeMb = (item.file.size / (1024 * 1024)).toFixed(1)
          const reason = extractionTimedOut
            ? 'Audio extraction timed out in browser.'
            : 'Audio extraction failed in browser.'
          throw {
            message:
              `${reason} Skipping direct upload of the ${sizeMb} MB original file because it is likely to exceed server upload timeout. ` +
              'Use the Converter page (or desktop FFmpeg) to create an MP3, then retry.',
            retryable: false,
          } satisfies RequestFailure
        }

        // Fall back to sending original media when in-browser extraction fails.
        // The backend can still convert before transcription.
        updateQueueItem(item.id, {
          status: 'transcribing',
          stageText: 'Audio extraction unavailable. Uploading original media...',
        })
        return item.file
      }
    },
    [appVariant, updateQueueItem],
  )

  const runQueue = useCallback(
    async (targetStatuses: QueueItemStatus[]) => {
      if (isProcessing) return

      setPageError('')
      setPageNotice('')
      setStep('transcribe')
      setIsProcessing(true)
      setStopAfterCurrent(false)
      stopAfterCurrentRef.current = false

      const targetStatusSet = new Set(targetStatuses)
      const snapshot = queueRef.current
      const targetIds = snapshot
        .filter((item) => targetStatusSet.has(item.status))
        .map((item) => item.id)

      if (!targetIds.length) {
        setIsProcessing(false)
        setPageNotice('No files matched that action.')
        return
      }

      const targetIdSet = new Set(targetIds)
      setQueue((prev) =>
        prev.map((item) => {
          if (!targetIdSet.has(item.id)) return item
          return {
            ...item,
            status: 'queued',
            stageText: 'Queued',
            error: '',
          }
        }),
      )

      let needsCaseRefresh = false

      for (const itemId of targetIds) {
        if (stopAfterCurrentRef.current) {
          break
        }

        const currentItem = queueRef.current.find((entry) => entry.id === itemId)
        if (!currentItem) {
          continue
        }

        let succeeded = false

        for (let attempt = 0; attempt < 2; attempt += 1) {
          const freshItem = queueRef.current.find((entry) => entry.id === itemId)
          if (!freshItem) break

          updateQueueItem(itemId, {
            attemptCount: attempt + 1,
            error: '',
            stageText: attempt === 0 ? 'Queued' : 'Retrying once...',
            status: attempt === 0 ? 'queued' : 'uploading',
          })

          try {
            const fileForUpload = await prepareUploadFile(freshItem)
            const uploadItem: QueueItem = fileForUpload === freshItem.file
              ? freshItem
              : { ...freshItem, file: fileForUpload }
            const data = await transcribeOneItem(uploadItem)

            // Criminal variant: save transcript + playable media source to local workspace.
            if (appVariant === 'criminal' && data.media_key) {
              const effectiveCaseId = getEffectiveCaseId(freshItem)
              const titleData = { ...(data.title_data || {}) }
              const shouldPersistBlobFallback = !freshItem.fileHandle
              const mediaFilename = freshItem.originalFileName || freshItem.file.name
              const mediaContentType = freshItem.file.type || 'application/octet-stream'
              if (freshItem.originalFileName) {
                titleData.FILE_NAME = freshItem.originalFileName
              }
              const transcriptToSave = {
                ...(data as unknown as Record<string, unknown>),
                title_data: titleData,
                media_filename: mediaFilename,
                media_content_type: mediaContentType,
                media_handle_id: data.media_key,
              } as TranscriptData
              await localSaveTranscript(
                data.media_key,
                transcriptToSave,
                effectiveCaseId || undefined,
              )

              try {
                // Store file handle when available (picker flow), and persist a blob fallback
                // when there is no handle.
                if (freshItem.fileHandle) {
                  await storeMediaHandle(data.media_key, freshItem.fileHandle)
                }
                if (shouldPersistBlobFallback) {
                  await storeMediaBlob(
                    data.media_key,
                    freshItem.file,
                    mediaFilename,
                    mediaContentType,
                  )
                }
              } catch {
                setPageNotice(
                  'Transcript saved, but media auto-linking was incomplete. You may need to relink the media in Editor/Viewer.',
                )
              }
            }

            updateQueueItem(itemId, {
              status: 'done',
              stageText: 'Complete',
              error: '',
              result: data,
              attemptCount: attempt + 1,
            })
            setActiveMediaKey(data.media_key)
            await refreshRecentTranscripts()

            const effectiveCaseId = getEffectiveCaseId(freshItem)
            if (effectiveCaseId) {
              needsCaseRefresh = true
            }

            succeeded = true
            break
          } catch (err) {
            const failure = err as RequestFailure
            const retryable = failure?.retryable ?? false
            const message = failure?.message || 'Transcription failed'

            if (attempt === 0 && retryable) {
              updateQueueItem(itemId, {
                status: 'uploading',
                stageText: 'Retrying once...',
                error: '',
                attemptCount: attempt + 1,
              })
              continue
            }

            updateQueueItem(itemId, {
              status: 'failed',
              stageText: 'Failed',
              error: message,
              attemptCount: attempt + 1,
            })
          }
        }

        preparedAudioByItemRef.current.delete(itemId)

        if (!succeeded) {
          // Continue with next file.
        }
      }

      if (stopAfterCurrentRef.current) {
        const pendingIds = new Set(targetIds)
        setQueue((prev) =>
          prev.map((item) => {
            if (!pendingIds.has(item.id)) return item
            if (item.status === 'queued') {
              return {
                ...item,
                status: 'canceled',
                stageText: 'Canceled before start',
                error: 'Processing was stopped before this file started.',
              }
            }
            return item
          }),
        )
        setPageNotice('Queue stopped. Current item finished; remaining queued items were canceled.')
      }

      if (needsCaseRefresh) {
        await refreshCases()
      }

      setIsProcessing(false)
      setStopAfterCurrent(false)
      stopAfterCurrentRef.current = false
    },
    [
      appVariant,
      getEffectiveCaseId,
      isProcessing,
      refreshCases,
      refreshRecentTranscripts,
      setActiveMediaKey,
      prepareUploadFile,
      transcribeOneItem,
      updateQueueItem,
    ],
  )

  const handleStartQueued = () => {
    if (!queue.length) {
      setPageError('Please add at least one file.')
      return
    }
    void runQueue(['queued'])
  }

  const handleRetryFailures = () => {
    void runQueue(['failed', 'canceled'])
  }

  const handleStopQueue = () => {
    setStopAfterCurrent(true)
    stopAfterCurrentRef.current = true
  }

  const downloadBase64File = (base64Data: string, filename: string, mimeType: string) => {
    const byteCharacters = atob(base64Data)
    const byteNumbers = new Array(byteCharacters.length)
    for (let i = 0; i < byteCharacters.length; i += 1) {
      byteNumbers[i] = byteCharacters.charCodeAt(i)
    }
    const byteArray = new Uint8Array(byteNumbers)
    const blob = new Blob([byteArray], { type: mimeType })
    const objectUrl = URL.createObjectURL(blob)
    const link = document.createElement('a')
    link.href = objectUrl
    link.download = filename
    document.body.appendChild(link)
    link.click()
    document.body.removeChild(link)
    URL.revokeObjectURL(objectUrl)
  }

  const buildItemFilename = useCallback(
    (item: QueueItem, extension: '.pdf' | '.xml' | '.html') => {
      const titleData = item.result?.title_data || {}
      if (extension === '.pdf') {
        const mediaName = titleData.FILE_NAME || item.originalFileName || item.file.name
        const mediaBaseName = sanitizeDownloadStem(stripExtension(mediaName))
        return `${mediaBaseName} transcript.pdf`
      }
      const caseName = titleData.CASE_NAME || formData.case_name || stripExtension(item.file.name)
      const datePart = titleData.DATE || formData.input_date
      const sanitizedBase = sanitizeFilenamePart(caseName)
      return `${sanitizedBase}${datePart ? `-${datePart}` : ''}${extension}`
    },
    [formData.case_name, formData.input_date],
  )

  const handleDownloadBatchZip = useCallback(
    async (kind: 'pdf' | 'variant') => {
      const completed = queueRef.current.filter((item) => item.status === 'done' && item.result)
      if (!completed.length) {
        setPageError('No completed transcripts available to download.')
        return
      }

      setPageError('')
      setZipBusy(kind)

      try {
        const zip = new JSZip()
        const usedNames = new Set<string>()

        const reserveUniqueName = (baseName: string) => {
          if (!usedNames.has(baseName)) {
            usedNames.add(baseName)
            return baseName
          }

          const dotIndex = baseName.lastIndexOf('.')
          const stem = dotIndex > 0 ? baseName.slice(0, dotIndex) : baseName
          const ext = dotIndex > 0 ? baseName.slice(dotIndex) : ''

          let counter = 2
          while (true) {
            const candidate = `${stem}-${counter}${ext}`
            if (!usedNames.has(candidate)) {
              usedNames.add(candidate)
              return candidate
            }
            counter += 1
          }
        }

        let addedCount = 0

        for (const item of completed) {
          const payload = item.result
          if (!payload) continue

          if (kind === 'pdf') {
            const pdfData = payload.pdf_base64 ?? payload.docx_base64
            if (!pdfData) continue
            const filename = reserveUniqueName(buildItemFilename(item, '.pdf'))
            zip.file(filename, pdfData, { base64: true })
            addedCount += 1
            continue
          }

          if (appVariant === 'oncue') {
            if (!payload.oncue_xml_base64) continue
            const filename = reserveUniqueName(buildItemFilename(item, '.xml'))
            zip.file(filename, payload.oncue_xml_base64, { base64: true })
            addedCount += 1
          } else {
            if (!payload.viewer_html_base64) continue
            const filename = reserveUniqueName(buildItemFilename(item, '.html'))
            zip.file(filename, payload.viewer_html_base64, { base64: true })
            addedCount += 1
          }
        }

        if (addedCount === 0) {
          setPageError(kind === 'pdf' ? 'No PDF files available to bundle.' : `No ${appVariant === 'oncue' ? 'XML' : 'HTML'} files available to bundle.`)
          return
        }

        const blob = await zip.generateAsync({ type: 'blob' })
        const url = URL.createObjectURL(blob)
        const anchor = document.createElement('a')
        anchor.href = url
        const stamp = new Date().toISOString().slice(0, 10)
        anchor.download =
          kind === 'pdf'
            ? `transcribealpha-pdfs-${stamp}.zip`
            : `transcribealpha-${appVariant === 'oncue' ? 'xml' : 'html'}-${stamp}.zip`
        document.body.appendChild(anchor)
        anchor.click()
        document.body.removeChild(anchor)
        URL.revokeObjectURL(url)
      } catch {
        setPageError('Failed to generate ZIP archive.')
      } finally {
        setZipBusy(null)
      }
    },
    [appVariant, buildItemFilename],
  )

  const hasQueue = queue.length > 0
  const isBatchSelection = queue.length > 1
  const singleQueueItem = queue[0] ?? null
  const hasProcessed = isProcessing || processedItems.length > 0
  const canProceedToConfig = hasQueue
  const canProceedToTranscribe = queuedCount > 0
  const currentStepIndex = wizardSteps.findIndex((wizardStep) => wizardStep.key === step)

  const canNavigateToStep = (targetStep: WizardStep) => {
    if (targetStep === 'upload') return true
    if (targetStep === 'configure') return canProceedToConfig
    return hasProcessed
  }

  const setFileCaseTarget = (itemId: string, value: string) => {
    updateQueueItem(itemId, { case_target: value })
  }

  const setFileSpeakerNames = (itemId: string, value: string) => {
    updateQueueItem(itemId, { speaker_names: value })
  }

  const setFileSpeakersExpected = (itemId: string, value: string) => {
    updateQueueItem(itemId, { speakers_expected: value })
  }

  const resetForNewBatch = () => {
    if (isProcessing) return
    preparedAudioByItemRef.current.clear()
    setQueue([])
    setStep('upload')
    setShowAllResults(false)
    setPageError('')
    setPageNotice('')
  }

  const renderCaseTargetLabel = (item: QueueItem) => {
    const effective = getEffectiveCaseId(item)
    if (!effective) return 'Uncategorized'
    return caseNameById.get(effective) || 'Assigned Case'
  }

  return (
    <div className="p-8 max-w-6xl mx-auto">
      <div className="mb-8 flex items-start justify-between gap-4">
        <div>
          <h1 className="text-2xl font-semibold text-gray-900">New Transcript</h1>
          <p className="text-gray-600 mt-1">
            {isBatchSelection
              ? `Upload up to ${MAX_BATCH_FILES} files and process them in a managed queue.`
              : 'Upload one file to transcribe, or add more files to run as a batch.'}
          </p>
        </div>
      </div>

      <div className="flex items-center mb-8">
        {wizardSteps.map((wizardStep, i) => (
          <div key={wizardStep.key} className="flex items-center">
            <button
              type="button"
              onClick={() => {
                if (canNavigateToStep(wizardStep.key)) {
                  setStep(wizardStep.key)
                }
              }}
              className={`flex items-center gap-2 px-4 py-2 rounded-lg font-medium transition-colors ${
                step === wizardStep.key
                  ? 'bg-primary-600 text-white'
                  : currentStepIndex > i
                    ? 'text-primary-600 hover:bg-primary-50'
                    : 'text-gray-400'
              }`}
              disabled={!canNavigateToStep(wizardStep.key)}
            >
              <span
                className={`w-6 h-6 rounded-full flex items-center justify-center text-sm ${
                  step === wizardStep.key ? 'bg-white text-primary-600' : 'bg-gray-200 text-gray-600'
                }`}
              >
                {i + 1}
              </span>
              <span>{wizardStep.label}</span>
            </button>
            {i < wizardSteps.length - 1 && (
              <div
                className={`w-12 h-0.5 mx-2 ${
                  currentStepIndex > i ? 'bg-primary-600' : 'bg-gray-200'
                }`}
              />
            )}
          </div>
        ))}
      </div>

      {(pageError || pageNotice) && (
        <div className="space-y-3 mb-6">
          {pageError && <div className="bg-red-50 border border-red-200 rounded-lg p-4 text-red-700">{pageError}</div>}
          {pageNotice && <div className="bg-amber-50 border border-amber-200 rounded-lg p-4 text-amber-800">{pageNotice}</div>}
        </div>
      )}

      {step === 'upload' && (
        <div className="space-y-6">
          <div className="bg-white rounded-xl shadow-sm border border-gray-100 p-6">
            <h2 className="text-lg font-semibold text-gray-900 mb-1">
              Upload Media {isBatchSelection ? 'Files' : 'File'}
            </h2>
            <p className="text-sm text-gray-600 mb-4">
              {isBatchSelection
                ? `Choose up to ${MAX_BATCH_FILES} files. Drag the grip handle in the queue to reorder.`
                : `Choose one or more audio/video files. Select multiple files to run a batch (up to ${MAX_BATCH_FILES}).`}
            </p>

            <label
              htmlFor="media-upload"
              onDrop={handleDrop}
              onDragOver={handleDragOver}
              className="block border-2 border-dashed rounded-xl p-10 text-center cursor-pointer transition-colors border-gray-300 hover:border-primary-400 hover:bg-primary-50"
            >
              <input
                id="media-upload"
                type="file"
                ref={fileInputRef}
                onChange={handleFileInputChange}
                multiple
                accept="audio/*,video/*,.mp4,.avi,.mov,.mkv,.wav,.mp3,.m4a,.flac,.ogg"
                className="sr-only"
              />
              <div className="space-y-3">
                <div className="w-16 h-16 bg-gray-100 rounded-full flex items-center justify-center mx-auto">
                  <svg className="w-8 h-8 text-gray-400" fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24">
                    <path d="M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12" />
                  </svg>
                </div>
                <div className="font-medium text-gray-900">
                  {isBatchSelection ? 'Drop files here or click to browse' : 'Drop file(s) here or click to browse'}
                </div>
                <div className="text-sm text-gray-500">Supports MP4, MOV, AVI, WAV, MP3, FLAC and more</div>
              </div>
            </label>

            {appVariant === 'criminal' && (
              <button
                type="button"
                onClick={handleOpenFilePicker}
                className="mt-3 w-full py-2.5 text-sm font-medium text-primary-700 bg-primary-50 border border-primary-200 rounded-lg hover:bg-primary-100 transition-colors"
              >
                Browse Files (preserves file access for playback)
              </button>
            )}
          </div>

          {queue.length > 0 && (
            <div className="bg-white rounded-xl shadow-sm border border-gray-100 overflow-hidden">
              <div className="p-4 border-b border-gray-100 flex items-center justify-between">
                <div>
                  <h3 className="font-semibold text-gray-900">Queue</h3>
                  <p className="text-sm text-gray-500">
                    {queue.length} file{queue.length !== 1 ? 's' : ''} selected
                  </p>
                </div>
                {!isProcessing && (
                  <button
                    type="button"
                    onClick={() => setQueue([])}
                    className="btn-outline text-sm px-3 py-1"
                  >
                    Clear
                  </button>
                )}
              </div>
              <div className="divide-y divide-gray-100">
                {queue.map((item, index) => (
                  <div
                    key={item.id}
                    draggable={!isProcessing}
                    onDragStart={() => setDraggingId(item.id)}
                    onDragOver={(event) => {
                      event.preventDefault()
                      if (draggingId && draggingId !== item.id) {
                        setDragOverId(item.id)
                      }
                    }}
                    onDragEnd={() => {
                      setDraggingId(null)
                      setDragOverId(null)
                    }}
                    onDrop={(event) => {
                      event.preventDefault()
                      if (!draggingId) return
                      reorderQueue(draggingId, item.id)
                      setDraggingId(null)
                      setDragOverId(null)
                    }}
                    className={`p-4 flex items-center gap-4 ${dragOverId === item.id ? 'bg-primary-50' : 'bg-white'}`}
                  >
                    <div className="text-gray-400 cursor-grab" title="Drag to reorder">
                      <svg className="w-5 h-5" fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24">
                        <path d="M8 6h.01M8 12h.01M8 18h.01M16 6h.01M16 12h.01M16 18h.01" />
                      </svg>
                    </div>
                    <div className="w-8 h-8 rounded-lg bg-primary-100 text-primary-700 flex items-center justify-center text-sm font-semibold">
                      {index + 1}
                    </div>
                    <div className="flex-1 min-w-0">
                      <p className="font-medium text-gray-900 truncate">{item.file.name}</p>
                      <p className="text-sm text-gray-500">{(item.file.size / (1024 * 1024)).toFixed(1)} MB</p>
                    </div>
                    <span className={`px-2.5 py-1 rounded-full text-xs font-medium ${statusBadgeClass(item.status)}`}>
                      {statusLabel(item.status)}
                    </span>
                    {!isProcessing && (
                      <button
                        type="button"
                        onClick={() => {
                          preparedAudioByItemRef.current.delete(item.id)
                          setQueue((prev) => prev.filter((entry) => entry.id !== item.id))
                        }}
                        className="text-gray-400 hover:text-red-600 transition-colors"
                        title="Remove"
                      >
                        <svg className="w-5 h-5" fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24">
                          <path d="M6 18L18 6M6 6l12 12" />
                        </svg>
                      </button>
                    )}
                  </div>
                ))}
              </div>
            </div>
          )}

          <div className="flex justify-end">
            <button
              type="button"
              onClick={() => setStep('configure')}
              disabled={!canProceedToConfig}
              className="btn-primary px-8 py-3"
            >
              Continue
            </button>
          </div>
        </div>
      )}

      {step === 'configure' && (
        <div className="space-y-6">
          <div className="bg-white rounded-xl shadow-sm border border-gray-100 p-6">
            <h2 className="text-lg font-semibold text-gray-900 mb-4">Assign to Case (Recommended)</h2>
            <p className="text-sm text-gray-500 mb-4">
              {isBatchSelection
                ? 'Batch default case assignment. Each file can optionally override this below.'
                : 'Case assignment for this transcript.'}
            </p>
            <div className="flex gap-3">
              <select
                name="case_id"
                value={formData.case_id}
                onChange={(event) => setFormData((prev) => ({ ...prev, case_id: event.target.value }))}
                className="input-field flex-1"
              >
                <option value="">{appVariant === 'criminal' ? 'No case (uncategorized)' : 'No case (expires in 30 days)'}</option>
                {cases.map((c) => (
                  <option key={c.case_id} value={c.case_id}>
                    {c.name}
                  </option>
                ))}
              </select>
              <button type="button" onClick={() => setShowNewCaseModal(true)} className="btn-outline whitespace-nowrap">
                + New Case
              </button>
            </div>
          </div>

          <div className="bg-white rounded-xl shadow-sm border border-gray-100 p-6">
            <div className="flex items-center justify-between mb-4">
              <h2 className="text-lg font-semibold text-gray-900">{isBatchSelection ? 'Batch Metadata Defaults' : 'Transcript Metadata'}</h2>
              <span className="text-sm text-gray-400">{isBatchSelection ? 'Applied to all files in this run' : 'Applied to this transcript'}</span>
            </div>
            <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
              <div>
                <label className="block text-sm font-medium text-gray-700 mb-1">Case Name</label>
                <input
                  type="text"
                  value={formData.case_name}
                  onChange={(event) => setFormData((prev) => ({ ...prev, case_name: event.target.value }))}
                  className="input-field"
                  placeholder="e.g., Smith vs. Johnson"
                />
              </div>
              <div>
                <label className="block text-sm font-medium text-gray-700 mb-1">Case Number</label>
                <input
                  type="text"
                  value={formData.case_number}
                  onChange={(event) => setFormData((prev) => ({ ...prev, case_number: event.target.value }))}
                  className="input-field"
                  placeholder="e.g., CV-2023-001234"
                />
              </div>
              <div>
                <label className="block text-sm font-medium text-gray-700 mb-1">Firm / Organization</label>
                <input
                  type="text"
                  value={formData.firm_name}
                  onChange={(event) => setFormData((prev) => ({ ...prev, firm_name: event.target.value }))}
                  className="input-field"
                  placeholder="e.g., Legal Associates LLC"
                />
              </div>
              <div>
                <label className="block text-sm font-medium text-gray-700 mb-1">Date</label>
                <input
                  type="date"
                  value={formData.input_date}
                  onChange={(event) => setFormData((prev) => ({ ...prev, input_date: event.target.value }))}
                  className="input-field"
                />
              </div>
              <div className="md:col-span-2">
                <label className="block text-sm font-medium text-gray-700 mb-1">Location</label>
                <input
                  type="text"
                  value={formData.location}
                  onChange={(event) => setFormData((prev) => ({ ...prev, location: event.target.value }))}
                  className="input-field"
                  placeholder="e.g., Conference Room A"
                />
              </div>
            </div>
          </div>

          <div className="bg-white rounded-xl shadow-sm border border-gray-100 p-6">
            <h2 className="text-lg font-semibold text-gray-900 mb-4">Transcription Model</h2>
            <select
              value={formData.transcription_model}
              onChange={(event) =>
                setFormData((prev) => ({
                  ...prev,
                  transcription_model: event.target.value as 'assemblyai' | 'gemini',
                }))
              }
              className="input-field"
            >
              <option value="assemblyai">AssemblyAI (Recommended)</option>
              <option value="gemini">Gemini 3.0 Pro</option>
            </select>
          </div>

          <div className="bg-white rounded-xl shadow-sm border border-gray-100 overflow-hidden">
            <div className="p-4 border-b border-gray-100">
              <h2 className="text-lg font-semibold text-gray-900">{isBatchSelection ? 'Per-File Overrides' : 'Transcript Options'}</h2>
              <p className="text-sm text-gray-500 mt-1">
                {isBatchSelection
                  ? 'Set optional speaker hints and case override per file.'
                  : 'Set optional speaker hints for this transcript.'}
              </p>
            </div>
            <div className="divide-y divide-gray-100">
              {queue.map((item, index) => (
                <div key={item.id} className="p-4 space-y-3">
                  <div className="flex items-center justify-between gap-3">
                    <div>
                      <p className="font-medium text-gray-900">
                        {index + 1}. {item.file.name}
                      </p>
                      <p className="text-xs text-gray-500">{(item.file.size / (1024 * 1024)).toFixed(1)} MB</p>
                    </div>
                    <span className={`px-2.5 py-1 rounded-full text-xs font-medium ${statusBadgeClass(item.status)}`}>
                      {statusLabel(item.status)}
                    </span>
                  </div>

                  <div className={`grid grid-cols-1 ${isBatchSelection ? 'lg:grid-cols-3' : 'lg:grid-cols-2'} gap-3`}>
                    {isBatchSelection && (
                      <div>
                        <label className="block text-xs font-semibold uppercase tracking-wide text-gray-500 mb-1">
                          Case Assignment
                        </label>
                        <select
                          value={item.case_target}
                          onChange={(event) => setFileCaseTarget(item.id, event.target.value)}
                          disabled={isProcessing}
                          className="input-field text-sm"
                        >
                          <option value={CASE_USE_BATCH}>Use batch setting</option>
                          <option value={CASE_UNCATEGORIZED}>No case (uncategorized)</option>
                          {cases.map((c) => (
                            <option key={c.case_id} value={c.case_id}>
                              {c.name}
                            </option>
                          ))}
                        </select>
                        <p className="text-xs text-gray-500 mt-1">Current: {renderCaseTargetLabel(item)}</p>
                      </div>
                    )}

                    <div className={isBatchSelection ? 'lg:col-span-2' : ''}>
                      <label className="block text-xs font-semibold uppercase tracking-wide text-gray-500 mb-1">
                        Speaker Names (Optional)
                      </label>
                      <input
                        type="text"
                        value={item.speaker_names}
                        onChange={(event) => setFileSpeakerNames(item.id, event.target.value)}
                        disabled={isProcessing}
                        className="input-field text-sm"
                        placeholder="e.g., John Smith, Jane Doe"
                      />
                    </div>

                    <div>
                      <label className="block text-xs font-semibold uppercase tracking-wide text-gray-500 mb-1">
                        Number of Speakers (Optional)
                      </label>
                      <input
                        type="number"
                        min={1}
                        step={1}
                        value={item.speakers_expected}
                        onChange={(event) => setFileSpeakersExpected(item.id, event.target.value)}
                        disabled={isProcessing}
                        className="input-field text-sm"
                        placeholder="e.g., 2"
                      />
                    </div>
                  </div>
                </div>
              ))}
            </div>
          </div>

          <div className="flex justify-between">
            <button type="button" onClick={() => setStep('upload')} className="btn-outline px-6 py-3">
              Back
            </button>
            <button
              type="button"
              onClick={handleStartQueued}
              disabled={!canProceedToTranscribe || isProcessing}
              className="btn-primary px-8 py-3"
            >
              {isBatchSelection ? 'Start Queue' : 'Start Transcription'}
            </button>
          </div>
        </div>
      )}

      {step === 'transcribe' && (
        <div className="space-y-6">
          <div className="bg-amber-50 border border-amber-200 rounded-lg p-4 text-amber-900 text-sm">
            {isBatchSelection
              ? 'Keep this tab open while processing. If you leave or close the tab, queued work stops.'
              : 'Keep this tab open while processing. If you leave or close the tab, transcription stops.'}
          </div>

          {isBatchSelection ? (
            <div className="bg-white rounded-xl shadow-sm border border-gray-100 overflow-hidden">
              <div className="p-4 border-b border-gray-100 flex items-center justify-between gap-3 flex-wrap">
                <div>
                  <h2 className="text-lg font-semibold text-gray-900">Queue Progress</h2>
                  <p className="text-sm text-gray-500">
                    {doneCount} complete, {failedCount} failed, {canceledCount} canceled, {queuedCount} queued
                  </p>
                </div>
                <div className="flex items-center gap-2">
                  {isProcessing ? (
                    <>
                      <span className="text-sm text-primary-700 font-medium">
                        {stopAfterCurrent ? 'Stopping after current file...' : `${inProgressCount || 1} file in progress`}
                      </span>
                      <button
                        type="button"
                        onClick={handleStopQueue}
                        disabled={stopAfterCurrent}
                        className="btn-outline px-3 py-2 text-sm disabled:opacity-50 disabled:cursor-not-allowed"
                      >
                        Stop Queue
                      </button>
                    </>
                  ) : (
                    <>
                      {queuedCount > 0 && (
                        <button type="button" onClick={handleStartQueued} className="btn-primary px-3 py-2 text-sm">
                          Resume Queue
                        </button>
                      )}
                      {(failedCount > 0 || canceledCount > 0) && (
                        <button type="button" onClick={handleRetryFailures} className="btn-outline px-3 py-2 text-sm">
                          Retry Failed/Canceled
                        </button>
                      )}
                      <button type="button" onClick={resetForNewBatch} className="btn-outline px-3 py-2 text-sm">
                        New Batch
                      </button>
                    </>
                  )}
                </div>
              </div>

              <div className="divide-y divide-gray-100">
                {queue.map((item, index) => (
                  <div key={item.id} className="p-4">
                    <div className="flex items-start justify-between gap-3">
                      <div className="min-w-0">
                        <p className="font-medium text-gray-900 truncate">
                          {index + 1}. {item.file.name}
                        </p>
                        <p className="text-sm text-gray-500">{item.stageText}</p>
                        {item.error && <p className="text-sm text-red-600 mt-1">{item.error}</p>}
                      </div>
                      <span className={`px-2.5 py-1 rounded-full text-xs font-medium ${statusBadgeClass(item.status)}`}>
                        {statusLabel(item.status)}
                      </span>
                    </div>
                  </div>
                ))}
              </div>
            </div>
          ) : (
            <div className="bg-white rounded-xl shadow-sm border border-gray-100 overflow-hidden">
              <div className="p-4 border-b border-gray-100 flex items-center justify-between gap-3 flex-wrap">
                <div>
                  <h2 className="text-lg font-semibold text-gray-900">Transcription Status</h2>
                  <p className="text-sm text-gray-500">{singleQueueItem?.file.name ?? 'No file selected'}</p>
                </div>
                <div className="flex items-center gap-2">
                  {isProcessing ? (
                    <>
                      <span className="text-sm text-primary-700 font-medium">
                        {stopAfterCurrent ? 'Stopping after current file...' : 'Processing...'}
                      </span>
                      <button
                        type="button"
                        onClick={handleStopQueue}
                        disabled={stopAfterCurrent}
                        className="btn-outline px-3 py-2 text-sm disabled:opacity-50 disabled:cursor-not-allowed"
                      >
                        Stop
                      </button>
                    </>
                  ) : (
                    <>
                      {queuedCount > 0 && (
                        <button type="button" onClick={handleStartQueued} className="btn-primary px-3 py-2 text-sm">
                          Start Transcription
                        </button>
                      )}
                      {(failedCount > 0 || canceledCount > 0) && (
                        <button type="button" onClick={handleRetryFailures} className="btn-outline px-3 py-2 text-sm">
                          Retry
                        </button>
                      )}
                      <button type="button" onClick={resetForNewBatch} className="btn-outline px-3 py-2 text-sm">
                        New Transcript
                      </button>
                    </>
                  )}
                </div>
              </div>
              {singleQueueItem && (
                <div className="p-4">
                  <div className="flex items-start justify-between gap-3">
                    <div className="min-w-0">
                      <p className="font-medium text-gray-900 truncate">{singleQueueItem.file.name}</p>
                      <p className="text-sm text-gray-500">{singleQueueItem.stageText}</p>
                      {singleQueueItem.error && <p className="text-sm text-red-600 mt-1">{singleQueueItem.error}</p>}
                    </div>
                    <span className={`px-2.5 py-1 rounded-full text-xs font-medium ${statusBadgeClass(singleQueueItem.status)}`}>
                      {statusLabel(singleQueueItem.status)}
                    </span>
                  </div>
                </div>
              )}
            </div>
          )}

          {doneCount > 0 && isBatchSelection && (
            <div className="bg-white rounded-xl shadow-sm border border-gray-100 p-4">
              <h3 className="font-semibold text-gray-900 mb-3">Batch Downloads</h3>
              <div className="flex flex-wrap gap-3">
                <button
                  type="button"
                  onClick={() => handleDownloadBatchZip('pdf')}
                  disabled={zipBusy !== null}
                  className="btn-primary px-4 py-2 disabled:opacity-60 disabled:cursor-not-allowed"
                >
                  {zipBusy === 'pdf' ? 'Building PDF ZIP...' : 'Download All PDFs (.zip)'}
                </button>
                <button
                  type="button"
                  onClick={() => handleDownloadBatchZip('variant')}
                  disabled={zipBusy !== null}
                  className="btn-primary px-4 py-2 disabled:opacity-60 disabled:cursor-not-allowed"
                >
                  {zipBusy === 'variant'
                    ? `Building ${appVariant === 'oncue' ? 'XML' : 'HTML'} ZIP...`
                    : `Download All ${appVariant === 'oncue' ? 'OnCue XML' : 'HTML Viewer'} (.zip)`}
                </button>
              </div>
            </div>
          )}

          {processedItems.length > 0 && (
            <div className="bg-white rounded-xl shadow-sm border border-gray-100 overflow-hidden">
              <div className="p-4 border-b border-gray-100 flex items-center justify-between">
                <h3 className="font-semibold text-gray-900">Results</h3>
                {processedItems.length > RESULTS_PREVIEW_LIMIT && (
                  <button
                    type="button"
                    onClick={() => setShowAllResults((prev) => !prev)}
                    className="text-sm text-primary-600 hover:text-primary-700"
                  >
                    {showAllResults ? 'Show fewer' : `Show all (${processedItems.length})`}
                  </button>
                )}
              </div>
              <div className="divide-y divide-gray-100">
                {visibleProcessedItems.map((item) => {
                  const result = item.result
                  const lineCount = Array.isArray(result?.lines) ? result?.lines.length : 0
                  const effectiveCaseId = getEffectiveCaseId(item)

                  return (
                    <div key={item.id} className="p-4 space-y-3">
                      <div className="flex items-start justify-between gap-3">
                        <div className="min-w-0">
                          <p className="font-medium text-gray-900 truncate">{item.file.name}</p>
                          <p className="text-sm text-gray-500">
                            {item.status === 'done'
                              ? `${lineCount} transcript lines`
                              : item.status === 'failed'
                                ? `Failed${item.attemptCount > 1 ? ' after retry' : ''}`
                                : 'Canceled'}
                          </p>
                        </div>
                        <span className={`px-2.5 py-1 rounded-full text-xs font-medium ${statusBadgeClass(item.status)}`}>
                          {statusLabel(item.status)}
                        </span>
                      </div>

                      {item.error && <p className="text-sm text-red-600">{item.error}</p>}

                      {item.status === 'done' && result && (
                        <div className="flex flex-wrap gap-2">
                          <button
                            type="button"
                            onClick={() => {
                              setActiveMediaKey(result.media_key)
                              guardedPush(router, routes.editor(result.media_key))
                            }}
                            className="btn-primary text-sm px-3 py-2"
                          >
                            Open Editor
                          </button>

                          <button
                            type="button"
                            onClick={() => {
                              const pdfData = result.pdf_base64 ?? result.docx_base64
                              if (!pdfData) return
                              downloadBase64File(pdfData, buildItemFilename(item, '.pdf'), 'application/pdf')
                            }}
                            disabled={!result.pdf_base64 && !result.docx_base64}
                            className="btn-outline text-sm px-3 py-2 disabled:opacity-50 disabled:cursor-not-allowed"
                          >
                            Download PDF
                          </button>

                          {appVariant === 'oncue' ? (
                            <button
                              type="button"
                              onClick={() => {
                                if (!result.oncue_xml_base64) return
                                downloadBase64File(result.oncue_xml_base64, buildItemFilename(item, '.xml'), 'application/xml')
                              }}
                              disabled={!result.oncue_xml_base64}
                              className="btn-outline text-sm px-3 py-2 disabled:opacity-50 disabled:cursor-not-allowed"
                            >
                              Download OnCue XML
                            </button>
                          ) : (
                            <button
                              type="button"
                              onClick={() => {
                                if (!result.viewer_html_base64) return
                                downloadBase64File(result.viewer_html_base64, buildItemFilename(item, '.html'), 'text/html')
                              }}
                              disabled={!result.viewer_html_base64}
                              className="btn-outline text-sm px-3 py-2 disabled:opacity-50 disabled:cursor-not-allowed"
                            >
                              Download HTML Viewer
                            </button>
                          )}

                          {effectiveCaseId && (
                            <Link href={routes.caseDetail(effectiveCaseId)} className="btn-outline text-sm px-3 py-2">
                              View Case
                            </Link>
                          )}
                        </div>
                      )}
                    </div>
                  )
                })}
              </div>
            </div>
          )}

          {!isProcessing && processedItems.length === 0 && (
            <div className="bg-white rounded-xl shadow-sm border border-gray-100 p-8 text-center text-gray-500">
              {isBatchSelection ? 'Queue has not started yet.' : 'Transcription has not started yet.'}
            </div>
          )}

          <div className="flex justify-start">
            <button type="button" onClick={() => setStep('configure')} className="btn-outline px-6 py-3">
              Back to Configure
            </button>
          </div>
        </div>
      )}

      {showNewCaseModal && (
        <div className="fixed inset-0 z-50 flex items-center justify-center bg-black/50 p-4">
          <div className="bg-white rounded-xl shadow-xl w-full max-w-md p-6">
            <h3 className="text-lg font-semibold text-gray-900 mb-4">Create New Case</h3>
            <div className="space-y-4">
              <div>
                <label className="block text-sm font-medium text-gray-700 mb-1">Case Name</label>
                <input
                  type="text"
                  value={newCaseName}
                  onChange={(event) => setNewCaseName(event.target.value)}
                  className="input-field"
                  placeholder="e.g., Smith vs. Johnson"
                  autoFocus
                />
              </div>
              <div>
                <label className="block text-sm font-medium text-gray-700 mb-1">Description (optional)</label>
                <textarea
                  value={newCaseDescription}
                  onChange={(event) => setNewCaseDescription(event.target.value)}
                  className="input-field"
                  rows={3}
                  placeholder="Brief description of the case..."
                />
              </div>
            </div>
            <div className="flex justify-end gap-3 mt-6">
              <button
                type="button"
                onClick={() => {
                  setShowNewCaseModal(false)
                  setNewCaseName('')
                  setNewCaseDescription('')
                }}
                className="btn-outline px-4 py-2"
              >
                Cancel
              </button>
              <button
                type="button"
                onClick={handleCreateCase}
                disabled={!newCaseName.trim() || creatingCase}
                className="btn-primary px-4 py-2 disabled:opacity-50 disabled:cursor-not-allowed"
              >
                {creatingCase ? 'Creating...' : 'Create Case'}
              </button>
            </div>
          </div>
        </div>
      )}
    </div>
  )
}
===== END FILE =====

===== FILE: frontend-next/src/app/(dashboard)/viewer/page.tsx =====
'use client'

import JSZip from 'jszip'
import Link from 'next/link'
import { useRouter, useSearchParams } from 'next/navigation'
import { useCallback, useEffect, useMemo, useRef, useState } from 'react'
import { useDashboard } from '@/context/DashboardContext'
import {
  deleteClip,
  deleteSequence,
  getTranscript,
  listCaseClips,
  listCaseSequences,
  saveClip,
  saveTranscript,
  saveSequence,
  type ClipRecord,
  type ClipSequenceEntry,
  type ClipSequenceRecord,
  type TranscriptData,
} from '@/lib/storage'
import {
  getMediaFile,
  getMediaObjectURL,
  promptRelinkMedia,
  storeMediaHandle,
} from '@/lib/mediaHandles'
import WaveSurfer from 'wavesurfer.js'
import { authenticatedFetch } from '@/utils/auth'
import { guardedPush } from '@/utils/navigationGuard'
import { routes } from '@/utils/routes'

interface ViewerLine {
  id: string
  speaker: string
  text: string
  rendered_text?: string
  start: number
  end: number
  page?: number | null
  line?: number | null
  pgln?: number | null
  is_continuation?: boolean
}

interface ViewerTranscript extends TranscriptData {
  media_key: string
  title_data: Record<string, string>
  lines: ViewerLine[]
  audio_duration: number
  lines_per_page: number
  case_id?: string | null
}

interface TitleCardState {
  visible: boolean
  title: string
  meta: string
  subtitle?: string
}

type SequencePauseBehavior = 'black-screen' | 'title-card' | 'continuous'

type SequenceState =
  | { phase: 'idle' }
  | { phase: 'title-card'; sequenceId: string; clipIndex: number }
  | { phase: 'transitioning'; sequenceId: string; clipIndex: number }
  | { phase: 'playing'; sequenceId: string; clipIndex: number }
  | { phase: 'finished'; sequenceId: string }

type ViewerMode = 'document' | 'caption'
type ToolsTab = 'clips' | 'sequences'

const SEARCH_TOLERANCE = 0.05
const PROGRAMMATIC_SCROLL_RESET_MS = 700
const PRESENTATION_UI_IDLE_MS = 1400
const SPEAKER_LINE_PATTERN = /^(\s*)([A-Z][A-Z0-9 .,'"&/()-]*:)(\s*)(.*)$/

const formatClock = (seconds: number) => {
  if (!Number.isFinite(seconds) || seconds < 0) return '0:00'
  const total = Math.floor(seconds)
  const hrs = Math.floor(total / 3600)
  const mins = Math.floor((total % 3600) / 60)
  const secs = total % 60
  if (hrs > 0) return `${hrs}:${String(mins).padStart(2, '0')}:${String(secs).padStart(2, '0')}`
  return `${mins}:${String(secs).padStart(2, '0')}`
}

const formatRange = (start: number, end: number) => `${formatClock(start)} - ${formatClock(end)}`

const parseTimeInput = (value: string): number | null => {
  const trimmed = value.trim()
  if (!trimmed) return null

  const parts = trimmed.split(':').map((part) => part.trim())
  if (parts.some((part) => !part.length)) return null

  const numeric = parts.map((part) => Number(part))
  if (numeric.some((part) => Number.isNaN(part))) return null

  if (numeric.length === 1) return numeric[0]
  if (numeric.length === 2) return numeric[0] * 60 + numeric[1]
  if (numeric.length === 3) return numeric[0] * 3600 + numeric[1] * 60 + numeric[2]
  return null
}

const escapeScriptBoundary = (value: string) => value.replace(/<\/script/gi, '<\\/script')

const sanitizeFilename = (value: string) => {
  const cleaned = value
    .replace(/[^a-zA-Z0-9._-]+/g, '-')
    .replace(/^-+/, '')
    .replace(/-+$/, '')
  return cleaned || 'item'
}

const sanitizeDownloadStem = (value: string) => {
  const cleaned = value
    .replace(/[\\/:*?"<>|]/g, ' ')
    .replace(/\s+/g, ' ')
    .trim()
  return cleaned || 'transcript'
}

const sleep = (ms: number) => new Promise<void>((resolve) => {
  window.setTimeout(resolve, ms)
})

const collapseWhitespace = (value: string) => value.replace(/\s+/g, ' ').trim()

const normalizeSpeakerToken = (speaker: string) => speaker.trim().replace(/:+$/, '').toUpperCase()

const buildLineText = (line: ViewerLine) => {
  const rendered = typeof line.rendered_text === 'string' ? line.rendered_text : ''
  if (rendered.trim()) return rendered

  const base = typeof line.text === 'string' ? line.text : ''
  const speaker = normalizeSpeakerToken(line.speaker || '')
  if (!line.is_continuation && speaker && base.trim()) {
    const compact = collapseWhitespace(base).toUpperCase()
    if (!compact.startsWith(`${speaker}:`)) {
      return `          ${speaker}:   ${base}`
    }
  }
  return base
}

const splitSpeakerPrefix = (line: ViewerLine) => {
  const lineText = buildLineText(line)
  if (!lineText) {
    return {
      lineText,
      leading: '',
      speakerLabel: null as string | null,
      trailing: '',
    }
  }

  if (line.is_continuation) {
    return {
      lineText,
      leading: '',
      speakerLabel: null as string | null,
      trailing: '',
    }
  }

  const match = lineText.match(SPEAKER_LINE_PATTERN)
  if (!match) {
    return {
      lineText,
      leading: '',
      speakerLabel: null as string | null,
      trailing: '',
    }
  }

  return {
    lineText,
    leading: match[1] || '',
    speakerLabel: match[2] || null,
    trailing: `${match[3] || ''}${match[4] || ''}`,
  }
}

const captionTextForLine = (line: ViewerLine | null | undefined) => {
  if (!line) return ''
  const baseText = collapseWhitespace(line.text || line.rendered_text || '')
  if (!baseText) return ''

  const speaker = normalizeSpeakerToken(line.speaker || '')
  if (!line.is_continuation && speaker) {
    if (baseText.toUpperCase().startsWith(`${speaker}:`)) return baseText
    return `${speaker}: ${baseText}`
  }

  return baseText
}

function normalizeTranscript(raw: TranscriptData, fallbackMediaKey: string): ViewerTranscript {
  const rawLines = Array.isArray(raw.lines) ? raw.lines : []
  const lines: ViewerLine[] = rawLines
    .map((entry, index) => {
      const lineObj = (entry || {}) as Record<string, unknown>
      const start = Number(lineObj.start)
      const end = Number(lineObj.end)
      const page = Number(lineObj.page)
      const lineNum = Number(lineObj.line)
      const pgln = Number(lineObj.pgln)
      return {
        id: String(lineObj.id || `line-${index}`),
        speaker: String(lineObj.speaker || ''),
        text: String(lineObj.text || ''),
        rendered_text: typeof lineObj.rendered_text === 'string' ? lineObj.rendered_text : undefined,
        start: Number.isFinite(start) ? start : 0,
        end: Number.isFinite(end) ? end : Number.isFinite(start) ? start : 0,
        page: Number.isFinite(page) ? page : null,
        line: Number.isFinite(lineNum) ? lineNum : null,
        pgln: Number.isFinite(pgln) ? pgln : null,
        is_continuation: Boolean(lineObj.is_continuation),
      }
    })
    .sort((a, b) => a.start - b.start)

  return {
    ...raw,
    media_key: String(raw.media_key || fallbackMediaKey),
    title_data: raw.title_data || {},
    lines,
    audio_duration: Number(raw.audio_duration || 0),
    lines_per_page: Number(raw.lines_per_page || 25),
  }
}

function linesToViewerPayload(transcript: ViewerTranscript) {
  const speakers = Array.from(
    new Set(
      transcript.lines
        .map((line) => line.speaker)
        .filter((speaker) => speaker && speaker.trim().length > 0),
    ),
  )

  const lines = transcript.lines.map((line, index) => ({
    id: line.id,
    speaker: line.speaker,
    text: line.text,
    rendered_text: line.rendered_text || line.text,
    start: line.start,
    end: line.end,
    page_number: line.page || Math.floor(index / transcript.lines_per_page) + 1,
    line_number: line.line || ((index % transcript.lines_per_page) + 1),
    pgln: line.pgln || 101 + index,
    is_continuation: Boolean(line.is_continuation),
  }))

  const pageMap = new Map<number, number[]>()
  lines.forEach((line, idx) => {
    const page = line.page_number
    if (!pageMap.has(page)) pageMap.set(page, [])
    pageMap.get(page)?.push(idx)
  })

  const pages = Array.from(pageMap.entries())
    .sort((a, b) => a[0] - b[0])
    .map(([pageNum, lineIndexes]) => ({
      page_number: pageNum,
      line_indexes: lineIndexes,
      pgln_start: lineIndexes.length ? lines[lineIndexes[0]].pgln : 101,
      pgln_end: lineIndexes.length ? lines[lineIndexes[lineIndexes.length - 1]].pgln : 101,
    }))

  return {
    meta: {
      title: transcript.title_data || {},
      duration_seconds: transcript.audio_duration || 0,
      lines_per_page: transcript.lines_per_page || 25,
      speakers,
    },
    media: {
      filename: transcript.media_filename || transcript.title_data?.FILE_NAME || 'media.mp4',
      content_type: transcript.media_content_type || 'video/mp4',
      relative_path: transcript.media_filename || transcript.title_data?.FILE_NAME || 'media.mp4',
    },
    lines,
    pages,
  }
}

export default function ViewerPage() {
  const router = useRouter()
  const searchParams = useSearchParams()
  const queryMediaKey = searchParams.get('key')
  const queryCaseId = searchParams.get('case')

  const { activeMediaKey, setActiveMediaKey, appVariant } = useDashboard()

  const [currentMediaKey, setCurrentMediaKey] = useState<string | null>(null)
  const [transcript, setTranscript] = useState<ViewerTranscript | null>(null)
  const [isLoading, setIsLoading] = useState(true)
  const [error, setError] = useState('')

  const [mediaUrl, setMediaUrl] = useState<string | null>(null)
  const [mediaAvailable, setMediaAvailable] = useState(true)
  const [mediaLoading, setMediaLoading] = useState(false)

  const [currentTime, setCurrentTime] = useState(0)
  const [duration, setDuration] = useState(0)
  const [activeLineId, setActiveLineId] = useState<string | null>(null)
  const [selectedLineId, setSelectedLineId] = useState<string | null>(null)
  const [autoFollow, setAutoFollow] = useState(true)
  const [showReturnToCurrent, setShowReturnToCurrent] = useState(false)

  const [searchQuery, setSearchQuery] = useState('')
  const [searchCursor, setSearchCursor] = useState(0)

  const [exportMenuOpen, setExportMenuOpen] = useState(false)
  const [exporting, setExporting] = useState(false)

  const [clips, setClips] = useState<ClipRecord[]>([])
  const [sequences, setSequences] = useState<ClipSequenceRecord[]>([])
  const [clipsLoading, setClipsLoading] = useState(false)

  const [clipName, setClipName] = useState('')
  const [clipStart, setClipStart] = useState('')
  const [clipEnd, setClipEnd] = useState('')
  const [clipError, setClipError] = useState('')
  const [editingClipId, setEditingClipId] = useState<string | null>(null)
  const [editClipName, setEditClipName] = useState('')
  const [editClipStart, setEditClipStart] = useState('')
  const [editClipEnd, setEditClipEnd] = useState('')
  const [dragClipId, setDragClipId] = useState<string | null>(null)

  const [newSequenceName, setNewSequenceName] = useState('')
  const [selectedSequenceId, setSelectedSequenceId] = useState<string | null>(null)
  const [sequenceNameDrafts, setSequenceNameDrafts] = useState<Record<string, string>>({})
  const [sequenceError, setSequenceError] = useState('')
  const [viewerMode, setViewerMode] = useState<ViewerMode>('document')
  const [showToolsPanel, setShowToolsPanel] = useState(false)
  const [activeToolsTab, setActiveToolsTab] = useState<ToolsTab>('clips')

  const [presentationMode, setPresentationMode] = useState(false)
  const [titleCard, setTitleCard] = useState<TitleCardState | null>(null)
  const [sequenceState, setSequenceState] = useState<SequenceState>({ phase: 'idle' })

  const [activeClipPlaybackId, setActiveClipPlaybackId] = useState<string | null>(null)
  const [presentationUiVisible, setPresentationUiVisible] = useState(false)
  const [showBlackScreen, setShowBlackScreen] = useState(false)
  const [waitingForResume, setWaitingForResume] = useState(false)
  const [sequencePauseBehavior, setSequencePauseBehavior] = useState<SequencePauseBehavior>(() => {
    if (typeof window === 'undefined') return 'black-screen'
    const saved = localStorage.getItem('sequence-pause-behavior')
    if (saved === 'black-screen' || saved === 'title-card' || saved === 'continuous') return saved
    return 'black-screen'
  })
  const [clipGapSeconds, setClipGapSeconds] = useState<number>(() => {
    if (typeof window === 'undefined') return 3
    const saved = localStorage.getItem('sequence-clip-gap')
    const parsed = Number(saved)
    return Number.isFinite(parsed) && parsed >= 0 ? parsed : 3
  })

  const videoRef = useRef<HTMLVideoElement>(null)
  const audioRef = useRef<HTMLAudioElement>(null)
  const viewerShellRef = useRef<HTMLDivElement>(null)
  const transcriptScrollRef = useRef<HTMLDivElement>(null)
  const searchInputRef = useRef<HTMLInputElement>(null)
  const exportMenuRef = useRef<HTMLDivElement>(null)
  const lineRefs = useRef<Record<string, HTMLDivElement | null>>({})

  const waveformRef = useRef<HTMLDivElement>(null)
  const wavesurferRef = useRef<WaveSurfer | null>(null)

  const blobUrlRef = useRef<string | null>(null)
  const programmaticScrollRef = useRef(false)
  const clipRafRef = useRef<number | null>(null)
  const presentationUiTimerRef = useRef<number | null>(null)
  const sequenceAbortRef = useRef(false)
  const clipFinishRef = useRef<(() => void) | null>(null)
  const sequenceResumeRef = useRef<(() => void) | null>(null)
  const transcriptCacheRef = useRef<Record<string, ViewerTranscript>>({})
  const templateCacheRef = useRef<string | null>(null)

  const isVideo = useMemo(
    () => (transcript?.media_content_type || '').startsWith('video/'),
    [transcript?.media_content_type],
  )

  const effectiveCaseId = useMemo(() => {
    if (queryCaseId) return queryCaseId
    if (transcript?.case_id && String(transcript.case_id).trim()) return String(transcript.case_id)
    return ''
  }, [queryCaseId, transcript?.case_id])

  const groupedPages = useMemo(() => {
    if (!transcript) return [] as Array<{ page: number; lines: ViewerLine[] }>
    const map = new Map<number, ViewerLine[]>()
    transcript.lines.forEach((line, idx) => {
      const pageNum = line.page || Math.floor(idx / transcript.lines_per_page) + 1
      if (!map.has(pageNum)) map.set(pageNum, [])
      map.get(pageNum)?.push(line)
    })

    return Array.from(map.entries())
      .sort((a, b) => a[0] - b[0])
      .map(([page, lines]) => ({ page, lines }))
  }, [transcript])

  const searchMatches = useMemo(() => {
    if (!transcript || !searchQuery.trim()) return [] as string[]
    const lower = searchQuery.toLowerCase()
    return transcript.lines
      .filter((line) => {
        const text = (line.rendered_text || line.text || '').toLowerCase()
        const speaker = (line.speaker || '').toLowerCase()
        return text.includes(lower) || speaker.includes(lower)
      })
      .map((line) => line.id)
  }, [transcript, searchQuery])

  const searchMatchSet = useMemo(() => new Set(searchMatches), [searchMatches])

  const visibleClips = useMemo(() => {
    const sorted = [...clips].sort((a, b) => {
      const aOrder = Number.isFinite(a.order) ? Number(a.order) : Number.MAX_SAFE_INTEGER
      const bOrder = Number.isFinite(b.order) ? Number(b.order) : Number.MAX_SAFE_INTEGER
      if (aOrder !== bOrder) return aOrder - bOrder
      return (a.created_at || '').localeCompare(b.created_at || '')
    })

    if (queryCaseId) return sorted
    if (!currentMediaKey) return []
    return sorted.filter((clip) => clip.source_media_key === currentMediaKey)
  }, [clips, currentMediaKey, queryCaseId])

  const groupedVisibleClips = useMemo(() => {
    const groups = new Map<string, ClipRecord[]>()
    visibleClips.forEach((clip) => {
      if (!groups.has(clip.source_media_key)) groups.set(clip.source_media_key, [])
      groups.get(clip.source_media_key)?.push(clip)
    })
    return Array.from(groups.entries())
  }, [visibleClips])

  const canEditClips = !!effectiveCaseId
  const currentSearchLineId = searchMatches.length > 0
    ? searchMatches[((searchCursor % searchMatches.length) + searchMatches.length) % searchMatches.length]
    : null

  const activeLineIndex = useMemo(() => {
    if (!transcript || !activeLineId) return -1
    return transcript.lines.findIndex((line) => line.id === activeLineId)
  }, [activeLineId, transcript])

  const captionWindow = useMemo(() => {
    if (!transcript || activeLineIndex < 0) {
      return {
        prev2: '',
        prev1: '',
        current: '',
        next1: '',
        next2: '',
      }
    }

    const at = (index: number) => captionTextForLine(transcript.lines[index])
    return {
      prev2: at(activeLineIndex - 2),
      prev1: at(activeLineIndex - 1),
      current: at(activeLineIndex),
      next1: at(activeLineIndex + 1),
      next2: at(activeLineIndex + 2),
    }
  }, [activeLineIndex, transcript])

  const getPlayerElement = useCallback((): HTMLMediaElement | null => {
    return isVideo ? videoRef.current : audioRef.current
  }, [isVideo])

  const stopClipPlaybackLoop = useCallback(() => {
    if (clipRafRef.current) {
      cancelAnimationFrame(clipRafRef.current)
      clipRafRef.current = null
    }
    clipFinishRef.current?.()
    clipFinishRef.current = null
    setActiveClipPlaybackId(null)
  }, [])

  const revokeMediaUrl = useCallback(() => {
    if (blobUrlRef.current) {
      URL.revokeObjectURL(blobUrlRef.current)
      blobUrlRef.current = null
    }
  }, [])

  const loadMediaForTranscript = useCallback(async (record: ViewerTranscript) => {
    if (appVariant !== 'criminal') return

    revokeMediaUrl()
    setMediaLoading(true)

    const handleId = record.media_handle_id || record.media_key
    const objectUrl = await getMediaObjectURL(handleId)
    if (objectUrl) {
      blobUrlRef.current = objectUrl
      setMediaUrl(objectUrl)
      setMediaAvailable(true)
    } else {
      setMediaUrl(null)
      setMediaAvailable(false)
    }
    setMediaLoading(false)
  }, [appVariant, revokeMediaUrl])

  const loadCaseArtifacts = useCallback(async (caseId: string) => {
    if (appVariant !== 'criminal') {
      setClips([])
      setSequences([])
      return
    }

    setClipsLoading(true)
    try {
      const [caseClips, caseSequences] = await Promise.all([
        listCaseClips(caseId),
        listCaseSequences(caseId),
      ])
      setClips(caseClips)
      setSequences(caseSequences)
    } finally {
      setClipsLoading(false)
    }
  }, [appVariant])

  const loadTranscriptByKey = useCallback(async (mediaKey: string, silent = false) => {
    if (appVariant !== 'criminal') {
      if (!silent) setIsLoading(false)
      return null
    }

    if (!silent) {
      setIsLoading(true)
      setError('')
    }

    try {
      let record = transcriptCacheRef.current[mediaKey]
      if (!record) {
        const raw = await getTranscript(mediaKey)
        if (!raw) throw new Error('Transcript not found')
        record = normalizeTranscript(raw, mediaKey)
        transcriptCacheRef.current[mediaKey] = record
      }

      setTranscript(record)
      setCurrentMediaKey(record.media_key)
      setDuration(record.audio_duration || 0)
      setCurrentTime(0)
      setActiveLineId(null)
      setSelectedLineId(null)
      setActiveMediaKey(record.media_key)
      setAutoFollow(true)
      setShowReturnToCurrent(false)
      await loadMediaForTranscript(record)

      return record
    } catch (err: unknown) {
      const message = err instanceof Error ? err.message : 'Failed to load transcript'
      setError(message)
      return null
    } finally {
      if (!silent) setIsLoading(false)
    }
  }, [appVariant, loadMediaForTranscript, setActiveMediaKey])

  useEffect(() => {
    if (queryMediaKey) {
      setCurrentMediaKey(queryMediaKey)
      return
    }
    if (activeMediaKey) {
      setCurrentMediaKey(activeMediaKey)
    }
  }, [queryMediaKey, activeMediaKey])

  useEffect(() => {
    if (appVariant !== 'criminal') {
      setIsLoading(false)
      return
    }

    if (!currentMediaKey) {
      setIsLoading(false)
      return
    }

    loadTranscriptByKey(currentMediaKey)
  }, [appVariant, currentMediaKey, loadTranscriptByKey])

  useEffect(() => {
    if (appVariant !== 'criminal') {
      setClips([])
      setSequences([])
      return
    }

    if (!effectiveCaseId) {
      setClips([])
      setSequences([])
      return
    }
    loadCaseArtifacts(effectiveCaseId)
  }, [appVariant, effectiveCaseId, loadCaseArtifacts])

  useEffect(() => {
    setSequenceNameDrafts((prev) => {
      const next: Record<string, string> = {}
      sequences.forEach((sequence) => {
        next[sequence.sequence_id] = prev[sequence.sequence_id] ?? sequence.name
      })
      return next
    })
  }, [sequences])

  useEffect(() => {
    localStorage.setItem('sequence-pause-behavior', sequencePauseBehavior)
  }, [sequencePauseBehavior])

  useEffect(() => {
    localStorage.setItem('sequence-clip-gap', String(clipGapSeconds))
  }, [clipGapSeconds])

  const clearPresentationUiTimer = useCallback(() => {
    if (presentationUiTimerRef.current) {
      window.clearTimeout(presentationUiTimerRef.current)
      presentationUiTimerRef.current = null
    }
  }, [])

  const revealPresentationUi = useCallback(() => {
    if (!presentationMode) return
    setPresentationUiVisible(true)
    clearPresentationUiTimer()
    presentationUiTimerRef.current = window.setTimeout(() => {
      setPresentationUiVisible(false)
      presentationUiTimerRef.current = null
    }, PRESENTATION_UI_IDLE_MS)
  }, [clearPresentationUiTimer, presentationMode])

  useEffect(() => {
    if (!presentationMode) {
      setPresentationUiVisible(false)
      clearPresentationUiTimer()
    }
  }, [clearPresentationUiTimer, presentationMode])

  useEffect(() => {
    return () => {
      revokeMediaUrl()
      stopClipPlaybackLoop()
      clearPresentationUiTimer()
      sequenceAbortRef.current = true
    }
  }, [clearPresentationUiTimer, revokeMediaUrl, stopClipPlaybackLoop])

  // WaveSurfer: initialize for audio-only playback
  useEffect(() => {
    if (isVideo || !mediaUrl || !waveformRef.current) {
      if (wavesurferRef.current) {
        wavesurferRef.current.destroy()
        wavesurferRef.current = null
      }
      return
    }

    const audioElement = audioRef.current
    if (!audioElement) return

    const ws = WaveSurfer.create({
      container: waveformRef.current,
      height: 'auto',
      waveColor: 'rgba(100, 116, 139, 0.35)',
      progressColor: 'rgba(51, 65, 85, 0.7)',
      cursorColor: 'rgba(245, 158, 11, 0.8)',
      cursorWidth: 2,
      barWidth: 2,
      barGap: 1,
      barRadius: 2,
      normalize: true,
      media: audioElement,
    })

    wavesurferRef.current = ws

    return () => {
      ws.destroy()
      wavesurferRef.current = null
    }
  // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [isVideo, mediaUrl])

  const findLineAtTime = useCallback((value: number): ViewerLine | null => {
    if (!transcript || !transcript.lines.length) return null

    let low = 0
    let high = transcript.lines.length - 1

    while (low <= high) {
      const mid = Math.floor((low + high) / 2)
      const line = transcript.lines[mid]
      if (value >= line.start && value < line.end) return line
      if (value < line.start) high = mid - 1
      else low = mid + 1
    }

    for (let index = Math.min(high, transcript.lines.length - 1); index >= 0; index -= 1) {
      const line = transcript.lines[index]
      if (value + SEARCH_TOLERANCE >= line.end) return line
    }

    return null
  }, [transcript])

  const seekToLine = useCallback((line: ViewerLine, autoplay = true) => {
    const player = getPlayerElement()
    if (!player) return
    const target = Math.max(0, line.start)
    player.currentTime = target
    if (autoplay) {
      player.play().catch(() => {
        // Ignore autoplay failures
      })
    }
  }, [getPlayerElement])

  const returnToCurrentLine = useCallback(() => {
    if (!activeLineId) return
    const target = lineRefs.current[activeLineId]
    if (!target) return

    programmaticScrollRef.current = true
    target.scrollIntoView({ behavior: 'smooth', block: 'center' })
    setAutoFollow(true)
    setShowReturnToCurrent(false)
    window.setTimeout(() => {
      programmaticScrollRef.current = false
    }, PROGRAMMATIC_SCROLL_RESET_MS)
  }, [activeLineId])

  useEffect(() => {
    if (!activeLineId || !autoFollow) return
    const target = lineRefs.current[activeLineId]
    if (!target) return

    programmaticScrollRef.current = true
    target.scrollIntoView({ behavior: 'smooth', block: 'center' })
    window.setTimeout(() => {
      programmaticScrollRef.current = false
    }, PROGRAMMATIC_SCROLL_RESET_MS)
  }, [activeLineId, autoFollow])

  useEffect(() => {
    const container = transcriptScrollRef.current
    if (!container) return

    const onScroll = () => {
      if (programmaticScrollRef.current) return
      if (autoFollow) {
        setAutoFollow(false)
        setShowReturnToCurrent(true)
      }
    }

    container.addEventListener('scroll', onScroll)
    return () => container.removeEventListener('scroll', onScroll)
  }, [autoFollow])

  const enterPresentationMode = useCallback(async () => {
    const target = viewerShellRef.current
    setPresentationMode(true)
    setPresentationUiVisible(true)
    clearPresentationUiTimer()
    presentationUiTimerRef.current = window.setTimeout(() => {
      setPresentationUiVisible(false)
      presentationUiTimerRef.current = null
    }, PRESENTATION_UI_IDLE_MS)

    if (target && !document.fullscreenElement) {
      try {
        await target.requestFullscreen()
      } catch {
        // Ignore fullscreen errors; presentation still toggles layout mode.
      }
    }
  }, [clearPresentationUiTimer])

  const exitPresentationMode = useCallback(async () => {
    sequenceAbortRef.current = true
    stopClipPlaybackLoop()
    setTitleCard(null)
    setShowBlackScreen(false)
    setWaitingForResume(false)
    if (sequenceResumeRef.current) {
      sequenceResumeRef.current()
      sequenceResumeRef.current = null
    }
    setSequenceState({ phase: 'idle' })
    setPresentationMode(false)
    setPresentationUiVisible(false)
    clearPresentationUiTimer()

    if (document.fullscreenElement) {
      try {
        await document.exitFullscreen()
      } catch {
        // Ignore exit fullscreen errors.
      }
    }
  }, [clearPresentationUiTimer, stopClipPlaybackLoop])

  useEffect(() => {
    const onKeyDown = (event: KeyboardEvent) => {
      const target = event.target as HTMLElement | null
      const tag = target?.tagName
      const typingInField =
        tag === 'INPUT' ||
        tag === 'TEXTAREA' ||
        tag === 'SELECT' ||
        target?.isContentEditable

      if ((event.metaKey || event.ctrlKey) && event.key.toLowerCase() === 'f') {
        event.preventDefault()
        searchInputRef.current?.focus()
        searchInputRef.current?.select()
        return
      }

      if (typingInField) return

      const player = getPlayerElement()
      if (!player) return

      if (event.code === 'Space') {
        event.preventDefault()
        if (sequenceResumeRef.current) {
          const resume = sequenceResumeRef.current
          sequenceResumeRef.current = null
          setWaitingForResume(false)
          resume()
          return
        }
        if (player.paused) player.play().catch(() => {})
        else player.pause()
        return
      }

      if (event.key === 'ArrowLeft') {
        event.preventDefault()
        player.currentTime = Math.max(0, player.currentTime - 5)
        return
      }

      if (event.key === 'ArrowRight') {
        event.preventDefault()
        const next = player.currentTime + 5
        if (Number.isFinite(player.duration)) player.currentTime = Math.min(player.duration, next)
        else player.currentTime = next
        return
      }

      if (event.key.toLowerCase() === 'f') {
        event.preventDefault()
        if (!presentationMode) {
          void enterPresentationMode()
        }
        return
      }

      if (event.key.toLowerCase() === 'c') {
        event.preventDefault()
        setViewerMode((prev) => (prev === 'document' ? 'caption' : 'document'))
        return
      }

      if (event.key === 'Escape' && presentationMode) {
        event.preventDefault()
        void exitPresentationMode()
      }
    }

    window.addEventListener('keydown', onKeyDown)
    return () => window.removeEventListener('keydown', onKeyDown)
  }, [enterPresentationMode, exitPresentationMode, getPlayerElement, presentationMode])

  useEffect(() => {
    if (!exportMenuOpen) return

    const onDocumentPointerDown = (event: MouseEvent) => {
      const target = event.target as Node | null
      if (!target) return
      if (exportMenuRef.current && !exportMenuRef.current.contains(target)) {
        setExportMenuOpen(false)
      }
    }

    document.addEventListener('mousedown', onDocumentPointerDown)
    return () => document.removeEventListener('mousedown', onDocumentPointerDown)
  }, [exportMenuOpen])

  useEffect(() => {
    const onFullscreenChange = () => {
      if (!document.fullscreenElement && presentationMode) {
        sequenceAbortRef.current = true
        stopClipPlaybackLoop()
        setShowBlackScreen(false)
        setWaitingForResume(false)
        if (sequenceResumeRef.current) {
          sequenceResumeRef.current()
          sequenceResumeRef.current = null
        }
        setPresentationMode(false)
        setPresentationUiVisible(false)
        clearPresentationUiTimer()
        setTitleCard(null)
        setSequenceState({ phase: 'idle' })
      }
    }
    document.addEventListener('fullscreenchange', onFullscreenChange)
    return () => document.removeEventListener('fullscreenchange', onFullscreenChange)
  }, [clearPresentationUiTimer, presentationMode, stopClipPlaybackLoop])

  const handleTimeUpdate = useCallback(() => {
    const player = getPlayerElement()
    if (!player) return
    const t = player.currentTime
    setCurrentTime(t)

    const found = findLineAtTime(t)
    setActiveLineId(found?.id || null)
  }, [findLineAtTime, getPlayerElement])

  const handleLoadedMetadata = useCallback(() => {
    const player = getPlayerElement()
    if (!player) return
    setDuration(Number.isFinite(player.duration) ? player.duration : transcript?.audio_duration || 0)
  }, [getPlayerElement, transcript?.audio_duration])

  const goToSearchResult = useCallback((direction: 1 | -1) => {
    if (!searchMatches.length) return
    setSearchCursor((prev) => {
      const next = (prev + direction + searchMatches.length) % searchMatches.length
      const lineId = searchMatches[next]

      window.requestAnimationFrame(() => {
        window.requestAnimationFrame(() => {
          const target = lineRefs.current[lineId]
          if (!target) return
          programmaticScrollRef.current = true
          target.scrollIntoView({ behavior: 'smooth', block: 'center' })
          window.setTimeout(() => {
            programmaticScrollRef.current = false
          }, PROGRAMMATIC_SCROLL_RESET_MS)
        })
      })
      return next
    })
  }, [searchMatches])

  useEffect(() => {
    setSearchCursor(0)
  }, [searchQuery])

  const relinkMedia = useCallback(async () => {
    if (!transcript) return
    const expected = transcript.media_filename || transcript.title_data?.FILE_NAME || 'media file'
    const result = await promptRelinkMedia(expected)
    if (!result) return

    await storeMediaHandle(result.handleId, result.handle)

    const nextTranscript: ViewerTranscript = {
      ...transcript,
      media_handle_id: result.handleId,
    }

    const caseId = transcript.case_id && String(transcript.case_id).trim()
      ? String(transcript.case_id)
      : undefined

    await saveTranscript(transcript.media_key, nextTranscript, caseId)
    transcriptCacheRef.current[transcript.media_key] = nextTranscript
    setTranscript(nextTranscript)
    await loadMediaForTranscript(nextTranscript)
  }, [loadMediaForTranscript, transcript])

  const nearestLineFromTime = useCallback((value: number): ViewerLine | null => {
    if (!transcript) return null
    let best: ViewerLine | null = null
    let bestDistance = Number.POSITIVE_INFINITY
    for (const line of transcript.lines as ViewerLine[]) {
      const center = (line.start + line.end) / 2
      const distance = Math.abs(center - value)
      if (distance < bestDistance) {
        best = line
        bestDistance = distance
      }
    }
    return best
  }, [transcript])

  const persistClipOrder = useCallback(async (orderedVisibleClips: ClipRecord[]) => {
    if (!effectiveCaseId) return

    const orderMap = new Map<string, number>()
    orderedVisibleClips.forEach((clip, idx) => {
      orderMap.set(clip.clip_id, idx)
    })

    const updatedAll = clips.map((clip, idx) => {
      if (orderMap.has(clip.clip_id)) {
        return { ...clip, order: orderMap.get(clip.clip_id) }
      }
      const base = Number.isFinite(clip.order) ? Number(clip.order) : idx + orderedVisibleClips.length
      return { ...clip, order: base + orderedVisibleClips.length }
    })

    await Promise.all(updatedAll.map(async (clip) => {
      await saveClip(effectiveCaseId, clip)
    }))

    await loadCaseArtifacts(effectiveCaseId)
  }, [clips, effectiveCaseId, loadCaseArtifacts])

  const createClip = useCallback(async () => {
    setClipError('')
    if (!transcript || !currentMediaKey || !effectiveCaseId) {
      setClipError('Clips are available only for transcripts assigned to a case.')
      return
    }

    const startVal = parseTimeInput(clipStart)
    const endVal = parseTimeInput(clipEnd)

    if (startVal === null || endVal === null) {
      setClipError('Enter valid start and end times (M:SS or H:MM:SS).')
      return
    }

    const maxDuration = duration || transcript.audio_duration || Number.MAX_SAFE_INTEGER
    const start = Math.max(0, Math.min(startVal, maxDuration))
    const end = Math.max(0, Math.min(endVal, maxDuration))

    if (end <= start) {
      setClipError('End time must be greater than start time.')
      return
    }

    const startLine = nearestLineFromTime(start)
    const endLine = nearestLineFromTime(end)

    const maxOrder = clips.reduce((max, clip) => {
      const order = Number.isFinite(clip.order) ? Number(clip.order) : max
      return Math.max(max, order)
    }, -1)

    const clip: ClipRecord = {
      clip_id: crypto.randomUUID(),
      name: clipName.trim() || `Clip ${clips.length + 1}`,
      source_media_key: currentMediaKey,
      start_time: start,
      end_time: end,
      start_pgln: startLine ? (startLine.pgln ?? null) : null,
      end_pgln: endLine ? (endLine.pgln ?? null) : null,
      start_page: startLine ? (startLine.page ?? null) : null,
      start_line: startLine ? (startLine.line ?? null) : null,
      end_page: endLine ? (endLine.page ?? null) : null,
      end_line: endLine ? (endLine.line ?? null) : null,
      created_at: new Date().toISOString(),
      order: maxOrder + 1,
    }

    await saveClip(effectiveCaseId, clip)
    await loadCaseArtifacts(effectiveCaseId)

    setClipName('')
    setClipStart('')
    setClipEnd('')
  }, [clipEnd, clipName, clipStart, clips, currentMediaKey, duration, effectiveCaseId, loadCaseArtifacts, nearestLineFromTime, transcript])

  const startEditingClip = useCallback((clip: ClipRecord) => {
    setEditingClipId(clip.clip_id)
    setEditClipName(clip.name)
    setEditClipStart(formatClock(clip.start_time))
    setEditClipEnd(formatClock(clip.end_time))
  }, [])

  const saveEditedClip = useCallback(async () => {
    setClipError('')
    if (!effectiveCaseId || !editingClipId) return
    const existing = clips.find((clip) => clip.clip_id === editingClipId)
    if (!existing) return

    const startVal = parseTimeInput(editClipStart)
    const endVal = parseTimeInput(editClipEnd)
    if (startVal === null || endVal === null || endVal <= startVal) {
      setClipError('Provide a valid clip range before saving.')
      return
    }

    const updated: ClipRecord = {
      ...existing,
      name: editClipName.trim() || existing.name,
      start_time: startVal,
      end_time: endVal,
      updated_at: new Date().toISOString(),
    }

    await saveClip(effectiveCaseId, updated)
    await loadCaseArtifacts(effectiveCaseId)
    setEditingClipId(null)
  }, [clips, editClipEnd, editClipName, editClipStart, editingClipId, effectiveCaseId, loadCaseArtifacts])

  const removeClip = useCallback(async (clip: ClipRecord) => {
    setClipError('')
    if (!effectiveCaseId) return
    if (!window.confirm(`Delete clip "${clip.name}"?`)) return
    await deleteClip(effectiveCaseId, clip.clip_id)
    await loadCaseArtifacts(effectiveCaseId)
  }, [effectiveCaseId, loadCaseArtifacts])

  const playRange = useCallback(async (start: number, end: number, clipId?: string) => {
    const player = getPlayerElement()
    if (!player) return

    sequenceAbortRef.current = false
    stopClipPlaybackLoop()
    player.currentTime = Math.max(0, start)
    setActiveClipPlaybackId(clipId || null)

    try {
      await player.play()
    } catch {
      setActiveClipPlaybackId(null)
      return
    }

    await new Promise<void>((resolve) => {
      let resolved = false
      const finish = () => {
        if (resolved) return
        resolved = true
        player.pause()
        clipFinishRef.current = null
        if (clipRafRef.current) {
          cancelAnimationFrame(clipRafRef.current)
          clipRafRef.current = null
        }
        setActiveClipPlaybackId(null)
        resolve()
      }

      clipFinishRef.current = finish

      const tick = () => {
        if (resolved) return
        if (sequenceAbortRef.current || player.currentTime >= end || player.ended) {
          finish()
          return
        }
        clipRafRef.current = requestAnimationFrame(tick)
      }

      clipRafRef.current = requestAnimationFrame(tick)
    })
  }, [getPlayerElement, stopClipPlaybackLoop])

  const playClip = useCallback(async (clip: ClipRecord) => {
    setClipError('')
    if (!currentMediaKey || !effectiveCaseId) return

    if (clip.source_media_key !== currentMediaKey) {
      const openOther = window.confirm('This clip belongs to another recording. Open that recording in Viewer now?')
      if (openOther) {
        guardedPush(router, routes.viewer(clip.source_media_key, effectiveCaseId))
      }
      return
    }

    await playRange(clip.start_time, clip.end_time, clip.clip_id)
  }, [currentMediaKey, effectiveCaseId, playRange, router])

  const reorderVisibleClips = useCallback(async (sourceClipId: string, targetClipId: string) => {
    setClipError('')
    const list = [...visibleClips]
    const fromIdx = list.findIndex((clip) => clip.clip_id === sourceClipId)
    const toIdx = list.findIndex((clip) => clip.clip_id === targetClipId)
    if (fromIdx < 0 || toIdx < 0 || fromIdx === toIdx) return

    const [moved] = list.splice(fromIdx, 1)
    list.splice(toIdx, 0, moved)

    await persistClipOrder(list)
  }, [persistClipOrder, visibleClips])

  const createSequence = useCallback(async () => {
    setSequenceError('')
    if (!effectiveCaseId) {
      setSequenceError('Sequences are available only for case transcripts.')
      return
    }

    const name = newSequenceName.trim() || `Sequence ${sequences.length + 1}`
    const now = new Date().toISOString()

    const sequence: ClipSequenceRecord = {
      sequence_id: crypto.randomUUID(),
      name,
      created_at: now,
      updated_at: now,
      entries: [],
    }

    await saveSequence(effectiveCaseId, sequence)
    await loadCaseArtifacts(effectiveCaseId)
    setNewSequenceName('')
    setSelectedSequenceId(sequence.sequence_id)
  }, [effectiveCaseId, loadCaseArtifacts, newSequenceName, sequences.length])

  const removeSequence = useCallback(async (sequence: ClipSequenceRecord) => {
    if (!effectiveCaseId) return
    if (!window.confirm(`Delete sequence "${sequence.name}"?`)) return
    await deleteSequence(effectiveCaseId, sequence.sequence_id)
    await loadCaseArtifacts(effectiveCaseId)
    if (selectedSequenceId === sequence.sequence_id) {
      setSelectedSequenceId(null)
    }
  }, [effectiveCaseId, loadCaseArtifacts, selectedSequenceId])

  const renameSequence = useCallback(async (sequence: ClipSequenceRecord, nextName: string) => {
    if (!effectiveCaseId) return
    const trimmed = nextName.trim()
    if (!trimmed) return

    const updated: ClipSequenceRecord = {
      ...sequence,
      name: trimmed,
      updated_at: new Date().toISOString(),
    }

    await saveSequence(effectiveCaseId, updated)
    await loadCaseArtifacts(effectiveCaseId)
  }, [effectiveCaseId, loadCaseArtifacts])

  const commitSequenceRename = useCallback(async (sequence: ClipSequenceRecord) => {
    const draftName = sequenceNameDrafts[sequence.sequence_id] ?? sequence.name
    const trimmed = draftName.trim()
    if (!trimmed) {
      setSequenceNameDrafts((prev) => ({ ...prev, [sequence.sequence_id]: sequence.name }))
      return
    }
    if (trimmed === sequence.name) return
    await renameSequence(sequence, trimmed)
  }, [renameSequence, sequenceNameDrafts])

  const addClipToSequence = useCallback(async (sequence: ClipSequenceRecord, clipId: string) => {
    if (!effectiveCaseId) return
    const clip = clips.find((item) => item.clip_id === clipId)
    if (!clip) return

    const nextEntries: ClipSequenceEntry[] = [
      ...sequence.entries,
      {
        clip_id: clip.clip_id,
        source_media_key: clip.source_media_key,
        order: sequence.entries.length,
      },
    ]

    await saveSequence(effectiveCaseId, {
      ...sequence,
      entries: nextEntries,
      updated_at: new Date().toISOString(),
    })
    await loadCaseArtifacts(effectiveCaseId)
  }, [clips, effectiveCaseId, loadCaseArtifacts])

  const removeSequenceEntry = useCallback(async (sequence: ClipSequenceRecord, index: number) => {
    if (!effectiveCaseId) return

    const nextEntries = sequence.entries
      .filter((_, idx) => idx !== index)
      .map((entry, idx) => ({ ...entry, order: idx }))

    await saveSequence(effectiveCaseId, {
      ...sequence,
      entries: nextEntries,
      updated_at: new Date().toISOString(),
    })
    await loadCaseArtifacts(effectiveCaseId)
  }, [effectiveCaseId, loadCaseArtifacts])

  const moveSequenceEntry = useCallback(async (sequence: ClipSequenceRecord, from: number, to: number) => {
    if (!effectiveCaseId) return
    if (to < 0 || to >= sequence.entries.length) return

    const next = [...sequence.entries]
    const [moved] = next.splice(from, 1)
    next.splice(to, 0, moved)

    const normalized = next.map((entry, idx) => ({ ...entry, order: idx }))
    await saveSequence(effectiveCaseId, {
      ...sequence,
      entries: normalized,
      updated_at: new Date().toISOString(),
    })
    await loadCaseArtifacts(effectiveCaseId)
  }, [effectiveCaseId, loadCaseArtifacts])

  const waitForCanPlay = useCallback(async () => {
    await sleep(50)
    const player = getPlayerElement()
    if (!player) return

    if (player.readyState >= 2) return

    await new Promise<void>((resolve, reject) => {
      const timer = window.setTimeout(() => {
        cleanup()
        reject(new Error('Media loading timed out.'))
      }, 15000)

      const cleanup = () => {
        window.clearTimeout(timer)
        player.removeEventListener('canplay', onReady)
        player.removeEventListener('error', onError)
      }

      const onReady = () => {
        cleanup()
        resolve()
      }

      const onError = () => {
        cleanup()
        const error = player.error
        reject(new Error(`Media failed to load (code ${error?.code ?? 'unknown'}).`))
      }

      player.addEventListener('canplay', onReady)
      player.addEventListener('error', onError)
    })
  }, [getPlayerElement])

  const waitForUserResume = useCallback((): Promise<void> => {
    return new Promise<void>((resolve) => {
      if (sequenceAbortRef.current) {
        resolve()
        return
      }
      setWaitingForResume(true)
      sequenceResumeRef.current = () => {
        setWaitingForResume(false)
        resolve()
      }
    })
  }, [])

  const runSequencePresentation = useCallback(async (sequence: ClipSequenceRecord) => {
    if (!sequence.entries.length) {
      setSequenceError('Select clips before presenting this sequence.')
      return
    }

    setSequenceError('')
    sequenceAbortRef.current = false
    await enterPresentationMode()

    try {
      const orderedEntries = [...sequence.entries].sort((a, b) => a.order - b.order)
      let activeTranscriptKey = currentMediaKey
      const pauseMode = sequencePauseBehavior

      // Pre-load transcript display names for title cards
      const transcriptNames: Record<string, string> = {}
      for (const entry of orderedEntries) {
        const key = entry.source_media_key
        if (transcriptNames[key] !== undefined) continue
        const cached = transcriptCacheRef.current[key]
        if (cached) {
          transcriptNames[key] = cached.title_data?.FILE_NAME || cached.media_filename || ''
        } else {
          try {
            const raw = await getTranscript(key)
            if (raw) {
              const normalized = normalizeTranscript(raw, key)
              transcriptCacheRef.current[key] = normalized
              transcriptNames[key] = normalized.title_data?.FILE_NAME || normalized.media_filename || ''
            } else {
              transcriptNames[key] = ''
            }
          } catch {
            transcriptNames[key] = ''
          }
        }
      }

      for (let clipIndex = 0; clipIndex < orderedEntries.length; clipIndex += 1) {
        if (sequenceAbortRef.current) break
        const entry = orderedEntries[clipIndex]
        const clip = clips.find((item) => item.clip_id === entry.clip_id)
        if (!clip) continue

        const mediaName = transcriptNames[clip.source_media_key] || ''

        // --- Black screen pause (before title card) ---
        if (pauseMode === 'black-screen') {
          setShowBlackScreen(true)
          setSequenceState({ phase: 'title-card', sequenceId: sequence.sequence_id, clipIndex })
          await waitForUserResume()
          setShowBlackScreen(false)
          if (sequenceAbortRef.current) break
        }

        // --- Title card ---
        setSequenceState({ phase: 'title-card', sequenceId: sequence.sequence_id, clipIndex })
        setTitleCard({
          visible: true,
          title: clip.name,
          meta: `Clip ${clipIndex + 1} of ${orderedEntries.length} — ${formatRange(clip.start_time, clip.end_time)}`,
          subtitle: mediaName || undefined,
        })

        if (pauseMode === 'title-card') {
          await waitForUserResume()
          if (sequenceAbortRef.current) break
        } else {
          await sleep(3000)
          if (sequenceAbortRef.current) break
        }

        setTitleCard(null)
        setSequenceState({ phase: 'transitioning', sequenceId: sequence.sequence_id, clipIndex })

        // --- Load transcript/media if different recording ---
        if (clip.source_media_key !== activeTranscriptKey) {
          const loaded = await loadTranscriptByKey(clip.source_media_key, true)
          if (!loaded) continue
          await sleep(100)
          await waitForCanPlay()
          activeTranscriptKey = clip.source_media_key
        }

        setSequenceState({ phase: 'playing', sequenceId: sequence.sequence_id, clipIndex })

        await playRange(clip.start_time, clip.end_time, clip.clip_id)

        // Gap between clips in continuous mode
        if (pauseMode === 'continuous' && clipGapSeconds > 0) {
          await sleep(clipGapSeconds * 1000)
        }
      }

      if (!sequenceAbortRef.current) {
        setSequenceState({ phase: 'finished', sequenceId: sequence.sequence_id })
        setTitleCard({
          visible: true,
          title: 'End of Presentation',
          meta: sequence.name,
        })
        await sleep(2000)
      }
    } catch (err: unknown) {
      const message = err instanceof Error ? err.message : 'Sequence presentation failed'
      setSequenceError(message)
      sequenceAbortRef.current = true
    } finally {
      setTitleCard(null)
      setShowBlackScreen(false)
      setWaitingForResume(false)
      sequenceResumeRef.current = null
      await exitPresentationMode()
    }
  }, [clipGapSeconds, clips, currentMediaKey, enterPresentationMode, exitPresentationMode, loadTranscriptByKey, playRange, sequencePauseBehavior, waitForCanPlay, waitForUserResume])

  const excerptLinesForClip = useCallback((record: ViewerTranscript, clip: ClipRecord) => {
    return record.lines.filter(
      (line) => line.end >= clip.start_time - SEARCH_TOLERANCE && line.start <= clip.end_time + SEARCH_TOLERANCE,
    )
  }, [])

  const requestClipPdfBlob = useCallback(async (record: ViewerTranscript, clip: ClipRecord) => {
    const lineEntries = excerptLinesForClip(record, clip)
    if (!lineEntries.length) {
      throw new Error('No transcript lines overlap this clip range.')
    }

    const response = await authenticatedFetch('/api/format-pdf', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        title_data: record.title_data,
        lines_per_page: record.lines_per_page,
        line_entries: lineEntries,
      }),
    })

    if (!response.ok) {
      const detail = await response.json().catch(() => ({}))
      throw new Error(detail?.detail || 'Failed to export clip PDF')
    }

    return response.blob()
  }, [excerptLinesForClip])

  const downloadBlob = useCallback((blob: Blob, filename: string) => {
    const objectUrl = URL.createObjectURL(blob)
    const a = document.createElement('a')
    a.href = objectUrl
    a.download = filename
    document.body.appendChild(a)
    a.click()
    document.body.removeChild(a)
    URL.revokeObjectURL(objectUrl)
  }, [])

  const exportClipPdf = useCallback(async (clip: ClipRecord) => {
    if (!transcript) return
    setClipError('')
    setExporting(true)
    try {
      const record = clip.source_media_key === transcript.media_key
        ? transcript
        : transcriptCacheRef.current[clip.source_media_key] || null

      const transcriptRecord = record || await loadTranscriptByKey(clip.source_media_key, true)
      if (!transcriptRecord) {
        throw new Error('Unable to load transcript for clip export.')
      }

      const blob = await requestClipPdfBlob(transcriptRecord, clip)
      const filename = sanitizeFilename(`${clip.name || 'clip'}-${clip.clip_id}`)
      downloadBlob(blob, `${filename}.pdf`)
    } catch (err: unknown) {
      const message = err instanceof Error ? err.message : 'Failed to export clip PDF'
      setClipError(message)
    } finally {
      setExporting(false)
    }
  }, [downloadBlob, loadTranscriptByKey, requestClipPdfBlob, transcript])

  const exportSequenceZip = useCallback(async (sequence: ClipSequenceRecord) => {
    setExporting(true)
    setSequenceError('')

    try {
      const zip = new JSZip()
      const folder = zip.folder(sanitizeFilename(sequence.name))
      if (!folder) throw new Error('Failed to initialize zip output')

      const orderedEntries = [...sequence.entries].sort((a, b) => a.order - b.order)
      let exportIndex = 1

      for (const entry of orderedEntries) {
        const clip = clips.find((item) => item.clip_id === entry.clip_id)
        if (!clip) continue

        const transcriptRecord = transcriptCacheRef.current[entry.source_media_key] || await loadTranscriptByKey(entry.source_media_key, true)
        if (!transcriptRecord) continue

        const pdfBlob = await requestClipPdfBlob(transcriptRecord, clip)
        const index = String(exportIndex).padStart(2, '0')
        const baseName = sanitizeFilename(clip.name || `clip-${clip.clip_id}`)
        folder.file(`${index}-${baseName}.pdf`, pdfBlob)
        exportIndex += 1
      }

      const output = await zip.generateAsync({ type: 'blob' })
      downloadBlob(output, `${sanitizeFilename(sequence.name)}.zip`)
      setSequenceError('Media clip files are disabled until ffmpeg worker integration is merged.')
    } catch (err: unknown) {
      const message = err instanceof Error ? err.message : 'Failed to export sequence zip'
      setSequenceError(message)
    } finally {
      setExporting(false)
    }
  }, [clips, downloadBlob, loadTranscriptByKey, requestClipPdfBlob])

  const getViewerTemplate = useCallback(async () => {
    if (templateCacheRef.current) return templateCacheRef.current

    const response = await authenticatedFetch('/api/viewer-template')
    if (!response.ok) {
      const detail = await response.json().catch(() => ({}))
      throw new Error(detail?.detail || 'Failed to fetch viewer template')
    }

    const template = await response.text()
    templateCacheRef.current = template
    return template
  }, [])

  const toBase64 = useCallback(async (file: File) => {
    const buffer = await file.arrayBuffer()
    const bytes = new Uint8Array(buffer)
    let binary = ''
    const chunkSize = 0x8000
    for (let index = 0; index < bytes.length; index += chunkSize) {
      const chunk = bytes.subarray(index, index + chunkSize)
      binary += String.fromCharCode(...Array.from(chunk))
    }
    return btoa(binary)
  }, [])

  const exportStandaloneViewer = useCallback(async () => {
    if (!transcript) return
    setExporting(true)

    try {
      const template = await getViewerTemplate()
      const payload = linesToViewerPayload(transcript)
      const transcriptJson = escapeScriptBoundary(JSON.stringify(payload))

      const mediaHandleId = transcript.media_handle_id || transcript.media_key
      const mediaFile = await getMediaFile(mediaHandleId)
      if (!mediaFile) {
        throw new Error('Media file not available. Relink media before exporting standalone viewer.')
      }

      const fileSizeMb = mediaFile.size / (1024 * 1024)
      const proceed = window.confirm(
        `This export embeds the entire media file (${fileSizeMb.toFixed(1)} MB). Continue?`,
      )
      if (!proceed) return

      const mediaBase64 = await toBase64(mediaFile)

      let html = template.replace('__TRANSCRIPT_JSON__', transcriptJson)
      const mediaTag = `<script id="media-data" type="application/octet-stream">${mediaBase64}</script>`
      const mediaPlaceholder = '<script id="media-data" type="application/octet-stream"></script>'
      const htmlWithMedia = html.replace(mediaPlaceholder, mediaTag)
      if (htmlWithMedia === html) {
        console.warn('Standalone viewer template is missing media placeholder script tag.')
        throw new Error('Standalone viewer template missing media placeholder; embedded media export failed.')
      }
      html = htmlWithMedia

      const blob = new Blob([html], { type: 'text/html' })
      const baseName = sanitizeFilename(transcript.title_data?.FILE_NAME || transcript.media_filename || transcript.media_key)
      downloadBlob(blob, `${baseName}-viewer.html`)
    } catch (err: unknown) {
      const message = err instanceof Error ? err.message : 'Failed to export standalone viewer'
      setError(message)
    } finally {
      setExporting(false)
    }
  }, [downloadBlob, getViewerTemplate, toBase64, transcript])

  const exportTranscriptPdf = useCallback(() => {
    if (!transcript?.pdf_base64) return
    const bytes = atob(transcript.pdf_base64)
    const array = new Uint8Array(bytes.length)
    for (let i = 0; i < bytes.length; i += 1) {
      array[i] = bytes.charCodeAt(i)
    }
    const mediaNameRaw = transcript.title_data?.FILE_NAME || transcript.media_filename || transcript.media_key || 'transcript'
    const mediaBaseName = sanitizeDownloadStem(String(mediaNameRaw).replace(/\.[^.]+$/, ''))
    downloadBlob(new Blob([array], { type: 'application/pdf' }), `${mediaBaseName} transcript.pdf`)
  }, [downloadBlob, transcript?.media_filename, transcript?.media_key, transcript?.pdf_base64, transcript?.title_data])

  const noTranscript = !currentMediaKey

  if (appVariant !== 'criminal') {
    return (
      <div className="mx-auto max-w-3xl p-8">
        <div className="rounded-2xl border border-amber-200 bg-amber-50 p-6 text-amber-900">
          Viewer is available in the criminal variant only.
        </div>
      </div>
    )
  }

  if (noTranscript) {
    return (
      <div className="mx-auto max-w-3xl p-8">
        <div className="rounded-2xl border border-gray-200 bg-white p-8 text-center">
          <h2 className="text-xl font-semibold text-gray-900">No Transcript Selected</h2>
          <p className="mt-2 text-sm text-gray-600">Open a transcript from Cases or Recent to launch Viewer.</p>
          <Link href={routes.home()} className="btn-primary mt-6 inline-flex px-4 py-2">
            Back to Dashboard
          </Link>
        </div>
      </div>
    )
  }

  const presentationControlsVisible = !presentationMode || presentationUiVisible

  const playerSharedProps = {
    controls: presentationControlsVisible,
    src: mediaUrl || undefined,
    onTimeUpdate: handleTimeUpdate,
    onLoadedMetadata: handleLoadedMetadata,
  }

  const isDocumentMode = viewerMode === 'document'
  const toolsVisible = !presentationMode && showToolsPanel
  const mediaStatusOverlay = (
    <>
      {!mediaAvailable && (
        <div className="absolute bottom-3 left-3 right-3 rounded border border-amber-200 bg-amber-50/95 p-3 text-sm text-amber-900">
          <p className="mb-2">Media file not found.</p>
          <button type="button" onClick={() => void relinkMedia()} className="btn-outline px-3 py-1.5 text-xs">
            Locate File
          </button>
        </div>
      )}

      {mediaLoading && (
        <div className="absolute right-3 top-3 rounded border border-stone-300 bg-white/95 px-2 py-1 text-xs text-stone-700">
          Loading media...
        </div>
      )}
    </>
  )

  return (
    <div ref={viewerShellRef} className="h-full bg-gradient-to-b from-blue-50/55 via-stone-100 to-stone-200 text-stone-900">
      {showBlackScreen && (
        <div
          className="fixed inset-0 z-50 flex cursor-pointer items-center justify-center bg-black"
          onClick={() => {
            if (sequenceResumeRef.current) {
              const resume = sequenceResumeRef.current
              sequenceResumeRef.current = null
              setWaitingForResume(false)
              resume()
            }
          }}
        >
          <div className="text-sm text-white/30 select-none">Press space to continue</div>
        </div>
      )}

      {titleCard?.visible && !showBlackScreen && (
        <div
          className={`fixed inset-0 z-50 flex items-center justify-center bg-black/45 ${waitingForResume ? 'cursor-pointer' : 'pointer-events-none'}`}
          onClick={() => {
            if (sequenceResumeRef.current) {
              const resume = sequenceResumeRef.current
              sequenceResumeRef.current = null
              setWaitingForResume(false)
              resume()
            }
          }}
        >
          <div className="rounded-xl border border-stone-300 bg-stone-50/95 px-8 py-6 text-center text-stone-900 shadow-2xl">
            <div className="text-2xl font-semibold">{titleCard.title}</div>
            <div className="mt-2 text-sm text-stone-700">{titleCard.meta}</div>
            {titleCard.subtitle && (
              <div className="mt-1 text-xs text-stone-500">{titleCard.subtitle}</div>
            )}
            {waitingForResume && (
              <div className="mt-3 text-xs text-stone-400 select-none">Press space to continue</div>
            )}
          </div>
        </div>
      )}

      {!presentationMode && (
        <div className="border-b border-blue-100 bg-white/95 px-6 py-4">
          <div className="flex flex-wrap items-center justify-between gap-3">
            <div className="flex items-center gap-2">
              <button
                type="button"
                onClick={() => {
                  if (queryCaseId) {
                    guardedPush(router, routes.caseDetail(queryCaseId))
                  } else {
                    guardedPush(router, routes.home())
                  }
                }}
                className="btn-outline px-3 py-1.5 text-sm"
              >
                {queryCaseId ? 'Back to Case' : 'Back to Dashboard'}
              </button>
              <button
                type="button"
                onClick={() => {
                  if (currentMediaKey) guardedPush(router, routes.editor(currentMediaKey))
                }}
                className="btn-outline px-3 py-1.5 text-sm"
              >
                Edit Transcript
              </button>
            </div>

              <div className="flex flex-wrap items-center gap-2">
                <div className="flex items-center rounded-lg border border-blue-200 bg-blue-50/60 p-0.5">
                  <button
                    type="button"
                    className={`rounded px-2.5 py-1 text-xs font-medium ${viewerMode === 'document' ? 'bg-blue-700 text-white shadow-sm' : 'text-blue-800 hover:bg-blue-100/80'}`}
                    onClick={() => setViewerMode('document')}
                  >
                    Doc
                  </button>
                  <button
                    type="button"
                    className={`rounded px-2.5 py-1 text-xs font-medium ${viewerMode === 'caption' ? 'bg-blue-700 text-white shadow-sm' : 'text-blue-800 hover:bg-blue-100/80'}`}
                    onClick={() => setViewerMode('caption')}
                  >
                    Caption
                  </button>
                </div>

              <button
                type="button"
                className="btn-outline px-3 py-1.5 text-sm"
                onClick={() => setShowToolsPanel((prev) => !prev)}
              >
                {showToolsPanel ? 'Hide Tools' : 'Show Tools'}
              </button>

              <button
                type="button"
                className="rounded border border-blue-200 bg-blue-50 px-3 py-1.5 text-sm font-medium text-blue-900 hover:bg-blue-100 disabled:cursor-not-allowed disabled:opacity-60"
                onClick={exportTranscriptPdf}
                disabled={!transcript?.pdf_base64}
                title={transcript?.pdf_base64 ? 'Download transcript PDF' : 'PDF is not available for this transcript'}
              >
                Download PDF
              </button>

              <div ref={exportMenuRef} className="relative">
                <button
                  type="button"
                  onClick={() => setExportMenuOpen((open) => !open)}
                  className="btn-outline px-3 py-1.5 text-sm"
                >
                  Export
                </button>
                {exportMenuOpen && (
                  <div className="absolute right-0 z-20 mt-2 w-56 rounded-lg border border-gray-200 bg-white p-1 shadow-lg">
                    <button
                      type="button"
                      className="block w-full rounded px-3 py-2 text-left text-sm hover:bg-gray-50"
                      onClick={() => {
                        setExportMenuOpen(false)
                        exportTranscriptPdf()
                      }}
                      disabled={!transcript?.pdf_base64}
                    >
                      Download PDF
                    </button>
                    <button
                      type="button"
                      className="block w-full rounded px-3 py-2 text-left text-sm hover:bg-gray-50"
                      onClick={() => {
                        setExportMenuOpen(false)
                        void exportStandaloneViewer()
                      }}
                    >
                      Standalone HTML (Embedded Media)
                    </button>
                  </div>
                )}
              </div>

              <button
                type="button"
                onClick={() => {
                  setSequenceState({ phase: 'idle' })
                  void enterPresentationMode()
                }}
                className="btn-primary px-3 py-1.5 text-sm"
              >
                Present
              </button>
            </div>
          </div>

          {error && (
            <div className="mt-3 rounded-lg border border-red-200 bg-red-50 px-3 py-2 text-sm text-red-700">
              {error}
            </div>
          )}
        </div>
      )}

      <div className={`min-h-0 ${presentationMode ? 'h-screen' : 'h-[calc(100vh-74px)]'}`}>
        <div className={`grid h-full min-h-0 ${toolsVisible ? 'grid-cols-1 xl:grid-cols-[minmax(0,1fr)_360px]' : 'grid-cols-1'}`}>
          <div className={`grid h-full min-h-0 ${isDocumentMode ? 'grid-cols-1 xl:grid-cols-[minmax(340px,44%)_minmax(0,1fr)]' : 'grid-cols-1'}`}>
            <section
              className="relative flex min-h-0 flex-col bg-stone-100"
              onMouseMove={() => {
                if (presentationMode) revealPresentationUi()
              }}
              onMouseLeave={() => {
                if (presentationMode) {
                  clearPresentationUiTimer()
                  setPresentationUiVisible(false)
                }
              }}
            >
              {presentationMode && (
                <div
                  onMouseEnter={revealPresentationUi}
                  onMouseMove={revealPresentationUi}
                  className={`absolute right-4 top-4 z-30 flex items-center gap-2 transition-opacity duration-200 ${
                    presentationControlsVisible ? 'opacity-100' : 'pointer-events-none opacity-0'
                  }`}
                >
                  <div className="flex items-center rounded border border-blue-200 bg-white/95 p-0.5 shadow-sm">
                    <button
                      type="button"
                      className={`rounded px-2.5 py-1 text-xs font-medium ${viewerMode === 'document' ? 'bg-blue-700 text-white' : 'text-blue-800 hover:bg-blue-100/80'}`}
                      onClick={() => setViewerMode('document')}
                    >
                      Doc
                    </button>
                    <button
                      type="button"
                      className={`rounded px-2.5 py-1 text-xs font-medium ${viewerMode === 'caption' ? 'bg-blue-700 text-white' : 'text-blue-800 hover:bg-blue-100/80'}`}
                      onClick={() => setViewerMode('caption')}
                    >
                      Caption
                    </button>
                  </div>
                  <button
                    type="button"
                    className="rounded border border-stone-300 bg-white/95 px-3 py-1.5 text-sm text-stone-800 shadow-sm hover:bg-stone-100"
                    onClick={() => void exitPresentationMode()}
                  >
                    Exit
                  </button>
                </div>
              )}

              {!presentationMode && (
                <div className="border-b border-blue-100 bg-white/95 px-4 py-3">
                  <div className="flex flex-wrap items-center justify-between gap-3">
                    <div className="text-sm font-medium text-stone-900">
                      {transcript?.title_data?.CASE_NAME || transcript?.title_data?.FILE_NAME || transcript?.media_key}
                    </div>
                    <div className="text-xs font-medium text-blue-800/80">
                      {formatClock(currentTime)} / {formatClock(duration || transcript?.audio_duration || 0)}
                    </div>
                  </div>
                </div>
              )}

              <div className="min-h-0 flex-1 p-3">
                {isVideo ? (
                  /* Video element: layout differs by mode */
                  viewerMode === 'caption' ? (
                    <div className="flex h-full min-h-0 flex-col gap-3">
                      <div className="relative min-h-0 flex-1 rounded-xl border border-blue-200 bg-white">
                        <video
                          ref={videoRef}
                          {...playerSharedProps}
                          className="h-full w-full rounded-xl bg-black object-contain"
                        />
                        {mediaStatusOverlay}
                      </div>
                      <div className="shrink-0 max-h-[24vh] overflow-y-auto rounded-xl border border-stone-300 bg-[#fffef8] px-6 py-4 shadow-sm">
                        <div className="space-y-2 font-mono">
                          <div className="text-base text-stone-400">{captionWindow.prev2}</div>
                          <div className="text-lg text-stone-500">{captionWindow.prev1}</div>
                          <div className="rounded border border-blue-200 bg-blue-50/45 px-3 py-2 text-2xl leading-snug text-stone-900">
                            {captionWindow.current}
                          </div>
                          <div className="text-lg text-stone-500">{captionWindow.next1}</div>
                          <div className="text-base text-stone-400">{captionWindow.next2}</div>
                        </div>
                      </div>
                    </div>
                  ) : (
                    <div className="relative h-full rounded-xl border border-stone-300 bg-stone-50">
                      <video
                        ref={videoRef}
                        {...playerSharedProps}
                        className="h-full w-full rounded-xl bg-black object-contain"
                      />
                      {mediaStatusOverlay}
                    </div>
                  )
                ) : (
                  /* Audio: waveform always mounted, captions shown below in caption mode */
                  <div className="flex h-full min-h-0 flex-col gap-3">
                    <audio
                      ref={audioRef}
                      {...playerSharedProps}
                      className="hidden"
                    />
                    <div className="relative min-h-0 flex-1 rounded-xl overflow-hidden bg-gradient-to-b from-slate-800 to-slate-900">
                      <div className="absolute inset-0 flex items-center px-6">
                        <div ref={waveformRef} className="w-full" />
                      </div>
                      {mediaStatusOverlay}
                    </div>
                    {viewerMode === 'caption' && (
                      <div className="shrink-0 max-h-[24vh] overflow-y-auto rounded-xl border border-stone-300 bg-[#fffef8] px-6 py-4 shadow-sm">
                        <div className="space-y-2 font-mono">
                          <div className="text-base text-stone-400">{captionWindow.prev2}</div>
                          <div className="text-lg text-stone-500">{captionWindow.prev1}</div>
                          <div className="rounded border border-blue-200 bg-blue-50/45 px-3 py-2 text-2xl leading-snug text-stone-900">
                            {captionWindow.current}
                          </div>
                          <div className="text-lg text-stone-500">{captionWindow.next1}</div>
                          <div className="text-base text-stone-400">{captionWindow.next2}</div>
                        </div>
                      </div>
                    )}
                  </div>
                )}
              </div>
            </section>

            {isDocumentMode && (
              <section className="relative flex min-h-0 flex-col bg-gradient-to-b from-blue-50/35 to-stone-100 text-stone-900">
                {!presentationMode && (
                  <div className="px-4 pb-2 pt-3">
                    <div className="rounded-xl border border-blue-100 bg-white p-2 shadow-sm">
                      <div className="flex items-center gap-2">
                        <input
                          ref={searchInputRef}
                          className="h-9 flex-1 rounded border border-blue-200 bg-white px-3 text-sm text-gray-900 placeholder:text-gray-500 focus:border-blue-400 focus:outline-none"
                          value={searchQuery}
                          onChange={(event) => setSearchQuery(event.target.value)}
                          onKeyDown={(event) => {
                            if (event.key === 'Enter') {
                              event.preventDefault()
                              goToSearchResult(event.shiftKey ? -1 : 1)
                            }
                          }}
                          placeholder="Search transcript"
                        />
                        <button type="button" className="btn-outline border-blue-200 px-2 py-1 text-xs text-blue-800 hover:bg-blue-50" onClick={() => goToSearchResult(-1)} disabled={!searchMatches.length}>
                          Prev
                        </button>
                        <button type="button" className="btn-outline border-blue-200 px-2 py-1 text-xs text-blue-800 hover:bg-blue-50" onClick={() => goToSearchResult(1)} disabled={!searchMatches.length}>
                          Next
                        </button>
                        <span className="min-w-[54px] text-right text-xs text-blue-700/80">
                          {searchMatches.length ? `${((searchCursor % searchMatches.length) + searchMatches.length) % searchMatches.length + 1}/${searchMatches.length}` : '0/0'}
                        </span>
                      </div>
                      <div className="mt-1.5 text-[11px] text-blue-700/75">
                        Single-click selects a line. Double-click starts playback from that line.
                      </div>
                    </div>
                  </div>
                )}

                <div ref={transcriptScrollRef} className="flex-1 overflow-y-auto px-4 pb-6">
                  {showReturnToCurrent && activeLineId && (
                    <div className="sticky top-2 z-20 mb-2 flex justify-end">
                      <button type="button" className="rounded border border-blue-200 bg-blue-50 px-3 py-1 text-xs font-medium text-blue-800" onClick={returnToCurrentLine}>
                        Return to current line
                      </button>
                    </div>
                  )}

                  {isLoading ? (
                    <div className="rounded-xl border border-blue-100 bg-white px-4 py-6 text-sm text-stone-600">
                      Loading transcript...
                    </div>
                  ) : groupedPages.length === 0 ? (
                    <div className="rounded-xl border border-blue-100 bg-white px-4 py-6 text-sm text-stone-600">
                      No transcript lines available.
                    </div>
                  ) : (
                    <div className="space-y-6">
                      {groupedPages.map((pageBlock) => (
                        <div
                          key={pageBlock.page}
                          className="relative mx-auto w-full max-w-[8.5in] bg-white shadow-[0_4px_24px_rgba(15,23,42,0.12)]"
                          style={{ padding: '24px' }}
                        >
                          {/* Double page border */}
                          <div
                            className="absolute inset-0 border border-stone-400 pointer-events-none"
                            style={{ margin: '8px' }}
                          />
                          <div
                            className="absolute inset-0 border border-stone-400 pointer-events-none"
                            style={{ margin: '12px' }}
                          />

                          <div
                            className="relative font-mono"
                            style={{ fontFamily: '"Courier New", Courier, monospace' }}
                          >
                            <div>
                              {pageBlock.lines.map((line) => {
                                const active = activeLineId === line.id
                                const selected = selectedLineId === line.id
                                const match = searchMatchSet.has(line.id)
                                const currentMatch = currentSearchLineId === line.id
                                const lineDisplay = splitSpeakerPrefix(line)

                                const lineClasses = [
                                  'group grid cursor-pointer grid-cols-[36px_minmax(0,1fr)] gap-2 px-1 font-mono text-[12pt] leading-[2] text-stone-900 transition-colors hover:bg-blue-50/30',
                                  active ? 'bg-amber-100/80' : '',
                                  selected ? 'ring-1 ring-inset ring-blue-400 bg-blue-50/70' : '',
                                  match ? 'bg-amber-50' : '',
                                  currentMatch ? 'outline outline-1 outline-amber-400' : '',
                                ]

                                return (
                                  <div
                                    key={line.id}
                                    ref={(node) => {
                                      lineRefs.current[line.id] = node
                                    }}
                                    className={lineClasses.join(' ')}
                                    onClick={() => {
                                      setSelectedLineId(line.id)
                                    }}
                                    onDoubleClick={() => {
                                      setSelectedLineId(line.id)
                                      seekToLine(line, true)
                                    }}
                                  >
                                    <div className="pt-0.5 text-right text-[10px] tabular-nums text-stone-400 select-none">
                                      {line.line || '-'}
                                    </div>
                                    <div className="whitespace-pre-wrap break-words">
                                      {lineDisplay.speakerLabel ? (
                                        <>
                                          {lineDisplay.leading}
                                          <span className="font-bold text-stone-900">
                                            {lineDisplay.speakerLabel}
                                          </span>
                                          {lineDisplay.trailing}
                                        </>
                                      ) : (
                                        lineDisplay.lineText || line.text
                                      )}
                                    </div>
                                  </div>
                                )
                              })}
                            </div>

                            {/* Page number at bottom center */}
                            <div className="mt-2 text-center text-[10px] font-mono tabular-nums text-stone-500 select-none">
                              {pageBlock.page}
                            </div>
                          </div>
                        </div>
                      ))}
                    </div>
                  )}
                </div>
              </section>
            )}
          </div>

          {toolsVisible && (
            <aside className="flex h-full min-h-0 flex-col border-l border-blue-100 bg-gradient-to-b from-white to-blue-50/35">
              <div className="border-b border-blue-100 px-4 py-3">
                <div className="flex items-center justify-between">
                  <div className="text-sm font-semibold text-gray-900">Tools</div>
                  <button type="button" className="btn-outline px-2 py-1 text-xs" onClick={() => setShowToolsPanel(false)}>
                    Hide
                  </button>
                </div>
                <div className="mt-3 flex items-center rounded-lg border border-blue-200 bg-blue-50/60 p-0.5">
                  <button
                    type="button"
                    className={`flex-1 rounded px-2.5 py-1.5 text-xs font-medium ${activeToolsTab === 'clips' ? 'bg-blue-700 text-white shadow-sm' : 'text-blue-800 hover:bg-blue-100/80'}`}
                    onClick={() => setActiveToolsTab('clips')}
                  >
                    Clips
                  </button>
                  <button
                    type="button"
                    className={`flex-1 rounded px-2.5 py-1.5 text-xs font-medium ${activeToolsTab === 'sequences' ? 'bg-blue-700 text-white shadow-sm' : 'text-blue-800 hover:bg-blue-100/80'}`}
                    onClick={() => setActiveToolsTab('sequences')}
                  >
                    Sequences
                  </button>
                </div>
              </div>

              <div className="min-h-0 flex-1 overflow-y-auto p-4">
                {activeToolsTab === 'clips' ? (
                  <div className="space-y-4">
                    <div className="rounded-xl border border-gray-200 p-3">
                      <div className="mb-3 flex items-center justify-between">
                        <h3 className="text-sm font-semibold text-gray-900">Clip Builder</h3>
                        {clipsLoading && <span className="text-xs text-gray-500">Loading...</span>}
                      </div>

                      {!canEditClips && (
                        <div className="mb-3 rounded border border-amber-200 bg-amber-50 px-3 py-2 text-xs text-amber-900">
                          Clips require case context. Open this transcript from Case Detail to edit clips.
                        </div>
                      )}

                      <div className="space-y-2">
                        <input
                          type="text"
                          value={clipName}
                          onChange={(e) => setClipName(e.target.value)}
                          className="input-field h-9 w-full text-sm"
                          placeholder="Clip name"
                          disabled={!canEditClips}
                        />

                        <div className="grid grid-cols-2 gap-2">
                          <input
                            type="text"
                            value={clipStart}
                            onChange={(e) => setClipStart(e.target.value)}
                            className="input-field h-9 text-sm"
                            placeholder="Start (0:00)"
                            disabled={!canEditClips}
                          />
                          <input
                            type="text"
                            value={clipEnd}
                            onChange={(e) => setClipEnd(e.target.value)}
                            className="input-field h-9 text-sm"
                            placeholder="End (0:00)"
                            disabled={!canEditClips}
                          />
                        </div>

                        <div className="flex flex-wrap gap-2">
                          <button
                            type="button"
                            className="btn-outline px-2 py-1 text-xs"
                            disabled={!canEditClips}
                            onClick={() => setClipStart(formatClock(currentTime))}
                          >
                            Set Start
                          </button>
                          <button
                            type="button"
                            className="btn-outline px-2 py-1 text-xs"
                            disabled={!canEditClips}
                            onClick={() => setClipEnd(formatClock(currentTime))}
                          >
                            Set End
                          </button>
                          <button
                            type="button"
                            className="btn-outline px-2 py-1 text-xs"
                            disabled={!canEditClips || !selectedLineId}
                            onClick={() => {
                              const selected = transcript?.lines.find((line) => line.id === selectedLineId)
                              if (selected) setClipStart(formatClock(selected.start))
                            }}
                          >
                            Start from line
                          </button>
                          <button
                            type="button"
                            className="btn-outline px-2 py-1 text-xs"
                            disabled={!canEditClips || !selectedLineId}
                            onClick={() => {
                              const selected = transcript?.lines.find((line) => line.id === selectedLineId)
                              if (selected) setClipEnd(formatClock(selected.end))
                            }}
                          >
                            End from line
                          </button>
                        </div>

                        <button
                          type="button"
                          className="btn-primary w-full px-3 py-2 text-sm"
                          disabled={!canEditClips}
                          onClick={() => void createClip()}
                        >
                          Save Clip
                        </button>
                      </div>
                    </div>

                    {clipError && (
                      <div className="rounded border border-red-200 bg-red-50 px-3 py-2 text-xs text-red-700">
                        {clipError}
                      </div>
                    )}

                    <div className="space-y-3">
                      {groupedVisibleClips.length === 0 ? (
                        <div className="rounded border border-dashed border-gray-200 p-3 text-xs text-gray-500">
                          No clips created yet.
                        </div>
                      ) : (
                        groupedVisibleClips.map(([sourceKey, sourceClips]) => (
                          <div key={sourceKey}>
                            {queryCaseId && (
                              <div className="mb-1 text-[11px] font-semibold uppercase tracking-wide text-gray-500">
                                {sourceKey === currentMediaKey ? 'Current recording' : sourceKey}
                              </div>
                            )}
                            <div className="space-y-2">
                              {sourceClips.map((clip) => (
                                <div
                                  key={clip.clip_id}
                                  className={`rounded-lg border p-2 text-xs ${activeClipPlaybackId === clip.clip_id ? 'border-amber-300 bg-amber-50' : 'border-gray-200 bg-gray-50'}`}
                                  draggable={canEditClips}
                                  onDragStart={() => setDragClipId(clip.clip_id)}
                                  onDragOver={(event) => {
                                    if (!canEditClips) return
                                    event.preventDefault()
                                  }}
                                  onDrop={(event) => {
                                    if (!canEditClips) return
                                    event.preventDefault()
                                    if (dragClipId) {
                                      void reorderVisibleClips(dragClipId, clip.clip_id)
                                    }
                                    setDragClipId(null)
                                  }}
                                >
                                  {editingClipId === clip.clip_id ? (
                                    <div className="space-y-2">
                                      <input
                                        className="input-field h-8 w-full text-xs"
                                        value={editClipName}
                                        onChange={(e) => setEditClipName(e.target.value)}
                                      />
                                      <div className="grid grid-cols-2 gap-2">
                                        <input
                                          className="input-field h-8 text-xs"
                                          value={editClipStart}
                                          onChange={(e) => setEditClipStart(e.target.value)}
                                        />
                                        <input
                                          className="input-field h-8 text-xs"
                                          value={editClipEnd}
                                          onChange={(e) => setEditClipEnd(e.target.value)}
                                        />
                                      </div>
                                      <div className="flex gap-2">
                                        <button type="button" className="btn-primary px-2 py-1 text-xs" onClick={() => void saveEditedClip()}>
                                          Save
                                        </button>
                                        <button type="button" className="btn-outline px-2 py-1 text-xs" onClick={() => setEditingClipId(null)}>
                                          Cancel
                                        </button>
                                      </div>
                                    </div>
                                  ) : (
                                    <>
                                      <div className="font-medium text-gray-800">{clip.name}</div>
                                      <div className="mt-0.5 text-gray-600">{formatRange(clip.start_time, clip.end_time)}</div>
                                      <div className="mt-2 flex flex-wrap gap-1">
                                        <button type="button" className="btn-outline px-2 py-1 text-xs" onClick={() => void playClip(clip)}>
                                          Play
                                        </button>
                                        <button type="button" className="btn-outline px-2 py-1 text-xs" onClick={() => startEditingClip(clip)}>
                                          Edit
                                        </button>
                                        <button type="button" className="btn-outline px-2 py-1 text-xs" onClick={() => void exportClipPdf(clip)} disabled={exporting}>
                                          Export PDF
                                        </button>
                                        <button type="button" className="btn-outline px-2 py-1 text-xs text-red-700" onClick={() => void removeClip(clip)}>
                                          Delete
                                        </button>
                                      </div>
                                    </>
                                  )}
                                </div>
                              ))}
                            </div>
                          </div>
                        ))
                      )}
                    </div>
                  </div>
                ) : (
                  <div className="space-y-4">
                    <div className="rounded-xl border border-gray-200 p-3">
                      <div className="mb-3 flex items-center justify-between">
                        <h3 className="text-sm font-semibold text-gray-900">Sequences</h3>
                      </div>

                      <label className="mb-3 block text-xs text-gray-700">
                        <span className="mb-1 block font-medium">Between clips</span>
                        <select
                          className="w-full rounded-lg border border-primary-300 bg-white px-2 py-1.5 text-xs shadow-sm focus:border-primary-500 focus:ring-2 focus:ring-primary-500"
                          value={sequencePauseBehavior}
                          onChange={(e) => setSequencePauseBehavior(e.target.value as SequencePauseBehavior)}
                        >
                          <option value="black-screen">Pause on black screen</option>
                          <option value="title-card">Pause on title card</option>
                          <option value="continuous">Play continuously</option>
                        </select>
                      </label>

                      {sequencePauseBehavior === 'continuous' && (
                        <label className="mb-3 block text-xs text-gray-700">
                          <span className="mb-1 block font-medium">Gap between clips (seconds)</span>
                          <input
                            type="number"
                            min="0"
                            max="30"
                            step="0.5"
                            className="w-full rounded-lg border border-primary-300 bg-white px-2 py-1.5 text-xs shadow-sm focus:border-primary-500 focus:ring-2 focus:ring-primary-500"
                            value={clipGapSeconds}
                            onChange={(e) => {
                              const val = Number(e.target.value)
                              if (Number.isFinite(val) && val >= 0) setClipGapSeconds(val)
                            }}
                          />
                        </label>
                      )}

                      {sequenceState.phase !== 'idle' && (
                        <div className="mb-2 text-xs text-primary-700">
                          Playback: {sequenceState.phase}
                        </div>
                      )}

                      <div className="space-y-2">
                        <input
                          className="input-field h-9 w-full text-sm"
                          value={newSequenceName}
                          onChange={(e) => setNewSequenceName(e.target.value)}
                          placeholder="New sequence name"
                          disabled={!canEditClips}
                        />
                        <button
                          type="button"
                          className="btn-primary w-full px-3 py-1.5 text-sm"
                          disabled={!canEditClips}
                          onClick={() => void createSequence()}
                        >
                          Create Sequence
                        </button>
                      </div>
                    </div>

                    {sequenceError && (
                      <div className="rounded border border-amber-200 bg-amber-50 px-3 py-2 text-xs text-amber-900">
                        {sequenceError}
                      </div>
                    )}

                    <div className="space-y-2">
                      {sequences.length === 0 ? (
                        <div className="rounded border border-dashed border-gray-200 p-3 text-xs text-gray-500">
                          No sequences yet.
                        </div>
                      ) : (
                        sequences.map((sequence) => {
                          const ordered = [...sequence.entries].sort((a, b) => a.order - b.order)
                          const totalDuration = ordered.reduce((total, entry) => {
                            const clip = clips.find((item) => item.clip_id === entry.clip_id)
                            if (!clip) return total
                            return total + Math.max(0, clip.end_time - clip.start_time)
                          }, 0)

                          return (
                            <div key={sequence.sequence_id} className="rounded-lg border border-gray-200 bg-gray-50 p-2">
                              <div className="flex items-center justify-between gap-2">
                                <button
                                  type="button"
                                  onClick={() => setSelectedSequenceId((prev) => prev === sequence.sequence_id ? null : sequence.sequence_id)}
                                  className="flex-1 text-left"
                                >
                                  <div className="text-xs font-semibold text-gray-900">{sequence.name}</div>
                                  <div className="text-[11px] text-gray-600">
                                    {ordered.length} clips • {formatClock(totalDuration)}
                                  </div>
                                </button>
                                <button
                                  type="button"
                                  className="btn-outline px-2 py-1 text-xs"
                                  onClick={() => void runSequencePresentation(sequence)}
                                >
                                  Present
                                </button>
                                <button
                                  type="button"
                                  className="btn-outline px-2 py-1 text-xs"
                                  onClick={() => void exportSequenceZip(sequence)}
                                  disabled={exporting}
                                >
                                  ZIP
                                </button>
                                <button
                                  type="button"
                                  className="btn-outline px-2 py-1 text-xs text-red-700"
                                  onClick={() => void removeSequence(sequence)}
                                >
                                  Delete
                                </button>
                              </div>

                              {selectedSequenceId === sequence.sequence_id && (
                                <div className="mt-2 space-y-2 border-t border-gray-200 pt-2">
                                  <input
                                    className="input-field h-8 w-full text-xs"
                                    value={sequenceNameDrafts[sequence.sequence_id] ?? sequence.name}
                                    onChange={(event) => {
                                      const nextName = event.target.value
                                      setSequenceNameDrafts((prev) => ({ ...prev, [sequence.sequence_id]: nextName }))
                                    }}
                                    onBlur={() => {
                                      void commitSequenceRename(sequence)
                                    }}
                                    onKeyDown={(event) => {
                                      if (event.key === 'Enter') {
                                        event.preventDefault()
                                        event.currentTarget.blur()
                                      }
                                    }}
                                  />

                                  <select
                                    className="w-full rounded-lg border border-primary-300 bg-white px-2 py-1.5 text-xs shadow-sm focus:border-primary-500 focus:ring-2 focus:ring-primary-500"
                                    onChange={(event) => {
                                      const value = event.target.value
                                      if (value) {
                                        void addClipToSequence(sequence, value)
                                        event.target.value = ''
                                      }
                                    }}
                                  >
                                    <option value="">Add clip...</option>
                                    {clips.map((clip) => (
                                      <option key={clip.clip_id} value={clip.clip_id}>
                                        {clip.name} ({formatRange(clip.start_time, clip.end_time)})
                                      </option>
                                    ))}
                                  </select>

                                  <div className="space-y-1">
                                    {ordered.map((entry, index) => {
                                      const clip = clips.find((item) => item.clip_id === entry.clip_id)
                                      if (!clip) return null

                                      return (
                                        <div key={`${entry.clip_id}-${index}`} className="flex items-center gap-1 rounded border border-gray-200 bg-white px-2 py-1">
                                          <div className="min-w-0 flex-1">
                                            <div className="truncate text-xs font-medium text-gray-800">{clip.name}</div>
                                            <div className="text-[11px] text-gray-600">{formatRange(clip.start_time, clip.end_time)}</div>
                                          </div>
                                          <button
                                            type="button"
                                            className="btn-outline px-1.5 py-0.5 text-[11px]"
                                            onClick={() => void moveSequenceEntry(sequence, index, index - 1)}
                                            disabled={index === 0}
                                          >
                                            ↑
                                          </button>
                                          <button
                                            type="button"
                                            className="btn-outline px-1.5 py-0.5 text-[11px]"
                                            onClick={() => void moveSequenceEntry(sequence, index, index + 1)}
                                            disabled={index === ordered.length - 1}
                                          >
                                            ↓
                                          </button>
                                          <button
                                            type="button"
                                            className="btn-outline px-1.5 py-0.5 text-[11px] text-red-700"
                                            onClick={() => void removeSequenceEntry(sequence, index)}
                                          >
                                            x
                                          </button>
                                        </div>
                                      )
                                    })}
                                  </div>
                                </div>
                              )}
                            </div>
                          )
                        })
                      )}
                    </div>
                  </div>
                )}
              </div>
            </aside>
          )}
        </div>
      </div>
    </div>
  )
}
===== END FILE =====

===== FILE: frontend-next/src/app/globals.css =====
@tailwind base;
@tailwind components;
@tailwind utilities;

@import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');

@layer base {
  html,
  body {
    @apply font-sans antialiased text-primary-900 bg-primary-50;
  }
}

@layer components {
  .btn-primary {
    @apply bg-primary-900 text-white px-6 py-3 rounded-lg font-medium hover:bg-primary-800 transition-all duration-200 disabled:opacity-50 disabled:cursor-not-allowed shadow-lg hover:shadow-xl;
  }
  
  .btn-secondary {
    @apply bg-white text-primary-900 border-2 border-primary-300 px-6 py-3 rounded-lg font-medium hover:border-primary-400 hover:bg-primary-100 transition-all duration-200 shadow-sm;
  }

  .btn-outline {
    @apply border border-primary-400 text-primary-700 px-4 py-2 rounded-lg font-medium bg-white hover:bg-primary-100 transition-all duration-200 disabled:opacity-50 disabled:cursor-not-allowed;
  }

  .input {
    @apply w-full px-3 py-2.5 border border-primary-300 rounded-md focus:ring-2 focus:ring-primary-500 focus:border-primary-500 bg-white text-base;
  }

  .textarea {
    @apply w-full px-3 py-2.5 border border-primary-300 rounded-md focus:ring-2 focus:ring-primary-500 focus:border-primary-500 bg-white text-base;
  }
  
  .input-field {
    @apply w-full px-4 py-3 border border-primary-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500 transition-all duration-200 bg-white shadow-sm text-base;
  }
  
  .card {
    @apply bg-white border border-primary-200 rounded-xl shadow-lg hover:shadow-xl transition-shadow duration-200;
  }
  
  .card-header {
    @apply px-6 py-4 border-b border-primary-200 bg-primary-700 text-white rounded-t-xl;
  }
  
  .card-body {
    @apply px-6 py-6;
  }
}
===== END FILE =====

===== FILE: frontend-next/src/app/layout.tsx =====
import type { Metadata, Viewport } from 'next'
import './globals.css'
import AuthProvider from '@/components/AuthProvider'
import ServiceWorkerRegistrar from '@/components/ServiceWorkerRegistrar'

export const metadata: Metadata = {
  title: 'TranscribeAlpha - Legal Transcript Generator',
  description: 'Professional legal transcript generation using AssemblyAI',
  manifest: '/manifest.json',
}

export const viewport: Viewport = {
  themeColor: '#0f172a',
}

export default function RootLayout({
  children,
}: {
  children: React.ReactNode
}) {
  return (
    <html lang="en">
      <body>
        <AuthProvider>
          {children}
        </AuthProvider>
        <ServiceWorkerRegistrar />
      </body>
    </html>
  )
}
===== END FILE =====

===== FILE: frontend-next/src/components/AuthProvider.tsx =====
"use client";

import React, { useEffect, useState } from 'react';
import LoginModal from './LoginModal';
import { isAuthenticated, initializeTokenRefresh, logout, getCurrentUser } from '@/utils/auth';

interface AuthProviderProps {
  children: React.ReactNode;
}

export default function AuthProvider({ children }: AuthProviderProps) {
  const [isAuth, setIsAuth] = useState(false);
  const [isLoading, setIsLoading] = useState(true);
  const [user, setUser] = useState<{ username: string; role: string } | null>(null);

  useEffect(() => {
    // Check authentication status on mount
    const authenticated = isAuthenticated();
    setIsAuth(authenticated);

    if (authenticated) {
      setUser(getCurrentUser());
      // Initialize automatic token refresh
      initializeTokenRefresh();
    }

    setIsLoading(false);
  }, []);

  const handleLoginSuccess = () => {
    setIsAuth(true);
    setUser(getCurrentUser());
    initializeTokenRefresh();
  };

  const handleLogout = () => {
    logout();
    setIsAuth(false);
    setUser(null);
  };

  if (isLoading) {
    return (
      <div className="min-h-screen bg-primary-50 flex items-center justify-center">
        <div className="text-center">
          <div className="inline-block animate-spin rounded-full h-12 w-12 border-b-2 border-primary-900"></div>
          <p className="mt-4 text-primary-600">Loading...</p>
        </div>
      </div>
    );
  }

  if (!isAuth) {
    return <LoginModal onLoginSuccess={handleLoginSuccess} />;
  }

  return (
    <>
      {/* User info bar */}
      <div className="bg-primary-800 text-white px-4 py-2 flex justify-between items-center shadow-md">
        <div className="text-sm">
          Signed in as <span className="font-semibold">{user?.username}</span>
        </div>
        <button
          onClick={handleLogout}
          className="text-sm bg-red-600 hover:bg-red-500 px-4 py-1.5 rounded font-medium transition-colors shadow-sm"
        >
          Sign Out
        </button>
      </div>
      {children}
    </>
  );
}
===== END FILE =====

===== FILE: frontend-next/src/components/LoginModal.tsx =====
"use client";

import React, { useState } from 'react';

interface LoginModalProps {
  onLoginSuccess: () => void;
}

export default function LoginModal({ onLoginSuccess }: LoginModalProps) {
  const [username, setUsername] = useState('');
  const [password, setPassword] = useState('');
  const [error, setError] = useState('');
  const [isLoading, setIsLoading] = useState(false);

  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault();
    setError('');
    setIsLoading(true);

    try {
      const response = await fetch('/api/auth/login', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({ username, password }),
      });

      if (!response.ok) {
        const errorData = await response.json();
        throw new Error(errorData.detail || 'Login failed');
      }

      const data = await response.json();

      // Store tokens in localStorage
      localStorage.setItem('access_token', data.access_token);
      localStorage.setItem('refresh_token', data.refresh_token);
      localStorage.setItem('user', JSON.stringify(data.user));

      // Call success callback
      onLoginSuccess();
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Login failed. Please try again.');
    } finally {
      setIsLoading(false);
    }
  };

  return (
    <div className="fixed inset-0 bg-black bg-opacity-50 flex items-center justify-center z-50">
      <div className="bg-white rounded-lg shadow-2xl p-8 max-w-md w-full mx-4">
        <div className="mb-6">
          <h2 className="text-3xl font-bold text-primary-900 mb-2">
            TranscribeAlpha
          </h2>
          <p className="text-primary-600">
            Please sign in to continue
          </p>
        </div>

        <form onSubmit={handleSubmit} className="space-y-4">
          <div>
            <label htmlFor="username" className="block text-sm font-medium text-primary-700 mb-2">
              Username
            </label>
            <input
              type="text"
              id="username"
              value={username}
              onChange={(e) => setUsername(e.target.value)}
              className="w-full px-4 py-3 border border-primary-300 rounded-lg focus:outline-none focus:ring-2 focus:ring-primary-500 focus:border-transparent shadow-sm"
              placeholder="Enter your username"
              required
              disabled={isLoading}
              autoComplete="username"
            />
          </div>

          <div>
            <label htmlFor="password" className="block text-sm font-medium text-primary-700 mb-2">
              Password
            </label>
            <input
              type="password"
              id="password"
              value={password}
              onChange={(e) => setPassword(e.target.value)}
              className="w-full px-4 py-3 border border-primary-300 rounded-lg focus:outline-none focus:ring-2 focus:ring-primary-500 focus:border-transparent shadow-sm"
              placeholder="Enter your password"
              required
              disabled={isLoading}
              autoComplete="current-password"
            />
          </div>

          {error && (
            <div className="bg-red-50 border border-red-200 text-red-700 px-4 py-3 rounded-lg text-sm">
              {error}
            </div>
          )}

          <button
            type="submit"
            disabled={isLoading}
            className="w-full bg-primary-900 text-white py-3 px-6 rounded-lg font-medium hover:bg-primary-800 focus:outline-none focus:ring-2 focus:ring-primary-500 focus:ring-offset-2 shadow-lg disabled:opacity-50 disabled:cursor-not-allowed transition-colors"
          >
            {isLoading ? 'Signing in...' : 'Sign In'}
          </button>
        </form>

        <div className="mt-6 text-center text-sm text-primary-600">
          <p>
            Need help? Contact your administrator.
          </p>
        </div>
      </div>
    </div>
  );
}
===== END FILE =====

===== FILE: frontend-next/src/components/MediaMissingBanner.tsx =====
'use client'

interface MediaMissingBannerProps {
  mediaKey: string
  appVariant?: 'oncue' | 'criminal'
  mediaFilename?: string
  onReimport: () => void
}

export default function MediaMissingBanner({ mediaKey, appVariant = 'oncue', mediaFilename, onReimport }: MediaMissingBannerProps) {
  const isCriminal = appVariant === 'criminal'

  return (
    <div className="bg-amber-50 border-b border-amber-200 px-6 py-3">
      <div className="flex items-center justify-between max-w-7xl mx-auto">
        <div className="flex items-center gap-3">
          <div className="w-8 h-8 bg-amber-100 rounded-full flex items-center justify-center flex-shrink-0">
            <svg className="w-4 h-4 text-amber-600" fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24">
              <path d="M12 9v2m0 4h.01m-6.938 4h13.856c1.54 0 2.502-1.667 1.732-3L13.732 4c-.77-1.333-2.694-1.333-3.464 0L3.34 16c-.77 1.333.192 3 1.732 3z" />
            </svg>
          </div>
          <div>
            <p className="font-medium text-amber-800">
              {isCriminal ? 'Media file not found' : 'Media file unavailable'}
            </p>
            <p className="text-sm text-amber-600">
              {isCriminal
                ? `${mediaFilename || 'The media file'} is not linked. Locate the file on your computer to enable playback.`
                : 'The original media has expired. Re-import to enable playback and clip creation.'}
            </p>
          </div>
        </div>
        <button
          onClick={onReimport}
          className="px-4 py-2 bg-amber-100 hover:bg-amber-200 text-amber-800 font-medium text-sm rounded-lg transition-colors"
        >
          {isCriminal ? 'Locate File' : 'Re-import Media'}
        </button>
      </div>
    </div>
  )
}
===== END FILE =====

===== FILE: frontend-next/src/components/ServiceWorkerRegistrar.tsx =====
'use client'

import { useEffect } from 'react'

export default function ServiceWorkerRegistrar() {
  useEffect(() => {
    if ('serviceWorker' in navigator) {
      navigator.serviceWorker.register('/sw.js').catch((err) => {
        console.warn('SW registration failed:', err)
      })
    }
  }, [])

  return null
}
===== END FILE =====

===== FILE: frontend-next/src/components/TranscriptEditor.tsx =====
'use client'

import { useCallback, useEffect, useMemo, useRef, useState } from 'react'
import { buildMediaUrl, authenticatedFetch } from '@/utils/auth'
import { saveTranscript as localSaveTranscript } from '@/lib/storage'
import { getMediaFile } from '@/lib/mediaHandles'

interface EditorLine {
  id: string
  speaker: string
  text: string
  rendered_text?: string
  start: number
  end: number
  page?: number | null
  line?: number | null
  pgln?: number | null
  is_continuation?: boolean
  timestamp_error?: boolean
}

export interface ClipSummary {
  clip_id: string
  name: string
  created_at: string
  duration: number
  start_time: number
  end_time: number
  start_pgln?: number | null
  end_pgln?: number | null
  start_page?: number | null
  start_line?: number | null
  end_page?: number | null
  end_line?: number | null
  media_blob_name?: string | null
  media_content_type?: string | null
  file_name?: string | null
}

export interface EditorSessionResponse {
  session_id?: string | null
  media_key?: string | null
  media_handle_id?: string | null
  media_blob_name?: string | null
  media_filename?: string | null
  media_content_type?: string | null
  title_data: Record<string, string>
  audio_duration: number
  lines_per_page: number
  lines: EditorLine[]
  created_at?: string
  updated_at?: string
  expires_at?: string
  pdf_base64?: string | null
  // Deprecated, retained for legacy sessions.
  docx_base64?: string | null
  oncue_xml_base64?: string | null
  viewer_html_base64?: string | null
  source_turns?: unknown[]
  transcript?: string | null
  transcript_text?: string | null
  clips?: ClipSummary[]
}

export type EditorSaveResponse = EditorSessionResponse

interface TranscriptEditorProps {
  mediaKey?: string | null
  initialData?: EditorSessionResponse | null
  mediaUrl?: string
  mediaType?: string
  pdfBase64?: string | null
  docxBase64?: string | null
  xmlBase64?: string | null
  viewerHtmlBase64?: string | null
  appVariant?: 'oncue' | 'criminal'
  onDownload: (base64Data: string, filename: string, mimeType: string) => void
  buildFilename: (baseName: string, extension: string) => string
  onSessionChange: (session: EditorSessionResponse) => void
  onSaveComplete: (result: EditorSaveResponse) => void
  onRequestMediaImport?: () => void
  onOpenHistory?: () => void
  onGeminiRefine?: () => void
  isGeminiBusy?: boolean
  geminiError?: string | null
}

const secondsToLabel = (seconds: number) => {
  if (!Number.isFinite(seconds) || seconds < 0) {
    return '0:00.000'
  }
  const wholeSeconds = Math.floor(seconds)
  const minutes = Math.floor(wholeSeconds / 60)
  const remainingSeconds = wholeSeconds % 60
  const millis = Math.floor((seconds - wholeSeconds) * 1000)
  return `${minutes}:${remainingSeconds.toString().padStart(2, '0')}.${millis
    .toString()
    .padStart(3, '0')}`
}

// localStorage helpers for cross-page state persistence
interface LocalStorageTranscriptState {
  mediaKey: string
  lines: EditorLine[]
  titleData: Record<string, string>
  mediaBlobName?: string | null
  mediaContentType?: string | null
  audioDuration: number
  linesPerPage: number
  lastSaved: string
}

const STORAGE_KEY_PREFIX = 'transcript_state_'
const AUTO_SHIFT_STORAGE_KEY = 'editor_auto_shift_next'
const AUTO_SHIFT_PADDING_SECONDS = 0.01

const escapeScriptBoundary = (value: string) => value.replace(/<\/script/gi, '<\\/script')

function bytesToBase64(bytes: Uint8Array): string {
  let binary = ''
  const chunkSize = 0x8000
  for (let index = 0; index < bytes.length; index += chunkSize) {
    const chunk = bytes.subarray(index, index + chunkSize)
    binary += String.fromCharCode(...Array.from(chunk))
  }
  return btoa(binary)
}

function utf8ToBase64(value: string): string {
  return bytesToBase64(new TextEncoder().encode(value))
}

function buildRenderedText(line: Pick<EditorLine, 'speaker' | 'text' | 'is_continuation'>): string {
  const speaker = (line.speaker || '').trim().replace(/:+$/, '')
  const text = line.text || ''
  if (line.is_continuation) return text
  if (!speaker) return text
  const compact = text.trimStart().toUpperCase()
  if (compact.startsWith(`${speaker.toUpperCase()}:`)) {
    return text
  }
  return `          ${speaker}:   ${text}`
}

function sanitizeDownloadStem(value: string): string {
  const sanitized = value
    .replace(/[\\/:*?"<>|]/g, ' ')
    .replace(/\s+/g, ' ')
    .trim()
  return sanitized || 'transcript'
}

function normalizeLineEntriesForArtifacts(lineEntries: EditorLine[], linesPerPage: number): EditorLine[] {
  const safeLinesPerPage = linesPerPage > 0 ? linesPerPage : 25
  return lineEntries.map((line, index) => {
    const pageNumber = Number.isFinite(line.page as number)
      ? Number(line.page)
      : Math.floor(index / safeLinesPerPage) + 1
    const lineNumber = Number.isFinite(line.line as number)
      ? Number(line.line)
      : (index % safeLinesPerPage) + 1
    const start = Number.isFinite(line.start) ? Number(line.start) : 0
    const rawEnd = Number.isFinite(line.end) ? Number(line.end) : start
    return {
      ...line,
      id: line.id || `line-${index}`,
      speaker: line.speaker || '',
      text: line.text || '',
      rendered_text: buildRenderedText(line),
      start,
      end: rawEnd >= start ? rawEnd : start,
      page: pageNumber,
      line: lineNumber,
      pgln: Number.isFinite(line.pgln as number) ? Number(line.pgln) : (pageNumber * 100) + lineNumber,
      is_continuation: Boolean(line.is_continuation),
    }
  })
}

function buildViewerPayloadFromLines(
  lineEntries: EditorLine[],
  titleData: Record<string, string>,
  audioDuration: number,
  linesPerPage: number,
  mediaFilename: string,
  mediaContentType: string,
) {
  const normalizedEntries = normalizeLineEntriesForArtifacts(lineEntries, linesPerPage)
  const speakers = Array.from(
    new Set(
      normalizedEntries
        .map((line) => line.speaker)
        .filter((speaker) => speaker && speaker.trim().length > 0),
    ),
  )

  const normalizedLines = normalizedEntries.map((line, index) => {
    const pageNumber = Number(line.page)
    const lineNumber = Number(line.line)
    return {
      id: line.id || `line-${index}`,
      speaker: line.speaker || '',
      text: line.text || '',
      rendered_text: line.rendered_text || buildRenderedText(line),
      start: Number.isFinite(line.start) ? line.start : 0,
      end: Number.isFinite(line.end) ? line.end : (Number.isFinite(line.start) ? line.start : 0),
      page_number: pageNumber,
      line_number: lineNumber,
      pgln: Number.isFinite(line.pgln as number) ? Number(line.pgln) : (pageNumber * 100) + lineNumber,
      is_continuation: Boolean(line.is_continuation),
    }
  })

  const pageMap = new Map<number, number[]>()
  normalizedLines.forEach((line, idx) => {
    if (!pageMap.has(line.page_number)) pageMap.set(line.page_number, [])
    pageMap.get(line.page_number)?.push(idx)
  })

  const pages = Array.from(pageMap.entries())
    .sort((a, b) => a[0] - b[0])
    .map(([pageNumber, lineIndexes]) => ({
      page_number: pageNumber,
      line_indexes: lineIndexes,
      pgln_start: lineIndexes.length ? normalizedLines[lineIndexes[0]].pgln : 101,
      pgln_end: lineIndexes.length ? normalizedLines[lineIndexes[lineIndexes.length - 1]].pgln : 101,
    }))

  return {
    meta: {
      title: titleData || {},
      duration_seconds: Number.isFinite(audioDuration) ? audioDuration : 0,
      lines_per_page: linesPerPage > 0 ? linesPerPage : 25,
      speakers,
    },
    media: {
      filename: mediaFilename,
      content_type: mediaContentType || 'video/mp4',
      relative_path: mediaFilename,
    },
    lines: normalizedLines,
    pages,
  }
}

function saveToLocalStorage(mediaKey: string, state: LocalStorageTranscriptState) {
  try {
    localStorage.setItem(
      `${STORAGE_KEY_PREFIX}${mediaKey}`,
      JSON.stringify(state)
    )
  } catch (err) {
    console.error('Failed to save to localStorage:', err)
  }
}

function loadFromLocalStorage(mediaKey: string): LocalStorageTranscriptState | null {
  try {
    const data = localStorage.getItem(`${STORAGE_KEY_PREFIX}${mediaKey}`)
    if (!data) return null
    return JSON.parse(data)
  } catch (err) {
    console.error('Failed to load from localStorage:', err)
    return null
  }
}

function clearLocalStorage(mediaKey: string) {
  try {
    localStorage.removeItem(`${STORAGE_KEY_PREFIX}${mediaKey}`)
  } catch (err) {
    console.error('Failed to clear localStorage:', err)
  }
}

export default function TranscriptEditor({
  mediaKey: initialMediaKey,
  initialData,
  mediaUrl,
  mediaType,
  pdfBase64,
  docxBase64,
  xmlBase64,
  viewerHtmlBase64,
  appVariant = 'oncue',
  onDownload,
  buildFilename,
  onSessionChange,
  onSaveComplete,
  onRequestMediaImport,
  onOpenHistory,
  onGeminiRefine,
  isGeminiBusy,
  geminiError,
}: TranscriptEditorProps) {
  const isCriminal = appVariant === 'criminal'
  const [lines, setLines] = useState<EditorLine[]>(initialData?.lines ?? [])
  const [sessionMeta, setSessionMeta] = useState<EditorSessionResponse | null>(initialData ?? null)
  const [loading, setLoading] = useState(false)
  const [error, setError] = useState<string | null>(null)
  const [saving, setSaving] = useState(false)
  const [isDirty, setIsDirty] = useState(false)
  const [activeMediaKey, setActiveMediaKey] = useState<string | null>(initialData?.media_key ?? initialMediaKey ?? null)
  const [activeLineId, setActiveLineId] = useState<string | null>(null)
  const [selectedLineId, setSelectedLineId] = useState<string | null>(null)
  const [autoScroll, setAutoScroll] = useState(true)
  const [editingField, setEditingField] = useState<{ lineId: string; field: 'speaker' | 'text'; value: string } | null>(null)
  const [autoShiftNextLine, setAutoShiftNextLine] = useState(true)
  const [searchQuery, setSearchQuery] = useState('')
  const [searchMatches, setSearchMatches] = useState<string[]>([])
  const [searchCurrentIndex, setSearchCurrentIndex] = useState(-1)
  const [resolvedMediaUrl, setResolvedMediaUrl] = useState<string | undefined>(undefined)

  const videoRef = useRef<HTMLVideoElement>(null)
  const audioRef = useRef<HTMLAudioElement>(null)
  const editInputRef = useRef<HTMLInputElement | HTMLTextAreaElement | null>(null)
  const transcriptScrollRef = useRef<HTMLDivElement | null>(null)
  const programmaticScrollRef = useRef(false)
  const scrollReleaseTimerRef = useRef<number | null>(null)
  const lineRefs = useRef<Record<string, HTMLDivElement | null>>({})
  const activeLineMarker = useRef<string | null>(null)
  // Skip resetting isDirty/history in SYNC EFFECT when we've just done a local update (e.g., resync)
  const skipSyncEffectReset = useRef(false)

  const [renameFrom, setRenameFrom] = useState('')
  const [renameTo, setRenameTo] = useState('')
  const [renameFeedback, setRenameFeedback] = useState<string | null>(null)
  const [showRenameModal, setShowRenameModal] = useState(false)
  const [addError, setAddError] = useState<string | null>(null)
  const [deleteError, setDeleteError] = useState<string | null>(null)
  const [history, setHistory] = useState<EditorLine[][]>([])
  const [future, setFuture] = useState<EditorLine[][]>([])
  const [snapshotError, setSnapshotError] = useState<string | null>(null)
  const lastSnapshotRef = useRef<number>(0)

  // Collapsible panel states
  const [showSettings, setShowSettings] = useState(false)
  const [manualScrollOverride, setManualScrollOverride] = useState(false)

  // Refs for auto-save to avoid resetting timer on every edit
  const linesRef = useRef<EditorLine[]>(initialData?.lines ?? [])
  const isDirtyRef = useRef(false)
  const sessionMetaRef = useRef<EditorSessionResponse | null>(initialData ?? null)
  const viewerTemplateCacheRef = useRef<string | null>(null)

  // Rev AI Re-sync State
  const [isResyncing, setIsResyncing] = useState(false)
  const [resyncError, setResyncError] = useState<string | null>(null)

  const baseMediaUrl = useMemo(() => {
    if (mediaUrl) return mediaUrl
    if (sessionMeta?.media_blob_name) {
      return `/api/media/${sessionMeta.media_blob_name}`
    }
    return undefined
  }, [mediaUrl, sessionMeta])

  useEffect(() => {
    let isActive = true
    const resolveMedia = async () => {
      if (!baseMediaUrl) {
        if (isActive) setResolvedMediaUrl(undefined)
        return
      }
      if (isCriminal) {
        // Criminal: mediaUrl is already a blob URL or direct path
        if (isActive) setResolvedMediaUrl(baseMediaUrl)
        return
      }
      const resolved = await buildMediaUrl(baseMediaUrl)
      if (isActive) {
        setResolvedMediaUrl(resolved)
      }
    }
    void resolveMedia()
    return () => {
      isActive = false
    }
  }, [baseMediaUrl, isCriminal])

  const effectiveMediaType = useMemo(
    () => mediaType ?? sessionMeta?.media_content_type ?? undefined,
    [mediaType, sessionMeta],
  )

  const isVideo = useMemo(
    () => (effectiveMediaType ?? '').startsWith('video/'),
    [effectiveMediaType],
  )

  const handleMediaError = useCallback(async () => {
    if (!baseMediaUrl) return
    // Criminal: blob URLs don't expire, nothing to refresh
    if (isCriminal) return
    const currentPlayer = isVideo ? videoRef.current : audioRef.current
    const resumeTime = currentPlayer?.currentTime ?? 0
    const wasPaused = currentPlayer?.paused ?? true
    const refreshed = await buildMediaUrl(baseMediaUrl, true)
    setResolvedMediaUrl(refreshed)
    setTimeout(() => {
      const nextPlayer = isVideo ? videoRef.current : audioRef.current
      if (!nextPlayer) return
      nextPlayer.currentTime = resumeTime
      if (!wasPaused) {
        nextPlayer.play().catch(() => {})
      }
    }, 0)
  }, [baseMediaUrl, isCriminal, isVideo])

  // Keep refs in sync with state for auto-save interval
  useEffect(() => { linesRef.current = lines }, [lines])
  useEffect(() => { isDirtyRef.current = isDirty }, [isDirty])
  useEffect(() => { sessionMetaRef.current = sessionMeta }, [sessionMeta])

  const lineBoundaries = useMemo(
    () =>
      lines.map((line) => {
        const start = Number.isFinite(line.start) ? line.start : 0
        const end = Number.isFinite(line.end) ? line.end : start
        return {
          id: line.id,
          start,
          end: end > start ? end : start + 0.05,
        }
      }),
    [lines],
  )

  const isLineVisibleInTranscript = useCallback((lineId: string) => {
    const container = transcriptScrollRef.current
    const row = lineRefs.current[lineId]
    if (!container || !row) return false
    const containerRect = container.getBoundingClientRect()
    const rowRect = row.getBoundingClientRect()
    return rowRect.top >= containerRect.top && rowRect.bottom <= containerRect.bottom
  }, [])

  const scrollTranscriptToLine = useCallback((lineId: string, behavior: ScrollBehavior = 'smooth') => {
    const target = lineRefs.current[lineId]
    if (!target) return
    programmaticScrollRef.current = true
    target.scrollIntoView({ block: 'center', behavior })
    if (scrollReleaseTimerRef.current) {
      window.clearTimeout(scrollReleaseTimerRef.current)
    }
    scrollReleaseTimerRef.current = window.setTimeout(() => {
      programmaticScrollRef.current = false
      scrollReleaseTimerRef.current = null
    }, behavior === 'smooth' ? 450 : 150)
  }, [])

  useEffect(() => {
    return () => {
      if (scrollReleaseTimerRef.current) {
        window.clearTimeout(scrollReleaseTimerRef.current)
      }
    }
  }, [])

  const fetchTranscript = useCallback(
    async (key?: string | null) => {
      // Criminal variant always receives initialData from the editor page; never fetch from API
      if (isCriminal) return

      const targetKey = key || activeMediaKey || initialMediaKey
      if (!targetKey) {
        setError('No media key provided')
        return
      }

      setLoading(true)
      setError(null)

      try {
        // Try loading from server first
        const response = await authenticatedFetch(`/api/transcripts/by-key/${encodeURIComponent(targetKey)}`)

        if (!response.ok) {
          if (response.status === 404) {
            // Try localStorage fallback
            const cached = loadFromLocalStorage(targetKey)
            if (cached) {
              setLines(cached.lines)
              setSessionMeta({
                title_data: cached.titleData,
                audio_duration: cached.audioDuration,
                lines_per_page: cached.linesPerPage,
                lines: cached.lines,
                media_blob_name: cached.mediaBlobName,
                media_content_type: cached.mediaContentType,
              } as EditorSessionResponse)
              setActiveMediaKey(targetKey)
              setError('Loaded from local cache. Save to sync with server.')
              setLoading(false)
              return
            }
          }

          const detail = await response.json().catch(() => ({}))
          throw new Error(detail?.detail || 'Failed to load transcript')
        }

        const data: EditorSessionResponse = await response.json()
        setSessionMeta(data)
        setLines(data.lines || [])
        setActiveMediaKey(targetKey)
        setHistory([])
        setFuture([])
        setIsDirty(false)
        setActiveLineId(null)
        setSelectedLineId(null)
        setEditingField(null)
        activeLineMarker.current = null
        onSessionChange(data)

        // Save to localStorage for offline access
        saveToLocalStorage(targetKey, {
          mediaKey: targetKey,
          lines: data.lines || [],
          titleData: data.title_data ?? {},
          mediaBlobName: data.media_blob_name,
          mediaContentType: data.media_content_type,
          audioDuration: data.audio_duration,
          linesPerPage: data.lines_per_page,
          lastSaved: new Date().toISOString(),
        })

      } catch (err: any) {
        setError(err.message || 'Failed to load transcript')
      } finally {
        setLoading(false)
      }
    },
    [activeMediaKey, isCriminal, initialMediaKey, onSessionChange],
  )

  useEffect(() => {
    if (!initialData) return
    setSessionMeta(initialData)
    setLines(initialData.lines ?? [])
    // Only update activeMediaKey from props, not from internal state (to avoid circular updates)
    const resolvedKey = initialData.media_key ?? initialMediaKey ?? null
    if (resolvedKey) {
      setActiveMediaKey(resolvedKey)
    }

    // Skip resetting edit state if we just did a local update (e.g., resync)
    if (skipSyncEffectReset.current) {
      skipSyncEffectReset.current = false
    } else {
      setHistory([])
      setFuture([])
      setIsDirty(false)
    }

    setActiveLineId(null)
    setSelectedLineId(null)
    setEditingField(null)
    setSnapshotError(null)
    activeLineMarker.current = null
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [initialData, initialMediaKey])

  useEffect(() => {
    if (initialData || sessionMeta) return
    if (initialMediaKey || activeMediaKey) {
      fetchTranscript(initialMediaKey || activeMediaKey)
    }
  }, [initialData, sessionMeta, initialMediaKey, activeMediaKey, fetchTranscript])

  // Track the current editing session to avoid re-selecting text on every keystroke
  const editingLineId = editingField?.lineId
  const editingFieldName = editingField?.field

  useEffect(() => {
    if (!editingLineId || !editingFieldName) return
    if (editInputRef.current) {
      editInputRef.current.focus()
      if (editingFieldName === 'speaker' && 'select' in editInputRef.current) {
        ;(editInputRef.current as HTMLInputElement).select()
      }
    }
  }, [editingLineId, editingFieldName]) // Only run when lineId or field changes, not when value changes

  const hasPendingInlineEdit = useMemo(() => {
    if (!editingField) return false
    const line = lines.find((entry) => entry.id === editingField.lineId)
    if (!line) return false
    const currentValue = editingField.field === 'speaker' ? line.speaker : line.text
    return currentValue !== editingField.value
  }, [editingField, lines])

  const materializeLinesForSave = useCallback((): EditorLine[] => {
    if (!editingField || !hasPendingInlineEdit) return lines
    return lines.map((line) =>
      line.id === editingField.lineId
        ? {
          ...line,
          [editingField.field]: editingField.value,
          ...(editingField.field === 'speaker' || editingField.field === 'text' ? { rendered_text: undefined } : null),
        }
        : line,
    )
  }, [editingField, hasPendingInlineEdit, lines])

  useEffect(() => {
    const player = resolvedMediaUrl ? (isVideo ? videoRef.current : audioRef.current) : null
    if (!player) return

    const handleTimeUpdate = () => {
      const currentTime = player.currentTime
      let currentLineId: string | null = null
      for (let i = 0; i < lineBoundaries.length; i += 1) {
        const boundary = lineBoundaries[i]
        if (currentTime >= boundary.start && currentTime < boundary.end + 0.01) {
          currentLineId = boundary.id
          break
        }
      }
      if (!currentLineId && lineBoundaries.length) {
        const lastBoundary = lineBoundaries[lineBoundaries.length - 1]
        if (currentTime >= lastBoundary.end) {
          currentLineId = lastBoundary.id
        }
      }
      if (currentLineId && currentLineId !== activeLineMarker.current) {
        activeLineMarker.current = currentLineId
        setActiveLineId(currentLineId)
        if (autoScroll && !manualScrollOverride) {
          scrollTranscriptToLine(currentLineId)
        }
      }
    }

    player.addEventListener('timeupdate', handleTimeUpdate)
    return () => {
      player.removeEventListener('timeupdate', handleTimeUpdate)
    }
  }, [resolvedMediaUrl, isVideo, lineBoundaries, autoScroll, manualScrollOverride, scrollTranscriptToLine])

  const handleLineFieldChange = useCallback(
    (lineId: string, field: keyof EditorLine, value: string | number) => {
      setLines((prev) => {
        const normalizedValue =
          field === 'speaker' || field === 'text'
            ? typeof value === 'string'
              ? value
              : value.toString()
            : typeof value === 'number'
              ? value
              : parseFloat(value as string) || 0

        const nextLines = prev.map((line) =>
          line.id === lineId
            ? {
              ...line,
              [field]: normalizedValue,
              ...(field === 'speaker' || field === 'text' ? { rendered_text: undefined } : null),
              ...(field === 'start' || field === 'end' ? { timestamp_error: false } : null),
            }
            : line,
        )

        if (field === 'end' && autoShiftNextLine) {
          const targetIndex = nextLines.findIndex((line) => line.id === lineId)
          if (targetIndex >= 0 && nextLines[targetIndex + 1]) {
            const targetLine = nextLines[targetIndex]
            const followingLine = nextLines[targetIndex + 1]
            const numericEnd =
              typeof normalizedValue === 'number'
                ? normalizedValue
                : parseFloat(normalizedValue as string) || targetLine.end
            const adjustedStart = Math.max(0, parseFloat((numericEnd + AUTO_SHIFT_PADDING_SECONDS).toFixed(3)))
            nextLines[targetIndex + 1] = { ...followingLine, start: adjustedStart }
          }
        }

        return nextLines
      })
      setIsDirty(true)
    },
    [autoShiftNextLine],
  )

  const playLine = useCallback(
    (line: EditorLine) => {
      if (!resolvedMediaUrl) return
      setSelectedLineId(line.id)
      const player = isVideo ? videoRef.current : audioRef.current
      if (!player) return

      const seekAndPlay = () => {
        player.currentTime = line.start
        player.play().catch(() => {})
      }

      // Check if media metadata is loaded (readyState >= 1 means HAVE_METADATA)
      if (player.readyState >= 1) {
        seekAndPlay()
      } else {
        // Wait for metadata to load before seeking
        const handleLoadedMetadata = () => {
          player.removeEventListener('loadedmetadata', handleLoadedMetadata)
          seekAndPlay()
        }
        player.addEventListener('loadedmetadata', handleLoadedMetadata)
        // Also trigger a load if the player hasn't started loading
        if (player.readyState === 0) {
          player.load()
        }
      }
    },
    [resolvedMediaUrl, isVideo],
  )

  // beforeunload handler for cross-page persistence (skip for criminal - data is in workspace)
  useEffect(() => {
    if (isCriminal) return
    const handleBeforeUnload = () => {
      if (activeMediaKey && sessionMeta) {
        saveToLocalStorage(activeMediaKey, {
          mediaKey: activeMediaKey,
          lines,
          titleData: sessionMeta.title_data ?? {},
          mediaBlobName: sessionMeta.media_blob_name,
          mediaContentType: sessionMeta.media_content_type,
          audioDuration: sessionMeta.audio_duration,
          linesPerPage: sessionMeta.lines_per_page,
          lastSaved: new Date().toISOString(),
        })
      }
    }

    window.addEventListener('beforeunload', handleBeforeUnload)
    return () => window.removeEventListener('beforeunload', handleBeforeUnload)
  }, [activeMediaKey, isCriminal, lines, sessionMeta])

  useEffect(() => {
    if (!activeMediaKey) return

    const interval = setInterval(async () => {
      // Read from refs to get latest values without resetting the timer
      if (!isDirtyRef.current) return
      const currentSessionMeta = sessionMetaRef.current
      if (!currentSessionMeta) return

      try {
        const now = Date.now()
        if (now - lastSnapshotRef.current < 5000) return  // Debounce

        if (isCriminal) {
          // Criminal: save directly to local workspace
          const dataToSave = {
            ...currentSessionMeta,
            lines: linesRef.current,
            updated_at: new Date().toISOString(),
          }
          await localSaveTranscript(
            activeMediaKey,
            dataToSave as unknown as Record<string, unknown>,
            (currentSessionMeta as unknown as Record<string, unknown>).case_id as string || undefined,
          )
        } else {
          // Oncue: auto-save to API
          await authenticatedFetch(`/api/transcripts/by-key/${encodeURIComponent(activeMediaKey)}`, {
            method: 'PUT',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
              lines: linesRef.current,
              title_data: currentSessionMeta.title_data ?? {},
              is_manual_save: false,
              audio_duration: currentSessionMeta.audio_duration,
              lines_per_page: currentSessionMeta.lines_per_page,
              media_blob_name: currentSessionMeta.media_blob_name,
              media_content_type: currentSessionMeta.media_content_type,
            }),
          })

          // Also save to localStorage for oncue
          saveToLocalStorage(activeMediaKey, {
            mediaKey: activeMediaKey,
            lines: linesRef.current,
            titleData: currentSessionMeta.title_data ?? {},
            mediaBlobName: currentSessionMeta.media_blob_name,
            mediaContentType: currentSessionMeta.media_content_type,
            audioDuration: currentSessionMeta.audio_duration,
            linesPerPage: currentSessionMeta.lines_per_page,
            lastSaved: new Date().toISOString(),
          })
        }

        lastSnapshotRef.current = now
        setSnapshotError(null)

      } catch (err: any) {
        setSnapshotError(err.message || 'Auto-save failed')
      }
    }, 60000)  // 60 seconds

    return () => clearInterval(interval)
  }, [activeMediaKey, isCriminal])  // Only reset interval when media key changes

  const cloneLines = useCallback((source: EditorLine[]) => source.map((line) => ({ ...line })), [])

  const pushHistory = useCallback(
    (snapshot: EditorLine[]) => {
      setHistory((prev) => [...prev.slice(-49), cloneLines(snapshot)])
      setFuture([])
    },
    [cloneLines],
  )

  const beginEdit = useCallback((line: EditorLine, field: 'speaker' | 'text') => {
    setEditingField({
      lineId: line.id,
      field,
      value: field === 'speaker' ? line.speaker : line.text,
    })
  }, [])

  const commitEdit = useCallback(() => {
    if (!editingField) return
    pushHistory(lines)
    handleLineFieldChange(editingField.lineId, editingField.field, editingField.value)
    setEditingField(null)
  }, [editingField, handleLineFieldChange, lines, pushHistory])

  const cancelEdit = useCallback(() => {
    setEditingField(null)
  }, [])

  // Search functionality
  const performSearch = useCallback((query: string) => {
    setSearchQuery(query)
    if (!query.trim()) {
      setSearchMatches([])
      setSearchCurrentIndex(-1)
      return
    }
    const lowerQuery = query.toLowerCase()
    const matches = lines
      .filter((line) => {
        const text = (line.text || '').toLowerCase()
        const speaker = (line.speaker || '').toLowerCase()
        return text.includes(lowerQuery) || speaker.includes(lowerQuery)
      })
      .map((line) => line.id)
    setSearchMatches(matches)
    if (matches.length > 0) {
      setSearchCurrentIndex(0)
      setManualScrollOverride(true)
      scrollTranscriptToLine(matches[0])
    } else {
      setSearchCurrentIndex(-1)
    }
  }, [lines, scrollTranscriptToLine])

  const goToSearchResult = useCallback((direction: 'next' | 'prev') => {
    if (searchMatches.length === 0) return
    let newIndex = searchCurrentIndex
    if (direction === 'next') {
      newIndex = (searchCurrentIndex + 1) % searchMatches.length
    } else {
      newIndex = (searchCurrentIndex - 1 + searchMatches.length) % searchMatches.length
    }
    setSearchCurrentIndex(newIndex)
    const lineId = searchMatches[newIndex]
    setManualScrollOverride(true)
    scrollTranscriptToLine(lineId)
  }, [searchMatches, searchCurrentIndex, scrollTranscriptToLine])

  const clearSearch = useCallback(() => {
    setSearchQuery('')
    setSearchMatches([])
    setSearchCurrentIndex(-1)
  }, [])

  const handleTranscriptScroll = useCallback(() => {
    if (!autoScroll || programmaticScrollRef.current || !activeLineId) return
    const activeVisible = isLineVisibleInTranscript(activeLineId)
    setManualScrollOverride((prev) => {
      if (!prev && !activeVisible) return true
      if (prev && activeVisible) return false
      return prev
    })
  }, [activeLineId, autoScroll, isLineVisibleInTranscript])

  const handleReturnToCurrentLine = useCallback(() => {
    if (!activeLineId) return
    setManualScrollOverride(false)
    scrollTranscriptToLine(activeLineId)
  }, [activeLineId, scrollTranscriptToLine])

  useEffect(() => {
    try {
      const stored = localStorage.getItem(AUTO_SHIFT_STORAGE_KEY)
      if (stored === 'true') {
        setAutoShiftNextLine(true)
      } else if (stored === 'false') {
        setAutoShiftNextLine(false)
      }
    } catch (err) {
      console.error('Failed to load auto-shift preference:', err)
    }
  }, [])

  useEffect(() => {
    try {
      localStorage.setItem(AUTO_SHIFT_STORAGE_KEY, autoShiftNextLine ? 'true' : 'false')
    } catch (err) {
      console.error('Failed to save auto-shift preference:', err)
    }
  }, [autoShiftNextLine])

  useEffect(() => {
    if (!autoScroll) {
      setManualScrollOverride(false)
    }
  }, [autoScroll])

  const handleAddUtterance = useCallback(() => {
    setAddError(null)
    setDeleteError(null)
    if (!lines.length) {
      setAddError('No lines available to insert after.')
      return
    }

    pushHistory(lines)

    const minDuration = 0.2
    const targetId = selectedLineId ?? activeLineId ?? lines[lines.length - 1]?.id
    const targetIndex = lines.findIndex((line) => line.id === targetId)
    if (targetIndex < 0) {
      setAddError('Select a line to insert after.')
      return
    }

    const currentLine = lines[targetIndex]
    const nextLine = lines[targetIndex + 1]
    const nextStart = nextLine ? Number(nextLine.start) : null
    const currentStart = Number(currentLine.start) || 0
    const currentEnd = Number(currentLine.end) || currentStart

    let newStart = currentEnd
    let newEnd: number
    let updatedCurrentEnd = currentEnd

    if (nextLine && nextStart !== null && !Number.isNaN(nextStart)) {
      const gap = nextStart - currentEnd
      if (gap >= 2) {
        newStart = currentEnd
        newEnd = nextStart
        if (newEnd - newStart < minDuration) {
          newEnd = newStart + minDuration
        }
      } else {
        const duration = Math.max(currentEnd - currentStart, minDuration * 2)
        updatedCurrentEnd = currentStart + duration / 2
        newStart = updatedCurrentEnd
        newEnd = Math.min(currentStart + duration, nextStart)
        if (newEnd - newStart < minDuration) {
          newEnd = newStart + minDuration
        }
      }
    } else {
      const fallbackDuration = Math.max((sessionMeta?.audio_duration ?? 0) - currentEnd, minDuration)
      newStart = currentEnd
      newEnd = newStart + fallbackDuration
    }

    const newLineId = `new-${Date.now()}`
    const updatedLines = [...lines]
    updatedLines[targetIndex] = {
      ...currentLine,
      end: updatedCurrentEnd,
    }
    updatedLines.splice(targetIndex + 1, 0, {
      id: newLineId,
      speaker: currentLine.speaker,
      text: '',
      start: newStart,
      end: newEnd,
      is_continuation: false,
    })

    setLines(updatedLines)
    setSelectedLineId(newLineId)
    setEditingField({ lineId: newLineId, field: 'text', value: '' })
    setIsDirty(true)
  }, [lines, selectedLineId, activeLineId, sessionMeta, pushHistory])

  const handleDeleteUtterance = useCallback(() => {
    setDeleteError(null)
    setAddError(null)
    if (!lines.length) {
      setDeleteError('No lines to delete.')
      return
    }
    const targetId = selectedLineId ?? activeLineId
    if (!targetId) {
      setDeleteError('Select a line to delete.')
      return
    }
    const targetIndex = lines.findIndex((line) => line.id === targetId)
    if (targetIndex < 0) {
      setDeleteError('Select a line to delete.')
      return
    }
    if (lines.length === 1) {
      setDeleteError('At least one utterance must remain.')
      return
    }

    pushHistory(lines)

    const nextSelection = lines[targetIndex + 1]?.id || lines[targetIndex - 1]?.id || null
    const updated = lines.filter((line) => line.id !== targetId)
    setLines(updated)
    setSelectedLineId(nextSelection)
    setIsDirty(true)
  }, [lines, selectedLineId, activeLineId, pushHistory])

  const handleRenameSpeaker = useCallback(
    (event?: React.FormEvent) => {
      if (event) {
        event.preventDefault()
      }
      const source = renameFrom.trim()
      const target = renameTo.trim()
      if (!source || !target) {
        setRenameFeedback('Enter both the current and new speaker names.')
        return
      }
      pushHistory(lines)
      const normalizedSource = source.toUpperCase()
      const normalizedTarget = target.toUpperCase()
      let changes = 0
      setLines((prev) =>
        prev.map((line) => {
          if (line.speaker.trim().toUpperCase() === normalizedSource) {
            changes += 1
            return { ...line, speaker: normalizedTarget, rendered_text: undefined }
          }
          return line
        }),
      )
      if (changes === 0) {
        setRenameFeedback('No matching speaker labels were found.')
        return
      }
      setIsDirty(true)
      setRenameFeedback(`Renamed ${changes} line${changes === 1 ? '' : 's'}. Save to update exports.`)
    },
    [renameFrom, renameTo, lines, pushHistory],
  )

  const handleUndo = useCallback(() => {
    if (!history.length) return
    const previous = history[history.length - 1]
    setHistory((prev) => prev.slice(0, prev.length - 1))
    setFuture((prev) => [cloneLines(lines), ...prev])
    setLines(previous)
    setSelectedLineId(null)
    setIsDirty(true)
  }, [history, cloneLines, lines])

  const handleRedo = useCallback(() => {
    if (!future.length) return
    const [next, ...rest] = future
    setFuture(rest)
    setHistory((prev) => [...prev.slice(-49), cloneLines(lines)])
    setLines(next)
    setSelectedLineId(null)
    setIsDirty(true)
  }, [future, cloneLines, lines])

  const getViewerTemplate = useCallback(async () => {
    if (viewerTemplateCacheRef.current) return viewerTemplateCacheRef.current
    const response = await authenticatedFetch('/api/viewer-template')
    if (!response.ok) {
      const detail = await response.json().catch(() => ({}))
      throw new Error(detail?.detail || 'Failed to fetch viewer template')
    }
    const template = await response.text()
    viewerTemplateCacheRef.current = template
    return template
  }, [])

  const buildCriminalArtifacts = useCallback(
    async (
      sourceLines: EditorLine[],
      sourceSessionMeta: EditorSessionResponse,
      mediaKeyForSave: string,
    ): Promise<{ lineEntries: EditorLine[]; pdfBase64: string; viewerHtmlBase64: string }> => {
      const linesPerPage = sourceSessionMeta.lines_per_page ?? 25
      const titleData = sourceSessionMeta.title_data ?? {}
      const lineEntries = normalizeLineEntriesForArtifacts(sourceLines, linesPerPage)

      const pdfResponse = await authenticatedFetch('/api/format-pdf', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          title_data: titleData,
          line_entries: lineEntries,
          lines_per_page: linesPerPage,
        }),
      })
      if (!pdfResponse.ok) {
        const detail = await pdfResponse.json().catch(() => ({}))
        throw new Error(detail?.detail || 'Failed to regenerate PDF')
      }
      const pdfBytes = new Uint8Array(await pdfResponse.arrayBuffer())
      const pdfBase64 = bytesToBase64(pdfBytes)

      const template = await getViewerTemplate()
      const mediaContentType = sourceSessionMeta.media_content_type || effectiveMediaType || 'video/mp4'
      const mediaFilename =
        sourceSessionMeta.media_filename ||
        sourceSessionMeta.media_blob_name ||
        sourceSessionMeta.title_data?.FILE_NAME ||
        `${mediaKeyForSave}.${mediaContentType.startsWith('audio/') ? 'wav' : 'mp4'}`
      const viewerPayload = buildViewerPayloadFromLines(
        lineEntries,
        titleData,
        sourceSessionMeta.audio_duration ?? 0,
        linesPerPage,
        mediaFilename,
        mediaContentType,
      )
      const transcriptJson = escapeScriptBoundary(JSON.stringify(viewerPayload))
      const viewerHtml = template.replace('__TRANSCRIPT_JSON__', transcriptJson)
      if (viewerHtml === template) {
        throw new Error('Standalone viewer template missing transcript placeholder')
      }
      const viewerHtmlBase64 = utf8ToBase64(viewerHtml)
      return { lineEntries, pdfBase64, viewerHtmlBase64 }
    },
    [effectiveMediaType, getViewerTemplate],
  )

  const refreshCriminalArtifacts = useCallback(async (): Promise<EditorSaveResponse | null> => {
    if (!isCriminal || !activeMediaKey || !sessionMeta) return null
    setSaving(true)
    setError(null)
    try {
      const artifacts = await buildCriminalArtifacts(lines, sessionMeta, activeMediaKey)
      const refreshedData: EditorSaveResponse = {
        ...sessionMeta,
        lines: artifacts.lineEntries,
        pdf_base64: artifacts.pdfBase64,
        viewer_html_base64: artifacts.viewerHtmlBase64,
        updated_at: new Date().toISOString(),
      }
      await localSaveTranscript(
        activeMediaKey,
        refreshedData as unknown as Record<string, unknown>,
        (sessionMeta as unknown as Record<string, unknown>)?.case_id as string | undefined,
      )
      setSessionMeta(refreshedData)
      setLines(refreshedData.lines || [])
      onSessionChange(refreshedData)
      onSaveComplete(refreshedData)
      return refreshedData
    } catch (err: any) {
      setError(err.message || 'Failed to refresh exports')
      return null
    } finally {
      setSaving(false)
    }
  }, [activeMediaKey, buildCriminalArtifacts, isCriminal, lines, onSaveComplete, onSessionChange, sessionMeta])

  const handleSave = useCallback(async (): Promise<EditorSaveResponse | null> => {
    if (!activeMediaKey) {
      setError('No media key available to save.')
      return null
    }
    if (!sessionMeta) {
      setError('No transcript available to save.')
      return null
    }

    setSaving(true)
    setError(null)

    try {
      let data: EditorSaveResponse
      const linesToSave = materializeLinesForSave()

      if (isCriminal) {
        const artifacts = await buildCriminalArtifacts(linesToSave, sessionMeta, activeMediaKey)
        const updatedData = {
          ...sessionMeta,
          lines: artifacts.lineEntries,
          pdf_base64: artifacts.pdfBase64,
          viewer_html_base64: artifacts.viewerHtmlBase64,
          title_data: sessionMeta?.title_data ?? {},
          audio_duration: sessionMeta?.audio_duration ?? 0,
          lines_per_page: sessionMeta?.lines_per_page ?? 25,
          updated_at: new Date().toISOString(),
        }
        await localSaveTranscript(
          activeMediaKey,
          updatedData as unknown as Record<string, unknown>,
          (sessionMeta as unknown as Record<string, unknown>)?.case_id as string | undefined,
        )
        data = updatedData as EditorSaveResponse
      } else {
        const response = await authenticatedFetch(`/api/transcripts/by-key/${encodeURIComponent(activeMediaKey)}`, {
          method: 'PUT',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            lines: linesToSave,
            title_data: sessionMeta?.title_data ?? {},
            is_manual_save: true,
            audio_duration: sessionMeta?.audio_duration ?? 0,
            lines_per_page: sessionMeta?.lines_per_page ?? 25,
            media_blob_name: sessionMeta?.media_blob_name,
            media_content_type: sessionMeta?.media_content_type,
          }),
        })

        if (!response.ok) {
          const detail = await response.json().catch(() => ({}))
          throw new Error(detail?.detail || 'Failed to save')
        }

        data = await response.json()
      }

      setSessionMeta(data)
      setLines(data.lines || linesToSave)
      setActiveMediaKey(data.media_key ?? activeMediaKey)
      setIsDirty(false)
      setActiveLineId(null)
      setSelectedLineId(null)
      setEditingField(null)
      activeLineMarker.current = null
      setHistory([])
      setFuture([])

      // Save to localStorage (skip for criminal - data is in workspace)
      if (!isCriminal) {
        saveToLocalStorage(data.media_key ?? activeMediaKey, {
          mediaKey: data.media_key ?? activeMediaKey!,
          lines: data.lines || [],
          titleData: data.title_data ?? {},
          mediaBlobName: data.media_blob_name,
          mediaContentType: data.media_content_type,
          audioDuration: data.audio_duration,
          linesPerPage: data.lines_per_page,
          lastSaved: new Date().toISOString(),
        })
      }

      onSaveComplete(data)
      onSessionChange(data)

      return data

    } catch (err: any) {
      setError(err.message || 'Failed to save')
      return null
    } finally {
      setSaving(false)
    }
  }, [
    activeMediaKey,
    buildCriminalArtifacts,
    isCriminal,
    materializeLinesForSave,
    onSaveComplete,
    onSessionChange,
    sessionMeta,
  ])

  const handleDownloadViewer = useCallback(async () => {
    if (!isCriminal) return
    const saved = hasPendingInlineEdit || isDirty ? await handleSave() : await refreshCriminalArtifacts()
    const htmlData = saved?.viewer_html_base64 ?? viewerHtmlBase64 ?? sessionMeta?.viewer_html_base64 ?? ''
    if (!htmlData) {
      setError('HTML viewer export is not available for this transcript.')
      return
    }
    const mediaBaseName = (sessionMeta?.title_data?.FILE_NAME || activeMediaKey || 'transcript')?.replace(/\.[^.]+$/, '')
    onDownload(htmlData, buildFilename(mediaBaseName + ' transcript', '.html'), 'text/html')
  }, [
    activeMediaKey,
    buildFilename,
    handleSave,
    hasPendingInlineEdit,
    isCriminal,
    isDirty,
    onDownload,
    refreshCriminalArtifacts,
    sessionMeta,
    viewerHtmlBase64,
  ])

  const handleResync = useCallback(async () => {
    if (!activeMediaKey) {
      setResyncError('No active transcript to re-sync.')
      return
    }

    if (!confirm('This will update timestamps to match the media. Text stays the same. Continue?')) {
      return
    }

    setIsResyncing(true)
    setResyncError(null)

    try {
      let data: Record<string, unknown>

      if (isCriminal) {
        // Criminal: upload media file + transcript as multipart to /api/resync-local
        const mediaSourceId = sessionMeta?.media_handle_id || activeMediaKey
        const mediaFile = await getMediaFile(mediaSourceId)
        if (!mediaFile) {
          throw new Error('Media file not available. Please relink the media file first.')
        }
        const transcriptPayload = {
          media_key: activeMediaKey,
          lines,
          audio_duration: sessionMeta?.audio_duration ?? 0,
          title_data: sessionMeta?.title_data ?? {},
          lines_per_page: sessionMeta?.lines_per_page ?? 25,
          source_turns: sessionMeta?.source_turns,
        }
        const formData = new FormData()
        formData.append('media_file', mediaFile)
        formData.append('transcript_data', JSON.stringify(transcriptPayload))
        const response = await authenticatedFetch('/api/resync-local', {
          method: 'POST',
          body: formData,
        })
        if (!response.ok) {
          const detail = await response.json().catch(() => ({}))
          throw new Error(detail?.detail || 'Re-sync failed')
        }
        data = await response.json()
      } else {
        // Oncue: JSON body with media_key
        const response = await authenticatedFetch('/api/resync', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            media_key: activeMediaKey,
          }),
        })

        if (!response.ok) {
          const detail = await response.json().catch(() => ({}))
          throw new Error(detail?.detail || 'Re-sync failed')
        }

        data = await response.json()
      }

      // Use the response data directly instead of refetching
      // (GCS write propagation can cause fetchTranscript to get stale data)
      if (data.lines) {
        // Save current state to history so user can undo the resync
        pushHistory(lines)
        setLines(data.lines as EditorLine[])
        setIsDirty(true)
      }

      // Update session meta with new artifacts
      setSessionMeta((prev) => prev ? {
        ...prev,
        lines: (data.lines as EditorLine[] | undefined) ?? prev.lines,
        pdf_base64: (data.pdf_base64 as string | undefined) ?? prev.pdf_base64,
        oncue_xml_base64: (data.oncue_xml_base64 as string | undefined) ?? prev.oncue_xml_base64,
        viewer_html_base64: (data.viewer_html_base64 as string | undefined) ?? prev.viewer_html_base64,
      } : prev)

      // Notify parent of the update (skip SYNC EFFECT reset since we already set isDirty/history)
      if (sessionMeta) {
        skipSyncEffectReset.current = true
        onSessionChange({
          ...sessionMeta,
          lines: (data.lines as EditorLine[] | undefined) ?? sessionMeta.lines,
          pdf_base64: (data.pdf_base64 as string | undefined) ?? sessionMeta.pdf_base64,
          oncue_xml_base64: (data.oncue_xml_base64 as string | undefined) ?? sessionMeta.oncue_xml_base64,
          viewer_html_base64: (data.viewer_html_base64 as string | undefined) ?? sessionMeta.viewer_html_base64,
        })
      }

    } catch (err: any) {
      setResyncError(err.message || 'Re-sync failed')
    } finally {
      setIsResyncing(false)
    }
  }, [activeMediaKey, sessionMeta, onSessionChange, pushHistory, lines, isCriminal])

  const pdfData = pdfBase64 ?? sessionMeta?.pdf_base64 ?? docxBase64 ?? sessionMeta?.docx_base64 ?? ''
  const xmlData = xmlBase64 ?? sessionMeta?.oncue_xml_base64 ?? ''
  const canSave = isDirty || hasPendingInlineEdit
  const updatedLabel = sessionMeta?.updated_at ? new Date(sessionMeta.updated_at).toLocaleString() : '—'

  const handleDownloadPdf = useCallback(async () => {
    let pdfToDownload = pdfData

    if (isCriminal) {
      const saved = canSave ? await handleSave() : await refreshCriminalArtifacts()
      pdfToDownload = saved?.pdf_base64 ?? pdfToDownload
    }

    if (!pdfToDownload) {
      setError('PDF export is not available for this transcript.')
      return
    }

    const mediaNameRaw = sessionMeta?.title_data?.FILE_NAME || sessionMeta?.media_filename || activeMediaKey || 'transcript'
    const mediaBaseName = sanitizeDownloadStem(String(mediaNameRaw).replace(/\.[^.]+$/, ''))
    onDownload(pdfToDownload, `${mediaBaseName} transcript.pdf`, 'application/pdf')
  }, [activeMediaKey, canSave, handleSave, isCriminal, onDownload, pdfData, refreshCriminalArtifacts, sessionMeta])

  const isTypingInField = useCallback((target: EventTarget | null) => {
    if (!(target instanceof HTMLElement)) return false
    const tag = target.tagName
    return tag === 'INPUT' || tag === 'TEXTAREA' || tag === 'SELECT' || target.isContentEditable
  }, [])

  useEffect(() => {
    const handleKeydown = (event: KeyboardEvent) => {
      const wantsSave = (event.metaKey || event.ctrlKey) && event.key.toLowerCase() === 's'
      if (wantsSave) {
        event.preventDefault()
        if (!saving && sessionMeta && canSave) {
          void handleSave()
        }
        return
      }

      if (isTypingInField(event.target)) return

      const player = isVideo ? videoRef.current : audioRef.current
      if (!player) return

      if (event.code === 'Space') {
        event.preventDefault()
        if (player.paused) {
          player.play().catch(() => {})
        } else {
          player.pause()
        }
        return
      }

      if (event.key === 'ArrowLeft') {
        event.preventDefault()
        player.currentTime = Math.max(0, player.currentTime - 5)
        return
      }

      if (event.key === 'ArrowRight') {
        event.preventDefault()
        const nextTime = player.currentTime + 5
        if (Number.isFinite(player.duration)) {
          player.currentTime = Math.min(player.duration, nextTime)
        } else {
          player.currentTime = nextTime
        }
      }
    }

    window.addEventListener('keydown', handleKeydown)
    return () => window.removeEventListener('keydown', handleKeydown)
  }, [canSave, handleSave, isTypingInField, isVideo, saving, sessionMeta])

  return (
    <div className="space-y-6 relative">
      <div className="bg-white rounded-xl shadow-sm border border-gray-200">
        {/* Clean Header Toolbar */}
        <div className="flex items-center justify-between gap-4 p-4 border-b border-gray-200">
          <div className="flex items-center gap-3">
            <button
              className="p-2 rounded-lg hover:bg-gray-100 text-gray-600 disabled:opacity-40"
              onClick={handleUndo}
              disabled={!history.length}
              title="Undo (Ctrl+Z)"
            >
              <svg className="w-5 h-5" fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24">
                <path d="M3 10h10a5 5 0 015 5v2M3 10l6-6M3 10l6 6" />
              </svg>
            </button>
            <button
              className="p-2 rounded-lg hover:bg-gray-100 text-gray-600 disabled:opacity-40"
              onClick={handleRedo}
              disabled={!future.length}
              title="Redo (Ctrl+Y)"
            >
              <svg className="w-5 h-5" fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24">
                <path d="M21 10h-10a5 5 0 00-5 5v2M21 10l-6-6M21 10l-6 6" />
              </svg>
            </button>
            <div className="w-px h-6 bg-gray-200" />
            <button
              className="px-3 py-1.5 rounded-lg bg-primary-50 hover:bg-primary-100 text-primary-700 text-sm font-medium"
              onClick={handleAddUtterance}
              title="Add new line after selection"
            >
              + Add Line
            </button>
            <button
              className="px-3 py-1.5 rounded-lg bg-red-50 hover:bg-red-100 text-red-600 text-sm font-medium"
              onClick={handleDeleteUtterance}
              title="Delete selected line"
            >
              Delete Line
            </button>
          </div>

          <div className="flex items-center gap-2 flex-wrap justify-end">
            <button
              className="px-3 py-1.5 rounded-lg border border-primary-200 bg-primary-50 hover:bg-primary-100 text-primary-700 text-sm font-medium disabled:opacity-40"
              onClick={handleDownloadPdf}
              disabled={saving || !sessionMeta || (isCriminal ? !activeMediaKey : !pdfData)}
            >
              Export PDF
            </button>
            {appVariant === 'oncue' ? (
              <button
                className="px-3 py-1.5 rounded-lg border border-primary-200 bg-primary-50 hover:bg-primary-100 text-primary-700 text-sm font-medium disabled:opacity-40"
                onClick={() => xmlData && onDownload(xmlData, buildFilename('Transcript-Edited', '.xml'), 'application/xml')}
                disabled={!xmlData}
              >
                Export XML
              </button>
            ) : (
              <button
                className="px-3 py-1.5 rounded-lg border border-primary-200 bg-primary-50 hover:bg-primary-100 text-primary-700 text-sm font-medium disabled:opacity-40"
                onClick={handleDownloadViewer}
                disabled={!activeMediaKey}
              >
                Export Player
              </button>
            )}
            <button
              className="px-3 py-1.5 rounded-lg border border-gray-200 hover:bg-gray-50 text-gray-700 text-sm font-medium flex items-center gap-2"
              onClick={() => setShowSettings(!showSettings)}
            >
              <svg className="w-4 h-4" fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24">
                <path d="M10.325 4.317c.426-1.756 2.924-1.756 3.35 0a1.724 1.724 0 002.573 1.066c1.543-.94 3.31.826 2.37 2.37a1.724 1.724 0 001.065 2.572c1.756.426 1.756 2.924 0 3.35a1.724 1.724 0 00-1.066 2.573c.94 1.543-.826 3.31-2.37 2.37a1.724 1.724 0 00-2.572 1.065c-.426 1.756-2.924 1.756-3.35 0a1.724 1.724 0 00-2.573-1.066c-1.543.94-3.31-.826-2.37-2.37a1.724 1.724 0 00-1.065-2.572c-1.756-.426-1.756-2.924 0-3.35a1.724 1.724 0 001.066-2.573c-.94-1.543.826-3.31 2.37-2.37.996.608 2.296.07 2.572-1.065z" />
                <circle cx="12" cy="12" r="3" />
              </svg>
              Settings
            </button>
            {onOpenHistory && (
              <button
                className="px-3 py-1.5 rounded-lg border border-gray-200 hover:bg-gray-50 text-gray-700 text-sm font-medium"
                onClick={onOpenHistory}
              >
                Edit History
              </button>
            )}
            <button
              className="px-3 py-1.5 rounded-lg border border-gray-200 hover:bg-gray-50 text-gray-700 text-sm font-medium"
              onClick={() => setShowRenameModal(true)}
            >
              Rename Speakers
            </button>
            <button
              className="px-3 py-1.5 rounded-lg bg-indigo-50 hover:bg-indigo-100 text-indigo-700 text-sm font-medium disabled:opacity-50"
              onClick={handleResync}
              disabled={isResyncing || !resolvedMediaUrl}
              title="Re-align timestamps to audio"
            >
              {isResyncing ? 'Fixing...' : 'Fix Timing to Audio'}
            </button>
            {onGeminiRefine && (
              <button
                className="px-3 py-1.5 rounded-lg bg-amber-50 hover:bg-amber-100 text-amber-700 text-sm font-medium disabled:opacity-50"
                onClick={onGeminiRefine}
                disabled={isGeminiBusy}
              >
                {isGeminiBusy ? 'Running...' : 'Clean Wording (AI)'}
              </button>
            )}
            <button
              className="px-4 py-1.5 rounded-lg bg-primary-600 hover:bg-primary-700 text-white text-sm font-medium disabled:opacity-50"
              onClick={handleSave}
              disabled={saving || !sessionMeta || !canSave}
            >
              {saving ? 'Saving...' : canSave ? 'Save Changes' : 'Saved'}
            </button>
          </div>
        </div>

        {/* Collapsible Settings Panel */}
        {showSettings && (
          <div className="px-4 py-3 bg-gray-50 border-b border-gray-200 flex flex-wrap items-center gap-6">
            <label className="flex items-center gap-2 text-sm text-gray-700 cursor-pointer">
              <input
                type="checkbox"
                className="rounded border-gray-300"
                checked={autoScroll}
                onChange={(event) => setAutoScroll(event.target.checked)}
              />
              Auto-scroll to current line
            </label>
            <label className="flex items-center gap-2 text-sm text-gray-700 cursor-pointer" title="When changing end time, adjust next line's start">
              <input
                type="checkbox"
                className="rounded border-gray-300"
                checked={autoShiftNextLine}
                onChange={(event) => setAutoShiftNextLine(event.target.checked)}
              />
              Auto-shift next line timing
            </label>
          </div>
        )}
        <div className="card-body space-y-4">
          {error && (
            <div className="rounded-lg border border-red-200 bg-red-50 p-3 text-sm text-red-700">
              {error}
            </div>
          )}
          {geminiError && (
            <div className="rounded-lg border border-red-200 bg-red-50 p-3 text-sm text-red-700">
              Gemini Error: {geminiError}
            </div>
          )}
          {snapshotError && (
            <div className="rounded-lg border border-amber-200 bg-amber-50 p-3 text-sm text-amber-800">
              {snapshotError}
            </div>
          )}
          {(addError || deleteError) && (
            <div className="rounded-lg border border-amber-200 bg-amber-50 p-3 text-sm text-amber-800">
              {addError || deleteError}
            </div>
          )}
          {resyncError && (
            <div className="rounded-lg border border-red-200 bg-red-50 p-3 text-sm text-red-700">
              Re-sync Error: {resyncError}
            </div>
          )}

          {/* Media Player */}
          {resolvedMediaUrl ? (
            <div className="rounded-xl bg-gray-900 p-3">
              {isVideo ? (
                <video
                  key={resolvedMediaUrl}
                  ref={videoRef}
                  controls
                  preload="metadata"
                  className="w-full max-h-[32vh] rounded-lg bg-black object-contain"
                  src={resolvedMediaUrl}
                  onError={() => { void handleMediaError() }}
                />
              ) : (
                <audio
                  key={resolvedMediaUrl}
                  ref={audioRef}
                  controls
                  preload="metadata"
                  className="w-full"
                  src={resolvedMediaUrl}
                  onError={() => { void handleMediaError() }}
                />
              )}
            </div>
          ) : (
            <div className="rounded-xl border-2 border-dashed border-gray-300 p-6 text-center">
              <svg className="w-8 h-8 mx-auto mb-2 text-gray-400" fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24">
                <path d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z" />
              </svg>
              <p className="text-sm text-gray-500">Import source audio/video to enable playback, clip creation, and timing correction.</p>
              {onRequestMediaImport && (
                <button
                  type="button"
                  onClick={onRequestMediaImport}
                  className="mt-4 inline-flex items-center justify-center rounded-lg bg-primary-600 px-5 py-2.5 text-sm font-medium text-white hover:bg-primary-700"
                >
                  Import Media File
                </button>
              )}
            </div>
          )}

          <div className="rounded-xl bg-gray-50 px-4 py-3 text-sm flex flex-wrap items-center justify-between gap-3">
            <div className="flex items-center gap-5 text-gray-600">
              <span>Lines <span className="font-medium text-gray-900">{lines.length}</span></span>
              <span>Duration <span className="font-medium text-gray-900">{secondsToLabel(sessionMeta?.audio_duration ?? 0)}</span></span>
              <span>Updated <span className="font-medium text-gray-900 text-xs">{updatedLabel}</span></span>
            </div>
            <span
              className="text-xs text-primary-700 underline decoration-dotted cursor-help"
              title={'Shortcuts:\nSpace - Play/Pause\nLeft/Right - Skip 5s\nDouble-click line - Play from line'}
            >
              Shortcuts
            </span>
          </div>

          {manualScrollOverride && autoScroll && activeLineId && (
            <div className="flex justify-end">
              <button
                type="button"
                className="rounded-lg border border-primary-300 bg-white px-3 py-1.5 text-xs font-medium text-primary-700 hover:bg-primary-50"
                onClick={handleReturnToCurrentLine}
              >
                Return to current line
              </button>
            </div>
          )}

          <div className="rounded-lg border border-primary-200 bg-white shadow-inner">
            <div className="border-b border-primary-200 px-5 py-3">
              <div className="relative">
                <input
                  type="text"
                  placeholder="Search transcript... (Ctrl+F)"
                  className="input w-full pr-20"
                  value={searchQuery}
                  onChange={(e) => performSearch(e.target.value)}
                  onKeyDown={(e) => {
                    if (e.key === 'Enter') {
                      e.preventDefault()
                      goToSearchResult(e.shiftKey ? 'prev' : 'next')
                    } else if (e.key === 'Escape') {
                      clearSearch()
                    }
                  }}
                />
                {searchQuery && (
                  <div className="absolute right-2 top-1/2 -translate-y-1/2 flex items-center gap-1">
                    <span className="text-xs text-primary-500">
                      {searchMatches.length > 0 ? `${searchCurrentIndex + 1}/${searchMatches.length}` : '0/0'}
                    </span>
                    <button
                      type="button"
                      className="p-1 text-primary-400 hover:text-primary-600"
                      onClick={() => goToSearchResult('prev')}
                      title="Previous (Shift+Enter)"
                    >
                      <svg className="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                        <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M5 15l7-7 7 7" />
                      </svg>
                    </button>
                    <button
                      type="button"
                      className="p-1 text-primary-400 hover:text-primary-600"
                      onClick={() => goToSearchResult('next')}
                      title="Next (Enter)"
                    >
                      <svg className="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                        <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M19 9l-7 7-7-7" />
                      </svg>
                    </button>
                    <button
                      type="button"
                      className="p-1 text-primary-400 hover:text-primary-600"
                      onClick={clearSearch}
                      title="Clear"
                    >
                      <svg className="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                        <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M6 18L18 6M6 6l12 12" />
                      </svg>
                    </button>
                  </div>
                )}
              </div>
            </div>

            <div className="grid grid-cols-[70px_170px_minmax(0,1fr)_220px] border-b border-primary-200 bg-primary-100 px-5 py-3 text-xs font-semibold uppercase tracking-wide text-primary-600">
              <div>Pg:Ln</div>
              <div>Speaker</div>
              <div>Utterance</div>
              <div className="text-right">Timing</div>
            </div>

            <div
              ref={transcriptScrollRef}
              className="h-[62vh] overflow-y-auto"
              onScroll={handleTranscriptScroll}
            >
              {loading ? (
                <div className="p-6 text-center text-primary-500">Loading editor…</div>
              ) : lines.length === 0 ? (
                <div className="p-6 text-center text-primary-500">No lines available.</div>
              ) : (
                lines.map((line) => {
                  const isActive = activeLineId === line.id
                  const isSelected = selectedLineId === line.id
                  const isSearchMatch = searchMatches.includes(line.id)
                  const isCurrentSearchMatch = searchMatches[searchCurrentIndex] === line.id
                  const rowBackgroundClass = isSelected
                    ? 'bg-primary-100 hover:bg-primary-100'
                    : isCurrentSearchMatch
                      ? 'bg-amber-300'
                      : isSearchMatch
                        ? 'bg-amber-100'
                        : isActive
                          ? 'bg-yellow-200'
                          : 'bg-white hover:bg-primary-200'
                  const rowClasses = [
                    'grid grid-cols-[70px_170px_minmax(0,1fr)_220px] items-start gap-5 border-b border-primary-100 px-5 py-3 text-sm transition-colors',
                    rowBackgroundClass,
                    isSelected ? 'ring-2 ring-inset ring-primary-500 border-l-4 border-l-primary-600' : '',
                  ]
                  const timingInputClass = line.timestamp_error
                    ? 'w-28 rounded border border-red-400 bg-red-50 px-2 py-1.5 text-sm text-red-700 focus:border-red-500 focus:outline-none focus:ring-1 focus:ring-red-400 text-right font-mono tabular-nums'
                    : 'w-28 rounded border border-primary-200 px-2 py-1.5 text-sm text-primary-800 focus:border-primary-500 focus:outline-none focus:ring-1 focus:ring-primary-400 text-right font-mono tabular-nums'
                  return (
                    <div
                      key={line.id}
                      ref={(el) => {
                        lineRefs.current[line.id] = el
                      }}
                      onClick={() => setSelectedLineId(line.id)}
                      onDoubleClick={() => playLine(line)}
                      className={rowClasses.join(' ')}
                    >
                      <div className="text-sm font-mono text-primary-500">
                        {line.page ?? '—'}:{line.line ?? '—'}
                      </div>
                      <div
                        className="min-w-0 cursor-pointer truncate text-primary-900 pr-4"
                        onClick={(event) => {
                          event.stopPropagation()
                          if (!isSelected) {
                            setSelectedLineId(line.id)
                            return
                          }
                          beginEdit(line, 'speaker')
                        }}
                      >
                        {editingField && editingField.lineId === line.id && editingField.field === 'speaker' ? (
                          <input
                            ref={editInputRef as React.MutableRefObject<HTMLInputElement | null>}
                            className="input text-sm uppercase"
                            value={editingField.value}
                            onChange={(event) =>
                              setEditingField((prev) =>
                                prev ? { ...prev, value: event.target.value.toUpperCase() } : prev,
                              )
                            }
                            onBlur={commitEdit}
                            onKeyDown={(event) => {
                              if (event.key === 'Enter') {
                                event.preventDefault()
                                commitEdit()
                              } else if (event.key === 'Escape') {
                                event.preventDefault()
                                cancelEdit()
                              }
                            }}
                          />
                        ) : (
                          <span className="uppercase">{line.speaker || '—'}</span>
                        )}
                      </div>
                      <div
                        className="min-w-0 cursor-text whitespace-pre-wrap font-mono text-primary-800 pr-6"
                        onClick={(event) => {
                          event.stopPropagation()
                          if (!isSelected) {
                            setSelectedLineId(line.id)
                            return
                          }
                          beginEdit(line, 'text')
                        }}
                      >
                        {editingField && editingField.lineId === line.id && editingField.field === 'text' ? (
                          <textarea
                            ref={editInputRef as React.MutableRefObject<HTMLTextAreaElement | null>}
                            className="textarea text-sm"
                            rows={3}
                            value={editingField.value}
                            onChange={(event) =>
                              setEditingField((prev) => (prev ? { ...prev, value: event.target.value } : prev))
                            }
                            onBlur={commitEdit}
                            onKeyDown={(event) => {
                              if (event.key === 'Enter' && !event.shiftKey) {
                                event.preventDefault()
                                commitEdit()
                              } else if (event.key === 'Escape') {
                                event.preventDefault()
                                cancelEdit()
                              }
                            }}
                          />
                        ) : (
                          <span>{line.text || '—'}</span>
                        )}
                      </div>
                      <div className="flex flex-col items-end gap-2 text-sm text-primary-600">
                        {isSelected ? (
                          <>
                            <div className="flex items-center gap-2 text-xs text-primary-500">
                              <span className="uppercase tracking-wide text-xs text-primary-400">Start</span>
                              <input
                                type="number"
                                step="0.01"
                                min={0}
                                value={line.start}
                                onChange={(event) =>
                                  handleLineFieldChange(line.id, 'start', parseFloat(event.target.value))
                                }
                                className={timingInputClass}
                                title={line.timestamp_error ? 'Missing timestamp — adjust start/end to fix.' : undefined}
                              />
                            </div>
                            <div className="flex items-center gap-2 text-xs text-primary-500">
                              <span className="uppercase tracking-wide text-xs text-primary-400">End</span>
                              <input
                                type="number"
                                step="0.01"
                                min={0}
                                value={line.end}
                                onChange={(event) =>
                                  handleLineFieldChange(line.id, 'end', parseFloat(event.target.value))
                                }
                                className={timingInputClass}
                                title={line.timestamp_error ? 'Missing timestamp — adjust start/end to fix.' : undefined}
                              />
                            </div>
                            {line.timestamp_error && (
                              <span className="text-[10px] font-semibold uppercase tracking-wide text-red-600">
                                Fix timing
                              </span>
                            )}
                          </>
                        ) : (
                          <span className="font-mono tabular-nums text-xs text-primary-600">
                            {secondsToLabel(line.start)}
                          </span>
                        )}
                      </div>
                    </div>
                  )
                })
              )}
            </div>
          </div>
        </div>
      </div>

      {showRenameModal && (
        <div className="fixed inset-0 z-[9998] flex items-center justify-center bg-black/50 p-4">
          <div className="w-full max-w-md rounded-xl bg-white shadow-xl border border-gray-200">
            <div className="flex items-center justify-between p-4 border-b border-gray-200">
              <h3 className="text-lg font-semibold text-gray-900">Rename Speakers</h3>
              <button
                type="button"
                className="rounded border border-gray-200 px-3 py-1 text-sm text-gray-700 hover:bg-gray-50"
                onClick={() => setShowRenameModal(false)}
              >
                Close
              </button>
            </div>
            <form
              className="p-4 space-y-3"
              onSubmit={(event) => {
                handleRenameSpeaker(event)
              }}
            >
              {renameFeedback && (
                <div className="rounded bg-primary-50 px-3 py-2 text-sm text-primary-700">{renameFeedback}</div>
              )}
              <input
                type="text"
                value={renameFrom}
                onChange={(e) => { setRenameFrom(e.target.value.toUpperCase()); if (renameFeedback) setRenameFeedback(null) }}
                className="w-full rounded-lg border border-gray-200 px-3 py-2 text-sm uppercase"
                placeholder="Current name"
              />
              <input
                type="text"
                value={renameTo}
                onChange={(e) => { setRenameTo(e.target.value.toUpperCase()); if (renameFeedback) setRenameFeedback(null) }}
                className="w-full rounded-lg border border-gray-200 px-3 py-2 text-sm uppercase"
                placeholder="New name"
              />
              <div className="flex justify-end gap-2">
                <button
                  type="button"
                  className="rounded border border-gray-200 px-3 py-2 text-sm text-gray-700 hover:bg-gray-50"
                  onClick={() => setShowRenameModal(false)}
                >
                  Cancel
                </button>
                <button type="submit" className="rounded bg-primary-600 px-3 py-2 text-sm font-medium text-white hover:bg-primary-700" disabled={!lines.length}>
                  Rename All
                </button>
              </div>
            </form>
          </div>
        </div>
      )}

      {/* Re-sync Loading Overlay - uses z-[9999] to ensure it's above everything */}
      {isResyncing && (
        <div className="fixed top-0 left-0 right-0 bottom-0 z-[9999] flex items-center justify-center bg-black/50 backdrop-blur-sm">
          <div className="w-full max-w-sm rounded-xl bg-white p-8 shadow-2xl text-center">
            <div className="mb-4 flex justify-center">
              {/* Simple Spinner */}
              <svg className="h-10 w-10 animate-spin text-indigo-600" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
                <circle className="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" strokeWidth="4"></circle>
                <path className="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
              </svg>
            </div>
            <h3 className="text-lg font-bold text-gray-900">Re-syncing Transcript</h3>
            <p className="mt-2 text-sm text-gray-600">
              Automatically re-syncing the transcript to the media file. <br />
              This could take a few minutes for longer files.
            </p>
          </div>
        </div>
      )}
    </div>
  )
}
===== END FILE =====

===== FILE: frontend-next/src/components/WorkspaceSetup.tsx =====
'use client'

import { useState } from 'react'
import { pickAndInitWorkspace } from '@/lib/storage'

interface WorkspaceSetupProps {
  onComplete: () => void
}

export default function WorkspaceSetup({ onComplete }: WorkspaceSetupProps) {
  const [picking, setPicking] = useState(false)
  const [error, setError] = useState('')
  const [isReturning, setIsReturning] = useState(false)

  const handleChooseFolder = async () => {
    setPicking(true)
    setError('')
    try {
      const { isExisting } = await pickAndInitWorkspace()

      if (isExisting) {
        setIsReturning(true)
        // Small delay so user sees the "Welcome back" message
        setTimeout(() => onComplete(), 800)
      } else {
        onComplete()
      }
    } catch (err: any) {
      if (err?.name === 'AbortError') {
        // User cancelled the picker
        setPicking(false)
        return
      }
      setError(err?.message || 'Failed to set up workspace folder')
      setPicking(false)
    }
  }

  if (isReturning) {
    return (
      <div className="fixed inset-0 z-50 flex items-center justify-center bg-slate-900">
        <div className="max-w-md text-center px-6">
          <div className="w-16 h-16 bg-green-500/20 rounded-full flex items-center justify-center mx-auto mb-6">
            <svg className="w-8 h-8 text-green-400" fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24">
              <path d="M5 13l4 4L19 7" />
            </svg>
          </div>
          <h1 className="text-2xl font-bold text-white mb-2">Welcome back!</h1>
          <p className="text-slate-300">We found your existing data. Loading your workspace...</p>
        </div>
      </div>
    )
  }

  return (
    <div className="fixed inset-0 z-50 flex items-center justify-center bg-slate-900">
      <div className="max-w-lg text-center px-6">
        <div className="w-20 h-20 bg-primary-500/20 rounded-2xl flex items-center justify-center mx-auto mb-8">
          <svg className="w-10 h-10 text-primary-400" fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24">
            <path d="M3 7v10a2 2 0 002 2h14a2 2 0 002-2V9a2 2 0 00-2-2h-6l-2-2H5a2 2 0 00-2 2z" />
          </svg>
        </div>

        <h1 className="text-3xl font-bold text-white mb-3">Welcome to TranscribeAlpha</h1>
        <p className="text-slate-300 text-lg mb-8 leading-relaxed">
          Choose a folder to store your case data. Your media files will stay where they
          are &mdash; we&apos;ll just save transcripts and case information here.
        </p>

        {error && (
          <div className="mb-6 bg-red-500/10 border border-red-500/30 rounded-lg p-4 text-red-300 text-sm">
            {error}
          </div>
        )}

        <button
          onClick={handleChooseFolder}
          disabled={picking}
          className="px-8 py-4 bg-primary-600 hover:bg-primary-500 text-white rounded-xl font-semibold text-lg transition-colors disabled:opacity-60 disabled:cursor-not-allowed"
        >
          {picking ? (
            <span className="flex items-center gap-3">
              <svg className="w-5 h-5 animate-spin" fill="none" viewBox="0 0 24 24">
                <circle className="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" strokeWidth="4" />
                <path className="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4z" />
              </svg>
              Setting up...
            </span>
          ) : (
            'Choose Folder'
          )}
        </button>

        <p className="text-slate-500 text-sm mt-6">
          Works best in Chrome or Edge. Your data stays on your computer.
        </p>
      </div>
    </div>
  )
}
===== END FILE =====

===== FILE: frontend-next/src/components/layout/Sidebar.tsx =====
'use client'

import Link from 'next/link'
import { usePathname, useRouter, useSearchParams } from 'next/navigation'
import { useDashboard } from '@/context/DashboardContext'
import { normalizePathname, routes } from '@/utils/routes'
import { guardedPush } from '@/utils/navigationGuard'

interface NavItemProps {
  href: string
  icon: React.ReactNode
  label: string
  active?: boolean
  collapsed?: boolean
  title?: string
}

function NavItem({ href, icon, label, active, collapsed, title }: NavItemProps) {
  return (
    <Link
      href={href}
      title={collapsed ? (title ?? label) : undefined}
      className={`flex items-center rounded-lg text-sm font-medium transition-colors ${
        collapsed ? 'justify-center px-2 py-3' : 'gap-3 px-4 py-3'
      } ${
        active
          ? 'bg-primary-700 text-white'
          : 'text-primary-300 hover:bg-primary-800 hover:text-white'
      }`}
    >
      <span className="w-5 h-5 flex items-center justify-center opacity-80">{icon}</span>
      {!collapsed && <span>{label}</span>}
    </Link>
  )
}

interface SidebarProps {
  collapsed: boolean
  onToggle: () => void
}

export default function Sidebar({ collapsed, onToggle }: SidebarProps) {
  const router = useRouter()
  const rawPathname = usePathname()
  const searchParams = useSearchParams()
  const pathname = normalizePathname(rawPathname)
  const { cases, uncategorizedCount, recentTranscripts, setActiveMediaKey } = useDashboard()

  const isActive = (path: string) => {
    if (path === '/') return pathname === '/'
    return pathname.startsWith(path)
  }
  const activeCaseId = searchParams.get('id')
  const isCaseDetail = pathname === routes.caseDetailBase()
  const isCasesRoute = isActive(routes.cases()) || isCaseDetail

  return (
    <aside className={`bg-primary-900 text-white flex flex-col h-screen sticky top-0 transition-all duration-200 ${collapsed ? 'w-20' : 'w-72'}`}>
      <div className="p-4 border-b border-primary-700">
        <div className={`flex items-center ${collapsed ? 'justify-center' : 'justify-between'} gap-2`}>
          <Link href={routes.home()} className={`flex items-center ${collapsed ? 'justify-center' : 'gap-3'} min-w-0`}>
            <div className="w-9 h-9 bg-gradient-to-br from-primary-600 to-primary-500 rounded-lg flex items-center justify-center font-semibold text-lg">
              T
            </div>
            {!collapsed && <span className="text-xl font-light truncate">TranscribeAlpha</span>}
          </Link>
          {!collapsed && (
            <button
              type="button"
              onClick={onToggle}
              className="p-2 rounded-lg text-primary-300 hover:text-white hover:bg-primary-800 transition-colors"
              title="Collapse sidebar"
              aria-label="Collapse sidebar"
            >
              <svg className="w-4 h-4" fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24">
                <path d="M15 19l-7-7 7-7" />
              </svg>
            </button>
          )}
        </div>
        {collapsed && (
          <div className="mt-3 flex justify-center">
            <button
              type="button"
              onClick={onToggle}
              className="p-2 rounded-lg text-primary-300 hover:text-white hover:bg-primary-800 transition-colors"
              title="Expand sidebar"
              aria-label="Expand sidebar"
            >
              <svg className="w-4 h-4" fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24">
                <path d="M9 5l7 7-7 7" />
              </svg>
            </button>
          </div>
        )}
      </div>

      <nav className={`flex-1 space-y-1 overflow-y-auto ${collapsed ? 'p-3' : 'p-4'}`}>
        <NavItem
          href={routes.home()}
          active={isActive(routes.home()) && pathname === routes.home()}
          collapsed={collapsed}
          icon={
            <svg fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24" className="w-5 h-5">
              <path d="M3 12l2-2m0 0l7-7 7 7M5 10v10a1 1 0 001 1h3m10-11l2 2m-2-2v10a1 1 0 01-1 1h-3m-6 0a1 1 0 001-1v-4a1 1 0 011-1h2a1 1 0 011 1v4a1 1 0 001 1m-6 0h6" />
            </svg>
          }
          label="Dashboard"
        />

        <NavItem
          href={routes.transcribe()}
          active={isActive(routes.transcribe())}
          collapsed={collapsed}
          icon={
            <svg fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24" className="w-5 h-5">
              <path d="M7 3h7l5 5v13a1 1 0 01-1 1H7a2 2 0 01-2-2V5a2 2 0 012-2z" />
              <path d="M14 3v5h5" />
              <path d="M8.5 15.5c.6-1 1.2-1 1.8 0 .6 1 1.2 1 1.8 0 .6-1 1.2-1 1.8 0 .6 1 1.2 1 1.8 0" />
            </svg>
          }
          label="New Transcript"
        />

        <NavItem
          href={routes.editor()}
          active={isActive(routes.editor())}
          collapsed={collapsed}
          icon={
            <svg fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24" className="w-5 h-5">
              <path d="M11 5H6a2 2 0 00-2 2v11a2 2 0 002 2h11a2 2 0 002-2v-5m-1.414-9.414a2 2 0 112.828 2.828L11.828 15H9v-2.828l8.586-8.586z" />
            </svg>
          }
          label="Editor"
        />

        <NavItem
          href={routes.viewer()}
          active={isActive(routes.viewer())}
          collapsed={collapsed}
          icon={
            <svg fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24" className="w-5 h-5">
              <path d="M2 12s3.5-6 10-6 10 6 10 6-3.5 6-10 6-10-6-10-6z" />
              <circle cx="12" cy="12" r="3" />
            </svg>
          }
          label="Viewer"
        />

        <NavItem
          href={routes.cases()}
          active={isCasesRoute}
          collapsed={collapsed}
          icon={
            <svg fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24" className="w-5 h-5">
              <path d="M3 7v10a2 2 0 002 2h14a2 2 0 002-2V9a2 2 0 00-2-2h-6l-2-2H5a2 2 0 00-2 2z" />
            </svg>
          }
          label="Cases"
        />

        <NavItem
          href={routes.converter()}
          active={isActive(routes.converter())}
          collapsed={collapsed}
          icon={
            <svg fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24" className="w-5 h-5">
              <path d="M4 4v6h6M20 20v-6h-6" />
              <path d="M20 10a8 8 0 00-14.8-4M4 14a8 8 0 0014.8 4" />
            </svg>
          }
          label="Converter"
        />

        {!collapsed && (
          <>
            <div className="pt-6">
              <div className="flex items-center justify-between px-4 mb-2">
                <span className="text-xs font-semibold uppercase tracking-wider text-primary-400">
                  Cases
                </span>
                <Link
                  href={routes.cases()}
                  className="text-xs text-primary-400 hover:text-white transition-colors"
                >
                  View All
                </Link>
              </div>

              <div className="space-y-0.5">
                {cases.slice(0, 5).map((caseItem) => (
                  <Link
                    key={caseItem.case_id}
                    href={routes.caseDetail(caseItem.case_id)}
                    className={`flex items-center gap-3 px-4 py-2 rounded-lg text-sm transition-colors ${
                      (isCaseDetail && activeCaseId === caseItem.case_id)
                        ? 'bg-primary-700 text-white'
                        : 'text-primary-300 hover:bg-primary-800 hover:text-white'
                    }`}
                  >
                    <span className="w-7 h-7 bg-primary-700 rounded flex items-center justify-center text-xs">
                      {caseItem.transcript_count}
                    </span>
                    <span className="truncate flex-1">{caseItem.name}</span>
                  </Link>
                ))}

                {uncategorizedCount > 0 && (
                  <Link
                    href={routes.casesTab('uncategorized')}
                    className="flex items-center gap-3 px-4 py-2 rounded-lg text-sm text-primary-400 hover:bg-primary-800 hover:text-white transition-colors"
                  >
                    <span className="w-7 h-7 bg-primary-800 rounded flex items-center justify-center text-xs">
                      {uncategorizedCount}
                    </span>
                    <span className="truncate flex-1">Uncategorized</span>
                  </Link>
                )}

                {cases.length === 0 && uncategorizedCount === 0 && (
                  <div className="px-4 py-2 text-sm text-primary-500">
                    No cases yet
                  </div>
                )}
              </div>
            </div>

            <div className="pt-6">
              <div className="px-4 mb-2">
                <span className="text-xs font-semibold uppercase tracking-wider text-primary-400">
                  Recent
                </span>
              </div>

              <div className="space-y-0.5">
                {recentTranscripts.map((transcript) => (
                  <button
                    key={transcript.media_key}
                    onClick={() => {
                      setActiveMediaKey(transcript.media_key)
                      guardedPush(router, routes.editor(transcript.media_key))
                    }}
                    className="w-full flex items-center gap-3 px-4 py-2 rounded-lg text-sm text-left text-primary-300 hover:bg-primary-800 hover:text-white transition-colors"
                  >
                    <span className="text-primary-500">
                      <svg fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24" className="w-4 h-4">
                        <path d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z" />
                      </svg>
                    </span>
                    <span className="truncate flex-1">{transcript.title_label}</span>
                  </button>
                ))}

                {recentTranscripts.length === 0 && (
                  <div className="px-4 py-2 text-sm text-primary-500">
                    No recent transcripts
                  </div>
                )}
              </div>
            </div>
          </>
        )}
      </nav>

      <div className={`border-t border-primary-700 ${collapsed ? 'p-3' : 'p-4'}`}>
        <NavItem
          href={routes.settings()}
          active={isActive(routes.settings())}
          collapsed={collapsed}
          icon={
            <svg fill="none" stroke="currentColor" strokeWidth="2" viewBox="0 0 24 24" className="w-5 h-5">
              <path d="M10.325 4.317c.426-1.756 2.924-1.756 3.35 0a1.724 1.724 0 002.573 1.066c1.543-.94 3.31.826 2.37 2.37a1.724 1.724 0 001.065 2.572c1.756.426 1.756 2.924 0 3.35a1.724 1.724 0 00-1.066 2.573c.94 1.543-.826 3.31-2.37 2.37a1.724 1.724 0 00-2.572 1.065c-.426 1.756-2.924 1.756-3.35 0a1.724 1.724 0 00-2.573-1.066c-1.543.94-3.31-.826-2.37-2.37a1.724 1.724 0 00-1.065-2.572c-1.756-.426-1.756-2.924 0-3.35a1.724 1.724 0 001.066-2.573c-.94-1.543.826-3.31 2.37-2.37.996.608 2.296.07 2.572-1.065z" />
              <circle cx="12" cy="12" r="3" />
            </svg>
          }
          label="Settings"
        />
      </div>
    </aside>
  )
}
===== END FILE =====

===== FILE: frontend-next/src/context/DashboardContext.tsx =====
'use client'

import { createContext, useCallback, useContext, useEffect, useState, ReactNode } from 'react'
import { authenticatedFetch } from '@/utils/auth'
import {
  listCases as localListCases,
  listUncategorizedTranscripts as localListUncategorized,
  listTranscriptsInCase,
  type TranscriptSummary,
} from '@/lib/storage'

interface CaseMeta {
  case_id: string
  name: string
  description?: string
  created_at: string
  updated_at: string
  transcript_count: number
}

interface TranscriptListItem {
  media_key: string
  title_label: string
  updated_at?: string | null
  line_count?: number
  expires_at?: string | null
}

interface DashboardContextValue {
  // Cases
  cases: CaseMeta[]
  uncategorizedCount: number
  casesLoading: boolean
  refreshCases: () => Promise<void>

  // Recent transcripts (for sidebar)
  recentTranscripts: TranscriptListItem[]
  recentLoading: boolean
  refreshRecentTranscripts: () => Promise<void>

  // Current session state
  activeMediaKey: string | null
  setActiveMediaKey: (key: string | null) => void

  // App variant
  appVariant: 'oncue' | 'criminal'
  variantResolved: boolean
}

const DashboardContext = createContext<DashboardContextValue | null>(null)

export function DashboardProvider({ children }: { children: ReactNode }) {
  const [cases, setCases] = useState<CaseMeta[]>([])
  const [uncategorizedCount, setUncategorizedCount] = useState(0)
  const [casesLoading, setCasesLoading] = useState(true)

  const [recentTranscripts, setRecentTranscripts] = useState<TranscriptListItem[]>([])
  const [recentLoading, setRecentLoading] = useState(true)

  const [activeMediaKey, setActiveMediaKey] = useState<string | null>(null)
  const [appVariant, setAppVariant] = useState<'oncue' | 'criminal'>('oncue')
  const [variantResolved, setVariantResolved] = useState(false)

  // Fetch app config
  useEffect(() => {
    fetch('/api/config')
      .then((res) => res.json())
      .then((data) => {
        if (data.variant === 'criminal' || data.variant === 'oncue') {
          setAppVariant(data.variant)
        }
        setVariantResolved(true)
      })
      .catch(() => {
        setAppVariant('oncue')
        setVariantResolved(true)
      })
  }, [])

  // Load active media key from localStorage
  useEffect(() => {
    const stored = localStorage.getItem('active_media_key')
    if (stored) {
      setActiveMediaKey(stored)
    }
  }, [])

  // Save active media key to localStorage
  useEffect(() => {
    if (activeMediaKey) {
      localStorage.setItem('active_media_key', activeMediaKey)
    } else {
      localStorage.removeItem('active_media_key')
    }
  }, [activeMediaKey])

  const refreshCases = useCallback(async () => {
    setCasesLoading(true)
    try {
      if (appVariant === 'criminal') {
        const localCases = await localListCases()
        setCases(localCases)
        const uncategorized = await localListUncategorized()
        setUncategorizedCount(uncategorized.length)
      } else {
        const response = await authenticatedFetch('/api/cases')
        if (response.ok) {
          const data = await response.json()
          setCases(data.cases || [])
          setUncategorizedCount(data.uncategorized_count || 0)
        }
      }
    } catch (err) {
      console.error('Failed to fetch cases:', err)
    } finally {
      setCasesLoading(false)
    }
  }, [appVariant])

  const refreshRecentTranscripts = useCallback(async () => {
    setRecentLoading(true)
    try {
      if (appVariant === 'criminal') {
        // Aggregate from all cases + uncategorized
        const allTranscripts: TranscriptSummary[] = []
        const localCases = await localListCases()
        for (const c of localCases) {
          const caseTranscripts = await listTranscriptsInCase(c.case_id)
          allTranscripts.push(...caseTranscripts)
        }
        const uncategorized = await localListUncategorized()
        allTranscripts.push(...uncategorized)
        // Sort by updated_at desc and take 5
        allTranscripts.sort((a, b) => (b.updated_at || '').localeCompare(a.updated_at || ''))
        setRecentTranscripts(
          allTranscripts.slice(0, 5).map((t) => ({
            media_key: t.media_key,
            title_label: t.title_label,
            updated_at: t.updated_at,
            line_count: t.line_count,
          })),
        )
      } else {
        const response = await authenticatedFetch('/api/transcripts')
        if (response.ok) {
          const data = await response.json()
          // Get most recent 5 for sidebar
          setRecentTranscripts((data.transcripts || []).slice(0, 5))
        }
      }
    } catch (err) {
      console.error('Failed to fetch transcripts:', err)
    } finally {
      setRecentLoading(false)
    }
  }, [appVariant])

  // Initial load - only after variant is resolved
  useEffect(() => {
    if (!variantResolved) return
    refreshCases()
    refreshRecentTranscripts()
  }, [variantResolved, refreshCases, refreshRecentTranscripts])

  return (
    <DashboardContext.Provider
      value={{
        cases,
        uncategorizedCount,
        casesLoading,
        refreshCases,
        recentTranscripts,
        recentLoading,
        refreshRecentTranscripts,
        activeMediaKey,
        setActiveMediaKey,
        appVariant,
        variantResolved,
      }}
    >
      {children}
    </DashboardContext.Provider>
  )
}

export function useDashboard() {
  const context = useContext(DashboardContext)
  if (!context) {
    throw new Error('useDashboard must be used within a DashboardProvider')
  }
  return context
}
===== END FILE =====

===== FILE: frontend-next/src/lib/ffmpegWorker.ts =====
import { FFmpeg } from '@ffmpeg/ffmpeg'
import { fetchFile } from '@ffmpeg/util'
import { openDB } from './idb'
import { readBinaryFile, writeBinaryFile } from './storage'

export type CodecInfo = {
  isStandard: boolean
  formatCode?: number
  codecName?: string
  sampleRate?: number
  channels?: number
  needsConversion: boolean
  isCorrupted?: boolean
}

type ProgressCallback = (ratio: number) => void
type IterableDirectoryHandle = FileSystemDirectoryHandle & {
  entries(): AsyncIterable<[string, FileSystemHandle]>
}

const STANDARD_WAV_FORMATS: Record<number, string> = {
  0x0001: 'PCM',
  0x0003: 'IEEE Float',
  0x0006: 'A-law',
  0x0007: 'mu-law',
  0x0055: 'MP3',
}

const KNOWN_PROPRIETARY_WAV_FORMATS: Record<number, string> = {
  0x2222: 'G.729',
  0x0131: 'GSM-AMR',
}

const STANDARD_AUDIO_EXTENSIONS = new Set(['mp3', 'm4a', 'aac', 'ogg', 'opus', 'flac', 'wav'])
const STANDARD_VIDEO_EXTENSIONS = new Set(['mp4', 'webm', 'mov'])
const KNOWN_VIDEO_EXTENSIONS = new Set(['mp4', 'webm', 'mov', 'm4v', 'avi', 'mkv'])
const KNOWN_AUDIO_EXTENSIONS = new Set(['mp3', 'm4a', 'aac', 'ogg', 'opus', 'flac', 'wav', 'wma'])
const MIME_TYPE_BY_EXTENSION: Record<string, string> = {
  aac: 'audio/aac',
  avi: 'video/x-msvideo',
  flac: 'audio/flac',
  m4a: 'audio/mp4',
  m4v: 'video/x-m4v',
  mkv: 'video/x-matroska',
  mov: 'video/quicktime',
  mp3: 'audio/mpeg',
  mp4: 'video/mp4',
  ogg: 'audio/ogg',
  opus: 'audio/opus',
  wav: 'audio/wav',
  webm: 'video/webm',
  wma: 'audio/x-ms-wma',
}

const CACHE_DIR = 'cache/converted'
const CACHE_KEY_SAMPLE_BYTES = 64 * 1024
const CONVERTED_CACHE_MAX_BYTES = 2 * 1024 * 1024 * 1024
const RESET_RUNTIME_AFTER_EXTRACT_BYTES = 200 * 1024 * 1024
const WORKERFS_SIZE_THRESHOLD = 2 * 1024 * 1024 * 1024
const WORKSPACE_IDB_KEY = 'workspace-dir-handle'

let ffmpegInstance: FFmpeg | null = null
let loadPromise: Promise<void> | null = null
let operationQueue: Promise<void> = Promise.resolve()
let activeProgressCallback: ProgressCallback | null = null
let terminatedByUser = false
let listenersAttached = false

const progressListener = ({ progress }: { progress: number }) => {
  if (!activeProgressCallback) return
  const ratio = Number.isFinite(progress) ? Math.max(0, Math.min(1, progress)) : 0
  activeProgressCallback(ratio)
}

export class FFmpegCanceledError extends Error {
  constructor() {
    super('Conversion canceled')
    this.name = 'FFmpegCanceledError'
  }
}

function runSerial<T>(operation: () => Promise<T>): Promise<T> {
  const next = operationQueue.then(operation, operation)
  operationQueue = next.then(() => undefined, () => undefined)
  return next
}

function resetFFmpegRuntime(): void {
  if (ffmpegInstance) {
    try {
      ffmpegInstance.terminate()
    } catch {
      // Ignore termination failures
    }
  }
  ffmpegInstance = null
  loadPromise = null
  listenersAttached = false
  activeProgressCallback = null
}

function getFileExtension(filename: string): string {
  const dotIndex = filename.lastIndexOf('.')
  if (dotIndex === -1) return ''
  return filename.slice(dotIndex + 1).toLowerCase()
}

function replaceExtension(filename: string, extension: string): string {
  const dotIndex = filename.lastIndexOf('.')
  const base = dotIndex === -1 ? filename : filename.slice(0, dotIndex)
  return `${base}${extension}`
}

function getConvertedExtension(file: File): 'wav' | 'mp4' {
  return isLikelyVideoFile(file) ? 'mp4' : 'wav'
}

function getConvertedMimeType(file: File): string {
  return isLikelyVideoFile(file) ? 'video/mp4' : 'audio/wav'
}

function getConvertedFilename(file: File): string {
  const ext = getConvertedExtension(file)
  return replaceExtension(file.name, `_converted.${ext}`)
}

function getMimeTypeFromFilename(filename: string, fallbackFile: File): string {
  const extension = getFileExtension(filename)
  const byExtension = MIME_TYPE_BY_EXTENSION[extension]
  if (byExtension) return byExtension
  if (fallbackFile.type) return fallbackFile.type
  return isLikelyVideoFile(fallbackFile) ? 'video/mp4' : 'audio/wav'
}

function isLikelyVideoFile(file: File): boolean {
  if ((file.type || '').startsWith('video/')) return true
  const extension = getFileExtension(file.name)
  return KNOWN_VIDEO_EXTENSIONS.has(extension)
}

function isLikelyWavFile(file: File): boolean {
  const extension = getFileExtension(file.name)
  return extension === 'wav' || (file.type || '').toLowerCase().includes('wav')
}

function isKnownStandardByExtension(file: File): CodecInfo | null {
  const extension = getFileExtension(file.name)
  if (STANDARD_AUDIO_EXTENSIONS.has(extension)) {
    return {
      isStandard: true,
      codecName: extension.toUpperCase(),
      needsConversion: false,
    }
  }
  if (STANDARD_VIDEO_EXTENSIONS.has(extension)) {
    return {
      isStandard: true,
      codecName: extension.toUpperCase(),
      needsConversion: false,
    }
  }
  return null
}

function getContainerKind(file: File): 'audio' | 'video' {
  if (isLikelyVideoFile(file)) return 'video'
  return 'audio'
}

function readAscii(view: DataView, offset: number, length: number): string {
  let text = ''
  for (let i = 0; i < length; i += 1) {
    text += String.fromCharCode(view.getUint8(offset + i))
  }
  return text
}

function toUint8Array(data: unknown): Uint8Array {
  if (data instanceof Uint8Array) return data
  if (data instanceof ArrayBuffer) return new Uint8Array(data)
  if (typeof data === 'string') return new TextEncoder().encode(data)
  throw new Error('Unexpected ffmpeg output data type')
}

function toBlobBuffer(bytes: Uint8Array): ArrayBuffer {
  // Ensure File/Blob always receives an ArrayBuffer-backed payload (not SharedArrayBuffer-backed).
  const copy = new Uint8Array(bytes.byteLength)
  copy.set(bytes)
  return copy.buffer
}

function normalizeError(error: unknown): Error {
  if (error instanceof Error) return error
  return new Error(typeof error === 'string' ? error : 'Unknown FFmpeg error')
}

function isOutOfMemoryError(error: Error): boolean {
  const message = error.message.toLowerCase()
  return (
    message.includes('memory') ||
    message.includes('cannot enlarge memory') ||
    message.includes('out of memory')
  )
}

async function canPlayNatively(file: File): Promise<boolean> {
  if (typeof document === 'undefined') return true
  const isVideo = getContainerKind(file) === 'video'
  const element = document.createElement(isVideo ? 'video' : 'audio')
  const url = URL.createObjectURL(file)

  return new Promise<boolean>((resolve) => {
    let done = false
    const cleanUp = () => {
      if (done) return
      done = true
      element.removeAttribute('src')
      element.load()
      URL.revokeObjectURL(url)
    }
    const finish = (result: boolean) => {
      cleanUp()
      resolve(result)
    }
    const timeout = window.setTimeout(() => finish(false), 2500)

    const onReady = () => {
      window.clearTimeout(timeout)
      finish(true)
    }
    const onError = () => {
      window.clearTimeout(timeout)
      finish(false)
    }

    element.addEventListener('canplay', onReady, { once: true })
    element.addEventListener('loadedmetadata', onReady, { once: true })
    element.addEventListener('error', onError, { once: true })
    element.preload = 'metadata'
    element.src = url
    element.load()
  })
}

async function parseWavHeader(file: File): Promise<CodecInfo | null> {
  const readSize = Math.min(file.size, 4096)
  if (readSize < 12) return null

  const buffer = await file.slice(0, readSize).arrayBuffer()
  const view = new DataView(buffer)

  let headerZeroed = true
  for (let i = 0; i < Math.min(60, view.byteLength); i += 1) {
    if (view.getUint8(i) !== 0) {
      headerZeroed = false
      break
    }
  }
  if (headerZeroed) {
    let hasData = false
    for (let i = 60; i < Math.min(view.byteLength, 1024); i += 1) {
      if (view.getUint8(i) !== 0) {
        hasData = true
        break
      }
    }
    if (hasData) {
      return {
        isStandard: false,
        codecName: 'Corrupted WAV header',
        needsConversion: true,
        isCorrupted: true,
      }
    }
  }

  if (readAscii(view, 0, 4) !== 'RIFF' || readAscii(view, 8, 4) !== 'WAVE') {
    return null
  }

  let offset = 12
  while (offset + 8 <= view.byteLength) {
    const chunkId = readAscii(view, offset, 4)
    const chunkSize = view.getUint32(offset + 4, true)
    const dataOffset = offset + 8

    if (chunkId === 'fmt ' && dataOffset + 16 <= view.byteLength) {
      const formatCode = view.getUint16(dataOffset, true)
      const channels = view.getUint16(dataOffset + 2, true)
      const sampleRate = view.getUint32(dataOffset + 4, true)

      let resolvedCode = formatCode
      let codecName: string | undefined

      if (formatCode === 0xfffe && dataOffset + 26 <= view.byteLength) {
        const subFormatCode = view.getUint16(dataOffset + 24, true)
        resolvedCode = subFormatCode
        codecName = STANDARD_WAV_FORMATS[subFormatCode] || KNOWN_PROPRIETARY_WAV_FORMATS[subFormatCode] || 'Extensible WAV'
      } else {
        codecName = STANDARD_WAV_FORMATS[formatCode] || KNOWN_PROPRIETARY_WAV_FORMATS[formatCode] || `Unknown (0x${formatCode.toString(16)})`
      }

      const isStandard = Boolean(STANDARD_WAV_FORMATS[resolvedCode])
      return {
        isStandard,
        formatCode: resolvedCode,
        codecName,
        sampleRate,
        channels,
        needsConversion: !isStandard,
      }
    }

    const paddedSize = chunkSize + (chunkSize % 2)
    offset = dataOffset + paddedSize
  }

  return {
    isStandard: false,
    codecName: 'Unknown WAV format',
    needsConversion: true,
    isCorrupted: true,
  }
}

async function maybeRepairWav(file: File): Promise<File> {
  if (!isLikelyWavFile(file)) return file
  const buffer = await file.arrayBuffer()
  const repaired = attemptWavHeaderRepair(buffer)
  if (!repaired) return file
  return new File([repaired], file.name, {
    type: file.type || 'audio/wav',
    lastModified: file.lastModified,
  })
}

async function removeVirtualFile(ffmpeg: FFmpeg, path: string): Promise<void> {
  try {
    await ffmpeg.deleteFile(path)
  } catch {
    // Ignore file cleanup errors
  }
}

function conversionArgs(file: File, inputName: string, outputName: string): string[] {
  if (isLikelyVideoFile(file)) {
    return [
      '-i', inputName,
      '-c:v', 'libx264',
      '-preset', 'fast',
      '-crf', '18',
      '-c:a', 'aac',
      '-b:a', '192k',
      '-movflags', '+faststart',
      outputName,
    ]
  }

  return [
    '-i', inputName,
    '-acodec', 'pcm_s16le',
    outputName,
  ]
}

function isLikelyG729Codec(codecInfo: CodecInfo | null): boolean {
  if (!codecInfo) return false
  if (codecInfo.formatCode === 0x2222) return true
  const label = (codecInfo.codecName || '').toLowerCase()
  return label.includes('g.729') || label.includes('g729')
}

type ConversionAttempt = {
  label: string
  args: string[]
}

function buildConversionAttempts(
  file: File,
  inputName: string,
  outputName: string,
  codecInfo: CodecInfo | null,
): ConversionAttempt[] {
  const attempts: ConversionAttempt[] = [
    {
      label: 'default',
      args: conversionArgs(file, inputName, outputName),
    },
  ]

  if (!isLikelyVideoFile(file) && isLikelyG729Codec(codecInfo)) {
    attempts.push({
      label: 'force-g729-decoder',
      args: [
        '-f', 'wav',
        '-c:a', 'g729',
        '-i', inputName,
        '-acodec', 'pcm_s16le',
        outputName,
      ],
    })
    attempts.push({
      label: 'force-g729-decoder-mono',
      args: [
        '-f', 'wav',
        '-ac', '1',
        '-c:a', 'g729',
        '-i', inputName,
        '-acodec', 'pcm_s16le',
        outputName,
      ],
    })
  }

  return attempts
}

export async function getFFmpeg(): Promise<FFmpeg> {
  if (ffmpegInstance?.loaded) return ffmpegInstance
  if (!ffmpegInstance) {
    ffmpegInstance = new FFmpeg()
    listenersAttached = false
  }

  if (!listenersAttached) {
    ffmpegInstance.on('progress', progressListener)
    listenersAttached = true
  }

  if (!loadPromise) {
    loadPromise = ffmpegInstance.load({
      coreURL: '/ffmpeg-core.js',
      wasmURL: '/ffmpeg-core.wasm',
    })
      .then(() => undefined)
      .catch((error) => {
        ffmpegInstance = null
        listenersAttached = false
        throw error
      })
      .finally(() => {
        loadPromise = null
      })
  }

  await loadPromise
  return ffmpegInstance
}

export function cancelActiveFFmpegJob(): void {
  terminatedByUser = true
  resetFFmpegRuntime()
}

export async function detectCodec(file: File): Promise<CodecInfo> {
  if (isLikelyWavFile(file)) {
    const wavInfo = await parseWavHeader(file)
    if (wavInfo) return wavInfo
    return {
      isStandard: false,
      codecName: 'Unknown WAV format',
      needsConversion: true,
      isCorrupted: true,
    }
  }

  const byExtension = isKnownStandardByExtension(file)
  if (byExtension) return byExtension

  const extension = getFileExtension(file.name)
  if (KNOWN_AUDIO_EXTENSIONS.has(extension) || KNOWN_VIDEO_EXTENSIONS.has(extension)) {
    const canPlay = await canPlayNatively(file)
    return {
      isStandard: canPlay,
      codecName: canPlay ? extension.toUpperCase() : `Unsupported ${extension.toUpperCase()}`,
      needsConversion: !canPlay,
    }
  }

  const canPlay = await canPlayNatively(file)
  return {
    isStandard: canPlay,
    codecName: canPlay ? 'Browser-supported' : 'Unknown',
    needsConversion: !canPlay,
  }
}

export async function convertToPlayable(
  file: File,
  onProgress?: ProgressCallback,
): Promise<File> {
  return runSerial(async () => {
    terminatedByUser = false
    const sourceFile = await maybeRepairWav(file)
    const ffmpeg = await getFFmpeg()
    const inputExt = getFileExtension(sourceFile.name) || (isLikelyVideoFile(sourceFile) ? 'mp4' : 'wav')
    const outputExt = getConvertedExtension(sourceFile)
    const inputName = `input.${inputExt}`
    const outputName = `output.${outputExt}`
    const sourceCodec = isLikelyWavFile(sourceFile) ? await parseWavHeader(sourceFile) : null

    activeProgressCallback = onProgress ?? null

    try {
      await ffmpeg.writeFile(inputName, await fetchFile(sourceFile))

      let lastError: Error | null = null
      const attempts = buildConversionAttempts(sourceFile, inputName, outputName, sourceCodec)

      for (const attempt of attempts) {
        await removeVirtualFile(ffmpeg, outputName)
        try {
          const exitCode = await ffmpeg.exec(attempt.args)
          if (exitCode !== 0) {
            throw new Error(`FFmpeg conversion failed (${attempt.label})`)
          }

          const outputData = await ffmpeg.readFile(outputName)
          const bytes = toUint8Array(outputData)
          if (bytes.byteLength === 0) {
            throw new Error(`FFmpeg conversion produced an empty output file (${attempt.label})`)
          }

          return new File([toBlobBuffer(bytes)], getConvertedFilename(file), {
            type: getConvertedMimeType(file),
          })
        } catch (attemptError) {
          if (terminatedByUser) {
            terminatedByUser = false
            throw new FFmpegCanceledError()
          }
          lastError = normalizeError(attemptError)
        }
      }

      if (lastError) {
        if (isOutOfMemoryError(lastError)) {
          throw new Error('File too large for in-browser conversion. Consider desktop FFmpeg.')
        }
        if (isLikelyG729Codec(sourceCodec)) {
          throw new Error(
            'This G.729 file could not be decoded in-browser by the current FFmpeg build. ' +
            'Convert locally with desktop FFmpeg and re-import.',
          )
        }
        throw lastError
      }
      throw new Error('FFmpeg conversion failed')
    } catch (error) {
      if (terminatedByUser) {
        terminatedByUser = false
        throw new FFmpegCanceledError()
      }
      const normalized = normalizeError(error)
      if (isOutOfMemoryError(normalized)) {
        throw new Error('File too large for in-browser conversion. Consider desktop FFmpeg.')
      }
      throw normalized
    } finally {
      activeProgressCallback = null
      await removeVirtualFile(ffmpeg, inputName)
      await removeVirtualFile(ffmpeg, outputName)
    }
  })
}

export async function clipMedia(
  file: File,
  startTime: number,
  endTime: number,
  onProgress?: ProgressCallback,
): Promise<File> {
  if (!Number.isFinite(startTime) || !Number.isFinite(endTime) || endTime <= startTime) {
    throw new Error('Invalid clip time range.')
  }

  return runSerial(async () => {
    terminatedByUser = false
    const ffmpeg = await getFFmpeg()
    const sourceFile = await maybeRepairWav(file)
    const inputExt = getFileExtension(sourceFile.name) || (isLikelyVideoFile(sourceFile) ? 'mp4' : 'wav')
    const inputName = `clip-input.${inputExt}`
    const copyOutputName = `clip-output.${inputExt}`
    const fallbackOutputName = isLikelyVideoFile(sourceFile) ? 'clip-output.mp4' : 'clip-output.wav'
    const duration = Math.max(0, endTime - startTime)

    activeProgressCallback = onProgress ?? null

    try {
      await ffmpeg.writeFile(inputName, await fetchFile(sourceFile))

      let outputName = copyOutputName

      try {
        const copyExit = await ffmpeg.exec([
          '-ss', startTime.toString(),
          '-t', duration.toString(),
          '-i', inputName,
          '-c', 'copy',
          '-avoid_negative_ts', 'make_zero',
          outputName,
        ])
        if (copyExit !== 0) throw new Error('Stream copy failed')
      } catch {
        await removeVirtualFile(ffmpeg, copyOutputName)
        outputName = fallbackOutputName

        const fallbackArgs = isLikelyVideoFile(sourceFile)
          ? [
            '-ss', startTime.toString(),
            '-t', duration.toString(),
            '-i', inputName,
            '-c:v', 'libx264',
            '-preset', 'fast',
            '-crf', '18',
            '-c:a', 'aac',
            '-b:a', '192k',
            '-avoid_negative_ts', 'make_zero',
            outputName,
          ]
          : [
            '-ss', startTime.toString(),
            '-t', duration.toString(),
            '-i', inputName,
            '-acodec', 'pcm_s16le',
            outputName,
          ]

        const fallbackExit = await ffmpeg.exec(fallbackArgs)
        if (fallbackExit !== 0) {
          throw new Error('Clip export failed')
        }
      }

      const outputData = await ffmpeg.readFile(outputName)
      const bytes = toUint8Array(outputData)
      const outputExtension = getFileExtension(outputName)
      const outputFilename = outputExtension
        ? replaceExtension(file.name, `_clip.${outputExtension}`)
        : replaceExtension(file.name, '_clip')
      return new File([toBlobBuffer(bytes)], outputFilename, {
        type: getMimeTypeFromFilename(outputName, sourceFile),
      })
    } catch (error) {
      if (terminatedByUser) {
        terminatedByUser = false
        throw new FFmpegCanceledError()
      }
      throw normalizeError(error)
    } finally {
      activeProgressCallback = null
      await removeVirtualFile(ffmpeg, inputName)
      await removeVirtualFile(ffmpeg, copyOutputName)
      await removeVirtualFile(ffmpeg, fallbackOutputName)
    }
  })
}

export async function extractAudio(
  file: File,
  onProgress?: ProgressCallback,
): Promise<File> {
  return runSerial(async () => {
    terminatedByUser = false
    const sourceFile = await maybeRepairWav(file)
    const inputExt = getFileExtension(sourceFile.name) || (isLikelyVideoFile(sourceFile) ? 'mp4' : 'wav')
    const inputName = `audio-input.${inputExt}`
    const outputName = 'audio-output.mp3'
    const useWorkerFS = sourceFile.size >= WORKERFS_SIZE_THRESHOLD
    const workerFSMount = '/input'
    const workerFSInputPath = `${workerFSMount}/${sourceFile.name}`

    const runExtractionAttempt = async (): Promise<File> => {
      const ffmpeg = await getFFmpeg()
      activeProgressCallback = onProgress ?? null
      let mounted = false
      const effectiveInput = useWorkerFS ? workerFSInputPath : inputName
      try {
        if (useWorkerFS) {
          await ffmpeg.mount('WORKERFS' as never, { files: [sourceFile] } as never, workerFSMount)
          mounted = true
        } else {
          await ffmpeg.writeFile(inputName, await fetchFile(sourceFile))
        }

        const attempts: Array<{ label: string; args: string[] }> = [
          {
            label: 'libmp3lame',
            args: [
              '-i', effectiveInput,
              '-map', '0:a:0?',
              '-vn',
              '-sn',
              '-dn',
              '-ac', '1',
              '-ar', '16000',
              '-c:a', 'libmp3lame',
              '-b:a', '96k',
              outputName,
            ],
          },
          {
            label: 'default-mp3',
            args: [
              '-i', effectiveInput,
              '-map', '0:a:0?',
              '-vn',
              '-sn',
              '-dn',
              '-ac', '1',
              '-ar', '16000',
              '-b:a', '96k',
              outputName,
            ],
          },
        ]

        let lastError: Error | null = null
        for (const attempt of attempts) {
          await removeVirtualFile(ffmpeg, outputName)
          try {
            const exitCode = await ffmpeg.exec(attempt.args)
            if (exitCode !== 0) {
              throw new Error(`Audio extraction failed (${attempt.label})`)
            }
            const outputData = await ffmpeg.readFile(outputName)
            const bytes = toUint8Array(outputData)
            if (bytes.byteLength === 0) {
              throw new Error(`Audio extraction produced empty output (${attempt.label})`)
            }
            return new File([toBlobBuffer(bytes)], replaceExtension(file.name, '_audio.mp3'), {
              type: 'audio/mpeg',
            })
          } catch (attemptError) {
            if (terminatedByUser) {
              terminatedByUser = false
              throw new FFmpegCanceledError()
            }
            lastError = normalizeError(attemptError)
          }
        }

        throw lastError ?? new Error('Audio extraction failed')
      } finally {
        activeProgressCallback = null
        if (mounted) {
          try { await ffmpeg.unmount(workerFSMount) } catch { /* ignore unmount errors */ }
        } else {
          await removeVirtualFile(ffmpeg, inputName)
        }
        await removeVirtualFile(ffmpeg, outputName)
      }
    }

    try {
      const extracted = await runExtractionAttempt()
      if (sourceFile.size >= RESET_RUNTIME_AFTER_EXTRACT_BYTES) {
        // Large jobs can leave wasm memory fragmented; recycle runtime between files.
        resetFFmpegRuntime()
      }
      return extracted
    } catch (firstError) {
      if (firstError instanceof FFmpegCanceledError) throw firstError
      const normalized = normalizeError(firstError)
      if (isOutOfMemoryError(normalized)) {
        throw new Error('File too large for in-browser audio extraction. Split the file or use desktop FFmpeg.')
      }

      resetFFmpegRuntime()

      try {
        const extracted = await runExtractionAttempt()
        if (sourceFile.size >= RESET_RUNTIME_AFTER_EXTRACT_BYTES) {
          resetFFmpegRuntime()
        }
        return extracted
      } catch (secondError) {
        if (secondError instanceof FFmpegCanceledError) throw secondError
        const finalError = normalizeError(secondError)
        if (isOutOfMemoryError(finalError)) {
          throw new Error('File too large for in-browser audio extraction. Split the file or use desktop FFmpeg.')
        }
        throw finalError
      }
    }
  })
}

function bytesToHex(bytes: Uint8Array): string {
  let hex = ''
  for (let i = 0; i < bytes.length; i += 1) {
    hex += bytes[i].toString(16).padStart(2, '0')
  }
  return hex
}

async function getWorkspaceHandleFromIndexedDB(): Promise<FileSystemDirectoryHandle | null> {
  try {
    const db = await openDB()
    return await new Promise<FileSystemDirectoryHandle | null>((resolve) => {
      const tx = db.transaction('workspace', 'readonly')
      const store = tx.objectStore('workspace')
      const request = store.get(WORKSPACE_IDB_KEY)
      request.onsuccess = () => {
        resolve((request.result as FileSystemDirectoryHandle | null) ?? null)
      }
      request.onerror = () => {
        resolve(null)
      }
    })
  } catch {
    return null
  }
}

async function getConvertedCacheDirectory(create: boolean): Promise<FileSystemDirectoryHandle | null> {
  const workspace = await getWorkspaceHandleFromIndexedDB()
  if (!workspace) return null

  try {
    const cache = await workspace.getDirectoryHandle('cache', { create })
    return await cache.getDirectoryHandle('converted', { create })
  } catch {
    return null
  }
}

async function pruneConvertedCache(maxBytes = CONVERTED_CACHE_MAX_BYTES): Promise<void> {
  const cacheDir = await getConvertedCacheDirectory(false)
  if (!cacheDir) return

  const entries: Array<{ name: string; size: number; lastModified: number }> = []

  for await (const [name, handle] of (cacheDir as IterableDirectoryHandle).entries()) {
    if (handle.kind !== 'file') continue
    try {
      const file = await (handle as FileSystemFileHandle).getFile()
      entries.push({
        name,
        size: file.size,
        lastModified: file.lastModified,
      })
    } catch {
      // Skip inaccessible cache entries.
    }
  }

  let totalSize = entries.reduce((sum, entry) => sum + entry.size, 0)
  if (totalSize <= maxBytes) return

  entries.sort((a, b) => a.lastModified - b.lastModified)

  for (const entry of entries) {
    if (totalSize <= maxBytes) break
    try {
      await cacheDir.removeEntry(entry.name)
      totalSize -= entry.size
    } catch {
      // Ignore deletion failures and continue pruning the remaining entries.
    }
  }
}

export async function cacheKey(file: File): Promise<string> {
  const sampleSize = Math.min(file.size, CACHE_KEY_SAMPLE_BYTES)
  const sample = await file.slice(0, sampleSize).arrayBuffer()
  const metadata = new TextEncoder().encode(`${file.name}|${file.size}|${file.lastModified}|`)
  const payload = new Uint8Array(metadata.byteLength + sample.byteLength)
  payload.set(metadata, 0)
  payload.set(new Uint8Array(sample), metadata.byteLength)
  const digest = await crypto.subtle.digest('SHA-256', payload)
  return bytesToHex(new Uint8Array(digest)).slice(0, 16)
}

export async function getConvertedCachePath(file: File): Promise<string> {
  const extension = getConvertedExtension(file)
  const key = await cacheKey(file)
  return `${CACHE_DIR}/${key}.${extension}`
}

export async function readConvertedFromCache(file: File): Promise<File | null> {
  const path = await getConvertedCachePath(file)
  const bytes = await readBinaryFile(path)
  if (!bytes) return null

  return new File([bytes], getConvertedFilename(file), {
    type: getConvertedMimeType(file),
    lastModified: Date.now(),
  })
}

export async function writeConvertedToCache(originalFile: File, convertedFile: File): Promise<void> {
  const path = await getConvertedCachePath(originalFile)
  const data = await convertedFile.arrayBuffer()
  await writeBinaryFile(path, data)
  await pruneConvertedCache().catch(() => undefined)
}

export function attemptWavHeaderRepair(buffer: ArrayBuffer): ArrayBuffer | null {
  const view = new DataView(buffer)
  if (buffer.byteLength < 60) return null

  let headerZeroed = true
  for (let i = 0; i < 60; i += 1) {
    if (view.getUint8(i) !== 0) {
      headerZeroed = false
      break
    }
  }
  if (!headerZeroed) return null

  let hasData = false
  for (let i = 60; i < Math.min(buffer.byteLength, 1024); i += 1) {
    if (view.getUint8(i) !== 0) {
      hasData = true
      break
    }
  }
  if (!hasData) return null

  const dataSize = buffer.byteLength - 60
  const header = new ArrayBuffer(60)
  const hv = new DataView(header)

  writeString(hv, 0, 'RIFF')
  hv.setUint32(4, dataSize + 52, true)
  writeString(hv, 8, 'WAVE')

  writeString(hv, 12, 'fmt ')
  hv.setUint32(16, 20, true)
  hv.setUint16(20, 0x2222, true)
  hv.setUint16(22, 2, true)
  hv.setUint32(24, 8000, true)
  hv.setUint32(28, 2000, true)
  hv.setUint16(32, 20, true)
  hv.setUint16(34, 1, true)
  hv.setUint16(36, 2, true)
  hv.setUint16(38, 1, true)

  writeString(hv, 40, 'fact')
  hv.setUint32(44, 4, true)
  hv.setUint32(48, 0, true)

  writeString(hv, 52, 'data')
  hv.setUint32(56, dataSize, true)

  const result = new ArrayBuffer(60 + dataSize)
  new Uint8Array(result).set(new Uint8Array(header))
  new Uint8Array(result).set(new Uint8Array(buffer, 60), 60)
  return result
}

function writeString(view: DataView, offset: number, str: string) {
  for (let i = 0; i < str.length; i += 1) {
    view.setUint8(offset + i, str.charCodeAt(i))
  }
}
===== END FILE =====

===== FILE: frontend-next/src/lib/idb.ts =====
const DB_NAME = 'transcribealpha'
const DB_VERSION = 2

let dbPromise: Promise<IDBDatabase> | null = null

export function openDB(): Promise<IDBDatabase> {
  if (dbPromise) return dbPromise

  dbPromise = new Promise<IDBDatabase>((resolve, reject) => {
    const request = indexedDB.open(DB_NAME, DB_VERSION)

    request.onupgradeneeded = () => {
      const db = request.result
      if (!db.objectStoreNames.contains('workspace')) {
        db.createObjectStore('workspace')
      }
      if (!db.objectStoreNames.contains('media-handles')) {
        db.createObjectStore('media-handles')
      }
      if (!db.objectStoreNames.contains('media-blobs')) {
        db.createObjectStore('media-blobs')
      }
    }

    request.onsuccess = () => resolve(request.result)

    request.onerror = () => {
      dbPromise = null
      reject(request.error)
    }
  })

  return dbPromise
}
===== END FILE =====

===== FILE: frontend-next/src/lib/mediaHandles.ts =====
import { openDB } from './idb'

const HANDLE_STORE = 'media-handles'
const BLOB_STORE = 'media-blobs'

interface StoredMediaBlobRecord {
  blob: Blob
  filename: string
  contentType: string
  saved_at: string
}

export async function storeMediaHandle(
  handleId: string,
  handle: FileSystemFileHandle,
): Promise<void> {
  const db = await openDB()
  await new Promise<void>((resolve, reject) => {
    const tx = db.transaction(HANDLE_STORE, 'readwrite')
    const store = tx.objectStore(HANDLE_STORE)
    const request = store.put(handle, handleId)
    request.onsuccess = () => resolve()
    request.onerror = () => reject(request.error)
  })
}

export async function storeMediaBlob(
  sourceId: string,
  media: File | Blob,
  filename?: string,
  contentType?: string,
): Promise<void> {
  const db = await openDB()
  const record: StoredMediaBlobRecord = {
    blob: media,
    filename: filename || ((media instanceof File && media.name) ? media.name : `${sourceId}.bin`),
    contentType: contentType || media.type || 'application/octet-stream',
    saved_at: new Date().toISOString(),
  }

  await new Promise<void>((resolve, reject) => {
    const tx = db.transaction(BLOB_STORE, 'readwrite')
    const store = tx.objectStore(BLOB_STORE)
    const request = store.put(record, sourceId)
    request.onsuccess = () => resolve()
    request.onerror = () => reject(request.error)
  })
}

export async function getMediaHandle(
  handleId: string,
): Promise<FileSystemFileHandle | null> {
  try {
    const db = await openDB()
    const handle: FileSystemFileHandle | undefined = await new Promise(
      (resolve, reject) => {
        const tx = db.transaction(HANDLE_STORE, 'readonly')
        const store = tx.objectStore(HANDLE_STORE)
        const request = store.get(handleId)
        request.onsuccess = () => resolve(request.result)
        request.onerror = () => reject(request.error)
      },
    )

    if (!handle) return null

    // Request read permission
    const permission = await (handle as any).requestPermission({ mode: 'read' })
    if (permission !== 'granted') return null

    return handle
  } catch {
    return null
  }
}

export async function getMediaBlob(sourceId: string): Promise<File | null> {
  try {
    const db = await openDB()
    const record: StoredMediaBlobRecord | undefined = await new Promise(
      (resolve, reject) => {
        const tx = db.transaction(BLOB_STORE, 'readonly')
        const store = tx.objectStore(BLOB_STORE)
        const request = store.get(sourceId)
        request.onsuccess = () => resolve(request.result)
        request.onerror = () => reject(request.error)
      },
    )

    if (!record || !(record.blob instanceof Blob)) return null

    const name = record.filename || `${sourceId}.bin`
    const type = record.contentType || record.blob.type || 'application/octet-stream'
    return new File([record.blob], name, { type })
  } catch {
    return null
  }
}

export async function removeMediaHandle(handleId: string): Promise<void> {
  try {
    const db = await openDB()
    await new Promise<void>((resolve, reject) => {
      const tx = db.transaction(HANDLE_STORE, 'readwrite')
      const store = tx.objectStore(HANDLE_STORE)
      const request = store.delete(handleId)
      request.onsuccess = () => resolve()
      request.onerror = () => reject(request.error)
    })
  } catch {
    // Ignore errors
  }
}

export async function removeMediaBlob(sourceId: string): Promise<void> {
  try {
    const db = await openDB()
    await new Promise<void>((resolve, reject) => {
      const tx = db.transaction(BLOB_STORE, 'readwrite')
      const store = tx.objectStore(BLOB_STORE)
      const request = store.delete(sourceId)
      request.onsuccess = () => resolve()
      request.onerror = () => reject(request.error)
    })
  } catch {
    // Ignore errors
  }
}

export async function getMediaFile(sourceId: string): Promise<File | null> {
  // Prefer stored playable blob when available (e.g., converted media fallback).
  const blobMedia = await getMediaBlob(sourceId)
  if (blobMedia) return blobMedia

  const handle = await getMediaHandle(sourceId)
  if (!handle) return null
  try {
    return await handle.getFile()
  } catch {
    return null
  }
}

export async function getMediaObjectURL(sourceId: string): Promise<string | null> {
  const file = await getMediaFile(sourceId)
  if (!file) return null
  return URL.createObjectURL(file)
}

export async function promptRelinkMedia(
  expectedFilename: string,
): Promise<{
  handle: FileSystemFileHandle
  handleId: string
} | null> {
  try {
    const [handle] = await (window as any).showOpenFilePicker({
      types: [
        {
          description: `Locate: ${expectedFilename}`,
          accept: {
            'audio/*': [],
            'video/*': [],
          },
        },
      ],
      multiple: false,
    })

    if (!handle) return null

    const handleId = crypto.randomUUID()
    await storeMediaHandle(handleId, handle)
    return { handle, handleId }
  } catch {
    // User cancelled or API not available
    return null
  }
}

export async function storeMediaFromPicker(): Promise<{
  handle: FileSystemFileHandle
  handleId: string
  filename: string
  contentType: string
} | null> {
  try {
    const [handle] = await (window as any).showOpenFilePicker({
      types: [
        {
          description: 'Audio or video files',
          accept: {
            'audio/*': [],
            'video/*': [],
          },
        },
      ],
      multiple: false,
    })

    if (!handle) return null

    const file = await handle.getFile()
    const handleId = crypto.randomUUID()
    await storeMediaHandle(handleId, handle)

    return {
      handle,
      handleId,
      filename: file.name,
      contentType: file.type || 'application/octet-stream',
    }
  } catch {
    // User cancelled or API not available
    return null
  }
}
===== END FILE =====

===== FILE: frontend-next/src/lib/storage.ts =====
import { openDB } from './idb'

// ─── Types ──────────────────────────────────────────────────────────

export interface CaseMeta {
  case_id: string
  name: string
  case_number?: string
  description?: string
  created_at: string
  updated_at: string
}

export interface CaseDetail extends CaseMeta {
  transcript_count: number
  transcripts: TranscriptSummary[]
}

export interface TranscriptSummary {
  media_key: string
  title_label: string
  created_at?: string
  updated_at?: string | null
  audio_duration?: number
  line_count?: number
  case_id?: string | null
}

export interface TranscriptData {
  media_key: string
  created_at: string
  updated_at: string
  title_data: Record<string, string>
  audio_duration: number
  lines_per_page: number
  lines: unknown[]
  source_turns?: unknown[]
  pdf_base64?: string
  transcript_text?: string
  transcript?: string
  viewer_html_base64?: string
  oncue_xml_base64?: string
  media_filename?: string
  media_content_type?: string
  media_handle_id?: string
  media_blob_name?: string
  case_id?: string | null
  [key: string]: unknown
}

export interface SearchResult {
  media_key: string
  title_label: string
  matches: SearchMatch[]
}

export interface SearchMatch {
  line_id: string
  page: number
  line: number
  text: string
  speaker: string
  match_type: string
}

// ─── Constants ──────────────────────────────────────────────────────

const IDB_KEY_WORKSPACE = 'workspace-dir-handle'
const MULTI_TAB_CHANNEL = 'ta-multi-tab'
const CONFIG_FILENAME = 'config.json'

// ─── Module State ───────────────────────────────────────────────────

let workspaceHandle: FileSystemDirectoryHandle | null = null
let multiTabChannel: BroadcastChannel | null = null

// ─── Multi-Tab Detection ────────────────────────────────────────────

export function setupMultiTabDetection(onConflict: () => void): () => void {
  if (typeof BroadcastChannel === 'undefined') return () => {}

  multiTabChannel = new BroadcastChannel(MULTI_TAB_CHANNEL)

  // Announce presence
  multiTabChannel.postMessage({ type: 'tab-open', timestamp: Date.now() })

  multiTabChannel.onmessage = (event) => {
    if (event.data?.type === 'tab-open') {
      onConflict()
    }
  }

  return () => {
    multiTabChannel?.close()
    multiTabChannel = null
  }
}

// ─── Workspace Initialization ───────────────────────────────────────

export async function isWorkspaceConfigured(): Promise<boolean> {
  try {
    const db = await openDB()
    return new Promise((resolve) => {
      const tx = db.transaction('workspace', 'readonly')
      const store = tx.objectStore('workspace')
      const request = store.get(IDB_KEY_WORKSPACE)
      request.onsuccess = () => resolve(!!request.result)
      request.onerror = () => resolve(false)
    })
  } catch {
    return false
  }
}

export async function initWorkspace(): Promise<FileSystemDirectoryHandle | null> {
  try {
    const db = await openDB()
    const handle: FileSystemDirectoryHandle | undefined = await new Promise((resolve, reject) => {
      const tx = db.transaction('workspace', 'readonly')
      const store = tx.objectStore('workspace')
      const request = store.get(IDB_KEY_WORKSPACE)
      request.onsuccess = () => resolve(request.result)
      request.onerror = () => reject(request.error)
    })

    if (!handle) return null

    // Request permission
    const permission = await (handle as any).requestPermission({ mode: 'readwrite' })
    if (permission !== 'granted') return null

    // Verify workspace structure
    await ensureWorkspaceStructure(handle)
    workspaceHandle = handle
    return handle
  } catch {
    return null
  }
}

export async function pickAndInitWorkspace(): Promise<{ handle: FileSystemDirectoryHandle; isExisting: boolean }> {
  const handle = await (window as any).showDirectoryPicker({ mode: 'readwrite' })

  // Check if returning user
  let isExisting = false
  try {
    await handle.getFileHandle(CONFIG_FILENAME)
    isExisting = true
  } catch {
    // New workspace
  }

  if (!isExisting) {
    await ensureWorkspaceStructure(handle)
    await writeJSONToHandle(handle, CONFIG_FILENAME, {
      version: 1,
      created_at: new Date().toISOString(),
      preferences: {
        lines_per_page: 25,
        auto_save_interval_seconds: 60,
        default_transcription_model: 'assemblyai',
      },
    })
  }

  // Store handle in IndexedDB
  const db = await openDB()
  await new Promise<void>((resolve, reject) => {
    const tx = db.transaction('workspace', 'readwrite')
    const store = tx.objectStore('workspace')
    const request = store.put(handle, IDB_KEY_WORKSPACE)
    request.onsuccess = () => resolve()
    request.onerror = () => reject(request.error)
  })

  workspaceHandle = handle
  return { handle, isExisting }
}

async function ensureWorkspaceStructure(root: FileSystemDirectoryHandle): Promise<void> {
  await root.getDirectoryHandle('cases', { create: true })
  await root.getDirectoryHandle('uncategorized', { create: true })
  const cache = await root.getDirectoryHandle('cache', { create: true })
  await cache.getDirectoryHandle('converted', { create: true })
}

// ─── Low-Level File Operations ──────────────────────────────────────

function getWorkspaceHandle(): FileSystemDirectoryHandle {
  if (!workspaceHandle) {
    throw new Error('Workspace not initialized. Call initWorkspace() first.')
  }
  return workspaceHandle
}

async function navigateToDir(
  root: FileSystemDirectoryHandle,
  pathParts: string[],
  create = false,
): Promise<FileSystemDirectoryHandle> {
  let current = root
  for (const part of pathParts) {
    if (!part) continue
    current = await current.getDirectoryHandle(part, { create })
  }
  return current
}

async function writeJSONToHandle(
  dir: FileSystemDirectoryHandle,
  filename: string,
  data: unknown,
): Promise<void> {
  const fileHandle = await dir.getFileHandle(filename, { create: true })
  const writable = await fileHandle.createWritable()
  await writable.write(JSON.stringify(data, null, 2))
  await writable.close()
}

export async function readJSON<T>(path: string): Promise<T | null> {
  try {
    const root = getWorkspaceHandle()
    const parts = path.split('/')
    const filename = parts.pop()!
    const dir = await navigateToDir(root, parts)
    const fileHandle = await dir.getFileHandle(filename)
    const file = await fileHandle.getFile()
    const text = await file.text()
    return JSON.parse(text) as T
  } catch {
    return null
  }
}

export async function writeJSON(path: string, data: unknown): Promise<void> {
  const root = getWorkspaceHandle()
  const parts = path.split('/')
  const filename = parts.pop()!
  const dir = await navigateToDir(root, parts, true)
  await writeJSONToHandle(dir, filename, data)
}

export async function deleteFile(path: string): Promise<void> {
  try {
    const root = getWorkspaceHandle()
    const parts = path.split('/')
    const filename = parts.pop()!
    const dir = await navigateToDir(root, parts)
    await dir.removeEntry(filename)
  } catch (err: any) {
    if (err?.name !== 'NotFoundError') throw err
  }
}

export async function deleteDirectory(path: string): Promise<void> {
  try {
    const root = getWorkspaceHandle()
    const parts = path.split('/')
    const dirname = parts.pop()!
    const parent = await navigateToDir(root, parts)
    await parent.removeEntry(dirname, { recursive: true })
  } catch (err: any) {
    if (err?.name !== 'NotFoundError') throw err
  }
}

export async function listDirectory(path: string): Promise<string[]> {
  try {
    const root = getWorkspaceHandle()
    const parts = path.split('/').filter(Boolean)
    const dir = await navigateToDir(root, parts)
    const entries: string[] = []
    for await (const name of (dir as any).keys()) {
      entries.push(name)
    }
    return entries
  } catch {
    return []
  }
}

export async function fileExists(path: string): Promise<boolean> {
  try {
    const root = getWorkspaceHandle()
    const parts = path.split('/')
    const filename = parts.pop()!
    const dir = await navigateToDir(root, parts)
    await dir.getFileHandle(filename)
    return true
  } catch {
    return false
  }
}

// ─── Case Operations ────────────────────────────────────────────────

export async function listCases(): Promise<(CaseMeta & { transcript_count: number })[]> {
  const entries = await listDirectory('cases')
  const cases: (CaseMeta & { transcript_count: number })[] = []

  for (const name of entries) {
    try {
      const meta = await readJSON<CaseMeta>(`cases/${name}/meta.json`)
      if (meta) {
        const transcripts = await listDirectory(`cases/${name}/transcripts`)
        cases.push({
          ...meta,
          transcript_count: transcripts.filter((f) => f.endsWith('.json')).length,
        })
      }
    } catch {
      // Skip invalid case directories
    }
  }

  cases.sort((a, b) => (b.updated_at || '').localeCompare(a.updated_at || ''))
  return cases
}

export async function getCase(caseId: string): Promise<CaseDetail | null> {
  const meta = await readJSON<CaseMeta>(`cases/${caseId}/meta.json`)
  if (!meta) return null

  const transcripts = await listTranscriptsInCase(caseId)
  return {
    ...meta,
    transcript_count: transcripts.length,
    transcripts,
  }
}

export async function createCase(meta: CaseMeta): Promise<void> {
  const root = getWorkspaceHandle()
  const casesDir = await root.getDirectoryHandle('cases', { create: true })
  const caseDir = await casesDir.getDirectoryHandle(meta.case_id, { create: true })
  await caseDir.getDirectoryHandle('transcripts', { create: true })
  await caseDir.getDirectoryHandle('clips', { create: true })
  await caseDir.getDirectoryHandle('sequences', { create: true })
  await writeJSONToHandle(caseDir, 'meta.json', meta)
}

export async function updateCase(caseId: string, updates: Partial<CaseMeta>): Promise<CaseMeta> {
  const existing = await readJSON<CaseMeta>(`cases/${caseId}/meta.json`)
  if (!existing) throw new Error('Case not found')
  const updated: CaseMeta = {
    ...existing,
    ...updates,
    case_id: caseId,
    updated_at: new Date().toISOString(),
  }
  await writeJSON(`cases/${caseId}/meta.json`, updated)
  return updated
}

export async function deleteCase(caseId: string, deleteTranscripts = false): Promise<void> {
  if (!deleteTranscripts) {
    // Move transcripts to uncategorized -- write ALL copies first, then delete the case
    const transcripts = await listTranscriptsInCase(caseId)
    const failedCopies: string[] = []
    for (const t of transcripts) {
      try {
        const data = await readJSON<TranscriptData>(`cases/${caseId}/transcripts/${t.media_key}.json`)
        if (data) {
          data.case_id = null
          await writeJSON(`uncategorized/${t.media_key}.json`, data)
        }
      } catch {
        failedCopies.push(t.media_key)
      }
    }
    if (failedCopies.length > 0) {
      throw new Error(`Could not move ${failedCopies.length} transcript(s) to uncategorized. Case was not deleted.`)
    }
  }
  await deleteDirectory(`cases/${caseId}`)
}

// ─── Transcript Operations ──────────────────────────────────────────

function buildTranscriptSummary(data: TranscriptData, caseId?: string | null): TranscriptSummary {
  const titleData = data.title_data || {}
  return {
    media_key: data.media_key,
    title_label: titleData.FILE_NAME || titleData.CASE_NAME || data.media_key,
    created_at: data.created_at,
    updated_at: data.updated_at,
    audio_duration: data.audio_duration,
    line_count: Array.isArray(data.lines) ? data.lines.length : 0,
    case_id: caseId ?? data.case_id ?? null,
  }
}

export async function listTranscriptsInCase(caseId: string): Promise<TranscriptSummary[]> {
  const files = await listDirectory(`cases/${caseId}/transcripts`)
  const summaries: TranscriptSummary[] = []

  for (const file of files) {
    if (!file.endsWith('.json')) continue
    try {
      const data = await readJSON<TranscriptData>(`cases/${caseId}/transcripts/${file}`)
      if (data) {
        summaries.push(buildTranscriptSummary(data, caseId))
      }
    } catch {
      // Skip unreadable files
    }
  }

  summaries.sort((a, b) => (b.updated_at || '').localeCompare(a.updated_at || ''))
  return summaries
}

export async function listUncategorizedTranscripts(): Promise<TranscriptSummary[]> {
  const files = await listDirectory('uncategorized')
  const summaries: TranscriptSummary[] = []

  for (const file of files) {
    if (!file.endsWith('.json')) continue
    try {
      const data = await readJSON<TranscriptData>(`uncategorized/${file}`)
      if (data) {
        summaries.push(buildTranscriptSummary(data, null))
      }
    } catch {
      // Skip unreadable files
    }
  }

  summaries.sort((a, b) => (b.updated_at || '').localeCompare(a.updated_at || ''))
  return summaries
}

export async function getTranscript(mediaKey: string): Promise<TranscriptData | null> {
  // Check uncategorized first
  const uncategorized = await readJSON<TranscriptData>(`uncategorized/${mediaKey}.json`)
  if (uncategorized) return uncategorized

  // Search cases
  const caseEntries = await listDirectory('cases')
  for (const caseId of caseEntries) {
    const data = await readJSON<TranscriptData>(`cases/${caseId}/transcripts/${mediaKey}.json`)
    if (data) return data
  }

  return null
}

export async function saveTranscript(
  mediaKey: string,
  data: TranscriptData | Record<string, unknown>,
  caseId?: string,
): Promise<void> {
  const record = data as Record<string, unknown>
  record.updated_at = new Date().toISOString()
  if (!record.created_at) {
    record.created_at = record.updated_at
  }

  if (caseId) {
    record.case_id = caseId
    // Ensure case transcripts directory exists
    const root = getWorkspaceHandle()
    const casesDir = await root.getDirectoryHandle('cases', { create: true })
    const caseDir = await casesDir.getDirectoryHandle(caseId, { create: true })
    await caseDir.getDirectoryHandle('transcripts', { create: true })
    await writeJSON(`cases/${caseId}/transcripts/${mediaKey}.json`, record)
  } else {
    record.case_id = null
    await writeJSON(`uncategorized/${mediaKey}.json`, record)
  }
}

export async function deleteTranscript(mediaKey: string): Promise<void> {
  // Try uncategorized
  if (await fileExists(`uncategorized/${mediaKey}.json`)) {
    await deleteFile(`uncategorized/${mediaKey}.json`)
    return
  }

  // Search cases
  const caseEntries = await listDirectory('cases')
  for (const caseId of caseEntries) {
    if (await fileExists(`cases/${caseId}/transcripts/${mediaKey}.json`)) {
      await deleteFile(`cases/${caseId}/transcripts/${mediaKey}.json`)
      return
    }
  }
}

export async function moveTranscriptToCase(mediaKey: string, targetCaseId: string): Promise<void> {
  // Find the transcript
  const data = await getTranscript(mediaKey)
  if (!data) throw new Error('Transcript not found')

  // Write to new location FIRST (so data is safe before we delete the old copy)
  if (targetCaseId === 'uncategorized' || !targetCaseId) {
    data.case_id = null
    await saveTranscript(mediaKey, data)
  } else {
    data.case_id = targetCaseId
    await saveTranscript(mediaKey, data, targetCaseId)
  }

  // Only delete from old location after write succeeded
  // Find old location (it's wherever getTranscript found it, excluding the new location)
  if (targetCaseId === 'uncategorized' || !targetCaseId) {
    // We wrote to uncategorized, so delete from any case
    const caseEntries = await listDirectory('cases')
    for (const caseId of caseEntries) {
      if (await fileExists(`cases/${caseId}/transcripts/${mediaKey}.json`)) {
        await deleteFile(`cases/${caseId}/transcripts/${mediaKey}.json`)
        return
      }
    }
  } else {
    // We wrote to a case, so delete from uncategorized or other cases
    if (await fileExists(`uncategorized/${mediaKey}.json`)) {
      await deleteFile(`uncategorized/${mediaKey}.json`)
      return
    }
    const caseEntries = await listDirectory('cases')
    for (const caseId of caseEntries) {
      if (caseId === targetCaseId) continue
      if (await fileExists(`cases/${caseId}/transcripts/${mediaKey}.json`)) {
        await deleteFile(`cases/${caseId}/transcripts/${mediaKey}.json`)
        return
      }
    }
  }
}

// ─── Search ─────────────────────────────────────────────────────────

export async function searchCaseTranscripts(
  caseId: string,
  query: string,
): Promise<SearchResult[]> {
  const lowerQuery = query.toLowerCase()
  const files = await listDirectory(`cases/${caseId}/transcripts`)
  const results: SearchResult[] = []

  for (const file of files) {
    if (!file.endsWith('.json')) continue
    try {
      const data = await readJSON<TranscriptData>(`cases/${caseId}/transcripts/${file}`)
      if (!data || !Array.isArray(data.lines)) continue

      const matches: SearchMatch[] = []
      for (const line of data.lines as any[]) {
        const text = (line.text || '').toLowerCase()
        const speaker = (line.speaker || '').toLowerCase()
        if (text.includes(lowerQuery) || speaker.includes(lowerQuery)) {
          matches.push({
            line_id: line.id || '',
            page: line.page || 0,
            line: line.line || 0,
            text: line.text || '',
            speaker: line.speaker || '',
            match_type: text.includes(lowerQuery) ? 'text' : 'speaker',
          })
        }
      }

      if (matches.length > 0) {
        const titleData = data.title_data || {}
        results.push({
          media_key: data.media_key,
          title_label: titleData.FILE_NAME || titleData.CASE_NAME || data.media_key,
          matches,
        })
      }
    } catch {
      // Skip unreadable files
    }
  }

  return results
}

// ─── Workspace Info ─────────────────────────────────────────────────

export function getWorkspaceName(): string | null {
  return workspaceHandle?.name ?? null
}

export async function getStorageEstimate(): Promise<{ fileCount: number; totalSize: number }> {
  let fileCount = 0
  let totalSize = 0

  async function walk(dir: FileSystemDirectoryHandle) {
    for await (const entry of (dir as any).values()) {
      if (entry.kind === 'file') {
        fileCount++
        try {
          const file = await (entry as FileSystemFileHandle).getFile()
          totalSize += file.size
        } catch {
          // Skip inaccessible files
        }
      } else if (entry.kind === 'directory') {
        await walk(entry as FileSystemDirectoryHandle)
      }
    }
  }

  if (workspaceHandle) {
    await walk(workspaceHandle)
  }

  return { fileCount, totalSize }
}

export async function clearWorkspace(): Promise<void> {
  const db = await openDB()
  await new Promise<void>((resolve, reject) => {
    const tx = db.transaction('workspace', 'readwrite')
    const store = tx.objectStore('workspace')
    const request = store.delete(IDB_KEY_WORKSPACE)
    request.onsuccess = () => resolve()
    request.onerror = () => reject(request.error)
  })
  workspaceHandle = null
}

// ─── Clip and Sequence Operations ──────────────────────────────────

export interface ClipRecord {
  clip_id: string
  name: string
  source_media_key: string
  start_time: number
  end_time: number
  start_pgln?: number | null
  end_pgln?: number | null
  start_page?: number | null
  start_line?: number | null
  end_page?: number | null
  end_line?: number | null
  created_at: string
  updated_at?: string
  order?: number
}

export interface ClipSequenceEntry {
  clip_id: string
  source_media_key: string
  order: number
}

export interface ClipSequenceRecord {
  sequence_id: string
  name: string
  created_at: string
  updated_at: string
  order?: number
  entries: ClipSequenceEntry[]
}

function sortByOrderThenCreatedAt<T extends { order?: number; created_at?: string }>(items: T[]): T[] {
  return [...items].sort((a, b) => {
    const aOrder = typeof a.order === 'number' ? a.order : Number.MAX_SAFE_INTEGER
    const bOrder = typeof b.order === 'number' ? b.order : Number.MAX_SAFE_INTEGER
    if (aOrder !== bOrder) return aOrder - bOrder
    return (a.created_at || '').localeCompare(b.created_at || '')
  })
}

function normalizeSequenceEntries(entries: ClipSequenceEntry[]): ClipSequenceEntry[] {
  return [...entries]
    .sort((a, b) => a.order - b.order)
    .map((entry, index) => ({
      clip_id: entry.clip_id,
      source_media_key: entry.source_media_key,
      order: Number.isFinite(entry.order) ? entry.order : index,
    }))
}

export async function listCaseClips(caseId: string): Promise<ClipRecord[]> {
  const files = await listDirectory(`cases/${caseId}/clips`)
  const clips: ClipRecord[] = []

  for (const file of files) {
    if (!file.endsWith('.json')) continue
    const clip = await readJSON<ClipRecord>(`cases/${caseId}/clips/${file}`)
    if (clip) clips.push(clip)
  }

  return sortByOrderThenCreatedAt(clips)
}

export async function listTranscriptClips(caseId: string, mediaKey: string): Promise<ClipRecord[]> {
  const allClips = await listCaseClips(caseId)
  return allClips.filter((clip) => clip.source_media_key === mediaKey)
}

export async function getClip(caseId: string, clipId: string): Promise<ClipRecord | null> {
  return readJSON<ClipRecord>(`cases/${caseId}/clips/${clipId}.json`)
}

export async function saveClip(caseId: string, clip: ClipRecord): Promise<void> {
  const now = new Date().toISOString()
  const record: ClipRecord = {
    ...clip,
    clip_id: clip.clip_id,
    created_at: clip.created_at || now,
    updated_at: now,
  }
  await writeJSON(`cases/${caseId}/clips/${record.clip_id}.json`, record)
}

export async function deleteClip(caseId: string, clipId: string): Promise<void> {
  await deleteFile(`cases/${caseId}/clips/${clipId}.json`)
}

export async function listCaseSequences(caseId: string): Promise<ClipSequenceRecord[]> {
  const files = await listDirectory(`cases/${caseId}/sequences`)
  const sequences: ClipSequenceRecord[] = []

  for (const file of files) {
    if (!file.endsWith('.json')) continue
    const sequence = await readJSON<ClipSequenceRecord>(`cases/${caseId}/sequences/${file}`)
    if (sequence) {
      sequences.push({
        ...sequence,
        entries: normalizeSequenceEntries(sequence.entries || []),
      })
    }
  }

  return sortByOrderThenCreatedAt(sequences)
}

export async function getSequence(caseId: string, sequenceId: string): Promise<ClipSequenceRecord | null> {
  const sequence = await readJSON<ClipSequenceRecord>(`cases/${caseId}/sequences/${sequenceId}.json`)
  if (!sequence) return null
  return {
    ...sequence,
    entries: normalizeSequenceEntries(sequence.entries || []),
  }
}

export async function saveSequence(caseId: string, sequence: ClipSequenceRecord): Promise<void> {
  const now = new Date().toISOString()
  const record: ClipSequenceRecord = {
    ...sequence,
    sequence_id: sequence.sequence_id,
    created_at: sequence.created_at || now,
    updated_at: now,
    entries: normalizeSequenceEntries(sequence.entries || []),
  }
  await writeJSON(`cases/${caseId}/sequences/${record.sequence_id}.json`, record)
}

export async function deleteSequence(caseId: string, sequenceId: string): Promise<void> {
  await deleteFile(`cases/${caseId}/sequences/${sequenceId}.json`)
}

// ─── Binary File Operations ────────────────────────────────────────

export async function writeBinaryFile(
  path: string,
  data: ArrayBuffer | Uint8Array | Blob,
): Promise<void> {
  const root = getWorkspaceHandle()
  const parts = path.split('/')
  const filename = parts.pop()!
  const dir = await navigateToDir(root, parts, true)
  const fileHandle = await dir.getFileHandle(filename, { create: true })
  const writable = await fileHandle.createWritable()
  let payload: ArrayBuffer | Blob
  if (data instanceof Uint8Array) {
    // Ensure the payload is ArrayBuffer-backed for File System Access typings.
    const copy = new Uint8Array(data.byteLength)
    copy.set(data)
    payload = copy.buffer
  } else {
    payload = data
  }
  await writable.write(payload)
  await writable.close()
}

export async function readBinaryFile(path: string): Promise<ArrayBuffer | null> {
  try {
    const root = getWorkspaceHandle()
    const parts = path.split('/')
    const filename = parts.pop()!
    const dir = await navigateToDir(root, parts)
    const fileHandle = await dir.getFileHandle(filename)
    const file = await fileHandle.getFile()
    return await file.arrayBuffer()
  } catch {
    return null
  }
}
===== END FILE =====

===== FILE: frontend-next/src/utils/auth.ts =====
/**
 * Authentication utility for TranscribeAlpha
 * Handles token storage, refresh, and API authentication
 */

export interface User {
  username: string;
  role: string;
}

export interface AuthTokens {
  access_token: string;
  refresh_token: string;
}

interface MediaTokenResponse {
  token?: string;
  expires_in?: number;
  expires_at?: string;
}

const MEDIA_TOKEN_REFRESH_BUFFER_MS = 10 * 1000
let cachedMediaToken: { token: string; expiresAt: number } | null = null
let mediaTokenPromise: Promise<string | null> | null = null

/**
 * Get the current access token from localStorage
 */
export function getAccessToken(): string | null {
  if (typeof window === 'undefined') return null;
  return localStorage.getItem('access_token');
}

/**
 * Get the current refresh token from localStorage
 */
export function getRefreshToken(): string | null {
  if (typeof window === 'undefined') return null;
  return localStorage.getItem('refresh_token');
}

/**
 * Get the current user from localStorage
 */
export function getCurrentUser(): User | null {
  if (typeof window === 'undefined') return null;
  const userStr = localStorage.getItem('user');
  if (!userStr) return null;
  try {
    return JSON.parse(userStr);
  } catch {
    return null;
  }
}

/**
 * Check if user is authenticated
 */
export function isAuthenticated(): boolean {
  return !!getAccessToken();
}

/**
 * Clear all authentication data
 */
export function clearAuth(): void {
  if (typeof window === 'undefined') return;
  localStorage.removeItem('access_token');
  localStorage.removeItem('refresh_token');
  localStorage.removeItem('user');
  cachedMediaToken = null
  mediaTokenPromise = null
}

/**
 * Logout the current user
 */
export async function logout(): Promise<void> {
  try {
    const token = getAccessToken();
    if (token) {
      await fetch('/api/auth/logout', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${token}`,
          'Content-Type': 'application/json',
        },
      });
    }
  } catch (error) {
    console.error('Logout error:', error);
  } finally {
    clearAuth();
    // Reload the page to show login screen
    window.location.reload();
  }
}

/**
 * Refresh the access token using the refresh token
 */
export async function refreshAccessToken(): Promise<string | null> {
  const refreshToken = getRefreshToken();
  if (!refreshToken) {
    return null;
  }

  try {
    const response = await fetch('/api/auth/refresh', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({ refresh_token: refreshToken }),
    });

    if (!response.ok) {
      clearAuth();
      return null;
    }

    const data = await response.json();
    localStorage.setItem('access_token', data.access_token);
    return data.access_token;
  } catch (error) {
    console.error('Token refresh error:', error);
    clearAuth();
    return null;
  }
}

/**
 * Make an authenticated API request with automatic token refresh
 */
export async function authenticatedFetch(
  url: string,
  options: RequestInit = {}
): Promise<Response> {
  let token = getAccessToken();

  if (!token) {
    throw new Error('No access token available');
  }

  // Add Authorization header
  const headers = new Headers(options.headers);
  headers.set('Authorization', `Bearer ${token}`);

  const requestOptions: RequestInit = {
    ...options,
    headers,
  };

  // Make the request
  let response = await fetch(url, requestOptions);

  // If unauthorized, try to refresh the token and retry once
  if (response.status === 401) {
    token = await refreshAccessToken();

    if (token) {
      // Retry with new token
      headers.set('Authorization', `Bearer ${token}`);
      response = await fetch(url, requestOptions);
    } else {
      // Refresh failed, redirect to login
      clearAuth();
      window.location.reload();
      throw new Error('Authentication failed');
    }
  }

  return response;
}

/**
 * Add Authorization header to fetch options
 * This is a simpler helper for when you want to handle the response yourself
 */
export function getAuthHeaders(): HeadersInit {
  const token = getAccessToken();
  if (!token) {
    return {};
  }
  return {
    'Authorization': `Bearer ${token}`,
  };
}

/**
 * Append the current access token to media URLs that can't send headers.
 */
export function appendAccessTokenToMediaUrl(url: string): string {
  if (!url || !url.includes('/api/media/')) {
    return url;
  }
  if (url.includes('token=')) {
    return url;
  }
  const token = getAccessToken();
  if (!token) {
    return url;
  }
  const separator = url.includes('?') ? '&' : '?';
  return `${url}${separator}token=${encodeURIComponent(token)}`;
}

/**
 * Fetch a short-lived media token for protected media URLs.
 */
export async function getMediaToken(forceRefresh = false): Promise<string | null> {
  if (typeof window === 'undefined') return null
  const now = Date.now()
  if (!forceRefresh && cachedMediaToken && cachedMediaToken.expiresAt - MEDIA_TOKEN_REFRESH_BUFFER_MS > now) {
    return cachedMediaToken.token
  }
  if (!forceRefresh && mediaTokenPromise) {
    return mediaTokenPromise
  }

  mediaTokenPromise = (async () => {
    try {
      const response = await authenticatedFetch('/api/media-token', { method: 'POST' })
      if (!response.ok) {
        return null
      }
      const data: MediaTokenResponse = await response.json().catch(() => ({}))
      if (!data.token) {
        return null
      }
      const expiresIn = typeof data.expires_in === 'number' ? data.expires_in : 300
      cachedMediaToken = {
        token: data.token,
        expiresAt: now + expiresIn * 1000,
      }
      return data.token
    } catch {
      return null
    } finally {
      mediaTokenPromise = null
    }
  })()

  return mediaTokenPromise
}

/**
 * Build a media URL with a short-lived token.
 */
export async function buildMediaUrl(url: string, forceRefresh = false): Promise<string> {
  if (!url || !url.includes('/api/media/')) {
    return url
  }
  const token = await getMediaToken(forceRefresh)
  if (!token) {
    return url
  }
  if (url.includes('token=')) {
    return url
  }
  const separator = url.includes('?') ? '&' : '?'
  return `${url}${separator}token=${encodeURIComponent(token)}`
}

/**
 * Check if the access token is expired
 */
export function isTokenExpired(): boolean {
  const token = getAccessToken();
  if (!token) return true;

  try {
    // Decode JWT payload (simple base64 decode, not cryptographic verification)
    const payload = JSON.parse(atob(token.split('.')[1]));
    const exp = payload.exp;

    if (!exp) return true;

    // Check if token is expired
    const now = Math.floor(Date.now() / 1000);
    return now >= exp;
  } catch {
    return true;
  }
}

/**
 * Initialize authentication (no automatic refresh needed - tokens last 1 year)
 * Users stay logged in until they explicitly log out
 */
export function initializeTokenRefresh(): void {
  // Tokens now last 1 year, so no automatic refresh is needed
  // Users will stay logged in until they explicitly log out
  // This function is kept for API compatibility
}
===== END FILE =====

===== FILE: frontend-next/src/utils/navigationGuard.ts =====
const QUEUE_GUARD_KEY = 'transcribe_queue_processing'

const LEAVE_QUEUE_MESSAGE =
  'A transcription queue is still running. Leaving this page will stop the remaining queued work. Leave anyway?'

export function setQueueNavigationGuardActive(active: boolean): void {
  if (typeof window === 'undefined') return
  try {
    if (active) {
      sessionStorage.setItem(QUEUE_GUARD_KEY, '1')
    } else {
      sessionStorage.removeItem(QUEUE_GUARD_KEY)
    }
  } catch {
    // Ignore storage errors
  }
}

export function isQueueNavigationGuardActive(): boolean {
  if (typeof window === 'undefined') return false
  try {
    return sessionStorage.getItem(QUEUE_GUARD_KEY) === '1'
  } catch {
    return false
  }
}

export function confirmQueueNavigation(): boolean {
  if (!isQueueNavigationGuardActive()) return true
  if (typeof window === 'undefined') return true
  return window.confirm(LEAVE_QUEUE_MESSAGE)
}

export function guardedPush(
  router: { push: (href: string) => void },
  href: string,
): void {
  if (!confirmQueueNavigation()) return
  router.push(href)
}
===== END FILE =====

===== FILE: frontend-next/src/utils/routes.ts =====
const withTrailingSlash = (path: string) => (path.endsWith('/') ? path : `${path}/`)

export const normalizePathname = (pathname: string) => {
  if (!pathname || pathname === '/') return '/'
  return pathname.endsWith('/') ? pathname : `${pathname}/`
}

export const routes = {
  home: () => '/',
  transcribe: (caseId?: string) => {
    const base = withTrailingSlash('/transcribe')
    if (!caseId) return base
    return `${base}?case_id=${encodeURIComponent(caseId)}`
  },
  editor: (mediaKey?: string) => {
    const base = withTrailingSlash('/editor')
    if (!mediaKey) return base
    return `${base}?key=${encodeURIComponent(mediaKey)}`
  },
  viewer: (mediaKey?: string, caseId?: string) => {
    const base = withTrailingSlash('/viewer')
    const params = new URLSearchParams()
    if (mediaKey) params.set('key', mediaKey)
    if (caseId) params.set('case', caseId)
    const query = params.toString()
    return query ? `${base}?${query}` : base
  },
  cases: () => withTrailingSlash('/cases'),
  casesTab: (tab: string) => `${withTrailingSlash('/cases')}?tab=${encodeURIComponent(tab)}`,
  caseDetailBase: () => withTrailingSlash('/case-detail'),
  caseDetail: (caseId: string) => `${withTrailingSlash('/case-detail')}?id=${encodeURIComponent(caseId)}`,
  settings: () => withTrailingSlash('/settings'),
  converter: () => withTrailingSlash('/converter'),
}
===== END FILE =====

===== FILE: frontend-next/tailwind.config.js =====
/** @type {import('tailwindcss').Config} */
module.exports = {
  content: [
    './src/pages/**/*.{js,ts,jsx,tsx,mdx}',
    './src/components/**/*.{js,ts,jsx,tsx,mdx}',
    './src/app/**/*.{js,ts,jsx,tsx,mdx}',
  ],
  theme: {
    extend: {
      colors: {
        primary: {
          50: '#f8fafc',
          100: '#f1f5f9',
          200: '#e2e8f0',
          300: '#cbd5e1',
          400: '#94a3b8',
          500: '#64748b',
          600: '#475569',
          700: '#334155',
          800: '#1e293b',
          900: '#0f172a',
        },
      },
      fontFamily: {
        sans: ['Inter', 'system-ui', 'sans-serif'],
        mono: ['"Courier New"', 'Courier', 'monospace'],
      },
    },
  },
  plugins: [],
}
===== END FILE =====

===== FILE: frontend-next/tsconfig.json =====
{
  "compilerOptions": {
    "target": "es5",
    "lib": ["dom", "dom.iterable", "es6"],
    "allowJs": true,
    "skipLibCheck": true,
    "strict": true,
    "noEmit": true,
    "esModuleInterop": true,
    "module": "esnext",
    "moduleResolution": "bundler",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "jsx": "preserve",
    "incremental": true,
    "plugins": [
      {
        "name": "next"
      }
    ],
    "paths": {
      "@/*": ["./src/*"]
    }
  },
  "include": ["next-env.d.ts", "**/*.ts", "**/*.tsx", ".next/types/**/*.ts"],
  "exclude": ["node_modules"]
}
===== END FILE =====

===== FILE: frontend-next/tsconfig.tsbuildinfo =====
{"fileNames":["./node_modules/typescript/lib/lib.es5.d.ts","./node_modules/typescript/lib/lib.es2015.d.ts","./node_modules/typescript/lib/lib.es2016.d.ts","./node_modules/typescript/lib/lib.es2017.d.ts","./node_modules/typescript/lib/lib.es2018.d.ts","./node_modules/typescript/lib/lib.es2019.d.ts","./node_modules/typescript/lib/lib.es2020.d.ts","./node_modules/typescript/lib/lib.dom.d.ts","./node_modules/typescript/lib/lib.dom.iterable.d.ts","./node_modules/typescript/lib/lib.es2015.core.d.ts","./node_modules/typescript/lib/lib.es2015.collection.d.ts","./node_modules/typescript/lib/lib.es2015.generator.d.ts","./node_modules/typescript/lib/lib.es2015.iterable.d.ts","./node_modules/typescript/lib/lib.es2015.promise.d.ts","./node_modules/typescript/lib/lib.es2015.proxy.d.ts","./node_modules/typescript/lib/lib.es2015.reflect.d.ts","./node_modules/typescript/lib/lib.es2015.symbol.d.ts","./node_modules/typescript/lib/lib.es2015.symbol.wellknown.d.ts","./node_modules/typescript/lib/lib.es2016.array.include.d.ts","./node_modules/typescript/lib/lib.es2016.intl.d.ts","./node_modules/typescript/lib/lib.es2017.arraybuffer.d.ts","./node_modules/typescript/lib/lib.es2017.date.d.ts","./node_modules/typescript/lib/lib.es2017.object.d.ts","./node_modules/typescript/lib/lib.es2017.sharedmemory.d.ts","./node_modules/typescript/lib/lib.es2017.string.d.ts","./node_modules/typescript/lib/lib.es2017.intl.d.ts","./node_modules/typescript/lib/lib.es2017.typedarrays.d.ts","./node_modules/typescript/lib/lib.es2018.asyncgenerator.d.ts","./node_modules/typescript/lib/lib.es2018.asynciterable.d.ts","./node_modules/typescript/lib/lib.es2018.intl.d.ts","./node_modules/typescript/lib/lib.es2018.promise.d.ts","./node_modules/typescript/lib/lib.es2018.regexp.d.ts","./node_modules/typescript/lib/lib.es2019.array.d.ts","./node_modules/typescript/lib/lib.es2019.object.d.ts","./node_modules/typescript/lib/lib.es2019.string.d.ts","./node_modules/typescript/lib/lib.es2019.symbol.d.ts","./node_modules/typescript/lib/lib.es2019.intl.d.ts","./node_modules/typescript/lib/lib.es2020.bigint.d.ts","./node_modules/typescript/lib/lib.es2020.date.d.ts","./node_modules/typescript/lib/lib.es2020.promise.d.ts","./node_modules/typescript/lib/lib.es2020.sharedmemory.d.ts","./node_modules/typescript/lib/lib.es2020.string.d.ts","./node_modules/typescript/lib/lib.es2020.symbol.wellknown.d.ts","./node_modules/typescript/lib/lib.es2020.intl.d.ts","./node_modules/typescript/lib/lib.es2020.number.d.ts","./node_modules/typescript/lib/lib.decorators.d.ts","./node_modules/typescript/lib/lib.decorators.legacy.d.ts","./node_modules/next/dist/styled-jsx/types/css.d.ts","./node_modules/@types/react/global.d.ts","./node_modules/csstype/index.d.ts","./node_modules/@types/prop-types/index.d.ts","./node_modules/@types/react/index.d.ts","./node_modules/next/dist/styled-jsx/types/index.d.ts","./node_modules/next/dist/styled-jsx/types/macro.d.ts","./node_modules/next/dist/styled-jsx/types/style.d.ts","./node_modules/next/dist/styled-jsx/types/global.d.ts","./node_modules/next/dist/shared/lib/amp.d.ts","./node_modules/next/amp.d.ts","./node_modules/@types/node/compatibility/disposable.d.ts","./node_modules/@types/node/compatibility/indexable.d.ts","./node_modules/@types/node/compatibility/iterators.d.ts","./node_modules/@types/node/compatibility/index.d.ts","./node_modules/@types/node/globals.typedarray.d.ts","./node_modules/@types/node/buffer.buffer.d.ts","../../../node_modules/buffer/index.d.ts","./node_modules/undici-types/header.d.ts","./node_modules/undici-types/readable.d.ts","./node_modules/undici-types/file.d.ts","./node_modules/undici-types/fetch.d.ts","./node_modules/undici-types/formdata.d.ts","./node_modules/undici-types/connector.d.ts","./node_modules/undici-types/client.d.ts","./node_modules/undici-types/errors.d.ts","./node_modules/undici-types/dispatcher.d.ts","./node_modules/undici-types/global-dispatcher.d.ts","./node_modules/undici-types/global-origin.d.ts","./node_modules/undici-types/pool-stats.d.ts","./node_modules/undici-types/pool.d.ts","./node_modules/undici-types/handlers.d.ts","./node_modules/undici-types/balanced-pool.d.ts","./node_modules/undici-types/agent.d.ts","./node_modules/undici-types/mock-interceptor.d.ts","./node_modules/undici-types/mock-agent.d.ts","./node_modules/undici-types/mock-client.d.ts","./node_modules/undici-types/mock-pool.d.ts","./node_modules/undici-types/mock-errors.d.ts","./node_modules/undici-types/proxy-agent.d.ts","./node_modules/undici-types/env-http-proxy-agent.d.ts","./node_modules/undici-types/retry-handler.d.ts","./node_modules/undici-types/retry-agent.d.ts","./node_modules/undici-types/api.d.ts","./node_modules/undici-types/interceptors.d.ts","./node_modules/undici-types/util.d.ts","./node_modules/undici-types/cookies.d.ts","./node_modules/undici-types/patch.d.ts","./node_modules/undici-types/websocket.d.ts","./node_modules/undici-types/eventsource.d.ts","./node_modules/undici-types/filereader.d.ts","./node_modules/undici-types/diagnostics-channel.d.ts","./node_modules/undici-types/content-type.d.ts","./node_modules/undici-types/cache.d.ts","./node_modules/undici-types/index.d.ts","./node_modules/@types/node/globals.d.ts","./node_modules/@types/node/assert.d.ts","./node_modules/@types/node/assert/strict.d.ts","./node_modules/@types/node/async_hooks.d.ts","./node_modules/@types/node/buffer.d.ts","./node_modules/@types/node/child_process.d.ts","./node_modules/@types/node/cluster.d.ts","./node_modules/@types/node/console.d.ts","./node_modules/@types/node/constants.d.ts","./node_modules/@types/node/crypto.d.ts","./node_modules/@types/node/dgram.d.ts","./node_modules/@types/node/diagnostics_channel.d.ts","./node_modules/@types/node/dns.d.ts","./node_modules/@types/node/dns/promises.d.ts","./node_modules/@types/node/domain.d.ts","./node_modules/@types/node/dom-events.d.ts","./node_modules/@types/node/events.d.ts","./node_modules/@types/node/fs.d.ts","./node_modules/@types/node/fs/promises.d.ts","./node_modules/@types/node/http.d.ts","./node_modules/@types/node/http2.d.ts","./node_modules/@types/node/https.d.ts","./node_modules/@types/node/inspector.d.ts","./node_modules/@types/node/module.d.ts","./node_modules/@types/node/net.d.ts","./node_modules/@types/node/os.d.ts","./node_modules/@types/node/path.d.ts","./node_modules/@types/node/perf_hooks.d.ts","./node_modules/@types/node/process.d.ts","./node_modules/@types/node/punycode.d.ts","./node_modules/@types/node/querystring.d.ts","./node_modules/@types/node/readline.d.ts","./node_modules/@types/node/readline/promises.d.ts","./node_modules/@types/node/repl.d.ts","./node_modules/@types/node/sea.d.ts","./node_modules/@types/node/stream.d.ts","./node_modules/@types/node/stream/promises.d.ts","./node_modules/@types/node/stream/consumers.d.ts","./node_modules/@types/node/stream/web.d.ts","./node_modules/@types/node/string_decoder.d.ts","./node_modules/@types/node/test.d.ts","./node_modules/@types/node/timers.d.ts","./node_modules/@types/node/timers/promises.d.ts","./node_modules/@types/node/tls.d.ts","./node_modules/@types/node/trace_events.d.ts","./node_modules/@types/node/tty.d.ts","./node_modules/@types/node/url.d.ts","./node_modules/@types/node/util.d.ts","./node_modules/@types/node/v8.d.ts","./node_modules/@types/node/vm.d.ts","./node_modules/@types/node/wasi.d.ts","./node_modules/@types/node/worker_threads.d.ts","./node_modules/@types/node/zlib.d.ts","./node_modules/@types/node/index.d.ts","./node_modules/next/dist/server/get-page-files.d.ts","./node_modules/@types/react/canary.d.ts","./node_modules/@types/react/experimental.d.ts","./node_modules/@types/react-dom/index.d.ts","./node_modules/@types/react-dom/canary.d.ts","./node_modules/@types/react-dom/experimental.d.ts","./node_modules/next/dist/compiled/webpack/webpack.d.ts","./node_modules/next/dist/server/config.d.ts","./node_modules/next/dist/lib/load-custom-routes.d.ts","./node_modules/next/dist/shared/lib/image-config.d.ts","./node_modules/next/dist/build/webpack/plugins/subresource-integrity-plugin.d.ts","./node_modules/next/dist/server/body-streams.d.ts","./node_modules/next/dist/server/future/route-kind.d.ts","./node_modules/next/dist/server/future/route-definitions/route-definition.d.ts","./node_modules/next/dist/server/future/route-matches/route-match.d.ts","./node_modules/next/dist/client/components/app-router-headers.d.ts","./node_modules/next/dist/server/request-meta.d.ts","./node_modules/next/dist/server/config-shared.d.ts","./node_modules/next/dist/server/base-http/index.d.ts","./node_modules/next/dist/server/api-utils/index.d.ts","./node_modules/next/dist/server/node-environment.d.ts","./node_modules/next/dist/server/require-hook.d.ts","./node_modules/next/dist/server/node-polyfill-crypto.d.ts","./node_modules/next/dist/build/analysis/get-page-static-info.d.ts","./node_modules/next/dist/build/webpack/loaders/get-module-build-info.d.ts","./node_modules/next/dist/build/webpack/plugins/middleware-plugin.d.ts","./node_modules/next/dist/server/lib/revalidate.d.ts","./node_modules/next/dist/lib/setup-exception-listeners.d.ts","./node_modules/next/dist/build/index.d.ts","./node_modules/next/dist/server/response-cache/types.d.ts","./node_modules/next/dist/server/response-cache/index.d.ts","./node_modules/next/dist/server/lib/incremental-cache/index.d.ts","./node_modules/next/dist/client/components/hooks-server-context.d.ts","./node_modules/next/dist/client/components/static-generation-async-storage.external.d.ts","./node_modules/next/dist/server/render-result.d.ts","./node_modules/next/dist/server/future/helpers/i18n-provider.d.ts","./node_modules/next/dist/server/web/next-url.d.ts","./node_modules/next/dist/compiled/@edge-runtime/cookies/index.d.ts","./node_modules/next/dist/server/web/spec-extension/cookies.d.ts","./node_modules/next/dist/server/web/spec-extension/request.d.ts","./node_modules/next/dist/server/web/spec-extension/fetch-event.d.ts","./node_modules/next/dist/server/web/spec-extension/response.d.ts","./node_modules/next/dist/server/web/types.d.ts","./node_modules/next/dist/build/webpack/plugins/pages-manifest-plugin.d.ts","./node_modules/next/dist/shared/lib/router/utils/route-regex.d.ts","./node_modules/next/dist/shared/lib/router/utils/route-matcher.d.ts","./node_modules/next/dist/shared/lib/router/utils/parse-url.d.ts","./node_modules/next/dist/server/base-http/node.d.ts","./node_modules/next/dist/server/font-utils.d.ts","./node_modules/next/dist/build/webpack/plugins/flight-manifest-plugin.d.ts","./node_modules/next/dist/server/future/route-modules/route-module.d.ts","./node_modules/next/dist/server/load-components.d.ts","./node_modules/next/dist/shared/lib/router/utils/middleware-route-matcher.d.ts","./node_modules/next/dist/build/webpack/plugins/next-font-manifest-plugin.d.ts","./node_modules/next/dist/server/future/route-definitions/locale-route-definition.d.ts","./node_modules/next/dist/server/future/route-definitions/pages-route-definition.d.ts","./node_modules/next/dist/shared/lib/mitt.d.ts","./node_modules/next/dist/client/with-router.d.ts","./node_modules/next/dist/client/router.d.ts","./node_modules/next/dist/client/route-loader.d.ts","./node_modules/next/dist/client/page-loader.d.ts","./node_modules/next/dist/shared/lib/bloom-filter.d.ts","./node_modules/next/dist/shared/lib/router/router.d.ts","./node_modules/next/dist/shared/lib/router-context.shared-runtime.d.ts","./node_modules/next/dist/shared/lib/loadable-context.shared-runtime.d.ts","./node_modules/next/dist/shared/lib/loadable.shared-runtime.d.ts","./node_modules/next/dist/shared/lib/image-config-context.shared-runtime.d.ts","./node_modules/next/dist/shared/lib/hooks-client-context.shared-runtime.d.ts","./node_modules/next/dist/shared/lib/head-manager-context.shared-runtime.d.ts","./node_modules/next/dist/server/future/route-definitions/app-page-route-definition.d.ts","./node_modules/next/dist/shared/lib/modern-browserslist-target.d.ts","./node_modules/next/dist/shared/lib/constants.d.ts","./node_modules/next/dist/build/webpack/loaders/metadata/types.d.ts","./node_modules/next/dist/build/webpack/loaders/next-app-loader.d.ts","./node_modules/next/dist/server/lib/app-dir-module.d.ts","./node_modules/next/dist/server/web/spec-extension/adapters/request-cookies.d.ts","./node_modules/next/dist/server/async-storage/draft-mode-provider.d.ts","./node_modules/next/dist/server/web/spec-extension/adapters/headers.d.ts","./node_modules/next/dist/client/components/request-async-storage.external.d.ts","./node_modules/next/dist/server/app-render/create-error-handler.d.ts","./node_modules/next/dist/server/app-render/app-render.d.ts","./node_modules/next/dist/shared/lib/server-inserted-html.shared-runtime.d.ts","./node_modules/next/dist/shared/lib/amp-context.shared-runtime.d.ts","./node_modules/next/dist/server/future/route-modules/app-page/vendored/contexts/entrypoints.d.ts","./node_modules/next/dist/server/future/route-modules/app-page/module.compiled.d.ts","./node_modules/next/dist/client/components/error-boundary.d.ts","./node_modules/next/dist/client/components/router-reducer/create-initial-router-state.d.ts","./node_modules/next/dist/client/components/app-router.d.ts","./node_modules/next/dist/client/components/layout-router.d.ts","./node_modules/next/dist/client/components/render-from-template-context.d.ts","./node_modules/next/dist/client/components/action-async-storage.external.d.ts","./node_modules/next/dist/client/components/static-generation-bailout.d.ts","./node_modules/next/dist/client/components/static-generation-searchparams-bailout-provider.d.ts","./node_modules/next/dist/client/components/searchparams-bailout-proxy.d.ts","./node_modules/next/dist/server/app-render/rsc/preloads.d.ts","./node_modules/next/dist/server/app-render/rsc/taint.d.ts","./node_modules/next/dist/client/components/not-found-boundary.d.ts","./node_modules/next/dist/server/app-render/entry-base.d.ts","./node_modules/next/dist/build/templates/app-page.d.ts","./node_modules/next/dist/server/future/route-modules/app-page/module.d.ts","./node_modules/next/dist/server/app-render/types.d.ts","./node_modules/next/dist/client/components/router-reducer/fetch-server-response.d.ts","./node_modules/next/dist/client/components/router-reducer/router-reducer-types.d.ts","./node_modules/next/dist/shared/lib/app-router-context.shared-runtime.d.ts","./node_modules/next/dist/server/future/route-modules/pages/vendored/contexts/entrypoints.d.ts","./node_modules/next/dist/server/future/route-modules/pages/module.compiled.d.ts","./node_modules/next/dist/build/templates/pages.d.ts","./node_modules/next/dist/server/future/route-modules/pages/module.d.ts","./node_modules/next/dist/server/render.d.ts","./node_modules/next/dist/server/future/route-definitions/pages-api-route-definition.d.ts","./node_modules/next/dist/server/future/route-matches/pages-api-route-match.d.ts","./node_modules/next/dist/server/future/route-matchers/route-matcher.d.ts","./node_modules/next/dist/server/future/route-matcher-providers/route-matcher-provider.d.ts","./node_modules/next/dist/server/future/route-matcher-managers/route-matcher-manager.d.ts","./node_modules/next/dist/server/future/normalizers/normalizer.d.ts","./node_modules/next/dist/server/future/normalizers/locale-route-normalizer.d.ts","./node_modules/next/dist/server/future/normalizers/request/rsc.d.ts","./node_modules/next/dist/server/future/normalizers/request/postponed.d.ts","./node_modules/next/dist/server/base-server.d.ts","./node_modules/next/dist/server/image-optimizer.d.ts","./node_modules/next/dist/server/next-server.d.ts","./node_modules/next/dist/lib/coalesced-function.d.ts","./node_modules/next/dist/trace/shared.d.ts","./node_modules/next/dist/trace/trace.d.ts","./node_modules/next/dist/trace/index.d.ts","./node_modules/next/dist/build/webpack-config.d.ts","./node_modules/next/dist/build/webpack/plugins/define-env-plugin.d.ts","./node_modules/next/dist/build/swc/index.d.ts","./node_modules/next/dist/server/dev/parse-version-info.d.ts","./node_modules/next/dist/server/dev/hot-reloader-types.d.ts","./node_modules/next/dist/telemetry/storage.d.ts","./node_modules/next/dist/server/lib/types.d.ts","./node_modules/next/dist/server/lib/router-utils/types.d.ts","./node_modules/next/dist/server/lib/render-server.d.ts","./node_modules/next/dist/server/lib/router-server.d.ts","./node_modules/next/dist/shared/lib/router/utils/path-match.d.ts","./node_modules/next/dist/server/lib/router-utils/filesystem.d.ts","./node_modules/next/dist/server/lib/router-utils/setup-dev-bundler.d.ts","./node_modules/next/dist/server/lib/dev-bundler-service.d.ts","./node_modules/next/dist/server/dev/static-paths-worker.d.ts","./node_modules/next/dist/server/dev/next-dev-server.d.ts","./node_modules/next/dist/server/next.d.ts","./node_modules/next/dist/lib/metadata/types/alternative-urls-types.d.ts","./node_modules/next/dist/lib/metadata/types/extra-types.d.ts","./node_modules/next/dist/lib/metadata/types/metadata-types.d.ts","./node_modules/next/dist/lib/metadata/types/manifest-types.d.ts","./node_modules/next/dist/lib/metadata/types/opengraph-types.d.ts","./node_modules/next/dist/lib/metadata/types/twitter-types.d.ts","./node_modules/next/dist/lib/metadata/types/metadata-interface.d.ts","./node_modules/next/types/index.d.ts","./node_modules/next/dist/shared/lib/html-context.shared-runtime.d.ts","./node_modules/@next/env/dist/index.d.ts","./node_modules/next/dist/shared/lib/utils.d.ts","./node_modules/next/dist/pages/_app.d.ts","./node_modules/next/app.d.ts","./node_modules/next/dist/server/web/spec-extension/unstable-cache.d.ts","./node_modules/next/dist/server/web/spec-extension/revalidate-path.d.ts","./node_modules/next/dist/server/web/spec-extension/revalidate-tag.d.ts","./node_modules/next/dist/server/web/spec-extension/unstable-no-store.d.ts","./node_modules/next/cache.d.ts","./node_modules/next/dist/shared/lib/runtime-config.external.d.ts","./node_modules/next/config.d.ts","./node_modules/next/dist/pages/_document.d.ts","./node_modules/next/document.d.ts","./node_modules/next/dist/shared/lib/dynamic.d.ts","./node_modules/next/dynamic.d.ts","./node_modules/next/dist/pages/_error.d.ts","./node_modules/next/error.d.ts","./node_modules/next/dist/shared/lib/head.d.ts","./node_modules/next/head.d.ts","./node_modules/next/dist/shared/lib/get-img-props.d.ts","./node_modules/next/dist/client/image-component.d.ts","./node_modules/next/dist/shared/lib/image-external.d.ts","./node_modules/next/image.d.ts","./node_modules/next/dist/client/link.d.ts","./node_modules/next/link.d.ts","./node_modules/next/dist/client/components/redirect.d.ts","./node_modules/next/dist/client/components/not-found.d.ts","./node_modules/next/dist/client/components/navigation.d.ts","./node_modules/next/navigation.d.ts","./node_modules/next/router.d.ts","./node_modules/next/dist/client/script.d.ts","./node_modules/next/script.d.ts","./node_modules/next/dist/server/web/spec-extension/user-agent.d.ts","./node_modules/next/dist/compiled/@edge-runtime/primitives/url.d.ts","./node_modules/next/dist/server/web/spec-extension/image-response.d.ts","./node_modules/next/dist/compiled/@vercel/og/satori/index.d.ts","./node_modules/next/dist/compiled/@vercel/og/emoji/index.d.ts","./node_modules/next/dist/compiled/@vercel/og/types.d.ts","./node_modules/next/server.d.ts","./node_modules/next/types/global.d.ts","./node_modules/next/types/compiled.d.ts","./node_modules/next/index.d.ts","./node_modules/next/image-types/global.d.ts","./next-env.d.ts","./src/lib/idb.ts","./src/lib/mediahandles.ts","./src/lib/storage.ts","./src/utils/auth.ts","./src/utils/navigationguard.ts","./src/utils/routes.ts","./src/components/loginmodal.tsx","./src/components/authprovider.tsx","./src/components/serviceworkerregistrar.tsx","./src/app/layout.tsx","./src/context/dashboardcontext.tsx","./src/components/layout/sidebar.tsx","./src/components/workspacesetup.tsx","./src/app/(dashboard)/layout.tsx","./src/app/(dashboard)/page.tsx","./src/app/(dashboard)/case-detail/page.tsx","./src/app/(dashboard)/cases/page.tsx","./src/components/transcripteditor.tsx","./src/components/clipcreator.tsx","./src/components/mediamissingbanner.tsx","./src/app/(dashboard)/clip-creator/page.tsx","./src/app/(dashboard)/editor/page.tsx","./src/app/(dashboard)/settings/page.tsx","./node_modules/jszip/index.d.ts","./src/app/(dashboard)/transcribe/page.tsx","./.next/types/app/(dashboard)/page.ts","./.next/types/app/(dashboard)/case-detail/page.ts","./.next/types/app/(dashboard)/cases/page.ts","./.next/types/app/(dashboard)/clip-creator/page.ts","./.next/types/app/(dashboard)/editor/page.ts","./.next/types/app/(dashboard)/settings/page.ts","./.next/types/app/(dashboard)/transcribe/page.ts","./node_modules/@types/json5/index.d.ts","../../../node_modules/@types/connect/index.d.ts","../../../node_modules/@types/body-parser/index.d.ts","../../../node_modules/@types/mime/index.d.ts","../../../node_modules/@types/send/index.d.ts","../../../node_modules/@types/qs/index.d.ts","../../../node_modules/@types/range-parser/index.d.ts","../../../node_modules/@types/express-serve-static-core/index.d.ts","../../../node_modules/@types/http-errors/index.d.ts","../../../node_modules/@types/serve-static/index.d.ts","../../../node_modules/@types/express/index.d.ts","../../../node_modules/form-data/index.d.ts","../../../node_modules/@types/node-fetch/externals.d.ts","../../../node_modules/@types/node-fetch/index.d.ts","../../../node_modules/@types/nodemailer/lib/dkim/index.d.ts","../../../node_modules/@types/nodemailer/lib/mailer/mail-message.d.ts","../../../node_modules/@types/nodemailer/lib/xoauth2/index.d.ts","../../../node_modules/@types/nodemailer/lib/mailer/index.d.ts","../../../node_modules/@types/nodemailer/lib/mime-node/index.d.ts","../../../node_modules/@types/nodemailer/lib/smtp-connection/index.d.ts","../../../node_modules/@types/nodemailer/lib/shared/index.d.ts","../../../node_modules/@types/nodemailer/lib/json-transport/index.d.ts","../../../node_modules/@types/nodemailer/lib/sendmail-transport/index.d.ts","../../../node_modules/@types/nodemailer/lib/ses-transport/index.d.ts","../../../node_modules/@types/nodemailer/lib/smtp-pool/index.d.ts","../../../node_modules/@types/nodemailer/lib/smtp-transport/index.d.ts","../../../node_modules/@types/nodemailer/lib/stream-transport/index.d.ts","../../../node_modules/@types/nodemailer/index.d.ts","../../../node_modules/@types/office-js/index.d.ts","../../../node_modules/typed-query-selector/parser.d.ts","../../../node_modules/devtools-protocol/types/protocol.d.ts","../../../node_modules/devtools-protocol/types/protocol-mapping.d.ts","../../../node_modules/chromium-bidi/lib/cjs/protocol/generated/webdriver-bidi.d.ts","../../../node_modules/chromium-bidi/lib/cjs/protocol/cdp.d.ts","../../../node_modules/chromium-bidi/lib/cjs/protocol/generated/webdriver-bidi-bluetooth.d.ts","../../../node_modules/chromium-bidi/lib/cjs/protocol/generated/webdriver-bidi-permissions.d.ts","../../../node_modules/chromium-bidi/lib/cjs/protocol/chromium-bidi.d.ts","../../../node_modules/chromium-bidi/lib/cjs/protocol/errorresponse.d.ts","../../../node_modules/chromium-bidi/lib/cjs/protocol/protocol.d.ts","../../../node_modules/puppeteer/lib/types.d.ts","../../../node_modules/@types/yauzl/index.d.ts"],"fileIdsList":[[64,107,122,156,385],[64,107,122,156],[64,107,119,122,156,388,389,390],[64,107,386,389,391,393],[64,107],[64,107,122,149,156,395,396],[64,107,156,399,401,405,406,407,408,409,410],[64,107,138,156],[64,107,119,156,399,401,402,404,411],[64,107,119,127,138,149,156,398,399,400,402,403,404,411],[64,107,138,156,401,402],[64,107,138,156,401],[64,107,156,399,401,402,404,411],[64,107,138,156,403],[64,107,119,127,138,146,156,400,402,404],[64,107,119,156,399,401,402,403,404,411],[64,107,119,138,156,399,400,401,402,403,404,411],[64,107,119,138,156,399,401,402,404,411],[64,107,122,138,156,404],[64,107,120,138,156,387],[64,107,122,156,388,392],[64,107,119,138,156],[64,107,414,415,416],[64,107,416,417,418,419],[64,107,416],[64,107,416,417,418,419,420,421],[64,107,414],[64,107,122,138,156],[64,107,108,138,156,413,414,415,422],[64,107,305,367],[64,107,305,368],[64,107,305,372],[64,107,305,373],[64,107,305,366],[64,107,305,374],[64,107,305,376],[64,107,349,350],[64,104,107],[64,106,107],[107],[64,107,112,141],[64,107,108,113,119,120,127,138,149],[64,107,108,109,119,127],[59,60,61,64,107],[64,107,110,150],[64,107,111,112,120,128],[64,107,112,138,146],[64,107,113,115,119,127],[64,106,107,114],[64,107,115,116],[64,107,117,119],[64,106,107,119],[64,107,119,120,121,138,149],[64,107,119,120,121,134,138,141],[64,102,107],[64,107,115,119,122,127,138,149],[64,107,119,120,122,123,127,138,146,149],[64,107,122,124,138,146,149],[62,63,64,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155],[64,107,119,125],[64,107,126,149,154],[64,107,115,119,127,138],[64,107,128],[64,107,129],[64,106,107,130],[64,104,105,106,107,108,109,110,111,112,113,114,115,116,117,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155],[64,107,132],[64,107,133],[64,107,119,134,135],[64,107,134,136,150,152],[64,107,119,138,139,141],[64,107,140,141],[64,107,138,139],[64,107,141],[64,107,142],[64,104,107,138,143],[64,107,119,144,145],[64,107,144,145],[64,107,112,127,138,146],[64,107,147],[64,107,127,148],[64,107,122,133,149],[64,107,112,150],[64,107,138,151],[64,107,126,152],[64,107,153],[64,107,119,121,130,138,141,149,152,154],[64,107,138,155],[52,64,107,160,161,162],[52,64,107,160,161],[52,64,107],[52,56,64,107,159,306,345],[52,56,64,107,158,306,345],[49,50,51,64,107],[64,107,156],[57,64,107],[64,107,310],[64,107,312,313,314,315],[64,107,317],[64,107,165,174,181,306],[64,107,165,172,176,183],[64,107,174,283],[64,107,231,241,254,348],[64,107,262],[64,107,165,174,180,218,228,281,348],[64,107,180,348],[64,107,174,228,229,348],[64,107,174,180,218,348],[64,107,348],[64,107,180,181,348],[64,106,107,156],[52,64,107,242,243,259],[52,64,107,159],[52,64,107,242,257],[64,107,238,260,333,334],[64,107,195],[64,106,107,156,195,232,233,234],[52,64,107,257,260],[64,107,257,259],[52,64,107,257,258,260],[64,106,107,156,175,188,189],[52,64,107,166,327],[52,64,107,149,156],[52,64,107,180,216],[52,64,107,180],[64,107,214,219],[52,64,107,215,309],[52,56,64,107,122,156,158,159,306,343,344],[64,107,164],[64,107,299,300,301,302,303,304],[64,107,301],[52,64,107,307,309],[52,64,107,309],[64,107,122,156,175,309],[64,107,122,156,173,190,191,206,235,236,256,257],[64,107,189,190,235,244,245,246,247,248,249,250,251,252,253,348],[52,64,107,133,156,174,188,206,208,210,256,306,348],[64,107,122,156,175,176,195,196,232],[64,107,122,156,174,176],[64,107,122,138,156,173,175,176],[64,107,122,133,149,156,164,166,173,174,175,176,180,183,185,187,188,191,192,200,202,205,206,208,209,210,257,265,267,270,272,273,274,306],[64,107,165,166,167,173,306,309,348],[64,107,174],[64,107,122,138,149,156,170,282,284,285,348],[64,107,133,149,156,170,173,175,188,199,200,202,203,204,208,270,275,277,295,296],[64,107,174,178,188],[64,107,173,174],[64,107,192,271],[64,107,271],[64,107,169,170],[64,107,169,211],[64,107,169],[64,107,171,192,269],[64,107,268],[64,107,170,171],[64,107,171,266],[64,107,170],[64,107,256],[64,107,122,156,173,191,207,226,231,237,240,255,257],[64,107,220,221,222,223,224,225,238,239,260,307],[64,107,264],[64,107,122,156,173,191,207,212,261,263,265,306,309],[64,107,122,149,156,166,173,174,187],[64,107,230],[64,107,122,156,288,294],[64,107,185,187,309],[64,107,289,295,298],[64,107,122,178,288,290],[64,107,165,174,185,209,292],[64,107,122,156,174,180,209,278,286,287,291,292,293],[64,107,157,206,207,306,309],[64,107,122,133,149,156,171,173,175,178,182,183,185,187,188,191,199,200,202,203,204,205,208,267,275,276,309],[64,107,122,156,173,174,178,277,297],[64,107,122,156,183,190],[52,64,107,122,133,156,164,166,173,176,191,205,206,208,210,264,306,309],[64,107,122,133,149,156,168,171,172,175],[64,107,186],[64,107,122,156,183,191],[64,107,122,156,174,192],[64,107,194],[64,107,196],[64,107,174,193,195,199],[64,107,174,193,195],[64,107,122,156,168,174,175,196,197,198],[52,64,107,257,258,259],[64,107,227],[52,64,107,166],[52,64,107,202],[52,64,107,157,205,210,306,309],[64,107,166,327,328],[52,64,107,219],[52,64,107,133,149,156,164,213,215,217,218,309],[64,107,175,180,202],[64,107,133,156],[64,107,201],[52,64,107,120,122,133,156,164,219,228,306,307,308],[48,52,53,54,55,64,107,158,159,306,345],[64,107,112],[64,107,279,280],[64,107,279],[64,107,319],[64,107,321],[64,107,323],[64,107,325],[64,107,329],[56,58,64,107,306,311,316,318,320,322,324,326,330,332,336,337,339,346,347,348],[64,107,331],[64,107,335],[64,107,215],[64,107,338],[64,106,107,196,197,198,199,340,341,342,345],[52,56,64,107,122,124,133,156,158,159,160,162,164,176,298,305,309,345],[64,74,78,107,149],[64,74,107,138,149],[64,69,107],[64,71,74,107,146,149],[64,107,127,146],[64,69,107,156],[64,71,74,107,127,149],[64,66,67,70,73,107,119,138,149],[64,74,81,107],[64,66,72,107],[64,74,95,96,107],[64,70,74,107,141,149,156],[64,95,107,156],[64,68,69,107,156],[64,74,107],[64,68,69,70,71,72,73,74,75,76,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,96,97,98,99,100,101,107],[64,74,89,107],[64,74,81,82,107],[64,72,74,82,83,107],[64,73,107],[64,66,69,74,107],[64,74,78,82,83,107],[64,78,107],[64,72,74,77,107,149],[64,66,71,74,81,107],[64,107,138],[64,69,74,95,107,154,156],[52,64,107,332,336,354,355,356,357,362],[52,64,107,332,336,355,357,362,370,371],[52,64,107,332,336,353,354,355,357,362,369,371],[52,64,107,354,356,362,363,364],[64,107,332,336,356,357,362],[52,64,107,354,362],[52,64,107,332,336,353,354,355,356,357,362,375],[64,107,349,359,360],[52,64,107,355,358],[52,64,107,355,369],[52,64,107,353,354,355],[52,64,107,354],[52,64,107,354,355],[64,107,352]],"fileInfos":[{"version":"c430d44666289dae81f30fa7b2edebf186ecc91a2d4c71266ea6ae76388792e1","affectsGlobalScope":true,"impliedFormat":1},{"version":"45b7ab580deca34ae9729e97c13cfd999df04416a79116c3bfb483804f85ded4","impliedFormat":1},{"version":"3facaf05f0c5fc569c5649dd359892c98a85557e3e0c847964caeb67076f4d75","impliedFormat":1},{"version":"e44bb8bbac7f10ecc786703fe0a6a4b952189f908707980ba8f3c8975a760962","impliedFormat":1},{"version":"5e1c4c362065a6b95ff952c0eab010f04dcd2c3494e813b493ecfd4fcb9fc0d8","impliedFormat":1},{"version":"68d73b4a11549f9c0b7d352d10e91e5dca8faa3322bfb77b661839c42b1ddec7","impliedFormat":1},{"version":"5efce4fc3c29ea84e8928f97adec086e3dc876365e0982cc8479a07954a3efd4","impliedFormat":1},{"version":"080941d9f9ff9307f7e27a83bcd888b7c8270716c39af943532438932ec1d0b9","affectsGlobalScope":true,"impliedFormat":1},{"version":"2e80ee7a49e8ac312cc11b77f1475804bee36b3b2bc896bead8b6e1266befb43","affectsGlobalScope":true,"impliedFormat":1},{"version":"c57796738e7f83dbc4b8e65132f11a377649c00dd3eee333f672b8f0a6bea671","affectsGlobalScope":true,"impliedFormat":1},{"version":"dc2df20b1bcdc8c2d34af4926e2c3ab15ffe1160a63e58b7e09833f616efff44","affectsGlobalScope":true,"impliedFormat":1},{"version":"515d0b7b9bea2e31ea4ec968e9edd2c39d3eebf4a2d5cbd04e88639819ae3b71","affectsGlobalScope":true,"impliedFormat":1},{"version":"0559b1f683ac7505ae451f9a96ce4c3c92bdc71411651ca6ddb0e88baaaad6a3","affectsGlobalScope":true,"impliedFormat":1},{"version":"0dc1e7ceda9b8b9b455c3a2d67b0412feab00bd2f66656cd8850e8831b08b537","affectsGlobalScope":true,"impliedFormat":1},{"version":"ce691fb9e5c64efb9547083e4a34091bcbe5bdb41027e310ebba8f7d96a98671","affectsGlobalScope":true,"impliedFormat":1},{"version":"8d697a2a929a5fcb38b7a65594020fcef05ec1630804a33748829c5ff53640d0","affectsGlobalScope":true,"impliedFormat":1},{"version":"4ff2a353abf8a80ee399af572debb8faab2d33ad38c4b4474cff7f26e7653b8d","affectsGlobalScope":true,"impliedFormat":1},{"version":"fb0f136d372979348d59b3f5020b4cdb81b5504192b1cacff5d1fbba29378aa1","affectsGlobalScope":true,"impliedFormat":1},{"version":"d15bea3d62cbbdb9797079416b8ac375ae99162a7fba5de2c6c505446486ac0a","affectsGlobalScope":true,"impliedFormat":1},{"version":"68d18b664c9d32a7336a70235958b8997ebc1c3b8505f4f1ae2b7e7753b87618","affectsGlobalScope":true,"impliedFormat":1},{"version":"eb3d66c8327153d8fa7dd03f9c58d351107fe824c79e9b56b462935176cdf12a","affectsGlobalScope":true,"impliedFormat":1},{"version":"38f0219c9e23c915ef9790ab1d680440d95419ad264816fa15009a8851e79119","affectsGlobalScope":true,"impliedFormat":1},{"version":"69ab18c3b76cd9b1be3d188eaf8bba06112ebbe2f47f6c322b5105a6fbc45a2e","affectsGlobalScope":true,"impliedFormat":1},{"version":"a680117f487a4d2f30ea46f1b4b7f58bef1480456e18ba53ee85c2746eeca012","affectsGlobalScope":true,"impliedFormat":1},{"version":"2f11ff796926e0832f9ae148008138ad583bd181899ab7dd768a2666700b1893","affectsGlobalScope":true,"impliedFormat":1},{"version":"4de680d5bb41c17f7f68e0419412ca23c98d5749dcaaea1896172f06435891fc","affectsGlobalScope":true,"impliedFormat":1},{"version":"954296b30da6d508a104a3a0b5d96b76495c709785c1d11610908e63481ee667","affectsGlobalScope":true,"impliedFormat":1},{"version":"ac9538681b19688c8eae65811b329d3744af679e0bdfa5d842d0e32524c73e1c","affectsGlobalScope":true,"impliedFormat":1},{"version":"0a969edff4bd52585473d24995c5ef223f6652d6ef46193309b3921d65dd4376","affectsGlobalScope":true,"impliedFormat":1},{"version":"9e9fbd7030c440b33d021da145d3232984c8bb7916f277e8ffd3dc2e3eae2bdb","affectsGlobalScope":true,"impliedFormat":1},{"version":"811ec78f7fefcabbda4bfa93b3eb67d9ae166ef95f9bff989d964061cbf81a0c","affectsGlobalScope":true,"impliedFormat":1},{"version":"717937616a17072082152a2ef351cb51f98802fb4b2fdabd32399843875974ca","affectsGlobalScope":true,"impliedFormat":1},{"version":"d7e7d9b7b50e5f22c915b525acc5a49a7a6584cf8f62d0569e557c5cfc4b2ac2","affectsGlobalScope":true,"impliedFormat":1},{"version":"71c37f4c9543f31dfced6c7840e068c5a5aacb7b89111a4364b1d5276b852557","affectsGlobalScope":true,"impliedFormat":1},{"version":"576711e016cf4f1804676043e6a0a5414252560eb57de9faceee34d79798c850","affectsGlobalScope":true,"impliedFormat":1},{"version":"89c1b1281ba7b8a96efc676b11b264de7a8374c5ea1e6617f11880a13fc56dc6","affectsGlobalScope":true,"impliedFormat":1},{"version":"74f7fa2d027d5b33eb0471c8e82a6c87216223181ec31247c357a3e8e2fddc5b","affectsGlobalScope":true,"impliedFormat":1},{"version":"d6d7ae4d1f1f3772e2a3cde568ed08991a8ae34a080ff1151af28b7f798e22ca","affectsGlobalScope":true,"impliedFormat":1},{"version":"063600664504610fe3e99b717a1223f8b1900087fab0b4cad1496a114744f8df","affectsGlobalScope":true,"impliedFormat":1},{"version":"934019d7e3c81950f9a8426d093458b65d5aff2c7c1511233c0fd5b941e608ab","affectsGlobalScope":true,"impliedFormat":1},{"version":"52ada8e0b6e0482b728070b7639ee42e83a9b1c22d205992756fe020fd9f4a47","affectsGlobalScope":true,"impliedFormat":1},{"version":"3bdefe1bfd4d6dee0e26f928f93ccc128f1b64d5d501ff4a8cf3c6371200e5e6","affectsGlobalScope":true,"impliedFormat":1},{"version":"59fb2c069260b4ba00b5643b907ef5d5341b167e7d1dbf58dfd895658bda2867","affectsGlobalScope":true,"impliedFormat":1},{"version":"639e512c0dfc3fad96a84caad71b8834d66329a1f28dc95e3946c9b58176c73a","affectsGlobalScope":true,"impliedFormat":1},{"version":"368af93f74c9c932edd84c58883e736c9e3d53cec1fe24c0b0ff451f529ceab1","affectsGlobalScope":true,"impliedFormat":1},{"version":"8e7f8264d0fb4c5339605a15daadb037bf238c10b654bb3eee14208f860a32ea","affectsGlobalScope":true,"impliedFormat":1},{"version":"782dec38049b92d4e85c1585fbea5474a219c6984a35b004963b00beb1aab538","affectsGlobalScope":true,"impliedFormat":1},{"version":"0990a7576222f248f0a3b888adcb7389f957928ce2afb1cd5128169086ff4d29","impliedFormat":1},{"version":"eb5b19b86227ace1d29ea4cf81387279d04bb34051e944bc53df69f58914b788","affectsGlobalScope":true,"impliedFormat":1},{"version":"8a8eb4ebffd85e589a1cc7c178e291626c359543403d58c9cd22b81fab5b1fb9","impliedFormat":1},{"version":"87d9d29dbc745f182683f63187bf3d53fd8673e5fca38ad5eaab69798ed29fbc","impliedFormat":1},{"version":"472f5aab7edc498a0a761096e8e254c5bc3323d07a1e7f5f8b8ec0d6395b60a0","affectsGlobalScope":true,"impliedFormat":1},{"version":"cc69795d9954ee4ad57545b10c7bf1a7260d990231b1685c147ea71a6faa265c","impliedFormat":1},{"version":"8bc6c94ff4f2af1f4023b7bb2379b08d3d7dd80c698c9f0b07431ea16101f05f","impliedFormat":1},{"version":"1b61d259de5350f8b1e5db06290d31eaebebc6baafd5f79d314b5af9256d7153","impliedFormat":1},{"version":"57194e1f007f3f2cbef26fa299d4c6b21f4623a2eddc63dfeef79e38e187a36e","impliedFormat":1},{"version":"0f6666b58e9276ac3a38fdc80993d19208442d6027ab885580d93aec76b4ef00","impliedFormat":1},{"version":"05fd364b8ef02fb1e174fbac8b825bdb1e5a36a016997c8e421f5fab0a6da0a0","impliedFormat":1},{"version":"70521b6ab0dcba37539e5303104f29b721bfb2940b2776da4cc818c07e1fefc1","affectsGlobalScope":true,"impliedFormat":1},{"version":"ab41ef1f2cdafb8df48be20cd969d875602483859dc194e9c97c8a576892c052","affectsGlobalScope":true,"impliedFormat":1},{"version":"d153a11543fd884b596587ccd97aebbeed950b26933ee000f94009f1ab142848","affectsGlobalScope":true,"impliedFormat":1},{"version":"21d819c173c0cf7cc3ce57c3276e77fd9a8a01d35a06ad87158781515c9a438a","impliedFormat":1},{"version":"a79e62f1e20467e11a904399b8b18b18c0c6eea6b50c1168bf215356d5bebfaf","affectsGlobalScope":true,"impliedFormat":1},{"version":"49a5a44f2e68241a1d2bd9ec894535797998841c09729e506a7cbfcaa40f2180","affectsGlobalScope":true,"impliedFormat":1},{"version":"8e9c23ba78aabc2e0a27033f18737a6df754067731e69dc5f52823957d60a4b6","impliedFormat":1},{"version":"5929864ce17fba74232584d90cb721a89b7ad277220627cc97054ba15a98ea8f","impliedFormat":1},{"version":"763fe0f42b3d79b440a9b6e51e9ba3f3f91352469c1e4b3b67bfa4ff6352f3f4","impliedFormat":1},{"version":"25c8056edf4314820382a5fdb4bb7816999acdcb929c8f75e3f39473b87e85bc","impliedFormat":1},{"version":"c464d66b20788266e5353b48dc4aa6bc0dc4a707276df1e7152ab0c9ae21fad8","impliedFormat":1},{"version":"78d0d27c130d35c60b5e5566c9f1e5be77caf39804636bc1a40133919a949f21","impliedFormat":1},{"version":"c6fd2c5a395f2432786c9cb8deb870b9b0e8ff7e22c029954fabdd692bff6195","impliedFormat":1},{"version":"1d6e127068ea8e104a912e42fc0a110e2aa5a66a356a917a163e8cf9a65e4a75","impliedFormat":1},{"version":"5ded6427296cdf3b9542de4471d2aa8d3983671d4cac0f4bf9c637208d1ced43","impliedFormat":1},{"version":"7f182617db458e98fc18dfb272d40aa2fff3a353c44a89b2c0ccb3937709bfb5","impliedFormat":1},{"version":"cadc8aced301244057c4e7e73fbcae534b0f5b12a37b150d80e5a45aa4bebcbd","impliedFormat":1},{"version":"385aab901643aa54e1c36f5ef3107913b10d1b5bb8cbcd933d4263b80a0d7f20","impliedFormat":1},{"version":"9670d44354bab9d9982eca21945686b5c24a3f893db73c0dae0fd74217a4c219","impliedFormat":1},{"version":"0b8a9268adaf4da35e7fa830c8981cfa22adbbe5b3f6f5ab91f6658899e657a7","impliedFormat":1},{"version":"11396ed8a44c02ab9798b7dca436009f866e8dae3c9c25e8c1fbc396880bf1bb","impliedFormat":1},{"version":"ba7bc87d01492633cb5a0e5da8a4a42a1c86270e7b3d2dea5d156828a84e4882","impliedFormat":1},{"version":"4893a895ea92c85345017a04ed427cbd6a1710453338df26881a6019432febdd","impliedFormat":1},{"version":"c21dc52e277bcfc75fac0436ccb75c204f9e1b3fa5e12729670910639f27343e","impliedFormat":1},{"version":"13f6f39e12b1518c6650bbb220c8985999020fe0f21d818e28f512b7771d00f9","impliedFormat":1},{"version":"9b5369969f6e7175740bf51223112ff209f94ba43ecd3bb09eefff9fd675624a","impliedFormat":1},{"version":"4fe9e626e7164748e8769bbf74b538e09607f07ed17c2f20af8d680ee49fc1da","impliedFormat":1},{"version":"24515859bc0b836719105bb6cc3d68255042a9f02a6022b3187948b204946bd2","impliedFormat":1},{"version":"ea0148f897b45a76544ae179784c95af1bd6721b8610af9ffa467a518a086a43","impliedFormat":1},{"version":"24c6a117721e606c9984335f71711877293a9651e44f59f3d21c1ea0856f9cc9","impliedFormat":1},{"version":"dd3273ead9fbde62a72949c97dbec2247ea08e0c6952e701a483d74ef92d6a17","impliedFormat":1},{"version":"405822be75ad3e4d162e07439bac80c6bcc6dbae1929e179cf467ec0b9ee4e2e","impliedFormat":1},{"version":"0db18c6e78ea846316c012478888f33c11ffadab9efd1cc8bcc12daded7a60b6","impliedFormat":1},{"version":"e61be3f894b41b7baa1fbd6a66893f2579bfad01d208b4ff61daef21493ef0a8","impliedFormat":1},{"version":"bd0532fd6556073727d28da0edfd1736417a3f9f394877b6d5ef6ad88fba1d1a","impliedFormat":1},{"version":"89167d696a849fce5ca508032aabfe901c0868f833a8625d5a9c6e861ef935d2","impliedFormat":1},{"version":"615ba88d0128ed16bf83ef8ccbb6aff05c3ee2db1cc0f89ab50a4939bfc1943f","impliedFormat":1},{"version":"a4d551dbf8746780194d550c88f26cf937caf8d56f102969a110cfaed4b06656","impliedFormat":1},{"version":"8bd86b8e8f6a6aa6c49b71e14c4ffe1211a0e97c80f08d2c8cc98838006e4b88","impliedFormat":1},{"version":"317e63deeb21ac07f3992f5b50cdca8338f10acd4fbb7257ebf56735bf52ab00","impliedFormat":1},{"version":"4732aec92b20fb28c5fe9ad99521fb59974289ed1e45aecb282616202184064f","impliedFormat":1},{"version":"2e85db9e6fd73cfa3d7f28e0ab6b55417ea18931423bd47b409a96e4a169e8e6","impliedFormat":1},{"version":"c46e079fe54c76f95c67fb89081b3e399da2c7d109e7dca8e4b58d83e332e605","impliedFormat":1},{"version":"bf67d53d168abc1298888693338cb82854bdb2e69ef83f8a0092093c2d562107","impliedFormat":1},{"version":"1ca84b44ad1d8e4576f24904d8b95dd23b94ea67e1575f89614ac90062fc67f4","affectsGlobalScope":true,"impliedFormat":1},{"version":"6d586db0a09a9495ebb5dece28f54df9684bfbd6e1f568426ca153126dac4a40","impliedFormat":1},{"version":"7394959e5a741b185456e1ef5d64599c36c60a323207450991e7a42e08911419","impliedFormat":1},{"version":"8c0bcd6c6b67b4b503c11e91a1fb91522ed585900eab2ab1f61bba7d7caa9d6f","impliedFormat":1},{"version":"567b7f607f400873151d7bc63a049514b53c3c00f5f56e9e95695d93b66a138e","affectsGlobalScope":true,"impliedFormat":1},{"version":"f3e58c4c18a031cbb17abec7a4ad0bd5ae9fc70c1f4ba1e7fb921ad87c504aca","impliedFormat":1},{"version":"84c1930e33d1bb12ad01bcbe11d656f9646bd21b2fb2afd96e8e10615a021aef","impliedFormat":1},{"version":"35ec8b6760fd7138bbf5809b84551e31028fb2ba7b6dc91d95d098bf212ca8b4","affectsGlobalScope":true,"impliedFormat":1},{"version":"5524481e56c48ff486f42926778c0a3cce1cc85dc46683b92b1271865bcf015a","impliedFormat":1},{"version":"4b87f767c7bc841511113c876a6b8bf1fd0cb0b718c888ad84478b372ec486b1","affectsGlobalScope":true,"impliedFormat":1},{"version":"8d04e3640dd9eb67f7f1e5bd3d0bf96c784666f7aefc8ac1537af6f2d38d4c29","impliedFormat":1},{"version":"9d19808c8c291a9010a6c788e8532a2da70f811adb431c97520803e0ec649991","impliedFormat":1},{"version":"2bf469abae4cc9c0f340d4e05d9d26e37f936f9c8ca8f007a6534f109dcc77e4","impliedFormat":1},{"version":"4aacb0dd020eeaef65426153686cc639a78ec2885dc72ad220be1d25f1a439df","impliedFormat":1},{"version":"f0bd7e6d931657b59605c44112eaf8b980ba7f957a5051ed21cb93d978cf2f45","impliedFormat":1},{"version":"71450bbc2d82821d24ca05699a533e72758964e9852062c53b30f31c36978ab8","affectsGlobalScope":true,"impliedFormat":1},{"version":"0ada07543808f3b967624645a8e1ccd446f8b01ade47842acf1328aec899fed0","affectsGlobalScope":true,"impliedFormat":1},{"version":"4c21aaa8257d7950a5b75a251d9075b6a371208fc948c9c8402f6690ef3b5b55","impliedFormat":1},{"version":"b5895e6353a5d708f55d8685c38a235c3a6d8138e374dee8ceb8ffde5aa8002a","impliedFormat":1},{"version":"54c4f21f578864961efc94e8f42bc893a53509e886370ec7dd602e0151b9266c","impliedFormat":1},{"version":"de735eca2c51dd8b860254e9fdb6d9ec19fe402dfe597c23090841ce3937cfc5","impliedFormat":1},{"version":"4ff41188773cbf465807dd2f7059c7494cbee5115608efc297383832a1150c43","impliedFormat":1},{"version":"5650cf3dace09e7c25d384e3e6b818b938f68f4e8de96f52d9c5a1b3db068e86","impliedFormat":1},{"version":"1354ca5c38bd3fd3836a68e0f7c9f91f172582ba30ab15bb8c075891b91502b7","affectsGlobalScope":true,"impliedFormat":1},{"version":"5155da3047ef977944d791a2188ff6e6c225f6975cc1910ab7bb6838ab84cede","impliedFormat":1},{"version":"93f437e1398a4f06a984f441f7fa7a9f0535c04399619b5c22e0b87bdee182cb","impliedFormat":1},{"version":"afbe24ab0d74694372baa632ecb28bb375be53f3be53f9b07ecd7fc994907de5","impliedFormat":1},{"version":"e16d218a30f6a6810b57f7e968124eaa08c7bb366133ea34bbf01e7cd6b8c0ad","affectsGlobalScope":true,"impliedFormat":1},{"version":"eb8692dea24c27821f77e397272d9ed2eda0b95e4a75beb0fdda31081d15a8ae","affectsGlobalScope":true,"impliedFormat":1},{"version":"9e043a1bc8fbf2a255bccf9bf27e0f1caf916c3b0518ea34aa72357c0afd42ec","impliedFormat":1},{"version":"b4f70ec656a11d570e1a9edce07d118cd58d9760239e2ece99306ee9dfe61d02","impliedFormat":1},{"version":"3bc2f1e2c95c04048212c569ed38e338873f6a8593930cf5a7ef24ffb38fc3b6","impliedFormat":1},{"version":"8145e07aad6da5f23f2fcd8c8e4c5c13fb26ee986a79d03b0829b8fce152d8b2","impliedFormat":1},{"version":"f9d9d753d430ed050dc1bf2667a1bab711ccbb1c1507183d794cc195a5b085cc","impliedFormat":1},{"version":"9eece5e586312581ccd106d4853e861aaaa1a39f8e3ea672b8c3847eedd12f6e","impliedFormat":1},{"version":"5b6844ad931dcc1d3aca53268f4bd671428421464b1286746027aede398094f2","impliedFormat":1},{"version":"37ba7b45141a45ce6e80e66f2a96c8a5ab1bcef0fc2d0f56bb58df96ec67e972","impliedFormat":1},{"version":"125d792ec6c0c0f657d758055c494301cc5fdb327d9d9d5960b3f129aff76093","impliedFormat":1},{"version":"0225ecb9ed86bdb7a2c7fd01f1556906902929377b44483dc4b83e03b3ef227d","affectsGlobalScope":true,"impliedFormat":1},{"version":"1851a3b4db78664f83901bb9cac9e45e03a37bb5933cc5bf37e10bb7e91ab4eb","impliedFormat":1},{"version":"461e54289e6287e8494a0178ba18182acce51a02bca8dea219149bf2cf96f105","impliedFormat":1},{"version":"12ed4559eba17cd977aa0db658d25c4047067444b51acfdcbf38470630642b23","affectsGlobalScope":true,"impliedFormat":1},{"version":"f3ffabc95802521e1e4bcba4c88d8615176dc6e09111d920c7a213bdda6e1d65","impliedFormat":1},{"version":"e31e51c55800014d926e3f74208af49cb7352803619855c89296074d1ecbb524","impliedFormat":1},{"version":"ae56f65caf3be91108707bd8dfbccc2a57a91feb5daabf7165a06a945545ed26","impliedFormat":1},{"version":"a136d5de521da20f31631a0a96bf712370779d1c05b7015d7019a9b2a0446ca9","impliedFormat":1},{"version":"dfb96ba5177b68003deec9e773c47257da5c4c8a74053d8956389d832df72002","affectsGlobalScope":true,"impliedFormat":1},{"version":"92d3070580cf72b4bb80959b7f16ede9a3f39e6f4ef2ac87cfa4561844fdc69f","affectsGlobalScope":true,"impliedFormat":1},{"version":"d3dffd70e6375b872f0b4e152de4ae682d762c61a24881ecc5eb9f04c5caf76f","impliedFormat":1},{"version":"613deebaec53731ff6b74fe1a89f094b708033db6396b601df3e6d5ab0ec0a47","impliedFormat":1},{"version":"d91a7d8b5655c42986f1bdfe2105c4408f472831c8f20cf11a8c3345b6b56c8c","impliedFormat":1},{"version":"e56eb632f0281c9f8210eb8c86cc4839a427a4ffffcfd2a5e40b956050b3e042","affectsGlobalScope":true,"impliedFormat":1},{"version":"e8a979b8af001c9fc2e774e7809d233c8ca955a28756f52ee5dee88ccb0611d2","impliedFormat":1},{"version":"cac793cc47c29e26e4ac3601dcb00b4435ebed26203485790e44f2ad8b6ad847","impliedFormat":1},{"version":"8caa5c86be1b793cd5f599e27ecb34252c41e011980f7d61ae4989a149ff6ccc","impliedFormat":1},{"version":"3609e455ffcba8176c8ce0aa57f8258fe10cf03987e27f1fab68f702b4426521","impliedFormat":1},{"version":"d1bd4e51810d159899aad1660ccb859da54e27e08b8c9862b40cd36c1d9ff00f","impliedFormat":1},{"version":"17ed71200119e86ccef2d96b73b02ce8854b76ad6bd21b5021d4269bec527b5f","impliedFormat":1},{"version":"1cfa8647d7d71cb03847d616bd79320abfc01ddea082a49569fda71ac5ece66b","impliedFormat":1},{"version":"bb7a61dd55dc4b9422d13da3a6bb9cc5e89be888ef23bbcf6558aa9726b89a1c","impliedFormat":1},{"version":"db6d2d9daad8a6d83f281af12ce4355a20b9a3e71b82b9f57cddcca0a8964a96","impliedFormat":1},{"version":"cfe4ef4710c3786b6e23dae7c086c70b4f4835a2e4d77b75d39f9046106e83d3","impliedFormat":1},{"version":"cbea99888785d49bb630dcbb1613c73727f2b5a2cf02e1abcaab7bcf8d6bf3c5","impliedFormat":1},{"version":"3b8f725c3d5ffb64bf876c87409686875102c6f7450b268d8f5188b6920f7c25","impliedFormat":1},{"version":"a86f82d646a739041d6702101afa82dcb935c416dd93cbca7fd754fd0282ce1f","impliedFormat":1},{"version":"2dad084c67e649f0f354739ec7df7c7df0779a28a4f55c97c6b6883ae850d1ce","impliedFormat":1},{"version":"fa5bbc7ab4130dd8cdc55ea294ec39f76f2bc507a0f75f4f873e38631a836ca7","impliedFormat":1},{"version":"df45ca1176e6ac211eae7ddf51336dc075c5314bc5c253651bae639defd5eec5","impliedFormat":1},{"version":"cf86de1054b843e484a3c9300d62fbc8c97e77f168bbffb131d560ca0474d4a8","impliedFormat":1},{"version":"37f7b8e560025858aae5195ca74a3e95ecd55591e2babc0acd57bc1dab4ea8ea","impliedFormat":1},{"version":"e2d5483c9a79900ba9d6012135f18b662b3ca1d33fde4f5e39b71f74e47d6331","impliedFormat":1},{"version":"22b9fab85e85b95f6378b5a2bd43c9d2e15106d760e0e58111c416fe224cc76f","impliedFormat":1},{"version":"fc46f093d1b754a8e3e34a071a1dd402f42003927676757a9a10c6f1d195a35b","impliedFormat":1},{"version":"b7b3258e8d47333721f9d4c287361d773f8fa88e52d1148812485d9fc06d2577","impliedFormat":1},{"version":"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855","impliedFormat":1},{"version":"49e567e0aa388ab416eeb7a7de9bce5045a7b628bad18d1f6fa9d3eacee7bc3f","impliedFormat":1},{"version":"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855","impliedFormat":1},{"version":"87eaecac33864ecec8972b1773c5d897f0f589deb7ac8fe0dcdf4b721b06e28d","impliedFormat":1},{"version":"47e5af2a841356a961f815e7c55d72554db0c11b4cba4d0caab91f8717846a94","impliedFormat":1},{"version":"4c91cc1ab59b55d880877ccf1999ded0bb2ebc8e3a597c622962d65bf0e76be8","impliedFormat":1},{"version":"fa1ea09d3e073252eccff2f6630a4ce5633cc2ff963ba672dd8fd6783108ea83","impliedFormat":1},{"version":"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855","impliedFormat":1},{"version":"309816cd6e597f4d4b080bc5e36215c6b78196f744d578adf61589bee5fd7eea","impliedFormat":1},{"version":"bdb44eca306ff5b62bcf2b4e70e96a40987e018029d95565e2f234aad80830cf","impliedFormat":1},{"version":"edaa0bbf2891b17f904a67aef7f9d53371c993fe3ff6dec708c2aff6083b01af","impliedFormat":1},{"version":"89aece12f9cd6d736ae7c350800f257a2363f6322ae8f998da73153fb405d8af","impliedFormat":1},{"version":"d23518a5f155f1a3e07214baf0295687507122ae2e6e9bd5e772551ebd4b3157","impliedFormat":1},{"version":"aa9a92be255ec97f669ea89678fafcbd35d165f65b68ff22685263f6eaeb3c9c","impliedFormat":1},{"version":"fa8b514302736759e491d3df074a61f54ed1a6a69b4aadee05dbcdda53f881c3","impliedFormat":1},{"version":"e8da637cbd6ed1cf6c36e9424f6bcee4515ca2c677534d4006cbd9a05f930f0c","impliedFormat":1},{"version":"ca1b882a105a1972f82cc58e3be491e7d750a1eb074ffd13b198269f57ed9e1b","impliedFormat":1},{"version":"c9d71f340f1a4576cd2a572f73a54dc7212161fa172dfe3dea64ac627c8fcb50","impliedFormat":1},{"version":"3867ca0e9757cc41e04248574f4f07b8f9e3c0c2a796a5eb091c65bfd2fc8bdb","impliedFormat":1},{"version":"6c66f6f7d9ff019a644ff50dd013e6bf59be4bf389092948437efa6b77dc8f9a","impliedFormat":1},{"version":"4e10622f89fea7b05dd9b52fb65e1e2b5cbd96d4cca3d9e1a60bb7f8a9cb86a1","impliedFormat":1},{"version":"ef2d1bd01d144d426b72db3744e7a6b6bb518a639d5c9c8d86438fb75a3b1934","impliedFormat":1},{"version":"b9750fe7235da7d8bf75cb171bf067b7350380c74271d3f80f49aea7466b55b5","impliedFormat":1},{"version":"ac60bbee0d4235643cc52b57768b22de8c257c12bd8c2039860540cab1fa1d82","impliedFormat":1},{"version":"973b59a17aaa817eb205baf6c132b83475a5c0a44e8294a472af7793b1817e89","impliedFormat":1},{"version":"ada39cbb2748ab2873b7835c90c8d4620723aedf323550e8489f08220e477c7f","impliedFormat":1},{"version":"6e5f5cee603d67ee1ba6120815497909b73399842254fc1e77a0d5cdc51d8c9c","impliedFormat":1},{"version":"f79e0681538ef94c273a46bb1a073b4fe9fdc93ef7f40cc2c3abd683b85f51fc","impliedFormat":1},{"version":"70f3814c457f54a7efe2d9ce9d2686de9250bb42eb7f4c539bd2280a42e52d33","impliedFormat":1},{"version":"17ace83a5bea3f1da7e0aef7aab0f52bca22619e243537a83a89352a611b837d","impliedFormat":1},{"version":"ef61792acbfa8c27c9bd113f02731e66229f7d3a169e3c1993b508134f1a58e0","impliedFormat":1},{"version":"6cf2d240d4e449ccfee82aff7ce0fd1890c1b6d4f144ec003aa51f7f70f68935","impliedFormat":1},{"version":"f6404e7837b96da3ea4d38c4f1a3812c96c9dcdf264e93d5bdb199f983a3ef4b","impliedFormat":1},{"version":"c5426dbfc1cf90532f66965a7aa8c1136a78d4d0f96d8180ecbfc11d7722f1a5","impliedFormat":1},{"version":"65a15fc47900787c0bd18b603afb98d33ede930bed1798fc984d5ebb78b26cf9","impliedFormat":1},{"version":"9d202701f6e0744adb6314d03d2eb8fc994798fc83d91b691b75b07626a69801","impliedFormat":1},{"version":"de9d2df7663e64e3a91bf495f315a7577e23ba088f2949d5ce9ec96f44fba37d","impliedFormat":1},{"version":"c7af78a2ea7cb1cd009cfb5bdb48cd0b03dad3b54f6da7aab615c2e9e9d570c5","impliedFormat":1},{"version":"1dc574e42493e8bf9bb37be44d9e38c5bd7bbc04f884e5e58b4d69636cb192b3","impliedFormat":1},{"version":"9deab571c42ed535c17054f35da5b735d93dc454d83c9a5330ecc7a4fb184e9e","affectsGlobalScope":true,"impliedFormat":1},{"version":"db01d18853469bcb5601b9fc9826931cc84cc1a1944b33cad76fd6f1e3d8c544","affectsGlobalScope":true,"impliedFormat":1},{"version":"6b8e8c0331a0c2e9fb53b8b0d346e44a8db8c788dae727a2c52f4cf3bd857f0d","impliedFormat":1},{"version":"903e299a28282fa7b714586e28409ed73c3b63f5365519776bf78e8cf173db36","affectsGlobalScope":true,"impliedFormat":1},{"version":"fa6c12a7c0f6b84d512f200690bfc74819e99efae69e4c95c4cd30f6884c526e","impliedFormat":1},{"version":"f1c32f9ce9c497da4dc215c3bc84b722ea02497d35f9134db3bb40a8d918b92b","impliedFormat":1},{"version":"b73c319af2cc3ef8f6421308a250f328836531ea3761823b4cabbd133047aefa","affectsGlobalScope":true,"impliedFormat":1},{"version":"e433b0337b8106909e7953015e8fa3f2d30797cea27141d1c5b135365bb975a6","impliedFormat":1},{"version":"dd3900b24a6a8745efeb7ad27629c0f8a626470ac229c1d73f1fe29d67e44dca","impliedFormat":1},{"version":"ddff7fc6edbdc5163a09e22bf8df7bef75f75369ebd7ecea95ba55c4386e2441","impliedFormat":1},{"version":"106c6025f1d99fd468fd8bf6e5bda724e11e5905a4076c5d29790b6c3745e50c","impliedFormat":1},{"version":"ec29be0737d39268696edcec4f5e97ce26f449fa9b7afc2f0f99a86def34a418","impliedFormat":1},{"version":"8945919709e0c6069c32ca26a675a0de90fd2ad70d5bc3ba281c628729a0c39d","impliedFormat":1},{"version":"ec6cba1c02c675e4dd173251b156792e8d3b0c816af6d6ad93f1a55d674591aa","impliedFormat":1},{"version":"763ee3998716d599321e34b7f7e93a8e57bef751206325226ebf088bf75ea460","impliedFormat":1},{"version":"e15d3c84d5077bb4a3adee4c791022967b764dc41cb8fa3cfa44d4379b2c95f5","impliedFormat":1},{"version":"3556cfbab7b43da96d15a442ddbb970e1f2fc97876d055b6555d86d7ac57dae5","impliedFormat":1},{"version":"437751e0352c6e924ddf30e90849f1d9eb00ca78c94d58d6a37202ec84eb8393","impliedFormat":1},{"version":"48e8af7fdb2677a44522fd185d8c87deff4d36ee701ea003c6c780b1407a1397","impliedFormat":1},{"version":"606e6f841ba9667de5d83ca458449f0ed8c511ba635f753eaa731e532dea98c7","impliedFormat":1},{"version":"7c0d4fc71fe32cedb758c7e3c08715235a51e5a22d184306a59dae10a9c7ffaa","impliedFormat":1},{"version":"ce8a0b21e80cf5f10adc9336b46ffc666696d1373a763b170baf69a722f85d67","impliedFormat":1},{"version":"2e4f37ffe8862b14d8e24ae8763daaa8340c0df0b859d9a9733def0eee7562d9","impliedFormat":1},{"version":"13283350547389802aa35d9f2188effaeac805499169a06ef5cd77ce2a0bd63f","impliedFormat":1},{"version":"680793958f6a70a44c8d9ae7d46b7a385361c69ac29dcab3ed761edce1c14ab8","impliedFormat":1},{"version":"6ac6715916fa75a1f7ebdfeacac09513b4d904b667d827b7535e84ff59679aff","impliedFormat":1},{"version":"baeffe1b7d836196d497eb755699718deb729a2033078a018f037a14ecaeb9a7","impliedFormat":1},{"version":"39da0a8478aede3a55308089e231c5966b2196e7201494280b1e19f8ec8e24d4","impliedFormat":1},{"version":"90be1a7f573bad71331ff10deeadce25b09034d3d27011c2155bcb9cb9800b7f","impliedFormat":1},{"version":"bc7221c9a8dc71587ff784120f7707985627282dad0a99439e893a1588651ef0","impliedFormat":1},{"version":"438c7513b1df91dcef49b13cd7a1c4720f91a36e88c1df731661608b7c055f10","impliedFormat":1},{"version":"ad444a874f011d3a797f1a41579dbfcc6b246623f49c20009f60e211dbd5315e","impliedFormat":1},{"version":"1124613ba0669e7ea5fb785ede1c3f254ed1968335468b048b8fc35c172393de","impliedFormat":1},{"version":"5fa139523e35fd907f3dd6c2e38ef2066687b27ed88e2680783e05662355ac04","impliedFormat":1},{"version":"9c250db4bab4f78fad08be7f4e43e962cc143e0f78763831653549ceb477344a","impliedFormat":1},{"version":"9385cdc09850950bc9b59cca445a3ceb6fcca32b54e7b626e746912e489e535e","impliedFormat":1},{"version":"0a72186f94215d020cb386f7dca81d7495ab6c17066eb07d0f44a5bf33c1b21a","impliedFormat":1},{"version":"db7c948e2e69559324be7628cb63296ec8986d60f26173f9e324aeb8a2fe23d8","impliedFormat":1},{"version":"9c2353ef1fb353a1c8f30af2cf104f0bc64ebc2fcdb98c2834d451bd654664ab","impliedFormat":1},{"version":"63a8e96f65a22604eae82737e409d1536e69a467bb738bec505f4f97cce9d878","impliedFormat":1},{"version":"3fd78152a7031315478f159c6a5872c712ece6f01212c78ea82aef21cb0726e2","impliedFormat":1},{"version":"7fda4c0e3f50513286029633c458ee82cee563cd6af20b92e43b4425c969c146","impliedFormat":1},{"version":"cda4052f66b1e6cb7cf1fdfd96335d1627aa24a3b8b82ba4a9f873ec3a7bcde8","impliedFormat":1},{"version":"703733dde084b7e856f5940f9c3c12007ca62858accb9482c2b65e030877702d","impliedFormat":1},{"version":"413cb597cc5933562ec064bfb1c3a9164ef5d2f09e5f6b7bd19f483d5352449e","impliedFormat":1},{"version":"fd933f824347f9edd919618a76cdb6a0c0085c538115d9a287fa0c7f59957ab3","impliedFormat":1},{"version":"6ac6715916fa75a1f7ebdfeacac09513b4d904b667d827b7535e84ff59679aff","impliedFormat":1},{"version":"6a1aa3e55bdc50503956c5cd09ae4cd72e3072692d742816f65c66ca14f4dfdd","impliedFormat":1},{"version":"ab75cfd9c4f93ffd601f7ca1753d6a9d953bbedfbd7a5b3f0436ac8a1de60dfa","impliedFormat":1},{"version":"6cc79183c88040697e1552ba81c5245b0c701b965623774587c4b9d1e7497278","impliedFormat":1},{"version":"b73cbf0a72c8800cf8f96a9acfe94f3ad32ca71342a8908b8ae484d61113f647","impliedFormat":1},{"version":"bae6dd176832f6423966647382c0d7ba9e63f8c167522f09a982f086cd4e8b23","impliedFormat":1},{"version":"1364f64d2fb03bbb514edc42224abd576c064f89be6a990136774ecdd881a1da","impliedFormat":1},{"version":"c9958eb32126a3843deedda8c22fb97024aa5d6dd588b90af2d7f2bfac540f23","impliedFormat":1},{"version":"950fb67a59be4c2dbe69a5786292e60a5cb0e8612e0e223537784c731af55db1","impliedFormat":1},{"version":"e927c2c13c4eaf0a7f17e6022eee8519eb29ef42c4c13a31e81a611ab8c95577","impliedFormat":1},{"version":"07ca44e8d8288e69afdec7a31fa408ce6ab90d4f3d620006701d5544646da6aa","impliedFormat":1},{"version":"82c27d4cf380b0e6cd62628f069b850298d20051f0b7b0a1904fdb38c53fa7a6","impliedFormat":1},{"version":"c97b9278c8ce212c1bdf4fae9c77d58c15565d4ebf663d761a9deb924b6ca8b3","impliedFormat":1},{"version":"8bb6e7ce91ec84336203e87010b1198514548c2e44789752c1741eaac02f2431","impliedFormat":1},{"version":"b33ac7d8d7d1bfc8cc06c75d1ee186d21577ab2026f482e29babe32b10b26512","impliedFormat":1},{"version":"24f8f342c14c911eedfee43074c6a0d0a5ebb5ec984353bffaeadddb3f6a6b1c","impliedFormat":1},{"version":"6459054aabb306821a043e02b89d54da508e3a6966601a41e71c166e4ea1474f","impliedFormat":1},{"version":"03d4a10c21ac451b682246f3261b769247baf774c4878551c02256ae98299b1c","impliedFormat":1},{"version":"2d9b710fee8c3d7eabee626af8fd6ec2cf6f71e6b7429b307b8f67d70b1707c5","impliedFormat":1},{"version":"652a4bbefba6aa309bfc3063f59ed1a2e739c1d802273b0e6e0aa7082659f3b3","impliedFormat":1},{"version":"d7ca19bfb1ba4c3ef59d43bd7cd3719d8c5ffb60a9b6f402dee4e229f4d921aa","impliedFormat":1},{"version":"0c0a85a19b60f2ec18a32ff051bb1423860977a16b645dbf159baa7202bc633b","impliedFormat":1},{"version":"fc5bdc1d13667041055811568043956c75150923d8b9a32b989ac7588418ce47","impliedFormat":1},{"version":"f974e4a06953682a2c15d5bd5114c0284d5abf8bc0fe4da25cb9159427b70072","impliedFormat":1},{"version":"d3b290cc3c08cbde2b463df2616b948fb32733dafe3ac29b9e6ded26baee5489","impliedFormat":1},{"version":"94404c4a878fe291e7578a2a80264c6f18e9f1933fbb57e48f0eb368672e389c","impliedFormat":1},{"version":"5c1b7f03aa88be854bc15810bfd5bd5a1943c5a7620e1c53eddd2a013996343e","impliedFormat":1},{"version":"f416c9c3eee9d47ff49132c34f96b9180e50485d435d5748f0e8b72521d28d2e","impliedFormat":1},{"version":"9558d365d0e72b6d9bd8c1742fe1185f983965c6d2eff88a117a59b9f51d3c5f","impliedFormat":1},{"version":"6cc2961fbe8d32e34fd4c7f1b7045353016fff50df98bc31af7c7d1b4b6eb552","impliedFormat":1},{"version":"01aa917531e116485beca44a14970834687b857757159769c16b228eb1e49c5f","impliedFormat":1},{"version":"a2e1f7010ae5f746b937621840cb87dee9eeb69188d32880bd9752029084212c","impliedFormat":1},{"version":"dd30eb34b5c4597a568de0efb8b34e328c224648c258759ac541beb16256ffb6","impliedFormat":1},{"version":"6129bd7098131a0e346352901bc8d461a76d0568686bb0e1f8499df91fde8a1f","impliedFormat":1},{"version":"7cd7923a36835c1194a92b808068a524c4e7c0ff7bdc8712865800e6963d75da","impliedFormat":1},{"version":"82200d39d66c91f502f74c85db8c7a8d56cfc361c20d7da6d7b68a4eeaaefbf4","impliedFormat":1},{"version":"741067675daa6d4334a2dc80a4452ca3850e89d5852e330db7cb2b5f867173b1","impliedFormat":1},{"version":"a1c8542ed1189091dd39e732e4390882a9bcd15c0ca093f6e9483eba4e37573f","impliedFormat":1},{"version":"131b1475d2045f20fb9f43b7aa6b7cb51f25250b5e4c6a1d4aa3cf4dd1a68793","impliedFormat":1},{"version":"3a17f09634c50cce884721f54fd9e7b98e03ac505889c560876291fcf8a09e90","impliedFormat":1},{"version":"32531dfbb0cdc4525296648f53b2b5c39b64282791e2a8c765712e49e6461046","impliedFormat":1},{"version":"0ce1b2237c1c3df49748d61568160d780d7b26693bd9feb3acb0744a152cd86d","impliedFormat":1},{"version":"e489985388e2c71d3542612685b4a7db326922b57ac880f299da7026a4e8a117","impliedFormat":1},{"version":"76264a4df0b7c78b7b12dfaedc05d9f1016f27be1f3d0836417686ff6757f659","impliedFormat":1},{"version":"c0fabd699e6e0b6bfc1728c048e52737b73fb6609eeeae0f7f4775ff14ff2df6","affectsGlobalScope":true,"impliedFormat":1},{"version":"fd1b9d883b9446f1e1da1e1033a6a98995c25fbf3c10818a78960e2f2917d10c","impliedFormat":1},{"version":"19252079538942a69be1645e153f7dbbc1ef56b4f983c633bf31fe26aeac32cd","impliedFormat":1},{"version":"4dd4f6e28afc1ee30ce76ffc659d19e14dff29cb19b7747610ada3535b7409af","impliedFormat":1},{"version":"1640728521f6ab040fc4a85edd2557193839d0cd0e41c02004fc8d415363d4e2","impliedFormat":1},{"version":"65c24a8baa2cca1de069a0ba9fba82a173690f52d7e2d0f1f7542d59d5eb4db0","impliedFormat":1},{"version":"ec9fd890d681789cb0aa9efbc50b1e0afe76fbf3c49c3ac50ff80e90e29c6bcb","impliedFormat":1},{"version":"5fbd292aa08208ae99bf06d5da63321fdc768ee43a7a104980963100a3841752","impliedFormat":1},{"version":"9eac5a6beea91cfb119688bf44a5688b129b804ede186e5e2413572a534c21bb","impliedFormat":1},{"version":"e81bf06c0600517d8f04cc5de398c28738bfdf04c91fb42ad835bfe6b0d63a23","impliedFormat":1},{"version":"363996fe13c513a7793aa28ffb05b5d0230db2b3d21b7bfaf21f79e4cde54b4e","impliedFormat":1},{"version":"b7fff2d004c5879cae335db8f954eb1d61242d9f2d28515e67902032723caeab","impliedFormat":1},{"version":"5f3dc10ae646f375776b4e028d2bed039a93eebbba105694d8b910feebbe8b9c","impliedFormat":1},{"version":"7f6c48cacd08c1b1e29737b8221b7661e6b855767f8778f9a181fa2f74c09d21","impliedFormat":1},{"version":"4545c1a1ceca170d5d83452dd7c4994644c35cf676a671412601689d9a62da35","impliedFormat":1},{"version":"15959543f93f27e8e2b1a012fe28e14b682034757e2d7a6c1f02f87107fc731e","impliedFormat":1},{"version":"a2d648d333cf67b9aeac5d81a1a379d563a8ffa91ddd61c6179f68de724260ff","impliedFormat":1},{"version":"4e828bf688597c32905215785730cbdb603b54e284d472a23fc0195c6d4aeee8","impliedFormat":1},{"version":"a3f41ed1b4f2fc3049394b945a68ae4fdefd49fa1739c32f149d32c0545d67f5","impliedFormat":1},{"version":"4da80db9ed5a1a20fd5bfce863dd178b8928bcaf4a3d75e8657bcae32e572ede","impliedFormat":1},{"version":"47699512e6d8bebf7be488182427189f999affe3addc1c87c882d36b7f2d0b0e","impliedFormat":1},{"version":"f72ee46ae3f73e6c5ff0da682177251d80500dd423bfd50286124cd0ca11e160","impliedFormat":1},{"version":"898b714aad9cfd0e546d1ad2c031571de7622bd0f9606a499bee193cf5e7cf0c","impliedFormat":1},{"version":"d707fb7ca32930495019a4c85500385f6850c785ee0987a1b6bcad6ade95235e","impliedFormat":1},{"version":"fedebeae32c5cdd1a85b4e0504a01996e4a8adf3dfa72876920d3dd6e42978e7","impliedFormat":1},{"version":"5d26aae738fa3efc87c24f6e5ec07c54694e6bcf431cc38d3da7576d6bb35bd6","impliedFormat":1},{"version":"cdf21eee8007e339b1b9945abf4a7b44930b1d695cc528459e68a3adc39a622e","impliedFormat":1},{"version":"e0aa1079d58134e55ad2f73508ad1be565a975f2247245d76c64c1ca9e5e5b26","impliedFormat":1},{"version":"cd0c5af42811a4a56a0f77856cfa6c170278e9522888db715b11f176df3ff1f2","impliedFormat":1},{"version":"68f81dad9e8d7b7aa15f35607a70c8b68798cf579ac44bd85325b8e2f1fb3600","impliedFormat":1},{"version":"1de80059b8078ea5749941c9f863aa970b4735bdbb003be4925c853a8b6b4450","impliedFormat":1},{"version":"1d079c37fa53e3c21ed3fa214a27507bda9991f2a41458705b19ed8c2b61173d","impliedFormat":1},{"version":"94fd3ce628bd94a2caf431e8d85901dbe3a64ab52c0bd1dbe498f63ca18789f7","impliedFormat":1},{"version":"5835a6e0d7cd2738e56b671af0e561e7c1b4fb77751383672f4b009f4e161d70","impliedFormat":1},{"version":"c0eeaaa67c85c3bb6c52b629ebbfd3b2292dc67e8c0ffda2fc6cd2f78dc471e6","impliedFormat":1},{"version":"4b7f74b772140395e7af67c4841be1ab867c11b3b82a51b1aeb692822b76c872","impliedFormat":1},{"version":"27be6622e2922a1b412eb057faa854831b95db9db5035c3f6d4b677b902ab3b7","impliedFormat":1},{"version":"2470a2412a59c6177cd4408dd7edb099ca7ace68c0187f54187dfee56dc9c5aa","impliedFormat":99},{"version":"c2008605e78208cfa9cd70bd29856b72dda7ad89df5dc895920f8e10bcb9cd0a","impliedFormat":99},{"version":"ec61ebac4d71c4698318673efbb5c481a6c4d374da8d285f6557541a5bd318d0","impliedFormat":99},{"version":"16fd66ae997b2f01c972531239da90fbf8ab4022bb145b9587ef746f6cecde5a","affectsGlobalScope":true,"impliedFormat":1},{"version":"fc8fbee8f73bf5ffd6ba08ba1c554d6f714c49cae5b5e984afd545ab1b7abe06","affectsGlobalScope":true,"impliedFormat":1},{"version":"3586f5ea3cc27083a17bd5c9059ede9421d587286d5a47f4341a4c2d00e4fa91","impliedFormat":1},{"version":"521fc35a732f1a19f5d52024c2c22e257aa63258554968f7806a823be2f82b03","impliedFormat":1},{"version":"b789bf89eb19c777ed1e956dbad0925ca795701552d22e68fd130a032008b9f9","impliedFormat":1},"9269d492817e359123ac64c8205e5d05dab63d71a3a7a229e68b5d9a0e8150bf",{"version":"2ed1f4528e9f6c3afd463a21d4699343489120b0dc51be0311095ba812ed53e3","signature":"19f50a275cc22648684a26293b742ec0aa7d0af1e0780fdda8cfff83b7fceccd"},{"version":"4621915b80ececce8add76bb2688023b0a13c32bc50842daffcea72c59f9811d","signature":"b3866e19c62ac158edc23e9f40459e2616b0c7b43296efc6fd3724f63d707d03"},{"version":"3970215ae699f8a73b70d32766c1c043803d720cac745dcbdd7d01f58870edcd","signature":"8558dd8fc2b6bcba6c5f6658d33840682082fc3ab8abc00762cbd98428005f5e"},{"version":"b55219f55931e3cf054a3cc1dd6807923531fc07e5821a7e2ed8aef6d3a0c617","signature":"b96946fd29fb636050a4cb07bac96263b83e7b9390223a38c538676bb017d871"},{"version":"35f1022856093c0aae548f91f73dddd481bff536a6db4a3a5bd61e10131aa385","signature":"94efda9025680a8d23a3cece7865cf566d2e5606f5e047e81e2af2da0c69e99d"},{"version":"36c6ae9870525c251242f2931161c72a22bf311085ad5cb100cbc074e65d6b97","signature":"3fe79b01124434e766a69d984fa52109e2f2e6cbfa9af93be433205a1e9c19dc"},{"version":"7b1c458861c98d128fbfaf390bd7b899f7de5aedbc0c26de68778d7c875b5bb8","signature":"96d4a93e3f9effef5ffa9144c8f1aaa74fbfd803b4016b3c429cd829f109aadc"},{"version":"99b901a4b18280099badd9dcb1a34923befca90aaded387f66a23cf897ec902a","signature":"a724ef7a7048adcb8b82a13d9125b7678fc1b6dc3c1a1159e439b59b785f75fa"},{"version":"bd9540714b8c8f176f860600067ae435bffb474eef6067ef46345eb7c2c7913d","signature":"01f93338dfef8b035cb7f6c3e49aaa0d46b209b8600bf1c4a2fa6be2113406ad"},{"version":"eda39b2c03f707333a748b59a753aed1660123ea8eddbc89af39c22ae8039f85","signature":"3ef1f2be3b347b6cec1f4332e296744f3b66a7db5e6d81db290a55fb90b6ce79"},{"version":"72d3c4944a670e872a7ae13866b0945adc81e00443d25113882a846f80342f07","signature":"43c58dee7351911004a1c7300a9e889e6676383fc77bab3d5330cea79c09a429"},{"version":"7295263abebff119da0e3f89eb2822a1278e1c58b9879be779c097e0cd9286ad","signature":"956268defed94ea94ee29662f323e13e4e0c3ad8e118505ec05f590a30417002"},{"version":"99d092ac08e3628f10b8ed8e03767fd59098b42d4f7155b0bd6ced2fc48ec422","signature":"14d3c2edc0598d34e46b9a2c783a695fccb849603656a0bd865b8ead0ff934ef"},{"version":"fa7545dccb5941f347eab64ed131074b317329ca918eb9e2c330465f1c604f3d","signature":"7fced774d307155dbe328583316013de87b8d033941c7c306909e3dba9a401d1"},{"version":"68322f13978ef50b9563c01c5aabdcdbb695f2b3bb0f7353059288edb7009bee","signature":"9c87095d53bd06837af999055aea93281b5e7450f54fc70b02085796e4e8dc92"},{"version":"d9f4f24f2753f960e31412c33f57afdb6013fbfca522dea173f513a48686a700","signature":"b5d2010147dad6dcc07351d5f3d115755a3af2ab2947c1338b79fdc7ae4fb655"},{"version":"1f65639e1682e74536dbdf1dfd45cb61e4d4eaede59a3666871edcb2195b9d6a","signature":"ebbe610a9e5ef3f3fa8ae5015314940a4990000db655f7faebc9d493b3cfa729"},{"version":"276c645e83c3aefc314654e3c9b83f3a31132fbccb35c67e527e5f14b1f05664","signature":"2c02feb748f8512cdcbab939911d3e2e83ab6e1b0b3088ec630f5af7ae83a0be"},{"version":"c586297dec6f98111d1cef4000808e82aa5194bb8c96c63f686b3af0eaaf49bc","signature":"9fad252409ee63c377df5b8e6360eb287676e45cd14c80401fe466981ff12108"},{"version":"ce465b7f19c4a660edf37ba169f7ef5e014f275e2fade94a5acbf57be9c84e03","signature":"41dfeb0a61dffc83b5c8929c867d39fbc5a87045f38a57ff98956efe3409f1eb"},{"version":"6e62d793a5210a3a514ff0835342a9e0262bf1ca8d173225d388d7bf345ccd9a","signature":"89241cf8091b09ffe6300fc894c432f4d36b12115d4797edc482005b21fe1f1e"},{"version":"435fab7b0cf777a154951d667cd6ed1d4d868a134bd78bd6ad772f12dae6e058","signature":"8cdac9d1aa3033578368b15b8c21e74a8660702a225879b8fc90540bcdda3393"},{"version":"da38506ac82d47baebb86cff4acf4a28283549594ef4a5409a04e6a9397dc3d5","signature":"3a8523bfa20e149df671c3166d3c2e0c8e5b9f015b121a6855deedf209096b5e"},{"version":"522cb15ff9bef5a65c2f3dbd10dbba9e7ecae4de32f90f5c0b4198132be63ae4","impliedFormat":1},{"version":"f4eb7cccaa1aeb966f123b23feb7e4f25c016da6289660de7582b5d3e283fe37","signature":"505c130ab8636470a22967b104b155f5a2112a2e30006c132d94475f63ec65ea"},{"version":"12bc9baca2a431726c281172ebb5dc27be4ae4a9049115761641a94fca6869ec","signature":"2cc743b624d6891f9275f11f76fedfe235af04641c806e7dc65e55740db4dd29"},{"version":"d8b0d7197f87607acd8b522d3db4e320afbe60a899d383f3eb52dd8c3adbd116","signature":"2cc743b624d6891f9275f11f76fedfe235af04641c806e7dc65e55740db4dd29"},{"version":"a2a95b534c86d4e0f5566af35342d8f4b9b1243e7129d4533b659e882a1abf17","signature":"2cc743b624d6891f9275f11f76fedfe235af04641c806e7dc65e55740db4dd29"},{"version":"c2dacecb15f3a94b3afd7e2b72ae576f3ea547d03ace84aecb0721a0d57061d0","signature":"2cc743b624d6891f9275f11f76fedfe235af04641c806e7dc65e55740db4dd29"},{"version":"465e3e33047db92bdc553eaa8eae081eeabd73e1f5d04bbe1187ef05feb53d51","signature":"2cc743b624d6891f9275f11f76fedfe235af04641c806e7dc65e55740db4dd29"},{"version":"f0def0d9e5def44e099a008db7a56697aa676537de9c1888df84b4168193c987","signature":"2cc743b624d6891f9275f11f76fedfe235af04641c806e7dc65e55740db4dd29"},{"version":"fcfc8426448da7200e28c2196db140f0e1a592e4d48e7253e89f5e6de7d51ce3","signature":"2cc743b624d6891f9275f11f76fedfe235af04641c806e7dc65e55740db4dd29"},{"version":"96d14f21b7652903852eef49379d04dbda28c16ed36468f8c9fa08f7c14c9538","impliedFormat":1},{"version":"104c67f0da1bdf0d94865419247e20eded83ce7f9911a1aa75fc675c077ca66e","impliedFormat":1},{"version":"cc0d0b339f31ce0ab3b7a5b714d8e578ce698f1e13d7f8c60bfb766baeb1d35c","impliedFormat":1},{"version":"d3f2d715f57df3f04bf7b16dde01dec10366f64fce44503c92b8f78f614c1769","impliedFormat":1},{"version":"b78cd10245a90e27e62d0558564f5d9a16576294eee724a59ae21b91f9269e4a","impliedFormat":1},{"version":"936eb43a381712a8ec1249f2afc819f6fc7ca68f10dfec71762b428dfdc53bf1","impliedFormat":1},{"version":"2f5747b1508ccf83fad0c251ba1e5da2f5a30b78b09ffa1cfaf633045160afed","impliedFormat":1},{"version":"86ea91bfa7fef1eeb958056f30f1db4e0680bc9b5132e5e9d6e9cfd773c0c4fd","affectsGlobalScope":true,"impliedFormat":1},{"version":"b71c603a539078a5e3a039b20f2b0a0d1708967530cf97dec8850a9ca45baa2b","impliedFormat":1},{"version":"0e13570a7e86c6d83dd92e81758a930f63747483e2cd34ef36fcdb47d1f9726a","impliedFormat":1},{"version":"5c45abf1e13e4463eacfd5dedda06855da8748a6a6cb3334f582b52e219acc04","impliedFormat":1},{"version":"736097ddbb2903bef918bb3b5811ef1c9c5656f2a73bd39b22a91b9cc2525e50","impliedFormat":1},{"version":"4340936f4e937c452ae783514e7c7bbb7fc06d0c97993ff4865370d0962bb9cf","impliedFormat":1},{"version":"5fc6e6b8232254d80ed6b802372dba7f426f0a596f5fe26b7773acfdc8232926","impliedFormat":1},{"version":"6825eb4d1c8beb77e9ed6681c830326a15ebf52b171f83ffbca1b1574c90a3b0","impliedFormat":1},{"version":"1741975791f9be7f803a826457273094096e8bba7a50f8fa960d5ed2328cdbcc","impliedFormat":1},{"version":"6ec0d1c15d14d63d08ccb10d09d839bf8a724f6b4b9ed134a3ab5042c54a7721","impliedFormat":1},{"version":"043a3b03dcb40d6b87d36ad26378c80086905232ee5602f067eaaed21baa42ef","impliedFormat":1},{"version":"b61028c5e29a0691e91a03fa2c4501ea7ed27f8fa536286dc2887a39a38b6c44","impliedFormat":1},{"version":"2c3bcb8a4ea2fcb4208a06672af7540dd65bf08298d742f041ffa6cbe487cf80","impliedFormat":1},{"version":"1cce0460d75645fc40044c729da9a16c2e0dabe11a58b5e4bfd62ac840a1835d","impliedFormat":1},{"version":"c784a9f75a6f27cf8c43cc9a12c66d68d3beb2e7376e1babfae5ae4998ffbc4a","impliedFormat":1},{"version":"feb4c51948d875fdbbaa402dad77ee40cf1752b179574094b613d8ad98921ce1","impliedFormat":1},{"version":"a6d3984b706cefe5f4a83c1d3f0918ff603475a2a3afa9d247e4114f18b1f1ef","impliedFormat":1},{"version":"b457d606cabde6ea3b0bc32c23dc0de1c84bb5cb06d9e101f7076440fc244727","impliedFormat":1},{"version":"9d59919309a2d462b249abdefba8ca36b06e8e480a77b36c0d657f83a63af465","impliedFormat":1},{"version":"9faa2661daa32d2369ec31e583df91fd556f74bcbd036dab54184303dee4f311","impliedFormat":1},{"version":"ba2e5b6da441b8cf9baddc30520c59dc3ab47ad3674f6cb51f64e7e1f662df12","impliedFormat":1},{"version":"9e8020e898d31ac0e771d197ce7391ce13065cd5e63c8cd26cdaf66b4f18a2a6","affectsGlobalScope":true,"impliedFormat":1},{"version":"f21ce049835dad382b22691fb6b34076d0717307d46d92320893765be010cd56","impliedFormat":1},{"version":"d14487891bf108abe8cd453e524c43adcc6ab460076de130fdceeae056716f5c","impliedFormat":1},{"version":"668ad7a30d682016ad429b19348e787c0b44ba48488f398fca2623f9be9bd2c9","impliedFormat":1},{"version":"a716e3f374ec689caa659bd11ea1c4bc710ecceb295baf224f93ece3344707ed","impliedFormat":1},{"version":"b20550496b496031dadad8f80eec01d115b299cb285ffc2bd64873e123efc0cf","impliedFormat":1},{"version":"c46813bfd156c5357506d49c461131c7f75367bf52052274c9889315fd12af29","impliedFormat":1},{"version":"665f83fc3e9992c7a5e15a470e4b9e10e8b588c35593b0058c8d1a9eca487c56","impliedFormat":1},{"version":"1d85c932bcb40ec1daa5fc23f7924e63d6537f6fda79a96cedeb6506c0ee6fa2","impliedFormat":1},{"version":"dd36b144e0e70b4e38f588913af663ed959b10b5cf80952a4beb22a10255bf08","impliedFormat":1},{"version":"d064b43717b5b5dfca0d6cd738022ab377c90e45f05edbcd5a0c8753e6627d88","impliedFormat":1},{"version":"d9f740654bb5703265eade0fb65edce48a32726e3b56041d23158121948c9a9f","impliedFormat":1},{"version":"74d5a87c3616cd5d8691059d531504403aa857e09cbaecb1c64dfb9ace0db185","impliedFormat":1}],"root":[[351,374],[376,383]],"options":{"allowJs":true,"esModuleInterop":true,"jsx":1,"module":99,"skipLibCheck":true,"strict":true,"target":1},"referencedMap":[[386,1],[385,2],[391,3],[394,4],[392,5],[387,5],[396,5],[397,6],[411,7],[398,8],[405,9],[401,10],[399,11],[402,12],[406,13],[407,9],[404,14],[403,15],[408,16],[409,17],[410,18],[400,19],[412,5],[389,5],[390,5],[388,20],[393,21],[424,22],[65,5],[417,23],[420,24],[421,25],[418,5],[419,5],[416,5],[422,26],[415,27],[414,5],[395,28],[423,29],[413,5],[378,30],[379,31],[380,32],[381,33],[377,34],[382,35],[383,36],[351,37],[308,5],[384,5],[104,38],[105,38],[106,39],[64,40],[107,41],[108,42],[109,43],[59,5],[62,44],[60,5],[61,5],[110,45],[111,46],[112,47],[113,48],[114,49],[115,50],[116,50],[118,5],[117,51],[119,52],[120,53],[121,54],[103,55],[63,5],[122,56],[123,57],[124,58],[156,59],[125,60],[126,61],[127,62],[128,63],[129,64],[130,65],[131,66],[132,67],[133,68],[134,69],[135,69],[136,70],[137,5],[138,71],[140,72],[139,73],[141,74],[142,75],[143,76],[144,77],[145,78],[146,79],[147,80],[148,81],[149,82],[150,83],[151,84],[152,85],[153,86],[154,87],[155,88],[51,5],[161,89],[162,90],[160,91],[158,92],[159,93],[49,5],[52,94],[50,5],[375,95],[58,96],[311,97],[316,98],[318,99],[180,100],[185,101],[284,102],[255,103],[263,104],[282,105],[181,106],[229,5],[230,107],[283,108],[206,109],[182,110],[210,109],[200,109],[167,109],[247,111],[172,5],[244,112],[242,113],[189,5],[245,114],[335,115],[253,91],[334,5],[333,116],[246,91],[235,117],[243,118],[258,119],[259,120],[250,5],[190,121],[248,5],[249,91],[328,122],[331,123],[217,124],[216,125],[215,126],[338,91],[214,127],[194,5],[341,5],[344,5],[343,91],[345,128],[163,5],[278,5],[165,129],[299,5],[300,5],[302,5],[305,130],[301,5],[303,131],[304,131],[184,5],[310,127],[319,132],[323,133],[176,134],[237,135],[236,5],[254,136],[251,5],[252,5],[257,137],[233,138],[175,139],[204,140],[275,141],[168,28],[174,142],[164,143],[286,144],[297,145],[285,5],[296,146],[205,5],[192,147],[272,148],[271,5],[274,149],[273,149],[226,150],[211,150],[266,151],[212,151],[170,152],[169,5],[270,153],[269,154],[268,155],[267,156],[171,157],[241,158],[256,159],[240,160],[262,161],[264,162],[261,160],[207,157],[157,5],[276,163],[231,164],[295,165],[188,166],[290,167],[183,5],[291,168],[293,169],[294,170],[289,5],[288,28],[208,171],[277,172],[298,173],[177,5],[179,5],[191,174],[265,175],[173,176],[178,5],[187,177],[186,178],[193,179],[234,2],[232,116],[195,180],[197,181],[342,5],[196,182],[198,183],[313,5],[314,5],[312,5],[315,5],[340,5],[199,184],[239,91],[57,5],[260,185],[218,5],[228,186],[321,91],[327,187],[225,91],[325,91],[224,188],[307,189],[223,187],[166,5],[329,190],[221,91],[222,91],[213,5],[227,5],[220,191],[219,192],[209,193],[203,194],[292,5],[202,195],[201,5],[317,5],[238,91],[309,196],[48,5],[56,197],[53,91],[54,5],[55,5],[287,198],[281,199],[279,5],[280,200],[320,201],[322,202],[324,203],[326,204],[350,205],[330,205],[349,206],[332,207],[336,208],[337,209],[339,210],[346,211],[348,5],[347,95],[306,212],[46,5],[47,5],[8,5],[9,5],[11,5],[10,5],[2,5],[12,5],[13,5],[14,5],[15,5],[16,5],[17,5],[18,5],[19,5],[3,5],[20,5],[21,5],[4,5],[22,5],[26,5],[23,5],[24,5],[25,5],[27,5],[28,5],[29,5],[5,5],[30,5],[31,5],[32,5],[33,5],[6,5],[37,5],[34,5],[35,5],[36,5],[38,5],[7,5],[39,5],[44,5],[45,5],[40,5],[41,5],[42,5],[43,5],[1,5],[81,213],[91,214],[80,213],[101,215],[72,216],[71,217],[100,95],[94,218],[99,219],[74,220],[88,221],[73,222],[97,223],[69,224],[68,95],[98,225],[70,226],[75,227],[76,5],[79,227],[66,5],[102,228],[92,229],[83,230],[84,231],[86,232],[82,233],[85,234],[95,95],[77,235],[78,236],[87,237],[67,238],[90,229],[89,227],[93,5],[96,239],[367,240],[368,240],[372,241],[373,242],[365,243],[366,244],[374,245],[376,246],[361,247],[359,248],[370,249],[363,244],[358,91],[371,5],[360,91],[369,250],[364,251],[362,252],[352,5],[353,253],[354,253],[355,5],[356,5],[357,5]],"affectedFilesPendingEmit":[378,379,380,381,377,382,383,367,368,372,373,365,366,374,376,361,359,370,363,358,371,360,369,364,362,352,353,354,355,356,357],"version":"5.9.2"}
===== END FILE =====

===== FILE: main.py =====
#!/usr/bin/env python3
"""
Main entry point for TranscribeAlpha application.
This file provides a direct import path for deployment platforms.

Build trigger: 2026-01-26
"""

import sys
import os
import logging

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

logger.info("TranscribeAlpha starting up")

# Ensure we can import from current directory and backend
current_dir = os.path.dirname(os.path.abspath(__file__))
backend_dir = os.path.join(current_dir, 'backend')

sys.path.insert(0, current_dir)
sys.path.insert(0, backend_dir)

# Import the app
try:
    from backend.server import app
    logger.info("Imported app from backend.server")
except ImportError as e:
    logger.warning("Failed to import from backend.server: %s", e)
    try:
        os.chdir(backend_dir)
        sys.path.insert(0, backend_dir)
        from server import app
        logger.info("Imported app from server")
    except ImportError as e2:
        logger.error("Failed to import app: %s, %s", e, e2)
        raise ImportError(f"Could not import app: {e}, {e2}")

if __name__ == "__main__":
    port = int(os.getenv("PORT", 8080))
    host = os.getenv("HOST", "0.0.0.0")
    logger.info("Starting server on %s:%d", host, port)

    import hypercorn.asyncio
    import hypercorn.config
    import asyncio

    config = hypercorn.config.Config()
    config.bind = [f"{host}:{port}"]
    config.h2 = True

    asyncio.run(hypercorn.asyncio.serve(app, config))
===== END FILE =====

===== FILE: requirements.txt =====
fastapi>=0.110.0
uvicorn[standard]>=0.27.0
hypercorn>=0.16.0
python-multipart>=0.0.6
google-cloud-storage>=2.10.0
python-docx>=1.1.0
reportlab>=4.2.0
ffmpeg-python>=0.2.0
pydub>=0.25.1
pydantic>=2.5.0
assemblyai>=0.50.0
packaging>=23.0
google-genai>=1.52.0
python-jose[cryptography]>=3.3.0
bcrypt>=4.0.0
google-cloud-secret-manager>=2.16.0
requests>=2.31.0
===== END FILE =====

===== FILE: scripts/add_user.sh =====
#!/bin/bash
#
# Add a new user to TranscribeAlpha
# Usage: ./scripts/add_user.sh <username> <password> [role]
#
# Example:
#   ./scripts/add_user.sh JohnDoe mypassword123
#   ./scripts/add_user.sh AdminUser adminpass admin
#

set -e

SECRET_NAME="transcribealpha-users"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# Check arguments
if [ $# -lt 2 ]; then
    echo -e "${RED}Usage: $0 <username> <password> [role]${NC}"
    echo ""
    echo "Arguments:"
    echo "  username  - The username for the new account"
    echo "  password  - The password for the new account"
    echo "  role      - Optional: 'admin' or 'user' (default: user)"
    echo ""
    echo "Example:"
    echo "  $0 JohnDoe mypassword123"
    echo "  $0 AdminUser adminpass admin"
    exit 1
fi

USERNAME="$1"
PASSWORD="$2"
ROLE="${3:-user}"

echo -e "${YELLOW}Adding user: ${USERNAME} (role: ${ROLE})${NC}"

# Check if gcloud is installed
if ! command -v gcloud &> /dev/null; then
    echo -e "${RED}Error: gcloud CLI is not installed${NC}"
    echo "Install it from: https://cloud.google.com/sdk/docs/install"
    exit 1
fi

# Check if logged in to gcloud
if ! gcloud auth print-identity-token &> /dev/null; then
    echo -e "${RED}Error: Not logged in to gcloud${NC}"
    echo "Run: gcloud auth login"
    exit 1
fi

# Check if Python is available
if ! command -v python3 &> /dev/null; then
    echo -e "${RED}Error: python3 is not installed${NC}"
    exit 1
fi

# Check if bcrypt is installed
if ! python3 -c "import bcrypt" 2>/dev/null; then
    echo -e "${YELLOW}Installing bcrypt...${NC}"
    pip3 install bcrypt --quiet
fi

# Generate password hash
echo "Generating password hash..."
PASSWORD_HASH=$(python3 -c "import bcrypt; print(bcrypt.hashpw('$PASSWORD'.encode(), bcrypt.gensalt()).decode())")

if [ -z "$PASSWORD_HASH" ]; then
    echo -e "${RED}Error: Failed to generate password hash${NC}"
    exit 1
fi

# Get current users from Secret Manager
echo "Fetching current users from Secret Manager..."
CURRENT_USERS=$(gcloud secrets versions access latest --secret="$SECRET_NAME" 2>/dev/null || echo '{"users":[]}')

# Check if user already exists
if echo "$CURRENT_USERS" | python3 -c "import sys, json; users = json.load(sys.stdin); exit(0 if any(u['username'] == '$USERNAME' for u in users.get('users', [])) else 1)" 2>/dev/null; then
    echo -e "${RED}Error: User '$USERNAME' already exists${NC}"
    exit 1
fi

# Add new user to JSON
echo "Adding user to configuration..."
TIMESTAMP=$(date -u +"%Y-%m-%dT%H:%M:%SZ")

NEW_USERS=$(echo "$CURRENT_USERS" | python3 -c "
import sys, json
data = json.load(sys.stdin)
data['users'].append({
    'username': '$USERNAME',
    'password_hash': '$PASSWORD_HASH',
    'role': '$ROLE',
    'created_at': '$TIMESTAMP'
})
print(json.dumps(data, indent=2))
")

# Save to temp file and upload
TEMP_FILE=$(mktemp)
echo "$NEW_USERS" > "$TEMP_FILE"

echo "Uploading to Secret Manager..."
gcloud secrets versions add "$SECRET_NAME" --data-file="$TEMP_FILE" --quiet

# Cleanup
rm -f "$TEMP_FILE"

echo ""
echo -e "${GREEN}User '$USERNAME' added successfully!${NC}"
echo ""
echo "Note: Changes take effect within 5 minutes (cache refresh)."
echo "To apply immediately, redeploy the Cloud Run service."
===== END FILE =====

===== FILE: scripts/backfill_media_metadata.py =====
#!/usr/bin/env python3
import argparse
import json
import logging
from typing import Optional

try:
    from backend.storage import storage_client, BUCKET_NAME
except ImportError:
    try:
        from storage import storage_client, BUCKET_NAME
    except ImportError:
        import storage as storage_module
        storage_client = storage_module.storage_client
        BUCKET_NAME = storage_module.BUCKET_NAME


logger = logging.getLogger(__name__)


def _derive_media_key_from_path(blob_name: str) -> Optional[str]:
    parts = blob_name.split("/")
    if len(parts) >= 3 and parts[0] == "transcripts" and parts[2] == "current.json":
        return parts[1]
    return None


def _update_blob_metadata(blob_name: str, user_id: str, media_key: Optional[str] = None,
                          parent_media_key: Optional[str] = None, dry_run: bool = True) -> bool:
    bucket = storage_client.bucket(BUCKET_NAME)
    blob = bucket.blob(blob_name)
    if not blob.exists():
        logger.warning("Blob not found: %s", blob_name)
        return False

    blob.reload()
    metadata = blob.metadata or {}
    updates = {}

    if user_id and metadata.get("user_id") != user_id:
        updates["user_id"] = user_id
    if media_key and metadata.get("media_key") != media_key:
        updates["media_key"] = media_key
    if parent_media_key and metadata.get("parent_media_key") != parent_media_key:
        updates["parent_media_key"] = parent_media_key

    if not updates:
        return False

    logger.info("Updating %s metadata: %s", blob_name, updates)
    if not dry_run:
        metadata.update(updates)
        blob.metadata = metadata
        blob.patch()
    return True


def backfill_media_metadata(dry_run: bool = True, limit: Optional[int] = None) -> int:
    bucket = storage_client.bucket(BUCKET_NAME)
    updated = 0
    processed = 0

    for blob in bucket.list_blobs(prefix="transcripts/"):
        if not blob.name.endswith("/current.json"):
            continue
        processed += 1
        if limit and processed > limit:
            break

        try:
            data = json.loads(blob.download_as_string())
        except Exception:
            logger.warning("Failed to parse transcript payload: %s", blob.name)
            continue

        user_id = data.get("user_id")
        if not user_id:
            logger.warning("Skipping transcript without user_id: %s", blob.name)
            continue

        media_key = data.get("media_key") or _derive_media_key_from_path(blob.name)

        media_blob_name = data.get("media_blob_name")
        if media_blob_name:
            if _update_blob_metadata(media_blob_name, user_id, media_key=media_key, dry_run=dry_run):
                updated += 1

        for clip in data.get("clips") or []:
            clip_blob = clip.get("media_blob_name")
            if clip_blob:
                if _update_blob_metadata(
                    clip_blob,
                    user_id,
                    parent_media_key=media_key,
                    dry_run=dry_run,
                ):
                    updated += 1

    logger.info("Processed %d transcripts; updated %d media blobs.", processed, updated)
    return updated


def main():
    parser = argparse.ArgumentParser(description="Backfill user_id metadata for media blobs.")
    parser.add_argument("--apply", action="store_true", help="Apply changes (default is dry run).")
    parser.add_argument("--limit", type=int, default=None, help="Limit number of transcripts to scan.")
    args = parser.parse_args()

    logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")
    dry_run = not args.apply
    if dry_run:
        logger.info("Dry run mode. Use --apply to persist changes.")
    backfill_media_metadata(dry_run=dry_run, limit=args.limit)


if __name__ == "__main__":
    main()
===== END FILE =====

===== FILE: scripts/export_codebase.py =====
#!/usr/bin/env python3
import argparse
import subprocess
import sys
from pathlib import Path
from typing import Iterable, List, Optional, Set


REPO_ROOT = Path(__file__).resolve().parents[1]

EXCLUDE_DIR_NAMES = {
    ".git",
    ".idea",
    ".next",
    ".pytest_cache",
    ".venv",
    ".vscode",
    "__pycache__",
    "node_modules",
    "out",
}
EXCLUDE_FILE_NAMES = {
    ".DS_Store",
    "Nielsen, Martin 2019-07-23.xml",
}
EXCLUDE_RELATIVE_PATHS = {
    "clip_template.docx",
    "transcript_template.docx",
    "frontend-next/public/icon-192.png",
    "frontend-next/public/icon-512.png",
}


PART_SPECS = {
    "transcriber": [
        "backend/api/transcripts.py",
        "backend/transcriber.py",
        "backend/gemini.py",
        "backend/transcript_formatting.py",
        "backend/transcript_utils.py",
        "backend/models.py",
        "backend/media_processing.py",
        "backend/rev_ai_sync.py",
        "frontend-next/src/components/TranscribeForm.tsx",
        "frontend-next/src/utils/auth.ts",
    ],
    "editor": [
        "backend/api/transcripts.py",
        "backend/rev_ai_sync.py",
        "backend/transcript_formatting.py",
        "backend/transcript_utils.py",
        "backend/storage.py",
        "backend/models.py",
        "frontend-next/src/components/TranscriptEditor.tsx",
        "frontend-next/src/components/TranscribeForm.tsx",
        "frontend-next/src/utils/auth.ts",
    ],
    "clip_creator": [
        "backend/api/clips.py",
        "backend/api/media.py",
        "backend/media_processing.py",
        "backend/transcript_formatting.py",
        "backend/transcript_utils.py",
        "backend/storage.py",
        "backend/models.py",
        "frontend-next/src/components/ClipCreator.tsx",
        "frontend-next/src/components/TranscribeForm.tsx",
        "frontend-next/src/utils/auth.ts",
    ],
}


def run_git(args: List[str], *, check: bool = True, input_text: Optional[str] = None) -> subprocess.CompletedProcess[str]:
    return subprocess.run(
        ["git", "-C", str(REPO_ROOT), *args],
        check=check,
        capture_output=True,
        text=True,
        input=input_text,
    )


def load_origin_main_paths() -> Set[str]:
    try:
        result = run_git(["ls-tree", "-r", "--name-only", "origin/main"])
    except subprocess.CalledProcessError as exc:
        stderr = (exc.stderr or "").strip()
        message = "Failed to list files from origin/main."
        if stderr:
            message = f"{message} {stderr}"
        raise RuntimeError(message) from exc
    return {line.strip() for line in result.stdout.splitlines() if line.strip()}


def find_git_ignored_paths(paths: Iterable[str]) -> Set[str]:
    path_list = [path for path in paths if path]
    if not path_list:
        return set()
    input_text = "".join(f"{path}\n" for path in path_list)
    result = run_git(["check-ignore", "--stdin", "--no-index"], check=False, input_text=input_text)
    if result.returncode not in {0, 1}:
        stderr = (result.stderr or "").strip()
        message = "Failed to evaluate .gitignore patterns."
        if stderr:
            message = f"{message} {stderr}"
        raise RuntimeError(message)
    return {line.strip() for line in result.stdout.splitlines() if line.strip()}


def filter_files_by_git_rules(files: Iterable[Path]) -> List[Path]:
    origin_main_paths = load_origin_main_paths()
    rel_path_to_file: dict[str, Path] = {}
    for path in files:
        rel_path_to_file[path.relative_to(REPO_ROOT).as_posix()] = path
    ignored_paths = find_git_ignored_paths(rel_path_to_file.keys())
    filtered = [
        path
        for rel_path, path in rel_path_to_file.items()
        if rel_path in origin_main_paths and rel_path not in ignored_paths
    ]
    return sorted(filtered, key=lambda path: path.relative_to(REPO_ROOT).as_posix())


def is_binary_bytes(data: bytes) -> bool:
    if b"\x00" in data:
        return True
    sample = data[:4096]
    if not sample:
        return False
    text_chars = set(b"\n\r\t\f\b")
    text_chars.update(range(0x20, 0x7F))
    non_text = sum(1 for b in sample if b not in text_chars)
    return non_text / len(sample) > 0.3


def should_exclude(path: Path) -> bool:
    rel_path = path.relative_to(REPO_ROOT).as_posix()
    if rel_path in EXCLUDE_RELATIVE_PATHS:
        return True
    if path.name in EXCLUDE_FILE_NAMES:
        return True
    for part in Path(rel_path).parts:
        if part in EXCLUDE_DIR_NAMES:
            return True
    return False


def iter_files_under(root: Path) -> Iterable[Path]:
    for path in root.rglob("*"):
        if not path.is_file():
            continue
        if should_exclude(path):
            continue
        yield path


def expand_specs(specs: Iterable[str]) -> List[Path]:
    files: Set[Path] = set()
    for spec in specs:
        candidate = (REPO_ROOT / spec).resolve()
        if any(ch in spec for ch in "*?["):
            for match in REPO_ROOT.glob(spec):
                if match.is_file() and not should_exclude(match):
                    files.add(match)
                elif match.is_dir():
                    files.update(iter_files_under(match))
            continue
        if candidate.is_dir():
            files.update(iter_files_under(candidate))
        elif candidate.is_file() and not should_exclude(candidate):
            files.add(candidate)
    return sorted(files, key=lambda path: path.relative_to(REPO_ROOT).as_posix())


def collect_files(args: argparse.Namespace, output_path: Path) -> List[Path]:
    files: Set[Path] = set()

    if args.backend:
        files.update(iter_files_under(REPO_ROOT / "backend"))
        main_py = REPO_ROOT / "main.py"
        if main_py.exists():
            files.add(main_py)
    if args.frontend:
        files.update(iter_files_under(REPO_ROOT / "frontend-next"))
    if args.transcriber:
        files.update(expand_specs(PART_SPECS["transcriber"]))
    if args.editor:
        files.update(expand_specs(PART_SPECS["editor"]))
    if args.clip_creator:
        files.update(expand_specs(PART_SPECS["clip_creator"]))

    if not any((args.backend, args.frontend, args.transcriber, args.editor, args.clip_creator)):
        files.update(iter_files_under(REPO_ROOT))
        main_py = REPO_ROOT / "main.py"
        if main_py.exists():
            files.add(main_py)

    files = {path for path in files if path.resolve() != output_path.resolve()}
    return filter_files_by_git_rules(files)


def write_export(output_path: Path, files: List[Path]) -> int:
    output_path.parent.mkdir(parents=True, exist_ok=True)
    total_chars = 0
    with output_path.open("w", encoding="utf-8", newline="\n") as handle:
        def write_chunk(text: str) -> None:
            nonlocal total_chars
            handle.write(text)
            total_chars += len(text)

        for path in files:
            rel_path = path.relative_to(REPO_ROOT).as_posix()
            write_chunk(f"===== FILE: {rel_path} =====\n")
            try:
                data = path.read_bytes()
            except OSError as exc:
                write_chunk(f"[unreadable file: {exc}]\n")
                write_chunk("===== END FILE =====\n\n")
                continue
            if is_binary_bytes(data):
                write_chunk("[binary file omitted]\n")
                write_chunk("===== END FILE =====\n\n")
                continue
            text = data.decode("utf-8", errors="replace")
            write_chunk(text)
            if not text.endswith("\n"):
                write_chunk("\n")
            write_chunk("===== END FILE =====\n\n")
    return total_chars


def build_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(
        description="Export TranscribeAlpha source files into a single plain text file.",
    )
    parser.add_argument(
        "--output",
        default=str(REPO_ROOT / "codebase_export.txt"),
        help="Output file path (default: %(default)s)",
    )
    parser.add_argument("--backend", action="store_true", help="Include backend sources (plus main.py).")
    parser.add_argument("--frontend", action="store_true", help="Include frontend sources.")
    parser.add_argument("--transcriber", action="store_true", help="Include transcriber-related files (backend + frontend).")
    parser.add_argument("--editor", action="store_true", help="Include editor-related files (backend + frontend).")
    parser.add_argument(
        "--clip-creator",
        "--clip_creator",
        dest="clip_creator",
        action="store_true",
        help="Include clip creator-related files (backend + frontend).",
    )
    return parser


def main() -> int:
    parser = build_parser()
    args = parser.parse_args()
    output_path = Path(args.output).expanduser()

    try:
        files = collect_files(args, output_path)
    except RuntimeError as exc:
        print(str(exc), file=sys.stderr)
        return 1
    if not files:
        print("No files matched the selected filters.", file=sys.stderr)
        return 1

    total_chars = write_export(output_path, files)
    token_estimate = (total_chars + 3) // 4
    rel_output = output_path
    try:
        rel_output = output_path.relative_to(REPO_ROOT)
    except ValueError:
        pass
    print(f"Wrote {len(files)} files to {rel_output}")
    print(f"Characters: {total_chars:,}")
    print(f"Estimated tokens (4 chars/token): {token_estimate:,}")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
===== END FILE =====

===== FILE: scripts/list_users.sh =====
#!/bin/bash
#
# List all TranscribeAlpha users
# Usage: ./scripts/list_users.sh
#

SECRET_NAME="transcribealpha-users"

# Check if gcloud is available and logged in
if ! gcloud auth print-identity-token &> /dev/null 2>&1; then
    echo "Error: Not logged in to gcloud. Run: gcloud auth login"
    exit 1
fi

echo "TranscribeAlpha Users"
echo "====================="
echo ""

gcloud secrets versions access latest --secret="$SECRET_NAME" 2>/dev/null | python3 -c "
import sys, json
data = json.load(sys.stdin)
users = data.get('users', [])
if not users:
    print('No users found.')
else:
    for u in users:
        role = u.get('role', 'user')
        created = u.get('created_at', 'unknown')[:10]
        print(f\"  {u['username']:20} role: {role:8} created: {created}\")
    print()
    print(f'Total: {len(users)} user(s)')
"
===== END FILE =====

===== FILE: scripts/remove_user.sh =====
#!/bin/bash
#
# Remove a user from TranscribeAlpha
# Usage: ./scripts/remove_user.sh <username>
#
# Note: This removes the user's login but their transcripts remain in storage.
#

set -e

SECRET_NAME="transcribealpha-users"

RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m'

if [ $# -lt 1 ]; then
    echo -e "${RED}Usage: $0 <username>${NC}"
    exit 1
fi

USERNAME="$1"

echo -e "${YELLOW}Removing user: ${USERNAME}${NC}"

# Check gcloud
if ! gcloud auth print-identity-token &> /dev/null 2>&1; then
    echo -e "${RED}Error: Not logged in to gcloud. Run: gcloud auth login${NC}"
    exit 1
fi

# Get current users
CURRENT_USERS=$(gcloud secrets versions access latest --secret="$SECRET_NAME" 2>/dev/null)

# Check if user exists
if ! echo "$CURRENT_USERS" | python3 -c "import sys, json; users = json.load(sys.stdin); exit(0 if any(u['username'] == '$USERNAME' for u in users.get('users', [])) else 1)" 2>/dev/null; then
    echo -e "${RED}Error: User '$USERNAME' not found${NC}"
    exit 1
fi

# Confirm
echo -e "${YELLOW}Are you sure you want to remove '$USERNAME'? (y/N)${NC}"
read -r CONFIRM
if [ "$CONFIRM" != "y" ] && [ "$CONFIRM" != "Y" ]; then
    echo "Cancelled."
    exit 0
fi

# Remove user
NEW_USERS=$(echo "$CURRENT_USERS" | python3 -c "
import sys, json
data = json.load(sys.stdin)
data['users'] = [u for u in data['users'] if u['username'] != '$USERNAME']
print(json.dumps(data, indent=2))
")

# Upload
TEMP_FILE=$(mktemp)
echo "$NEW_USERS" > "$TEMP_FILE"
gcloud secrets versions add "$SECRET_NAME" --data-file="$TEMP_FILE" --quiet
rm -f "$TEMP_FILE"

echo ""
echo -e "${GREEN}User '$USERNAME' removed successfully!${NC}"
echo ""
echo "Note: Their transcripts remain in Cloud Storage."
===== END FILE =====

