===== FILE: .claude/settings.local.json =====
{
  "permissions": {
    "allow": [
      "Bash(git fetch:*)",
      "Bash(git pull:*)",
      "Bash(find:*)",
      "Bash(python3:*)",
      "Bash(pip3 install:*)",
      "WebSearch",
      "WebFetch(domain:ai.google.dev)",
      "Bash(npm run build:*)",
      "Bash(git add:*)",
      "Bash(git commit -m \"$(cat <<''EOF''\nAdd Gemini 3.0 Pro as alternative transcription engine with model selector\n\n- Add transcription_model parameter to /api/transcribe endpoint (assemblyai|gemini)\n- Implement transcribe_with_gemini function for direct Gemini transcription\n- Add thinking_config with thinking_level=\"low\" to both:\n  - New Gemini transcription feature\n  - Existing Gemini polish/refine feature\n- Add model selector dropdown to TranscribeForm UI\n- Update cache key to include model selection\n- Dynamic info panel shows selected model description\n\nðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)\n\nCo-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>\nEOF\n)\")",
      "Bash(git push:*)",
      "Bash(git commit:*)",
      "Bash(gcloud run logs read:*)",
      "Bash(gcloud run services logs read:*)",
      "Bash(gcloud logging read:*)",
      "Bash(gcloud config get-value:*)",
      "Bash(gcloud run services describe:*)",
      "Bash(curl:*)",
      "Bash(gcloud builds list:*)",
      "Bash(gcloud run revisions list:*)",
      "WebFetch(domain:docs.rev.ai)"
    ],
    "deny": [],
    "ask": []
  }
}
===== END FILE =====

===== FILE: .dockerignore =====
node_modules
.next
.git
.gitignore
README.md
frontend-next/node_modules
frontend-next/.next
frontend-next/out
__pycache__
*.pyc
.env
.env.local
===== END FILE =====

===== FILE: .gcloudignore =====
# This file specifies files that are *not* uploaded to Google Cloud
# The rules in this file follow the same syntax as .gitignore

.git
.gitignore
README.md
.DS_Store
.vscode/
.pytest_cache/
__pycache__/
*.pyc
*.pyo
*.pyd
.Python
env/
venv/
.venv/
pip-log.txt
pip-delete-this-directory.txt
.tox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.log
.mypy_cache/
.dmypy.json
dmypy.json

# Railway specific files (not needed for Cloud Run)
railway.json
packages.txt
===== END FILE =====

===== FILE: .gitignore =====
.streamlit/
__pycache__/
.DS_Store

# Next.js
frontend-next/.next/
frontend-next/out/
frontend-next/node_modules/

# Environment variables
.env
.env.local
.env.production.local
.env.development.local

# Secrets (never commit these!)
users.json
*.secret
*.pem

# Logs
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# Dependencies
node_modules/
===== END FILE =====

===== FILE: AGENTS.md =====
# AGENTS.md

Instructions for AI coding agents (Claude Code, Cursor, Copilot, etc.) working on this repository.

## Project Overview

**TranscribeAlpha** is a legal transcript generation web application that converts audio/video files into professionally formatted legal transcripts.

| Component | Technology |
|-----------|------------|
| Backend | FastAPI (Python 3.x) |
| Frontend | Next.js 14 + TypeScript + Tailwind CSS |
| Transcription | AssemblyAI (slam-1) or Gemini 3.0 Pro |
| Timestamp Alignment | Rev AI Forced Alignment API |
| Deployment | Google Cloud Run + Cloud Storage |
| HTTP Server | Hypercorn (HTTP/2 support) |

## Codebase Architecture

```
TranscribeAlpha/
â”œâ”€â”€ backend/                    # Python backend (FastAPI)
â”‚   â”œâ”€â”€ server.py              # FastAPI app wiring (routers, middleware, static files)
â”‚   â”œâ”€â”€ config.py              # Env-driven constants (CORS, TTLs, defaults)
â”‚   â”œâ”€â”€ models.py              # Pydantic models (TranscriptTurn, WordTimestamp, Gemini structs)
â”‚   â”œâ”€â”€ transcript_formatting.py # DOCX/XML generation + line timing helpers
â”‚   â”œâ”€â”€ transcript_utils.py    # Session serialization + line normalization helpers
â”‚   â”œâ”€â”€ storage.py             # Cloud Storage ops + snapshots/sessions persistence
â”‚   â”œâ”€â”€ media_processing.py    # ffmpeg helpers, clip extraction, audio prep
â”‚   â”œâ”€â”€ gemini.py              # Gemini transcription + refine flow
â”‚   â”œâ”€â”€ api/                   # FastAPI routers
â”‚   â”‚   â”œâ”€â”€ auth.py            # Auth endpoints
â”‚   â”‚   â”œâ”€â”€ transcripts.py     # Transcribe/import/save/resync endpoints
â”‚   â”‚   â”œâ”€â”€ media.py           # Media upload/streaming endpoints
â”‚   â”‚   â”œâ”€â”€ clips.py           # Clip creation/lookup endpoints
â”‚   â”‚   â””â”€â”€ health.py          # Health + cleanup endpoints
â”‚   â”œâ”€â”€ transcriber.py         # AssemblyAI integration + media probing
â”‚   â”œâ”€â”€ rev_ai_sync.py         # Rev AI forced alignment
â”‚   â”‚                          # - Re-sync transcript with audio after edits
â”‚   â”‚                          # - DOCX import alignment
â”‚   â”‚                          # - Word-level timestamp correction
â”‚   â”œâ”€â”€ auth.py                # JWT authentication
â”‚   â”‚                          # - Google Secret Manager integration
â”‚   â”‚                          # - User management
â”‚   â”œâ”€â”€ templates/             # Word document templates
â”‚   â””â”€â”€ requirements.txt       # Python dependencies
â”‚
â”œâ”€â”€ frontend-next/             # Next.js frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/               # App Router (layout, page)
â”‚   â”‚   â”œâ”€â”€ components/        # React components
â”‚   â”‚   â”‚   â”œâ”€â”€ TranscribeForm.tsx    # Main upload/transcribe UI
â”‚   â”‚   â”‚   â”œâ”€â”€ TranscriptEditor.tsx  # Line-by-line editor
â”‚   â”‚   â”‚   â”œâ”€â”€ ClipCreator.tsx       # Video clip extraction
â”‚   â”‚   â”‚   â”œâ”€â”€ AuthProvider.tsx      # Auth context
â”‚   â”‚   â”‚   â””â”€â”€ LoginModal.tsx        # Login UI
â”‚   â”‚   â””â”€â”€ utils/             # Utility functions
â”‚   â””â”€â”€ out/                   # Static export (production)
â”‚
â”œâ”€â”€ scripts/                   # Admin utility scripts
â”‚   â”œâ”€â”€ add_user.sh           # Add user to Secret Manager
â”‚   â”œâ”€â”€ list_users.sh         # List all users
â”‚   â””â”€â”€ remove_user.sh        # Remove user
â”‚
â”œâ”€â”€ main.py                    # Entry point (Hypercorn server)
â”œâ”€â”€ Dockerfile                 # Multi-stage build
â”œâ”€â”€ cloudbuild.yaml            # Cloud Build configuration
â””â”€â”€ AGENTS.md                  # This file
```

## Key Design Decisions

### Router-first HTTP layer
The HTTP layer is now organized around routers under `backend/api/`, with `backend/server.py`
kept intentionally thin to wire middleware, include routers, and mount the static frontend.

### Module Responsibilities

| Module | Responsibility | Should Contain |
|--------|----------------|----------------|
| `server.py` | HTTP app wiring | Router inclusion, middleware, startup cleanup, static mount |
| `backend/api/*.py` | HTTP layer | Endpoints and request/response handling |
| `transcriber.py` | Core transcription logic | AssemblyAI integration, media probing, transcription flow |
| `transcript_formatting.py` | Transcript rendering | DOCX/XML generation, line timing rules |
| `transcript_utils.py` | Transcript/session helpers | Line normalization, snapshot payloads, serialization |
| `storage.py` | Persistence layer | GCS ops, snapshots, session storage |
| `media_processing.py` | Media utilities | ffmpeg conversion, clip extraction, audio prep |
| `gemini.py` | Gemini flows | ASR and refinement logic |
| `rev_ai_sync.py` | Forced alignment | Rev AI API calls, timestamp correction |
| `auth.py` | Authentication | JWT, Secret Manager, user verification |

### Transcription Pipeline

The transcription flow uses ASR timestamps first, with optional Rev AI alignment later:

```
Audio/Video â†’ ASR (AssemblyAI or Gemini) â†’ DOCX/XML
                         â†˜ Rev AI Alignment (re-sync + DOCX import only)
```

1. **ASR Stage**: AssemblyAI or Gemini extracts text + word timestamps
2. **Artifact Generation**: DOCX and OnCue XML generated from ASR timestamps
3. **Alignment Stage (optional)**: Rev AI forced alignment re-syncs edited transcripts or aligns DOCX imports

If `REV_AI_API_KEY` is not configured, re-sync and DOCX import alignment are skipped.
The alignment step preserves original text (punctuation, capitalization) while only updating timestamps.

**Line timing rules**
- Generated line timestamps enforce a 1.25s minimum duration by expanding into adjacent gaps without overlap.
- User-edited line timings are preserved (minimum-duration enforcement is skipped during manual saves).

**Speaker label display**
- The editor shows a speaker label on every line for easy reassignment.
- DOCX/XML outputs collapse consecutive identical speakers by omitting repeated labels (via `is_continuation`).

### Import Pattern
The codebase uses a multi-context import pattern to work in different execution contexts:
```python
try:
    from .module import func  # Package import
except ImportError:
    try:
        from module import func  # Direct import
    except ImportError:
        import module
        func = module.func  # Fallback
```
**Do not simplify** this pattern - it's necessary for Cloud Run deployment.

## API Endpoints Reference

| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/api/transcribe` | POST | Main transcription (file â†’ DOCX + XML) |
| `/api/upload-preview` | POST | Upload media for preview |
| `/api/media/{file_id}` | GET | Stream media files |
| `/api/auth/login` | POST | User authentication |
| `/api/auth/refresh` | POST | Refresh access token |
| `/api/auth/logout` | POST | Logout (client deletes tokens) |
| `/api/auth/me` | GET | Current user info |
| `/api/transcripts` | GET | List transcripts for the current user |
| `/api/transcripts/by-key/{media_key}` | GET/PUT | Load/save transcript session |
| `/api/transcripts/by-key/{media_key}/history` | GET | List snapshots for a transcript |
| `/api/transcripts/by-key/{media_key}/restore/{snapshot_id}` | POST | Restore a snapshot |
| `/api/transcripts/import` | POST | Import XML/DOCX with media |
| `/api/transcripts/by-key/{media_key}/gemini-refine` | POST | Gemini refine pass |
| `/api/resync` | POST | Re-align transcript with audio (Rev AI) |
| `/api/clips/*` | Various | Clip creation/management |
| `/health` | GET | Health check + cleanup trigger |

## Development Guidelines

### Before Making Changes
1. **Read relevant files first** - Understand the existing code before modifying
2. **Check for existing patterns** - Follow established conventions
3. **Avoid over-engineering** - Only add what's explicitly needed

### Code Style
- **Python**: Follow existing patterns (logging, error handling)
- **TypeScript**: Use existing component structure
- **No unnecessary abstractions** - Direct code is preferred
- **No premature optimization** - Working code first

### What to Avoid
- Creating new modules without explicit request
- Adding features beyond what was asked
- Refactoring unrelated code during a fix
- Adding extensive comments to existing code
- Creating documentation files unless requested

### Safe Refactoring Checklist
Before any refactor, verify:
- [ ] All existing tests pass (if any)
- [ ] `/health` endpoint responds correctly
- [ ] File upload â†’ transcription flow works
- [ ] Editor save/load cycle works
- [ ] Media playback functions

## Environment Variables

| Variable | Required | Purpose |
|----------|----------|---------|
| `ASSEMBLYAI_API_KEY` | Yes* | AssemblyAI transcription |
| `GEMINI_API_KEY` | Yes* | Gemini transcription (alt: `GOOGLE_API_KEY`) |
| `REV_AI_API_KEY` | Recommended | Forced alignment for accurate timestamps |
| `JWT_SECRET_KEY` | For auth | Token signing |
| `GOOGLE_CLOUD_PROJECT` | For auth | Secret Manager access |
| `PORT` | No | Server port (default: 8080) |
| `ENVIRONMENT` | No | "production" for strict CORS |

*At least one transcription API key required (AssemblyAI or Gemini).

## Deployment

This app is designed for **Google Cloud Run only**.

```bash
# Deploy via Cloud Build (recommended)
gcloud builds submit --config cloudbuild.yaml \
  --substitutions=_ASSEMBLYAI_API_KEY=your_key

# Or direct deploy
gcloud run deploy transcribealpha \
  --source . \
  --platform managed \
  --region us-central1 \
  --port 8080 \
  --http2
```

## Common Tasks

### Add New API Endpoint
1. Add the route handler in the appropriate `backend/api/*.py` router
2. Use existing patterns for error handling
3. Add authentication if needed: `current_user: dict = Depends(get_current_user)`
4. If you add a new router module, include it in `backend/server.py`

### Modify Transcript Formatting
- Edit `backend/transcript_formatting.py`
- Functions: `create_docx()`, `generate_oncue_xml()`, `compute_transcript_line_entries()`

### Update Frontend Component
- Edit files in `frontend-next/src/components/`
- Run `npm run build` in `frontend-next/` to regenerate static output

### Add User Management Script
- See existing scripts in `scripts/` for pattern
- Use `gcloud secrets` for Secret Manager operations

## Troubleshooting

| Issue | Solution |
|-------|----------|
| 502 errors | Check ffmpeg installation, memory limits |
| Import errors | Verify Python path setup in deployment |
| CORS errors | Check `ENVIRONMENT` variable |
| Auth failures | Verify `JWT_SECRET_KEY` and Secret Manager access |
| Large file upload fails | Ensure HTTP/2 is enabled |

## Testing Checklist

After any change, verify:
1. `curl https://your-app.run.app/health` returns 200
2. File upload completes without error
3. Transcript download works (DOCX + XML)
4. Editor loads and saves correctly
5. Media playback functions
6. History modal shows snapshots after edits

---

*Last updated: 2025-12-30*
===== END FILE =====

===== FILE: AUTHENTICATION_IMPLEMENTATION_SUMMARY.md =====
# Authentication Implementation Summary

## What Was Implemented

A complete JWT-based authentication system with Google Secret Manager integration for secure user management.

---

## Key Features

### âœ… Backend Authentication
- **JWT token generation** with 8-hour access tokens and 30-day refresh tokens
- **Bcrypt password hashing** for secure credential storage
- **Google Secret Manager integration** for centralized user management
- **Protected API endpoints** - all transcript/clip endpoints require authentication
- **User isolation** - each user only sees their own transcripts

### âœ… Frontend Authentication
- **Login modal** with professional UI matching your design system
- **Automatic token refresh** - tokens refresh automatically before expiration
- **Sign out functionality** with session cleanup
- **User info display** - shows logged-in username in header
- **Persistent sessions** - tokens stored in localStorage

### âœ… Security Features
- **Password security**: Bcrypt hashing with salt (industry standard)
- **Token security**: Cryptographically signed JWTs with expiration
- **HTTPS enforcement**: Via Cloud Run TLS termination
- **CORS protection**: Production-only domain restrictions
- **Data isolation**: User-specific transcript access control

---

## Files Modified/Created

### Backend
- âœ… `backend/auth.py` - NEW: JWT/password management, Secret Manager client
- âœ… `backend/server.py` - MODIFIED: Added auth endpoints, protected routes, user_id tracking
- âœ… `requirements.txt` - MODIFIED: Added python-jose, passlib, google-cloud-secret-manager

### Frontend
- âœ… `frontend-next/src/components/LoginModal.tsx` - NEW: Login UI component
- âœ… `frontend-next/src/components/AuthProvider.tsx` - NEW: Authentication wrapper
- âœ… `frontend-next/src/utils/auth.ts` - NEW: Token management utilities
- âœ… `frontend-next/src/app/layout.tsx` - MODIFIED: Wrapped with AuthProvider
- âœ… `frontend-next/src/components/TranscribeForm.tsx` - MODIFIED: Added auth headers to all API calls
- âœ… `frontend-next/src/components/TranscriptEditor.tsx` - MODIFIED: Added auth headers to all API calls

### Deployment
- âœ… `cloudbuild.yaml` - MODIFIED: Added JWT_SECRET_KEY and GOOGLE_CLOUD_PROJECT env vars
- âœ… `scripts/migrate_existing_transcripts.py` - NEW: Migration script for existing data
- âœ… `AUTHENTICATION_SETUP.md` - NEW: Complete setup guide

---

## API Endpoints

### New Authentication Endpoints
- `POST /api/auth/login` - Authenticate and receive tokens
- `POST /api/auth/refresh` - Refresh access token
- `POST /api/auth/logout` - Logout (client-side token deletion)
- `GET /api/auth/me` - Get current user info

### Protected Endpoints (Now Require Authentication)
- `POST /api/transcribe` - Create new transcription
- `GET /api/transcripts` - List user's transcripts
- `GET /api/transcripts/by-key/{media_key}` - Get specific transcript
- `PUT /api/transcripts/by-key/{media_key}` - Save transcript
- `GET /api/transcripts/by-key/{media_key}/history` - List snapshots
- `POST /api/transcripts/by-key/{media_key}/restore/{snapshot_id}` - Restore snapshot
- `POST /api/transcripts/by-key/{media_key}/gemini-refine` - Gemini refinement
- `GET /api/transcripts/snapshots` - List all snapshots
- `POST /api/clips` - Create clip
- `GET /api/clips/{clip_id}` - Get clip
- `POST /api/transcripts/import` - Import OnCue XML
- `POST /api/upload-preview` - Upload media preview

### Unauthenticated Endpoints (Public)
- `GET /health` - Health check
- `GET /api/media/{file_id}` - Stream media files

---

## How It Works

### User Login Flow
1. User visits site â†’ sees login modal
2. Enters username/password â†’ POST to `/api/auth/login`
3. Backend validates credentials from Secret Manager
4. Backend returns access_token + refresh_token
5. Frontend stores tokens in localStorage
6. Frontend includes `Authorization: Bearer <token>` in all API requests

### Token Refresh Flow
1. Access token expires after 8 hours
2. Frontend detects expiration automatically
3. Frontend uses refresh_token to get new access_token
4. Refresh token valid for 30 days
5. If refresh fails, user is redirected to login

### Transcript Isolation Flow
1. User creates/uploads transcript â†’ `user_id` set from JWT
2. User requests transcript list â†’ filtered by their `user_id`
3. User tries to access other user's transcript â†’ 403 Forbidden error
4. Each user has completely separate history

---

## Configuration Requirements

### Cloud Build Trigger Substitutions
You need to set these in your Cloud Build trigger:

```yaml
_ASSEMBLYAI_API_KEY: "your-assemblyai-api-key"
_GEMINI_API_KEY: "your-gemini-api-key"
_GEMINI_MODEL_NAME: "models/gemini-3-pro-preview"
_JWT_SECRET_KEY: "your-generated-jwt-secret-key"  # NEW
```

### Google Secret Manager
Create a secret named `transcribealpha-users` with this structure:

```json
{
  "users": [
    {
      "username": "VerdictGroup",
      "password_hash": "$2b$12$...",
      "role": "admin",
      "created_at": "2025-12-04T00:00:00Z"
    },
    {
      "username": "Admin",
      "password_hash": "$2b$12$...",
      "role": "admin",
      "created_at": "2025-12-04T00:00:00Z"
    }
  ]
}
```

---

## Migration Strategy

### For Existing Transcripts
Run the migration script **once** to assign all existing transcripts to VerdictGroup:

```bash
# Dry run first to preview changes
python3 scripts/migrate_existing_transcripts.py --dry-run

# Apply migration
python3 scripts/migrate_existing_transcripts.py --user-id VerdictGroup
```

**Important**: This is a ONE-TIME operation. After migration:
- âœ… All existing transcripts â†’ belong to "VerdictGroup"
- âœ… New transcripts â†’ belong to whoever creates them
- âœ… Each user has separate history going forward

---

## User Management

### Adding Users (No Redeployment Required!)
1. Generate password hash: `python3 -c "from passlib.hash import bcrypt; print(bcrypt.hash('password'))"`
2. Update `users.json` with new user
3. Update Secret Manager: `gcloud secrets versions add transcribealpha-users --data-file=users.json`
4. Wait ~5 minutes for cache refresh (or restart Cloud Run)

### Changing Passwords (No Redeployment Required!)
1. Generate new hash
2. Update `users.json` for that user
3. Update Secret Manager

### Removing Users
1. Remove user from `users.json`
2. Update Secret Manager
3. Their transcripts remain in Cloud Storage but become inaccessible

---

## Testing Checklist

### Before Deployment
- [ ] Generate JWT_SECRET_KEY
- [ ] Generate password hashes for VerdictGroup and Admin
- [ ] Create users.json
- [ ] Set up Secret Manager
- [ ] Grant Cloud Run access to Secret Manager
- [ ] Update Cloud Build trigger with JWT_SECRET_KEY

### After Deployment
- [ ] Visit site - should show login screen
- [ ] Test VerdictGroup login - should succeed
- [ ] Test Admin login - should succeed
- [ ] Create transcript as VerdictGroup - should save
- [ ] Logout and login as Admin - should NOT see VerdictGroup's transcript
- [ ] Create transcript as Admin - should save
- [ ] Logout and login as VerdictGroup - should NOT see Admin's transcript
- [ ] Run migration script - existing transcripts assigned to VerdictGroup
- [ ] Login as VerdictGroup - should see all old + new transcripts

---

## Security Considerations

### âœ… Implemented
- Password hashing with bcrypt
- JWT token signing
- HTTPS via Cloud Run
- CORS restrictions in production
- User data isolation
- Automatic token expiration
- Secure secret storage (Secret Manager)

### âš ï¸ Future Enhancements (Optional)
- Rate limiting for login attempts
- Account lockout after failed attempts
- Email verification for new users
- Password reset functionality
- Multi-factor authentication (MFA)
- Session timeout after inactivity
- Audit logging of user actions

---

## Troubleshooting

### Login fails with "Incorrect username or password"
- Verify password hash is correct in Secret Manager
- Check Secret Manager permissions for Cloud Run service account
- Ensure GOOGLE_CLOUD_PROJECT is set correctly

### "Could not validate credentials" error
- Check JWT_SECRET_KEY is set in Cloud Build
- Verify tokens aren't expired (8-hour limit)
- Try logging out and back in

### Users see each other's transcripts
- Check user_id is being set correctly from JWT
- Verify backend is filtering by user_id
- Check migration script ran correctly

### Can't add/remove users
- Verify Secret Manager access
- Ensure users.json format is correct
- Wait 5 minutes for cache refresh

---

## Cost Impact

- **Secret Manager**: ~$0.06/month per secret (first 6 free)
- **Cloud Run**: No additional cost (same compute)
- **Total**: **~$0.00-$0.50/month**

---

## Summary

You now have a **production-ready authentication system** with:
- âœ… Secure login with bcrypt password hashing
- âœ… JWT tokens with automatic refresh
- âœ… Google Secret Manager for easy user management
- âœ… Complete user isolation (each user sees only their own transcripts)
- âœ… Migration path for existing data
- âœ… Professional UI/UX
- âœ… Zero-downtime user management

**Next step**: Follow `AUTHENTICATION_SETUP.md` to deploy!
===== END FILE =====

===== FILE: AUTHENTICATION_SETUP.md =====
# TranscribeAlpha Authentication - Admin Guide

Quick reference for managing user accounts. Users stay logged in permanently until they click "Sign Out".

---

## Initial Setup (One-Time)

### 1. Generate a JWT Secret Key

```bash
python3 -c "import secrets; print(secrets.token_urlsafe(64))"
```

Save this key - you'll need it for Cloud Build.

### 2. Create Password Hashes

```bash
pip install bcrypt

# For each user, run:
python3 -c "import bcrypt; print(bcrypt.hashpw('YOUR_PASSWORD_HERE'.encode(), bcrypt.gensalt()).decode())"
```

### 3. Create users.json

```json
{
  "users": [
    {
      "username": "VerdictGroup",
      "password_hash": "$2b$12$YOUR_HASH_HERE",
      "role": "admin",
      "created_at": "2025-01-01T00:00:00Z"
    },
    {
      "username": "Admin",
      "password_hash": "$2b$12$YOUR_HASH_HERE",
      "role": "admin",
      "created_at": "2025-01-01T00:00:00Z"
    }
  ]
}
```

### 4. Upload to Secret Manager

```bash
# Enable API (first time only)
gcloud services enable secretmanager.googleapis.com

# Create the secret
gcloud secrets create transcribealpha-users --data-file=users.json --replication-policy="automatic"

# Grant Cloud Run access (get project number first)
gcloud projects describe YOUR_PROJECT_ID --format="value(projectNumber)"

gcloud secrets add-iam-policy-binding transcribealpha-users \
  --member="serviceAccount:PROJECT_NUMBER-compute@developer.gserviceaccount.com" \
  --role="roles/secretmanager.secretAccessor"
```

### 5. Add JWT_SECRET_KEY to Cloud Build

Go to **Cloud Console** > **Cloud Build** > **Triggers** > Edit your trigger

Add substitution variable:
- `_JWT_SECRET_KEY`: (paste your generated key)

---

## Common Admin Tasks

### Add a New User

```bash
# 1. Generate password hash
python3 -c "import bcrypt; print(bcrypt.hashpw('new_password'.encode(), bcrypt.gensalt()).decode())"

# 2. Add to users.json
{
  "username": "NewUser",
  "password_hash": "$2b$12$NEW_HASH",
  "role": "user",
  "created_at": "2025-01-01T00:00:00Z"
}

# 3. Update Secret Manager
gcloud secrets versions add transcribealpha-users --data-file=users.json
```

Wait 5 minutes for cache to refresh (or redeploy).

### Change a Password

```bash
# 1. Generate new hash
python3 -c "import bcrypt; print(bcrypt.hashpw('new_password'.encode(), bcrypt.gensalt()).decode())"

# 2. Update the password_hash in users.json

# 3. Upload new version
gcloud secrets versions add transcribealpha-users --data-file=users.json
```

### Remove a User

1. Delete the user object from `users.json`
2. Run: `gcloud secrets versions add transcribealpha-users --data-file=users.json`

### View Current Users

```bash
gcloud secrets versions access latest --secret=transcribealpha-users
```

---

## Migrate Existing Transcripts

One-time migration to assign existing transcripts to a user:

```bash
# Preview changes
python3 scripts/migrate_existing_transcripts.py --dry-run

# Apply
python3 scripts/migrate_existing_transcripts.py --user-id VerdictGroup
```

---

## Troubleshooting

| Problem | Solution |
|---------|----------|
| "Incorrect username or password" | Verify hash is correct in Secret Manager |
| "Could not validate credentials" | Check JWT_SECRET_KEY in Cloud Build trigger |
| Users see each other's transcripts | Run migration script to set user_id |
| Changes not taking effect | Wait 5 min for cache, or redeploy |

---

## Quick Commands Reference

```bash
# Generate password hash
python3 -c "import bcrypt; print(bcrypt.hashpw('password'.encode(), bcrypt.gensalt()).decode())"

# Generate JWT secret
python3 -c "import secrets; print(secrets.token_urlsafe(64))"

# Update users secret
gcloud secrets versions add transcribealpha-users --data-file=users.json

# View users secret
gcloud secrets versions access latest --secret=transcribealpha-users

# Run migration
python3 scripts/migrate_existing_transcripts.py --user-id USERNAME
```
===== END FILE =====

===== FILE: Dockerfile =====
# Multi-stage build: Node.js for frontend, Python for backend
FROM node:18-alpine AS frontend-builder

# Build the Next.js frontend
WORKDIR /app/frontend-next
COPY frontend-next/package.json frontend-next/package-lock.json* ./
RUN npm install
COPY frontend-next/ .
RUN npm run build

# Python backend stage
FROM python:3.11-slim AS backend

# Set working directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    ffmpeg \
    libsndfile1-dev \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements first for better caching
COPY requirements.txt .

# Install Python dependencies
RUN pip install --no-cache-dir -r requirements.txt

# Copy the application code
COPY . .

# Copy the built frontend from the frontend-builder stage
COPY --from=frontend-builder /app/frontend-next/out ./frontend

# Expose the port that Cloud Run expects
EXPOSE 8080

# Set environment variables for Cloud Run
ENV PORT=8080
ENV HOST=0.0.0.0

# Run the application
CMD ["python", "main.py"]
===== END FILE =====

===== FILE: README.md =====
# TranscribeAlpha

A simple transcript generator powered by AssemblyAI. The original Streamlit prototype has been replaced with a small FastAPI backend and a static HTML front-end.

## Running Locally

1. Install system packages listed in `packages.txt` (ffmpeg and libsndfile1).
2. Install Python dependencies:

```bash
pip install -r requirements.txt
```

3. Export your AssemblyAI API key:

```bash
export ASSEMBLYAI_API_KEY="YOUR_ASSEMBLYAI_KEY_HERE"
```

4. Start the server:

```bash
uvicorn backend.server:app --reload
```

5. Open [http://localhost:8000](http://localhost:8000) in your browser and interact with the app.

## Notes

The backend relies on the [AssemblyAI Python SDK](https://github.com/AssemblyAI/assemblyai-python-sdk) for transcription and formatting.
- Transcriptions run on AssemblyAI's `slam-1` model to take advantage of its speaker-and-language-aware accuracy.

## File Size & Duration Limits

- Maximum upload size enforced by the backend: **2 GB** (requests larger than this return HTTP 413).
- Files larger than **100 MB** are automatically stored in **Google Cloud Storage** (`transcribealpha-uploads-1750110926`) before processing; Cloud Storage itself supports multiâ€‘terabyte objects, so it is not the limiting factor.
- Cloud Run's default 32 MB HTTP/1 request limit is bypassed via HTTP/2 and Cloud Storage, so the app-level 2 GB cap is the effective size limit.
- Maximum audio duration is effectively bounded by what AssemblyAI accepts for a single transcription job and by container resources; AssemblyAI supports multiâ€‘hour recordings, but for current hard limits you should refer to their docs: https://www.assemblyai.com/docs.
===== END FILE =====

===== FILE: ToDo.md =====
# ToDo.md

This file provides a list, sorted by category and not in any particular order, of desired features or improvements to be added to the transcription app. 

## Fixes
- Fix thing where it gives you cached transcript automatically for files that aren't the same
- Clean up codebase
- Fix errors with large video files
- Speed up functions that turn .json into DOCX/XML (optimize formatting pipeline)
- ~~**URGENT**: Replace temporary even-distribution timestamp interpolation strategy with more robust solution~~
  - **COMPLETED**: Implemented AssemblyAI integration with word-level timestamps
  - AssemblyAI now provides accurate per-line timing using word-level data
  - Gemini integration has been removed from the codebase

### Additional Features/Capabilities, Generally
- Devise internal transcription benchmark using a human-generated transcript and audio file
- Provide other methods to transcribe besides u.i; e.g. Box, DropBox, Zapier, Email integrations/automations
- Create cache/persistent storage of past transcripts, "history" page
- Batch processing?
- Make the UI look more professional
- Optional AI Summary

### Changes to Core Transcribing Functionality
- Remove need for Gemini vs AssemblyAI comparison (AssemblyAI is the sole engine)
- Improve OnCue transcript formatting
- ~~Delete option to enter number of lines per page~~
  - **COMPLETED**: Backend uses fixed 25 lines per page for OnCue XML
  - Frontend control removed to avoid user confusion
### Logistics, Deployment, Etc.
- Setup login system w/api key management, etc. 
- Figure out cost tracking

## Transcript Editor
- Create a transcript editor for both synced and unsynced transcripts, or else integrate with external editor and allow re-importing/re-syncing of oncue transcripts

## Sync Mode
- Create sync mode using forced allignment to produce OnCue transcripts from human-generated pdfs/docx. Ensure persistent formatting accross different styles, line numbering schema

## FFMPEG Clip Creator
- Features:
 - Clip by timestamp
 - Clip by transcript
    - Page/line numbers
    - 'when X said Y'
    - Highlight/select interface
 - Convert between formats, mute audio/separate, compress/reduce size 
===== END FILE =====

===== FILE: __init__.py =====
# This file makes the directory a Python package
===== END FILE =====

===== FILE: backend/__init__.py =====
# This file makes the backend directory a Python package
===== END FILE =====

===== FILE: backend/access_control.py =====
import json
import logging
from typing import Optional

from fastapi import Request

try:
    from .auth import decode_token
except ImportError:
    try:
        from auth import decode_token
    except ImportError:
        import auth as auth_module
        decode_token = auth_module.decode_token

try:
    from .storage import load_current_transcript, storage_client, BUCKET_NAME
except ImportError:
    try:
        from storage import load_current_transcript, storage_client, BUCKET_NAME
    except ImportError:
        import storage as storage_module
        load_current_transcript = storage_module.load_current_transcript
        storage_client = storage_module.storage_client
        BUCKET_NAME = storage_module.BUCKET_NAME

logger = logging.getLogger(__name__)


def _extract_token_from_request(request: Request) -> Optional[str]:
    auth_header = request.headers.get("authorization") or request.headers.get("Authorization")
    if auth_header:
        parts = auth_header.split()
        if len(parts) == 2 and parts[0].lower() == "bearer":
            return parts[1]
    token_param = request.query_params.get("token")
    return token_param or None


def _get_user_from_request(request: Request) -> Optional[dict]:
    token = _extract_token_from_request(request)
    if not token:
        return None
    payload = decode_token(token)
    if not payload or payload.get("type") != "access":
        return None
    username = payload.get("sub")
    if not username:
        return None
    return {
        "username": username,
        "role": payload.get("role", "user"),
        "user_id": username,
    }


def _user_can_access_media_blob(user_id: str, blob_name: str, metadata: Optional[dict]) -> bool:
    if metadata and metadata.get("user_id"):
        return metadata.get("user_id") == user_id

    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        for blob in bucket.list_blobs(prefix="transcripts/"):
            if not blob.name.endswith("/current.json"):
                continue
            try:
                data = json.loads(blob.download_as_string())
            except Exception:
                continue
            if data.get("user_id") != user_id:
                continue
            if data.get("media_blob_name") == blob_name:
                return True
            for clip in data.get("clips") or []:
                if clip.get("media_blob_name") == blob_name:
                    return True
        return False
    except Exception as exc:
        logger.warning("Failed to verify media ownership for %s: %s", blob_name, exc)
        return False


def _user_owns_media_key(media_key: str, user_id: str) -> bool:
    current = load_current_transcript(media_key)
    if current and current.get("user_id") == user_id:
        return True

    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        prefix = f"transcripts/{media_key}/history/"
        for blob in bucket.list_blobs(prefix=prefix):
            try:
                snapshot_data = json.loads(blob.download_as_string())
            except Exception:
                continue
            if snapshot_data.get("user_id") == user_id:
                return True
        return False
    except Exception as exc:
        logger.warning("Failed to verify transcript ownership for %s: %s", media_key, exc)
        return False
===== END FILE =====

===== FILE: backend/api/__init__.py =====
# API router package
===== END FILE =====

===== FILE: backend/api/auth.py =====
import logging
from typing import Dict

from fastapi import APIRouter, Body, Depends, HTTPException

try:
    from ..auth import (
        authenticate_user,
        create_access_token,
        create_refresh_token,
        get_current_user,
        decode_token,
    )
except ImportError:
    try:
        from auth import (
            authenticate_user,
            create_access_token,
            create_refresh_token,
            get_current_user,
            decode_token,
        )
    except ImportError:
        import auth as auth_module
        authenticate_user = auth_module.authenticate_user
        create_access_token = auth_module.create_access_token
        create_refresh_token = auth_module.create_refresh_token
        get_current_user = auth_module.get_current_user
        decode_token = auth_module.decode_token

router = APIRouter()
logger = logging.getLogger(__name__)


@router.post("/api/auth/login")
async def login(credentials: Dict = Body(...)):
    """
    Authenticate user and return access and refresh tokens.

    Request body:
    {
        "username": "string",
        "password": "string"
    }
    """
    username = credentials.get("username")
    password = credentials.get("password")

    if not username or not password:
        raise HTTPException(
            status_code=400,
            detail="Username and password are required"
        )

    user = authenticate_user(username, password)
    if not user:
        raise HTTPException(
            status_code=401,
            detail="Incorrect username or password",
            headers={"WWW-Authenticate": "Bearer"},
        )

    # Create tokens
    access_token = create_access_token(
        data={"sub": username, "role": user.get("role", "user")}
    )
    refresh_token = create_refresh_token(
        data={"sub": username, "role": user.get("role", "user")}
    )

    logger.info("User '%s' logged in successfully", username)

    return {
        "access_token": access_token,
        "refresh_token": refresh_token,
        "token_type": "bearer",
        "user": {
            "username": username,
            "role": user.get("role", "user"),
        },
    }


@router.post("/api/auth/refresh")
async def refresh_token(token_data: Dict = Body(...)):
    """
    Refresh access token using refresh token.

    Request body:
    {
        "refresh_token": "string"
    }
    """
    refresh_token_value = token_data.get("refresh_token")

    if not refresh_token_value:
        raise HTTPException(
            status_code=400,
            detail="Refresh token is required"
        )

    # Decode and validate refresh token
    payload = decode_token(refresh_token_value)

    if not payload or payload.get("type") != "refresh":
        raise HTTPException(
            status_code=401,
            detail="Invalid refresh token",
            headers={"WWW-Authenticate": "Bearer"},
        )

    username = payload.get("sub")
    if not username:
        raise HTTPException(
            status_code=401,
            detail="Invalid refresh token",
            headers={"WWW-Authenticate": "Bearer"},
        )

    # Create new access token
    access_token = create_access_token(
        data={"sub": username, "role": payload.get("role", "user")}
    )

    return {
        "access_token": access_token,
        "token_type": "bearer",
    }


@router.post("/api/auth/logout")
async def logout(current_user: dict = Depends(get_current_user)):
    """
    Logout endpoint (client should delete tokens).
    """
    logger.info("User '%s' logged out", current_user["username"])
    return {"message": "Successfully logged out"}


@router.get("/api/auth/me")
async def get_current_user_info(current_user: dict = Depends(get_current_user)):
    """Get current user information from token."""
    return {
        "username": current_user["username"],
        "role": current_user.get("role", "user"),
        "user_id": current_user["user_id"],
    }
===== END FILE =====

===== FILE: backend/api/clips.py =====
import base64
import uuid
from datetime import datetime, timedelta, timezone
from typing import Dict

from fastapi import APIRouter, Body, Depends, HTTPException
from fastapi.responses import JSONResponse

try:
    from ..auth import get_current_user
except ImportError:
    try:
        from auth import get_current_user
    except ImportError:
        import auth as auth_module
        get_current_user = auth_module.get_current_user

try:
    from ..config import CLIP_SESSION_TTL_DAYS, DEFAULT_LINES_PER_PAGE
except ImportError:
    try:
        from config import CLIP_SESSION_TTL_DAYS, DEFAULT_LINES_PER_PAGE
    except ImportError:
        import config as config_module
        CLIP_SESSION_TTL_DAYS = config_module.CLIP_SESSION_TTL_DAYS
        DEFAULT_LINES_PER_PAGE = config_module.DEFAULT_LINES_PER_PAGE

try:
    from ..media_processing import clip_media_segment
except ImportError:
    try:
        from media_processing import clip_media_segment
    except ImportError:
        import media_processing as media_processing_module
        clip_media_segment = media_processing_module.clip_media_segment

try:
    from ..storage import (
        delete_clip_session,
        load_clip_session,
        load_current_transcript,
        save_clip_session,
        save_current_transcript,
    )
except ImportError:
    try:
        from storage import (
            delete_clip_session,
            load_clip_session,
            load_current_transcript,
            save_clip_session,
            save_current_transcript,
        )
    except ImportError:
        import storage as storage_module
        delete_clip_session = storage_module.delete_clip_session
        load_clip_session = storage_module.load_clip_session
        load_current_transcript = storage_module.load_current_transcript
        save_clip_session = storage_module.save_clip_session
        save_current_transcript = storage_module.save_current_transcript

try:
    from ..transcript_utils import (
        build_session_artifacts,
        construct_turns_from_lines,
        ensure_session_clip_list,
        normalize_line_payloads,
        parse_timecode_to_seconds,
        resolve_line_index,
        sanitize_clip_label,
    )
except ImportError:
    try:
        from transcript_utils import (
            build_session_artifacts,
            construct_turns_from_lines,
            ensure_session_clip_list,
            normalize_line_payloads,
            parse_timecode_to_seconds,
            resolve_line_index,
            sanitize_clip_label,
        )
    except ImportError:
        import transcript_utils as transcript_utils_module
        build_session_artifacts = transcript_utils_module.build_session_artifacts
        construct_turns_from_lines = transcript_utils_module.construct_turns_from_lines
        ensure_session_clip_list = transcript_utils_module.ensure_session_clip_list
        normalize_line_payloads = transcript_utils_module.normalize_line_payloads
        parse_timecode_to_seconds = transcript_utils_module.parse_timecode_to_seconds
        resolve_line_index = transcript_utils_module.resolve_line_index
        sanitize_clip_label = transcript_utils_module.sanitize_clip_label

try:
    from ..transcript_formatting import create_clip_docx
except ImportError:
    try:
        from transcript_formatting import create_clip_docx
    except ImportError:
        import transcript_formatting as transcript_formatting_module
        create_clip_docx = transcript_formatting_module.create_clip_docx

router = APIRouter()


@router.post("/api/clips")
async def create_clip(payload: Dict = Body(...), current_user: dict = Depends(get_current_user)):
    media_key = payload.get("media_key")
    if not media_key:
        raise HTTPException(status_code=400, detail="media_key is required")

    session_data = load_current_transcript(media_key)
    if not session_data:
        raise HTTPException(status_code=404, detail="Transcript not found")
    if session_data.get("user_id") and session_data.get("user_id") != current_user["user_id"]:
        raise HTTPException(status_code=403, detail="Access denied to this transcript")

    lines = session_data.get("lines") or []
    if not lines:
        raise HTTPException(status_code=400, detail="Session does not contain transcript lines")

    # Resolve lines-per-page for the clip
    try:
        lines_per_page = int(payload.get("lines_per_page") or session_data.get("lines_per_page") or DEFAULT_LINES_PER_PAGE)
    except (TypeError, ValueError):
        lines_per_page = DEFAULT_LINES_PER_PAGE
    if lines_per_page <= 0:
        lines_per_page = DEFAULT_LINES_PER_PAGE

    # Accept page/line pairs if provided and derive pgln value for lookup
    start_pgln = payload.get("start_pgln")
    if start_pgln is None and payload.get("start_page") is not None and payload.get("start_line") is not None:
        try:
            start_pgln = int(payload["start_page"]) * 100 + int(payload["start_line"])
        except (TypeError, ValueError):
            start_pgln = None

    end_pgln = payload.get("end_pgln")
    if end_pgln is None and payload.get("end_page") is not None and payload.get("end_line") is not None:
        try:
            end_pgln = int(payload["end_page"]) * 100 + int(payload["end_line"])
        except (TypeError, ValueError):
            end_pgln = None

    start_time = parse_timecode_to_seconds(payload.get("start_time"))
    end_time = parse_timecode_to_seconds(payload.get("end_time"))

    start_index = resolve_line_index(
        lines,
        line_id=payload.get("start_line_id"),
        pgln=start_pgln,
        time_seconds=start_time,
        prefer_start=True,
    )
    if start_index is None:
        raise HTTPException(status_code=400, detail="Unable to resolve clip start line")

    end_index = resolve_line_index(
        lines,
        line_id=payload.get("end_line_id"),
        pgln=end_pgln,
        time_seconds=end_time,
        prefer_start=False,
    )
    if end_index is None:
        raise HTTPException(status_code=400, detail="Unable to resolve clip end line")

    if start_index > end_index:
        start_index, end_index = end_index, start_index

    selected_slice = lines[start_index : end_index + 1]
    if not selected_slice:
        raise HTTPException(status_code=400, detail="Selected clip range is empty")

    start_line = selected_slice[0]
    end_line = selected_slice[-1]

    start_absolute = float(start_line.get("start", 0.0) or 0.0)
    end_absolute = float(end_line.get("end", start_absolute) or start_absolute)

    if end_absolute <= start_absolute:
        end_absolute = start_absolute + 0.01

    rebased_lines = []
    for local_idx, original_line in enumerate(selected_slice):
        original_start = float(original_line.get("start", 0.0) or 0.0)
        original_end = float(original_line.get("end", original_start) or original_start)
        if original_end <= original_start:
            original_end = original_start + 0.01

        rebased_lines.append(
            {
                "id": f"clip-{local_idx}",
                "speaker": (str(original_line.get("speaker", "SPEAKER"))).strip().upper() or "SPEAKER",
                "text": str(original_line.get("text", "")),
                "start": max(original_start - start_absolute, 0.0),
                "end": max(original_end - start_absolute, 0.0),
                "is_continuation": False if local_idx == 0 else bool(original_line.get("is_continuation", False)),
            }
        )

    clip_duration_hint = max(end_absolute - start_absolute, 0.01)
    normalized_lines, normalized_duration = normalize_line_payloads(rebased_lines, clip_duration_hint)
    turns = construct_turns_from_lines(normalized_lines)
    if not turns:
        raise HTTPException(status_code=400, detail="Unable to construct transcript turns for clip")

    clip_count = len(ensure_session_clip_list(session_data))
    default_name = f"Clip {clip_count + 1}"
    clip_name = sanitize_clip_label(payload.get("clip_label"), default_name)

    clip_title_data = dict(session_data.get("title_data") or {})
    title_overrides = payload.get("title_overrides") if isinstance(payload.get("title_overrides"), dict) else {}
    for key, value in title_overrides.items():
        if value is not None:
            clip_title_data[key] = str(value)

    hours, remainder = divmod(normalized_duration, 3600)
    minutes, seconds = divmod(remainder, 60)
    clip_title_data["CLIP_DURATION"] = f"{int(hours):02d}:{int(minutes):02d}:{int(round(seconds)):02d}"
    clip_title_data["CLIP_TITLE"] = clip_name

    docx_bytes, oncue_xml, transcript_text, clip_line_entries = build_session_artifacts(
        turns,
        clip_title_data,
        normalized_duration,
        lines_per_page,
        enforce_min_line_duration=False,
    )
    docx_bytes = create_clip_docx(clip_title_data, turns, clip_name)

    docx_b64 = base64.b64encode(docx_bytes).decode()
    oncue_b64 = base64.b64encode(oncue_xml.encode("utf-8")).decode()

    clip_media_blob_name, clip_media_content_type = clip_media_segment(
        session_data.get("media_blob_name"),
        start_absolute,
        end_absolute,
        session_data.get("media_content_type"),
        clip_name,
        user_id=session_data.get("user_id"),
        parent_media_key=media_key,
    )

    clip_id = uuid.uuid4().hex
    created_at = datetime.now(timezone.utc)
    clip_expires_at = created_at + timedelta(days=CLIP_SESSION_TTL_DAYS)

    clip_data = {
        "clip_id": clip_id,
        "parent_media_key": media_key,
        "user_id": session_data.get("user_id"),
        "name": clip_name,
        "created_at": created_at.isoformat(),
        "expires_at": clip_expires_at.isoformat(),
        "duration": float(normalized_duration),
        "start_time": float(start_absolute),
        "end_time": float(end_absolute),
        "start_line_id": start_line.get("id"),
        "end_line_id": end_line.get("id"),
        "start_pgln": start_line.get("pgln"),
        "end_pgln": end_line.get("pgln"),
        "start_page": start_line.get("page"),
        "start_line_number": start_line.get("line"),
        "end_page": end_line.get("page"),
        "end_line_number": end_line.get("line"),
        "docx_base64": docx_b64,
        "oncue_xml_base64": oncue_b64,
        "transcript_text": transcript_text,
        "lines": clip_line_entries,
        "title_data": clip_title_data,
        "lines_per_page": lines_per_page,
        "media_blob_name": clip_media_blob_name,
        "media_content_type": clip_media_content_type,
    }

    clip_summary = {
        "clip_id": clip_id,
        "parent_media_key": media_key,
        "name": clip_name,
        "created_at": created_at.isoformat(),
        "duration": float(normalized_duration),
        "start_time": float(start_absolute),
        "end_time": float(end_absolute),
        "start_pgln": start_line.get("pgln"),
        "end_pgln": end_line.get("pgln"),
        "start_page": start_line.get("page"),
        "start_line": start_line.get("line"),
        "end_page": end_line.get("page"),
        "end_line": end_line.get("line"),
        "media_blob_name": clip_media_blob_name,
        "media_content_type": clip_media_content_type,
        "file_name": clip_title_data.get("FILE_NAME"),
    }

    try:
        save_clip_session(clip_id, clip_data)
    except Exception as exc:
        raise HTTPException(status_code=500, detail="Unable to persist clip data") from exc

    clips_list = ensure_session_clip_list(session_data)
    clips_list.append(clip_summary)

    session_data["updated_at"] = created_at.isoformat()
    session_data["media_key"] = media_key

    try:
        save_current_transcript(media_key, session_data)
    except Exception as exc:
        clips_list.pop()
        delete_clip_session(clip_id)
        raise HTTPException(status_code=500, detail="Unable to update session with clip metadata") from exc

    clip_response = dict(clip_data)
    clip_response.pop("parent_media_key", None)
    clip_response.pop("user_id", None)
    clip_response["transcript"] = clip_response.pop("transcript_text", "")
    clip_response["summary"] = clip_summary

    return JSONResponse({
        "clip": clip_response,
        "transcript": session_data,
    })


@router.get("/api/clips/{clip_id}")
async def get_clip_session(clip_id: str, current_user: dict = Depends(get_current_user)):
    clip_data = load_clip_session(clip_id)
    if not clip_data:
        raise HTTPException(status_code=404, detail="Clip session not found")

    if clip_data.get("user_id") and clip_data.get("user_id") != current_user["user_id"]:
        raise HTTPException(status_code=403, detail="Access denied to this clip")

    expires_at = clip_data.get("expires_at")
    if expires_at:
        try:
            expires_dt = datetime.fromisoformat(expires_at)
        except ValueError:
            try:
                expires_dt = datetime.fromisoformat(expires_at.replace("Z", "+00:00"))
            except ValueError:
                expires_dt = None
        if expires_dt and expires_dt < datetime.now(timezone.utc):
            delete_clip_session(clip_id)
            raise HTTPException(status_code=404, detail="Clip session expired")

    response_payload = dict(clip_data)
    response_payload.pop("user_id", None)
    response_payload["transcript"] = response_payload.pop("transcript_text", "")
    return JSONResponse(response_payload)
===== END FILE =====

===== FILE: backend/api/health.py =====
import logging
import os
from datetime import datetime, timedelta

from fastapi import APIRouter

try:
    from ..storage import cleanup_expired_clip_sessions, cleanup_old_files
except ImportError:
    try:
        from storage import cleanup_expired_clip_sessions, cleanup_old_files
    except ImportError:
        import storage as storage_module
        cleanup_expired_clip_sessions = storage_module.cleanup_expired_clip_sessions
        cleanup_old_files = storage_module.cleanup_old_files

router = APIRouter()
logger = logging.getLogger(__name__)

# Track last cleanup time for periodic cleanup
last_cleanup_time = datetime.now()


@router.get("/health")
async def health_check():
    """Health check endpoint for deployment platforms"""
    global last_cleanup_time

    # Run cleanup every 12 hours
    current_time = datetime.now()
    if current_time - last_cleanup_time > timedelta(hours=12):
        try:
            cleanup_old_files()
            cleanup_expired_clip_sessions()
            last_cleanup_time = current_time
            logger.info("Periodic cleanup completed via health check")
        except Exception as e:
            logger.error("Periodic cleanup failed: %s", str(e))

    return {
        "status": "healthy",
        "service": "TranscribeAlpha",
        "assemblyai_api_key_configured": bool(os.getenv("ASSEMBLYAI_API_KEY")),
        "last_cleanup": last_cleanup_time.isoformat(),
    }
===== END FILE =====

===== FILE: backend/api/media.py =====
import logging
import os
import mimetypes
import re
from typing import Optional

from fastapi import APIRouter, Depends, File, HTTPException, Request, UploadFile
from fastapi.responses import JSONResponse, StreamingResponse

try:
    from ..auth import get_current_user
except ImportError:
    try:
        from auth import get_current_user
    except ImportError:
        import auth as auth_module
        get_current_user = auth_module.get_current_user

try:
    from ..access_control import _get_user_from_request, _user_can_access_media_blob
except ImportError:
    try:
        from access_control import _get_user_from_request, _user_can_access_media_blob
    except ImportError:
        import access_control as access_control_module
        _get_user_from_request = access_control_module._get_user_from_request
        _user_can_access_media_blob = access_control_module._user_can_access_media_blob

try:
    from ..storage import (
        get_blob_metadata,
        save_upload_to_tempfile,
        storage_client,
        BUCKET_NAME,
        upload_preview_file_to_cloud_storage_from_path,
    )
except ImportError:
    try:
        from storage import (
            get_blob_metadata,
            save_upload_to_tempfile,
            storage_client,
            BUCKET_NAME,
            upload_preview_file_to_cloud_storage_from_path,
        )
    except ImportError:
        import storage as storage_module
        get_blob_metadata = storage_module.get_blob_metadata
        save_upload_to_tempfile = storage_module.save_upload_to_tempfile
        storage_client = storage_module.storage_client
        BUCKET_NAME = storage_module.BUCKET_NAME
        upload_preview_file_to_cloud_storage_from_path = storage_module.upload_preview_file_to_cloud_storage_from_path

router = APIRouter()
logger = logging.getLogger(__name__)


@router.post("/api/upload-preview")
async def upload_media_preview(file: UploadFile = File(...), current_user: dict = Depends(get_current_user)):
    """Upload media file for preview purposes"""
    temp_path = None
    try:
        temp_path, file_size = await save_upload_to_tempfile(file)
        if not temp_path or file_size == 0:
            raise HTTPException(status_code=400, detail="Uploaded media file is empty")

        content_type = file.content_type or mimetypes.guess_type(file.filename)[0]

        blob_name = upload_preview_file_to_cloud_storage_from_path(
            temp_path,
            file.filename,
            content_type,
            user_id=current_user["user_id"],
        )

        logger.info("Uploaded media file for preview: %s (%d bytes)", file.filename, file_size)

        return JSONResponse({
            "file_id": blob_name,
            "filename": file.filename,
            "size": file_size,
            "content_type": content_type,
        })

    except HTTPException:
        raise
    except Exception as e:
        logger.error("Media preview upload failed: %s", str(e))
        raise HTTPException(status_code=500, detail=f"Upload failed: {str(e)}")
    finally:
        if temp_path:
            try:
                os.remove(temp_path)
            except OSError:
                pass


@router.get("/api/media/{file_id}")
async def serve_media_file(file_id: str, request: Request):
    """Serve media file for preview"""
    try:
        request_user = _get_user_from_request(request)
        if not request_user:
            raise HTTPException(status_code=401, detail="Authentication required")

        metadata = get_blob_metadata(file_id)
        if not metadata:
            raise HTTPException(status_code=404, detail="Media file not found")

        if not _user_can_access_media_blob(request_user["user_id"], file_id, metadata):
            raise HTTPException(status_code=403, detail="Access denied to media file")

        bucket = storage_client.bucket(BUCKET_NAME)
        blob = bucket.blob(file_id)
        if not blob.exists():
            raise HTTPException(status_code=404, detail="Media file not found")

        blob.reload()
        file_size = metadata.get("size") or blob.size or 0
        logger.info("Serving media %s: size=%s, content_type=%s", file_id, file_size, metadata.get("content_type"))
        content_type = metadata.get("content_type", "application/octet-stream")

        range_header = request.headers.get("range")
        start = 0
        end = file_size - 1 if file_size else None
        status_code = 200
        headers = {
            "Accept-Ranges": "bytes",
            "Cache-Control": "public, max-age=3600",
        }

        if range_header and file_size:
            range_match = re.match(r"bytes=(\d*)-(\d*)", range_header)
            if range_match:
                if range_match.group(1):
                    start = int(range_match.group(1))
                if range_match.group(2):
                    end = int(range_match.group(2))
                if end is None or end >= file_size:
                    end = file_size - 1
                if start > end:
                    raise HTTPException(status_code=416, detail="Invalid range header")

                status_code = 206
                headers["Content-Range"] = f"bytes {start}-{end}/{file_size}"
                headers["Content-Length"] = str(end - start + 1)
            else:
                logger.warning("Invalid range header received: %s", range_header)

        elif file_size:
            headers["Content-Length"] = str(file_size)

        def iter_chunks(start_pos: int, end_pos: Optional[int]):
            chunk_size = 1024 * 1024  # 1MB chunks
            bytes_remaining = (end_pos - start_pos + 1) if end_pos is not None else None
            with blob.open("rb") as stream:
                if start_pos:
                    stream.seek(start_pos)
                while True:
                    read_size = chunk_size if bytes_remaining is None else min(chunk_size, bytes_remaining)
                    if read_size <= 0:
                        break
                    data = stream.read(read_size)
                    if not data:
                        break
                    yield data
                    if bytes_remaining is not None:
                        bytes_remaining -= len(data)
                        if bytes_remaining <= 0:
                            break

        return StreamingResponse(
            iter_chunks(start, end),
            media_type=content_type,
            status_code=status_code,
            headers=headers,
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error("Error serving media file %s: %s", file_id, str(e))
        raise HTTPException(status_code=500, detail="Error serving media file")
===== END FILE =====

===== FILE: backend/api/transcripts.py =====
import base64
import json
import logging
import mimetypes
import os
import tempfile
import time
import uuid
from datetime import datetime, timezone
from typing import Dict, List, Optional

import anyio
from fastapi import APIRouter, Body, Depends, File, Form, HTTPException, Request, UploadFile
from fastapi.responses import JSONResponse

try:
    from ..access_control import _user_owns_media_key
except ImportError:
    try:
        from access_control import _user_owns_media_key
    except ImportError:
        import access_control as access_control_module
        _user_owns_media_key = access_control_module._user_owns_media_key

try:
    from ..auth import get_current_user
except ImportError:
    try:
        from auth import get_current_user
    except ImportError:
        import auth as auth_module
        get_current_user = auth_module.get_current_user

try:
    from ..config import DEFAULT_LINES_PER_PAGE
except ImportError:
    try:
        from config import DEFAULT_LINES_PER_PAGE
    except ImportError:
        import config as config_module
        DEFAULT_LINES_PER_PAGE = config_module.DEFAULT_LINES_PER_PAGE

try:
    from ..gemini import run_gemini_edit, transcribe_with_gemini
except ImportError:
    try:
        from gemini import run_gemini_edit, transcribe_with_gemini
    except ImportError:
        import gemini as gemini_module
        run_gemini_edit = gemini_module.run_gemini_edit
        transcribe_with_gemini = gemini_module.transcribe_with_gemini

try:
    from ..media_processing import prepare_audio_for_gemini
except ImportError:
    try:
        from media_processing import prepare_audio_for_gemini
    except ImportError:
        import media_processing as media_processing_module
        prepare_audio_for_gemini = media_processing_module.prepare_audio_for_gemini

try:
    from ..models import TranscriptTurn
except ImportError:
    try:
        from models import TranscriptTurn
    except ImportError:
        import models as models_module
        TranscriptTurn = models_module.TranscriptTurn

try:
    from ..rev_ai_sync import RevAIAligner
except ImportError:
    try:
        from rev_ai_sync import RevAIAligner
    except ImportError:
        import rev_ai_sync as rev_ai_sync_module
        RevAIAligner = rev_ai_sync_module.RevAIAligner

try:
    from ..storage import (
        BUCKET_NAME,
        list_all_transcripts,
        load_current_transcript,
        prune_snapshots,
        save_current_transcript,
        save_upload_to_tempfile,
        storage_client,
        upload_preview_file_to_cloud_storage_from_path,
    )
except ImportError:
    try:
        from storage import (
            BUCKET_NAME,
            list_all_transcripts,
            load_current_transcript,
            prune_snapshots,
            save_current_transcript,
            save_upload_to_tempfile,
            storage_client,
            upload_preview_file_to_cloud_storage_from_path,
        )
    except ImportError:
        import storage as storage_module
        BUCKET_NAME = storage_module.BUCKET_NAME
        list_all_transcripts = storage_module.list_all_transcripts
        load_current_transcript = storage_module.load_current_transcript
        prune_snapshots = storage_module.prune_snapshots
        save_current_transcript = storage_module.save_current_transcript
        save_upload_to_tempfile = storage_module.save_upload_to_tempfile
        storage_client = storage_module.storage_client
        upload_preview_file_to_cloud_storage_from_path = storage_module.upload_preview_file_to_cloud_storage_from_path

try:
    from ..transcriber import (
        convert_video_to_audio,
        get_media_duration,
        process_transcription,
    )
except ImportError:
    try:
        from transcriber import (
            convert_video_to_audio,
            get_media_duration,
            process_transcription,
        )
    except ImportError:
        import transcriber as transcriber_module
        convert_video_to_audio = transcriber_module.convert_video_to_audio
        get_media_duration = transcriber_module.get_media_duration
        process_transcription = transcriber_module.process_transcription

try:
    from ..transcript_formatting import parse_docx_to_turns
except ImportError:
    try:
        from transcript_formatting import parse_docx_to_turns
    except ImportError:
        import transcript_formatting as transcript_formatting_module
        parse_docx_to_turns = transcript_formatting_module.parse_docx_to_turns

try:
    from ..transcript_utils import (
        build_session_artifacts,
        build_snapshot_payload,
        construct_turns_from_lines,
        normalize_line_payloads,
        parse_oncue_xml,
        serialize_transcript_turns,
    )
except ImportError:
    try:
        from transcript_utils import (
            build_session_artifacts,
            build_snapshot_payload,
            construct_turns_from_lines,
            normalize_line_payloads,
            parse_oncue_xml,
            serialize_transcript_turns,
        )
    except ImportError:
        import transcript_utils as transcript_utils_module
        build_session_artifacts = transcript_utils_module.build_session_artifacts
        build_snapshot_payload = transcript_utils_module.build_snapshot_payload
        construct_turns_from_lines = transcript_utils_module.construct_turns_from_lines
        normalize_line_payloads = transcript_utils_module.normalize_line_payloads
        parse_oncue_xml = transcript_utils_module.parse_oncue_xml
        serialize_transcript_turns = transcript_utils_module.serialize_transcript_turns

router = APIRouter()
logger = logging.getLogger(__name__)


@router.post("/api/transcribe")
async def transcribe(
    file: UploadFile = File(...),
    case_name: str = Form(""),
    case_number: str = Form(""),
    firm_name: str = Form(""),
    input_date: str = Form(""),
    input_time: str = Form(""),
    location: str = Form(""),
    speaker_names: Optional[str] = Form(None),
    transcription_model: str = Form("assemblyai"),
    current_user: dict = Depends(get_current_user),
):
    logger.info("Received transcription request for file: %s using model: %s", file.filename, transcription_model)

    # Validate model selection
    valid_models = {"assemblyai", "gemini"}
    if transcription_model not in valid_models:
        raise HTTPException(
            status_code=400,
            detail=f"Invalid transcription model. Must be one of: {', '.join(valid_models)}",
        )

    # Check for required API key based on model
    if transcription_model == "assemblyai":
        if not os.getenv("ASSEMBLYAI_API_KEY"):
            logger.error("ASSEMBLYAI_API_KEY environment variable not set")
            raise HTTPException(
                status_code=500,
                detail="Server configuration error: AssemblyAI API key not configured",
            )
    elif transcription_model == "gemini":
        if not (os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_API_KEY")):
            logger.error("GEMINI_API_KEY/GOOGLE_API_KEY environment variable not set")
            raise HTTPException(
                status_code=500,
                detail="Server configuration error: Gemini API key not configured",
            )

    temp_upload_path = None
    try:
        temp_upload_path, file_size = await save_upload_to_tempfile(file)
        logger.info("File size: %.2f MB", file_size / (1024 * 1024))

        # Increase limit to 2GB
        if file_size > 2 * 1024 * 1024 * 1024:
            raise HTTPException(status_code=413, detail="File too large. Maximum size is 2GB.")

        if not temp_upload_path:
            raise HTTPException(status_code=400, detail="Unable to read uploaded file")

        speaker_list: Optional[List[str]] = None
        if speaker_names:
            speaker_names = speaker_names.strip()
            if speaker_names.startswith('[') and speaker_names.endswith(']'):
                try:
                    speaker_list = json.loads(speaker_names)
                except json.JSONDecodeError:
                    raise HTTPException(status_code=400, detail="Invalid JSON format for speaker names")
            else:
                speaker_list = [name.strip() for name in speaker_names.split(',') if name.strip()]

        # Generate stable MEDIA_ID for this transcript
        media_key = uuid.uuid4().hex
        title_data = {
            "CASE_NAME": case_name,
            "CASE_NUMBER": case_number,
            "FIRM_OR_ORGANIZATION_NAME": firm_name,
            "DATE": input_date,
            "TIME": input_time,
            "LOCATION": location,
            "FILE_NAME": file.filename,
            "FILE_DURATION": "Calculating...",
            "MEDIA_ID": media_key,
        }

        # Upload media for editor playback
        media_blob_name = None
        media_content_type = file.content_type or mimetypes.guess_type(file.filename)[0]
        try:
            media_blob_name = upload_preview_file_to_cloud_storage_from_path(
                temp_upload_path,
                file.filename,
                media_content_type,
                user_id=current_user["user_id"],
                media_key=media_key,
            )
        except Exception as e:
            logger.warning("Failed to store media preview for editor session: %s", e)
            media_blob_name = None
            media_content_type = None

        duration_seconds = 0.0
        asr_start_time = time.time()

        if transcription_model == "assemblyai":
            logger.info("Starting AssemblyAI transcription...")
            try:
                turns, _docx_bytes, duration_seconds = process_transcription(
                    None,
                    file.filename,
                    speaker_list,
                    title_data,
                    input_path=temp_upload_path,
                )
                asr_elapsed = time.time() - asr_start_time
                logger.info("AssemblyAI completed in %.1fs. Generated %d turns.", asr_elapsed, len(turns))
            except Exception as e:
                logger.exception("AssemblyAI transcription error")
                raise HTTPException(status_code=500, detail=f"AssemblyAI transcription failed: {str(e)}") from e

        elif transcription_model == "gemini":
            logger.info("Starting Gemini transcription...")
            try:
                with tempfile.TemporaryDirectory() as temp_dir:
                    input_path = temp_upload_path

                    ext = file.filename.split('.')[-1].lower()
                    audio_path = input_path
                    audio_mime = "audio/mpeg"

                    SUPPORTED_VIDEO_TYPES = ["mp4", "mov", "avi", "mkv"]
                    if ext in SUPPORTED_VIDEO_TYPES:
                        output_audio = os.path.join(
                            temp_dir,
                            f"{os.path.splitext(os.path.basename(file.filename))[0]}.mp3",
                        )
                        audio_path = convert_video_to_audio(input_path, output_audio) or input_path
                        audio_mime = "audio/mpeg"
                    else:
                        mime_map = {
                            "mp3": "audio/mpeg",
                            "wav": "audio/wav",
                            "m4a": "audio/mp4",
                            "flac": "audio/flac",
                            "ogg": "audio/ogg",
                            "aac": "audio/aac",
                            "aiff": "audio/aiff",
                        }
                        audio_mime = mime_map.get(ext, "audio/mpeg")

                    duration_seconds = get_media_duration(audio_path) or 0.0

                    hours, rem = divmod(duration_seconds, 3600)
                    minutes, seconds = divmod(rem, 60)
                    title_data["FILE_DURATION"] = "{:0>2}:{:0>2}:{:0>2}".format(
                        int(hours),
                        int(minutes),
                        int(round(seconds)),
                    )

                    gemini_lines = await anyio.to_thread.run_sync(
                        transcribe_with_gemini,
                        audio_path,
                        audio_mime,
                        duration_seconds,
                        speaker_list,
                    )

                    normalized_lines, normalized_duration = normalize_line_payloads(
                        gemini_lines,
                        duration_seconds,
                    )
                    turns = construct_turns_from_lines(normalized_lines)

                    if not turns:
                        raise HTTPException(status_code=400, detail="Gemini transcription returned no usable turns")

                    duration_seconds = normalized_duration
                    asr_elapsed = time.time() - asr_start_time
                    logger.info("Gemini completed in %.1fs. Generated %d turns.", asr_elapsed, len(turns))

            except HTTPException:
                raise
            except Exception as e:
                logger.exception("Gemini transcription error")
                raise HTTPException(status_code=500, detail=f"Gemini transcription failed: {str(e)}") from e

        logger.info("Preserving native ASR/Gemini word timestamps for initial transcription")

        docx_bytes, oncue_xml, transcript_text, line_payloads = build_session_artifacts(
            turns,
            title_data,
            duration_seconds or 0,
            DEFAULT_LINES_PER_PAGE,
        )
        docx_b64 = base64.b64encode(docx_bytes).decode()
        oncue_b64 = base64.b64encode(oncue_xml.encode("utf-8")).decode()

        created_at = datetime.now(timezone.utc)

        transcript_data = {
            "media_key": media_key,
            "created_at": created_at.isoformat(),
            "title_data": title_data,
            "audio_duration": float(duration_seconds or 0),
            "lines_per_page": DEFAULT_LINES_PER_PAGE,
            "turns": serialize_transcript_turns(turns),
            "source_turns": serialize_transcript_turns(turns),
            "lines": line_payloads,
            "docx_base64": docx_b64,
            "oncue_xml_base64": oncue_b64,
            "transcript_text": transcript_text,
            "transcript": transcript_text,
            "media_blob_name": media_blob_name,
            "media_content_type": media_content_type,
            "updated_at": created_at.isoformat(),
            "user_id": current_user["user_id"],
            "clips": [],
        }

        try:
            save_current_transcript(media_key, transcript_data)

            snapshot_id = uuid.uuid4().hex
            snapshot_payload = build_snapshot_payload(transcript_data, is_manual_save=True)
            bucket = storage_client.bucket(BUCKET_NAME)
            snapshot_blob = bucket.blob(f"transcripts/{media_key}/history/{snapshot_id}.json")
            snapshot_blob.upload_from_string(json.dumps(snapshot_payload), content_type="application/json")

        except Exception as e:
            logger.error("Failed to store transcript: %s", e)
            raise HTTPException(status_code=500, detail="Unable to persist transcript") from e

        response_data = {
            **transcript_data,
            "transcript": transcript_text,
        }

        return JSONResponse(response_data)
    finally:
        if temp_upload_path and os.path.exists(temp_upload_path):
            try:
                os.remove(temp_upload_path)
            except OSError:
                pass


@router.get("/api/transcripts")
async def list_transcripts_endpoint(current_user: dict = Depends(get_current_user)):
    """List all transcripts for authenticated user."""
    try:
        transcripts = list_all_transcripts(current_user["user_id"])
        return JSONResponse(content={"transcripts": transcripts})
    except Exception as e:
        logger.error("Failed to list transcripts: %s", e)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/api/transcripts/by-key/{media_key:path}/history")
async def list_transcript_history_by_media_key(media_key: str, current_user: dict = Depends(get_current_user)):
    """List all snapshots for a media_key."""
    try:
        if not _user_owns_media_key(media_key, current_user["user_id"]):
            raise HTTPException(status_code=403, detail="Access denied to this transcript")

        logger.info("Fetching history for media_key: %s", media_key)
        bucket = storage_client.bucket(BUCKET_NAME)
        prefix = f"transcripts/{media_key}/history/"
        logger.info("Looking for snapshots at prefix: %s", prefix)

        snapshots = []
        blob_count = 0
        for blob in bucket.list_blobs(prefix=prefix):
            blob_count += 1
            try:
                data = json.loads(blob.download_as_string())
                is_manual = data.get("is_manual_save", data.get("saved", False))
                snapshots.append(
                    {
                        "snapshot_id": blob.name.split("/")[-1].replace(".json", ""),
                        "created_at": data.get("created_at"),
                        "is_manual_save": is_manual,
                        "line_count": data.get("line_count", 0),
                        "title_label": data.get("title_label", "Transcript"),
                    }
                )
            except Exception as e:
                logger.warning("Failed to parse snapshot blob %s: %s", blob.name, e)
                continue

        logger.info("Found %d blobs, %d valid snapshots", blob_count, len(snapshots))

        snapshots.sort(key=lambda x: x["created_at"] or "", reverse=True)

        return JSONResponse(content={"snapshots": snapshots})

    except HTTPException:
        raise
    except Exception as e:
        logger.error("Failed to list history for %s: %s", media_key, e)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/api/transcripts/by-key/{media_key:path}")
async def get_transcript_by_media_key(media_key: str, current_user: dict = Depends(get_current_user)):
    """Get current transcript state or latest snapshot by media_key."""
    try:
        data = load_current_transcript(media_key)
        if not data:
            raise HTTPException(status_code=404, detail="Transcript not found")

        if data.get("user_id") != current_user["user_id"]:
            raise HTTPException(status_code=403, detail="Access denied to this transcript")

        return JSONResponse(content=data)
    except HTTPException:
        raise
    except Exception as e:
        logger.error("Failed to load transcript %s: %s", media_key, e)
        raise HTTPException(status_code=500, detail=str(e))


@router.put("/api/transcripts/by-key/{media_key:path}")
async def save_transcript_by_media_key(media_key: str, request: Request, current_user: dict = Depends(get_current_user)):
    """Save transcript changes (auto-save or manual save)."""
    try:
        payload = await request.json()

        lines = payload.get("lines", [])
        title_data = payload.get("title_data", {})
        is_manual_save = payload.get("is_manual_save", False)
        user_id = current_user["user_id"]

        existing = load_current_transcript(media_key) or {}
        if existing and existing.get("user_id") and existing.get("user_id") != user_id:
            raise HTTPException(status_code=403, detail="Access denied to this transcript")

        transcript_data = {
            **existing,
            "media_key": media_key,
            "lines": lines,
            "title_data": title_data,
            "user_id": user_id,
            "created_at": existing.get("created_at", datetime.now(timezone.utc).isoformat()),
            "updated_at": datetime.now(timezone.utc).isoformat(),
            "audio_duration": payload.get("audio_duration", existing.get("audio_duration", 0.0)),
            "lines_per_page": payload.get("lines_per_page", existing.get("lines_per_page", DEFAULT_LINES_PER_PAGE)),
            "media_blob_name": payload.get("media_blob_name", existing.get("media_blob_name")),
            "media_content_type": payload.get("media_content_type", existing.get("media_content_type")),
        }

        try:
            normalized_lines, normalized_duration = normalize_line_payloads(
                lines,
                float(transcript_data.get("audio_duration") or 0.0),
            )
            turns = construct_turns_from_lines(normalized_lines)
            docx_bytes, oncue_xml, transcript_text, updated_lines = build_session_artifacts(
                turns,
                title_data,
                normalized_duration,
                transcript_data.get("lines_per_page", DEFAULT_LINES_PER_PAGE),
                enforce_min_line_duration=False,
            )
            transcript_data["lines"] = updated_lines
            transcript_data["audio_duration"] = normalized_duration
            transcript_data["docx_base64"] = base64.b64encode(docx_bytes).decode("ascii")
            transcript_data["oncue_xml_base64"] = base64.b64encode(oncue_xml.encode("utf-8")).decode("ascii")
            transcript_data["transcript_text"] = transcript_text
            transcript_data["transcript"] = transcript_text
        except Exception as e:
            logger.warning("Failed to regenerate documents: %s", e)

        save_current_transcript(media_key, transcript_data)

        snapshot_id = uuid.uuid4().hex
        snapshot_payload = build_snapshot_payload(transcript_data, is_manual_save=is_manual_save)
        bucket = storage_client.bucket(BUCKET_NAME)
        snapshot_blob = bucket.blob(f"transcripts/{media_key}/history/{snapshot_id}.json")
        snapshot_blob.upload_from_string(json.dumps(snapshot_payload), content_type="application/json")

        prune_snapshots(media_key)

        return JSONResponse(content=transcript_data)

    except HTTPException:
        raise
    except Exception as e:
        logger.error("Save failed for %s: %s", media_key, e)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/api/transcripts/by-key/{media_key:path}/restore/{snapshot_id}")
async def restore_snapshot_by_media_key(media_key: str, snapshot_id: str, current_user: dict = Depends(get_current_user)):
    """Restore a specific snapshot as current state."""
    try:
        if not _user_owns_media_key(media_key, current_user["user_id"]):
            raise HTTPException(status_code=403, detail="Access denied to this transcript")

        bucket = storage_client.bucket(BUCKET_NAME)
        blob = bucket.blob(f"transcripts/{media_key}/history/{snapshot_id}.json")

        if not blob.exists():
            raise HTTPException(status_code=404, detail="Snapshot not found")

        snapshot_data = json.loads(blob.download_as_string())

        if not snapshot_data.get("media_key"):
            snapshot_data["media_key"] = media_key

        lines = snapshot_data.get("lines") or []
        if lines:
            title_data = snapshot_data.get("title_data") or {}
            lines_per_page = snapshot_data.get("lines_per_page", DEFAULT_LINES_PER_PAGE)
            audio_duration = float(snapshot_data.get("audio_duration") or 0.0)
            try:
                normalized_lines, normalized_duration = normalize_line_payloads(lines, audio_duration)
                turns = construct_turns_from_lines(normalized_lines)
                if turns:
                    docx_bytes, oncue_xml, transcript_text, updated_lines = build_session_artifacts(
                        turns,
                        title_data,
                        normalized_duration,
                        lines_per_page,
                        enforce_min_line_duration=False,
                    )
                    snapshot_data["lines"] = updated_lines
                    snapshot_data["audio_duration"] = normalized_duration
                    snapshot_data["docx_base64"] = base64.b64encode(docx_bytes).decode("ascii")
                    snapshot_data["oncue_xml_base64"] = base64.b64encode(oncue_xml.encode("utf-8")).decode("ascii")
                    snapshot_data["transcript_text"] = transcript_text
                    snapshot_data["transcript"] = transcript_text
            except Exception as exc:
                logger.warning("Failed to rebuild snapshot artifacts for %s: %s", media_key, exc)

        snapshot_data["updated_at"] = datetime.now(timezone.utc).isoformat()

        save_current_transcript(media_key, snapshot_data)

        return JSONResponse(content=snapshot_data)

    except HTTPException:
        raise
    except Exception as e:
        logger.error("Failed to restore snapshot %s for %s: %s", snapshot_id, media_key, e)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/api/transcripts/by-key/{media_key:path}/gemini-refine")
async def gemini_refine_transcript(media_key: str, current_user: dict = Depends(get_current_user)):
    session_data = load_current_transcript(media_key)
    if not session_data:
        raise HTTPException(status_code=404, detail="Transcript not found")
    if session_data.get("user_id") and session_data.get("user_id") != current_user["user_id"]:
        raise HTTPException(status_code=403, detail="Access denied to this transcript")

    media_blob_name = session_data.get("media_blob_name")
    if not media_blob_name:
        raise HTTPException(status_code=400, detail="This session has no media attached for Gemini refinement")

    xml_b64 = session_data.get("oncue_xml_base64")
    if not xml_b64:
        raise HTTPException(status_code=400, detail="OnCue XML is missing for this session")

    try:
        xml_text = base64.b64decode(xml_b64).decode("utf-8", errors="replace")
    except Exception as e:
        raise HTTPException(status_code=400, detail="Unable to decode the session XML") from e

    audio_path = None
    media_path = None
    try:
        audio_path, audio_mime, duration_seconds, media_path = await anyio.to_thread.run_sync(
            prepare_audio_for_gemini,
            media_blob_name,
            session_data.get("media_content_type"),
        )
        duration_hint = duration_seconds or float(session_data.get("audio_duration") or 0)
        gemini_lines = await anyio.to_thread.run_sync(
            run_gemini_edit,
            xml_text,
            audio_path,
            audio_mime,
            duration_hint,
        )

        normalized_lines, normalized_duration = normalize_line_payloads(gemini_lines, duration_hint)
        turns = construct_turns_from_lines(normalized_lines)
        if not turns:
            raise HTTPException(status_code=400, detail="Gemini refinement returned no usable turns")

        lines_per_page = session_data.get("lines_per_page", DEFAULT_LINES_PER_PAGE)
        title_data = session_data.get("title_data") or {}

        docx_bytes, oncue_xml, transcript_text, updated_lines_payload = build_session_artifacts(
            turns,
            title_data,
            normalized_duration,
            lines_per_page,
        )

        docx_b64 = base64.b64encode(docx_bytes).decode()
        oncue_b64 = base64.b64encode(oncue_xml.encode("utf-8")).decode()

        hours, rem = divmod(normalized_duration, 3600)
        minutes, seconds = divmod(rem, 60)
        title_data["FILE_DURATION"] = "{:0>2}:{:0>2}:{:0>2}".format(
            int(hours),
            int(minutes),
            int(round(seconds)),
        )

        updated_at = datetime.now(timezone.utc)
        session_data["turns"] = serialize_transcript_turns(turns)
        session_data["lines"] = updated_lines_payload
        session_data["title_data"] = title_data
        session_data["audio_duration"] = normalized_duration
        session_data["docx_base64"] = docx_b64
        session_data["oncue_xml_base64"] = oncue_b64
        session_data["transcript_text"] = transcript_text
        session_data["transcript"] = transcript_text
        session_data["updated_at"] = updated_at.isoformat()

        save_current_transcript(media_key, session_data)

        return JSONResponse(session_data)
    finally:
        for path in (audio_path, media_path):
            if path and os.path.exists(path):
                try:
                    os.remove(path)
                except Exception:
                    pass


@router.post("/api/transcripts/import")
async def import_transcript(
    transcript_file: UploadFile = File(...),
    media_file: UploadFile = File(...),
    case_name: str = Form(""),
    case_number: str = Form(""),
    firm_name: str = Form(""),
    input_date: str = Form(""),
    input_time: str = Form(""),
    location: str = Form(""),
    current_user: dict = Depends(get_current_user),
):
    """
    Import a transcript from OnCue XML or DOCX file.

    - XML: Parses OnCue format, uses embedded timestamps
    - DOCX: Parses speaker/text, runs Rev AI alignment for timestamps

    Media file is required for both to enable playback and re-sync.
    """
    filename = transcript_file.filename or ""
    file_ext = filename.lower().split('.')[-1] if '.' in filename else ''

    logger.info(
        "Import request: file=%s (type=%s), media=%s",
        filename,
        file_ext,
        media_file.filename if media_file else "None",
    )

    media_key = uuid.uuid4().hex
    transcript_path = None
    media_path = None
    try:
        transcript_path, transcript_size = await save_upload_to_tempfile(transcript_file)
        if not transcript_path or transcript_size == 0:
            raise HTTPException(status_code=400, detail="Uploaded transcript file is empty")

        if not media_file:
            raise HTTPException(status_code=400, detail="Media file is required for import")

        media_path, media_size = await save_upload_to_tempfile(media_file)
        if not media_path or media_size == 0:
            raise HTTPException(status_code=400, detail="Uploaded media file is empty")

        media_blob_name = None
        media_content_type = media_file.content_type or mimetypes.guess_type(media_file.filename)[0]
        duration_seconds = 0.0

        try:
            media_blob_name = upload_preview_file_to_cloud_storage_from_path(
                media_path,
                media_file.filename,
                media_content_type,
                user_id=current_user["user_id"],
                media_key=media_key,
            )
            logger.info("Import: uploaded media to blob %s", media_blob_name)

            audio_path, _, dur, original_media_path = await anyio.to_thread.run_sync(
                prepare_audio_for_gemini,
                media_blob_name,
                media_content_type,
            )
            duration_seconds = dur or 0.0
            for temp_path in (audio_path, original_media_path):
                if temp_path and os.path.exists(temp_path):
                    try:
                        os.remove(temp_path)
                    except OSError:
                        pass
        except Exception as e:
            logger.error("Failed to process media during import: %s", e)
            raise HTTPException(status_code=500, detail=f"Failed to process media file: {e}") from e

        with open(transcript_path, "rb") as transcript_stream:
            file_bytes = transcript_stream.read()
        if not file_bytes:
            raise HTTPException(status_code=400, detail="Uploaded transcript file is empty")

        if file_ext == 'xml':
            xml_text = file_bytes.decode("utf-8", errors="replace")
            parsed = parse_oncue_xml(xml_text)
            title_data = parsed["title_data"]
            xml_duration = float(parsed["audio_duration"] or 0)
            if xml_duration > 0:
                duration_seconds = xml_duration

            lines_payload = parsed["lines"]
            normalized_lines, duration_seconds = normalize_line_payloads(lines_payload, duration_seconds)
            turns = construct_turns_from_lines(normalized_lines)

            if not turns:
                raise HTTPException(status_code=400, detail="Unable to construct transcript turns from XML")

        elif file_ext == 'docx':
            docx_turns = parse_docx_to_turns(file_bytes)

            if not docx_turns:
                raise HTTPException(status_code=400, detail="Unable to parse transcript from DOCX")

            turns = [
                TranscriptTurn(
                    speaker=turn["speaker"],
                    text=turn["text"],
                    timestamp=None,
                    words=None,
                    is_continuation=bool(turn.get("is_continuation", False)),
                )
                for turn in docx_turns
            ]

            rev_api_key = os.getenv("REV_AI_API_KEY")
            if rev_api_key and media_blob_name:
                alignment_audio_path = None
                alignment_media_path = None
                alignment_start_time = time.time()
                try:
                    logger.info("Running Rev AI alignment for DOCX import...")

                    alignment_audio_path, _, _, alignment_media_path = await anyio.to_thread.run_sync(
                        prepare_audio_for_gemini,
                        media_blob_name,
                        media_content_type,
                    )

                    aligner = RevAIAligner(rev_api_key)
                    turns_payload = [turn.model_dump() for turn in turns]

                    aligned_turns_payload = await anyio.to_thread.run_sync(
                        aligner.align_transcript,
                        turns_payload,
                        alignment_audio_path,
                        None,
                    )

                    turns = [TranscriptTurn(**turn) for turn in aligned_turns_payload]
                    alignment_elapsed = time.time() - alignment_start_time
                    logger.info("Rev AI alignment completed in %.1fs for DOCX import", alignment_elapsed)

                except Exception as e:
                    logger.warning("Rev AI alignment failed for DOCX import: %s", e)
                finally:
                    for temp_path in (alignment_audio_path, alignment_media_path):
                        if temp_path and os.path.exists(temp_path):
                            try:
                                os.remove(temp_path)
                            except OSError:
                                pass
            else:
                logger.warning("REV_AI_API_KEY not configured, DOCX import will have no timestamps")

            title_data = {}
        else:
            raise HTTPException(
                status_code=400,
                detail=f"Unsupported file type: {file_ext}. Use .xml (OnCue) or .docx",
            )

        overrides = {
            "CASE_NAME": case_name or title_data.get("CASE_NAME", ""),
            "CASE_NUMBER": case_number or title_data.get("CASE_NUMBER", ""),
            "FIRM_OR_ORGANIZATION_NAME": firm_name or title_data.get("FIRM_OR_ORGANIZATION_NAME", ""),
            "DATE": input_date or title_data.get("DATE", ""),
            "TIME": input_time or title_data.get("TIME", ""),
            "LOCATION": location or title_data.get("LOCATION", ""),
            "FILE_NAME": title_data.get("FILE_NAME") or filename or "imported",
        }
        title_data.update(overrides)

        title_data["MEDIA_ID"] = media_key

        docx_bytes_out, oncue_xml, transcript_text, line_payloads = build_session_artifacts(
            turns,
            title_data,
            duration_seconds,
            DEFAULT_LINES_PER_PAGE,
        )

        docx_b64 = base64.b64encode(docx_bytes_out).decode()
        oncue_b64 = base64.b64encode(oncue_xml.encode("utf-8")).decode()

        created_at = datetime.now(timezone.utc)

        try:
            transcript_data = {
                "media_key": media_key,
                "created_at": created_at.isoformat(),
                "updated_at": created_at.isoformat(),
                "title_data": title_data,
                "audio_duration": duration_seconds,
                "lines_per_page": DEFAULT_LINES_PER_PAGE,
                "turns": serialize_transcript_turns(turns),
                "source_turns": serialize_transcript_turns(turns),
                "lines": line_payloads,
                "docx_base64": docx_b64,
                "oncue_xml_base64": oncue_b64,
                "transcript_text": transcript_text,
                "transcript": transcript_text,
                "media_blob_name": media_blob_name,
                "media_content_type": media_content_type,
                "user_id": current_user["user_id"],
                "clips": [],
            }

            save_current_transcript(media_key, transcript_data)

            snapshot_id = uuid.uuid4().hex
            snapshot_payload = build_snapshot_payload(transcript_data, is_manual_save=True)
            bucket = storage_client.bucket(BUCKET_NAME)
            snapshot_blob = bucket.blob(f"transcripts/{media_key}/history/{snapshot_id}.json")
            snapshot_blob.upload_from_string(json.dumps(snapshot_payload), content_type="application/json")
            logger.info("Created initial snapshot for imported transcript: %s", media_key)

        except Exception as e:
            logger.error("Failed to save imported transcript: %s", e)
            raise HTTPException(status_code=500, detail="Unable to persist imported transcript") from e

        return JSONResponse(dict(transcript_data))
    finally:
        for temp_path in (transcript_path, media_path):
            if temp_path and os.path.exists(temp_path):
                try:
                    os.remove(temp_path)
                except OSError:
                    pass


@router.post("/api/resync")
async def resync_transcript(
    payload: dict = Body(...),
    current_user: dict = Depends(get_current_user),
):
    """
    Re-sync the transcript using Rev AI Forced Alignment.

    Payload:
      - media_key: string
      - api_key: string (optional, checks env if missing)
    """
    media_key = payload.get("media_key")
    if not media_key:
        raise HTTPException(status_code=400, detail="Missing media_key")

    session_data = load_current_transcript(media_key)
    if not session_data:
        raise HTTPException(status_code=404, detail="Transcript not found")
    if session_data.get("user_id") and session_data.get("user_id") != current_user["user_id"]:
        raise HTTPException(status_code=403, detail="Access denied to this transcript")

    media_blob_name = session_data.get("media_blob_name")
    media_content_type = session_data.get("media_content_type")

    logger.info(
        "Resync: media_key=%s, media_blob_name=%s, media_content_type=%s",
        media_key,
        media_blob_name,
        media_content_type,
    )

    if not media_blob_name:
        raise HTTPException(status_code=400, detail="Audio file reference not found in session")

    audio_path = None
    try:
        audio_path, _, _, _ = await anyio.to_thread.run_sync(
            prepare_audio_for_gemini,
            media_blob_name,
            media_content_type,
        )
    except Exception as e:
        logger.error("Failed to prepare audio for re-sync: %s", e)
        raise HTTPException(status_code=500, detail=f"Failed to prepare audio: {e}") from e

    try:
        rev_api_key = payload.get("api_key") or os.getenv("REV_AI_API_KEY")
        if not rev_api_key:
            raise HTTPException(status_code=500, detail="Rev AI API Key not configured")

        aligner = RevAIAligner(rev_api_key)

        lines = session_data.get("lines", [])
        if not lines:
            raise HTTPException(status_code=400, detail="No transcript lines to align")

        audio_duration = session_data.get("audio_duration", 0.0)
        normalized_lines, _ = normalize_line_payloads(lines, audio_duration)
        turns = construct_turns_from_lines(normalized_lines)

        turns_payload = [turn.model_dump() for turn in turns]
        source_turns_payload = session_data.get("source_turns")

        updated_turns_payload = await anyio.to_thread.run_sync(
            aligner.align_transcript,
            turns_payload,
            audio_path,
            None,
            source_turns_payload,
        )

        updated_turns = [TranscriptTurn(**turn) for turn in updated_turns_payload]

        title_data = session_data.get("title_data", {})
        lines_per_page = session_data.get("lines_per_page", DEFAULT_LINES_PER_PAGE)

        docx_bytes, oncue_xml, transcript_text, new_line_entries = build_session_artifacts(
            updated_turns,
            title_data,
            audio_duration,
            lines_per_page,
        )

        session_data["lines"] = new_line_entries
        session_data["turns"] = serialize_transcript_turns(updated_turns)
        session_data["docx_base64"] = base64.b64encode(docx_bytes).decode()
        session_data["oncue_xml_base64"] = base64.b64encode(oncue_xml.encode("utf-8")).decode()
        session_data["transcript_text"] = transcript_text
        session_data["updated_at"] = datetime.now(timezone.utc).isoformat()

        save_current_transcript(media_key, session_data)

        return {
            "status": "success",
            "lines": new_line_entries,
            "docx_base64": session_data["docx_base64"],
            "oncue_xml_base64": session_data["oncue_xml_base64"],
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error("Re-sync failed: %s", e)
        raise HTTPException(status_code=502, detail=f"Re-sync process failed: {e}") from e

    finally:
        if audio_path and os.path.exists(audio_path):
            try:
                os.remove(audio_path)
            except OSError:
                pass
===== END FILE =====

===== FILE: backend/auth.py =====
"""
Authentication module for TranscribeAlpha.
Handles JWT token generation, password verification, and Secret Manager integration.
"""

import os
import json
import logging
from datetime import datetime, timedelta, timezone
from typing import Optional, Dict, List

from jose import JWTError, jwt
import bcrypt
from google.cloud import secretmanager
from fastapi import HTTPException, status, Depends
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials

logger = logging.getLogger(__name__)

# JWT configuration
JWT_SECRET_KEY = os.getenv("JWT_SECRET_KEY", "dev-secret-key-change-in-production")
JWT_ALGORITHM = "HS256"
ACCESS_TOKEN_EXPIRE_DAYS = 365  # 1 year - effectively permanent
REFRESH_TOKEN_EXPIRE_DAYS = 3650  # 10 years - effectively permanent

# Secret Manager configuration
PROJECT_ID = os.getenv("GOOGLE_CLOUD_PROJECT", "")
SECRET_NAME = "transcribealpha-users"

# Security scheme
security = HTTPBearer()

# In-memory cache for users (refreshed periodically)
_users_cache: Optional[Dict[str, dict]] = None
_cache_timestamp: Optional[datetime] = None
CACHE_TTL_MINUTES = 5


def get_secret_manager_client():
    """Get Secret Manager client."""
    try:
        return secretmanager.SecretManagerServiceClient()
    except Exception as e:
        logger.error(f"Failed to create Secret Manager client: {e}")
        return None


def load_users_from_secret_manager() -> Dict[str, dict]:
    """
    Load users from Google Secret Manager.
    Returns a dictionary mapping username to user data.
    """
    global _users_cache, _cache_timestamp

    # Check cache first
    if _users_cache and _cache_timestamp:
        if datetime.now(timezone.utc) - _cache_timestamp < timedelta(minutes=CACHE_TTL_MINUTES):
            return _users_cache

    try:
        client = get_secret_manager_client()
        if not client:
            logger.warning("Secret Manager client not available, using fallback")
            return {}

        # Build the resource name
        if not PROJECT_ID:
            logger.warning("GOOGLE_CLOUD_PROJECT not set, cannot access Secret Manager")
            return {}

        name = f"projects/{PROJECT_ID}/secrets/{SECRET_NAME}/versions/latest"

        # Access the secret version
        response = client.access_secret_version(request={"name": name})
        secret_data = response.payload.data.decode("UTF-8")

        # Parse JSON
        users_data = json.loads(secret_data)

        # Convert to dictionary mapping username -> user data
        users_dict = {}
        for user in users_data.get("users", []):
            username = user.get("username")
            if username:
                users_dict[username] = user

        # Update cache
        _users_cache = users_dict
        _cache_timestamp = datetime.now(timezone.utc)

        logger.info(f"Loaded {len(users_dict)} users from Secret Manager")
        return users_dict

    except Exception as e:
        logger.error(f"Failed to load users from Secret Manager: {e}")
        # Return cached data if available
        if _users_cache:
            logger.info("Using cached user data due to Secret Manager error")
            return _users_cache
        return {}


def verify_password(plain_password: str, hashed_password: str) -> bool:
    """Verify a password against its hash."""
    try:
        return bcrypt.checkpw(plain_password.encode('utf-8'), hashed_password.encode('utf-8'))
    except Exception as e:
        logger.error(f"Password verification error: {e}")
        return False


def get_password_hash(password: str) -> str:
    """Generate password hash (for admin use)."""
    return bcrypt.hashpw(password.encode('utf-8'), bcrypt.gensalt()).decode('utf-8')


def authenticate_user(username: str, password: str) -> Optional[dict]:
    """
    Authenticate a user by username and password.
    Returns user data if successful, None otherwise.
    """
    users = load_users_from_secret_manager()
    user = users.get(username)

    if not user:
        logger.warning(f"Authentication failed: user '{username}' not found")
        return None

    if not verify_password(password, user.get("password_hash", "")):
        logger.warning(f"Authentication failed: invalid password for user '{username}'")
        return None

    logger.info(f"User '{username}' authenticated successfully")
    return user


def create_access_token(data: dict, expires_delta: Optional[timedelta] = None) -> str:
    """Create a JWT access token."""
    to_encode = data.copy()

    if expires_delta:
        expire = datetime.now(timezone.utc) + expires_delta
    else:
        expire = datetime.now(timezone.utc) + timedelta(days=ACCESS_TOKEN_EXPIRE_DAYS)

    to_encode.update({"exp": expire, "type": "access"})
    encoded_jwt = jwt.encode(to_encode, JWT_SECRET_KEY, algorithm=JWT_ALGORITHM)
    return encoded_jwt


def create_refresh_token(data: dict) -> str:
    """Create a JWT refresh token."""
    to_encode = data.copy()
    expire = datetime.now(timezone.utc) + timedelta(days=REFRESH_TOKEN_EXPIRE_DAYS)
    to_encode.update({"exp": expire, "type": "refresh"})
    encoded_jwt = jwt.encode(to_encode, JWT_SECRET_KEY, algorithm=JWT_ALGORITHM)
    return encoded_jwt


def decode_token(token: str) -> Optional[dict]:
    """
    Decode and validate a JWT token.
    Returns the payload if valid, None otherwise.
    """
    try:
        payload = jwt.decode(token, JWT_SECRET_KEY, algorithms=[JWT_ALGORITHM])
        return payload
    except JWTError as e:
        logger.warning(f"Token decode error: {e}")
        return None


async def get_current_user(credentials: HTTPAuthorizationCredentials = Depends(security)) -> dict:
    """
    Dependency to get the current authenticated user from JWT token.
    Raises HTTPException if authentication fails.
    """
    credentials_exception = HTTPException(
        status_code=status.HTTP_401_UNAUTHORIZED,
        detail="Could not validate credentials",
        headers={"WWW-Authenticate": "Bearer"},
    )

    try:
        token = credentials.credentials
        payload = decode_token(token)

        if payload is None:
            raise credentials_exception

        # Check token type
        if payload.get("type") != "access":
            raise credentials_exception

        username: str = payload.get("sub")
        if username is None:
            raise credentials_exception

        # Return user info from token
        return {
            "username": username,
            "role": payload.get("role", "user"),
            "user_id": username  # Use username as user_id for simplicity
        }

    except Exception as e:
        logger.error(f"Authentication error: {e}")
        raise credentials_exception


async def get_current_user_optional(credentials: Optional[HTTPAuthorizationCredentials] = Depends(security)) -> Optional[dict]:
    """
    Optional authentication dependency.
    Returns user if authenticated, None if not.
    Useful for endpoints that work with or without auth.
    """
    if credentials is None:
        return None

    try:
        return await get_current_user(credentials)
    except HTTPException:
        return None


def generate_initial_password_hash(password: str) -> str:
    """
    Helper function to generate password hash for initial setup.
    This should be run locally, not in production code.
    """
    return get_password_hash(password)


# For development/testing: Generate a sample users JSON structure
def generate_sample_users_json(username: str, password: str) -> str:
    """
    Generate a sample users JSON for Secret Manager.
    Usage: python -c "from backend.auth import generate_sample_users_json; print(generate_sample_users_json('VerdictGroup', 'your_secure_password'))"
    """
    password_hash = get_password_hash(password)
    users_data = {
        "users": [
            {
                "username": username,
                "password_hash": password_hash,
                "role": "admin",
                "created_at": datetime.now(timezone.utc).isoformat()
            }
        ]
    }
    return json.dumps(users_data, indent=2)


if __name__ == "__main__":
    # Helper script to generate password hash
    import sys
    if len(sys.argv) > 1:
        password = sys.argv[1]
        print(f"Password hash: {get_password_hash(password)}")
    else:
        print("Usage: python auth.py <password>")
        print("Or: python -c \"from backend.auth import generate_sample_users_json; print(generate_sample_users_json('username', 'password'))\"")
===== END FILE =====

===== FILE: backend/config.py =====
import os

# Environment-based CORS configuration
ENVIRONMENT = os.getenv("ENVIRONMENT", "development")
ALLOWED_ORIGINS = ["*"] if ENVIRONMENT == "development" else [
    "https://transcribealpha-*.cloudfunctions.net",
    "https://transcribealpha-*.appspot.com",
    "https://transcribealpha-*.run.app",
    # Add your production domains here
]

# Cloud Storage configuration
BUCKET_NAME = "transcribealpha-uploads-1750110926"

# Default transcript layout configuration
DEFAULT_LINES_PER_PAGE = 25

# Session / cleanup configuration
EDITOR_SESSION_TTL_DAYS = int(os.getenv("EDITOR_SESSION_TTL_DAYS", "7"))
CLIP_SESSION_PREFIX = "clip_sessions/"
CLIP_SESSION_TTL_DAYS = int(os.getenv("CLIP_SESSION_TTL_DAYS", str(EDITOR_SESSION_TTL_DAYS)))
SNAPSHOT_TTL_DAYS = int(os.getenv("SNAPSHOT_TTL_DAYS", "14"))
MEDIA_TTL_DAYS = int(os.getenv("MEDIA_TTL_DAYS", "1"))
MEDIA_CLEANUP_PREFIXES = ("preview_", "clip_", "raw_")
===== END FILE =====

===== FILE: backend/gemini.py =====
import json
import logging
import os
import time
from typing import Any, List, Optional

from fastapi import HTTPException

logger = logging.getLogger(__name__)


def run_gemini_edit(xml_text: str, audio_path: str, audio_mime: str, duration_hint: float) -> List[dict]:
    api_key = os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_API_KEY")
    if api_key:
        api_key = api_key.strip()
        if (api_key.startswith('"') and api_key.endswith('"')) or (api_key.startswith("'") and api_key.endswith("'")):
            api_key = api_key[1:-1].strip()
        if api_key in {"your-gemini-key-here", "YOUR_GEMINI_KEY_HERE"}:
            raise HTTPException(
                status_code=500,
                detail="GEMINI_API_KEY is still set to the placeholder value; update your Cloud Run env var or Cloud Build trigger substitution _GEMINI_API_KEY.",
            )
    if not api_key:
        raise HTTPException(status_code=500, detail="GEMINI_API_KEY not configured")

    try:
        from google import genai
        from google.genai import types as genai_types
    except Exception as exc:
        logger.error("google-genai not available: %s", exc)
        raise HTTPException(status_code=500, detail="Gemini client library not installed") from exc

    model_name = os.getenv("GEMINI_MODEL_NAME", "gemini-3-pro-preview").strip()
    if not model_name:
        model_name = "gemini-3-pro-preview"

    instructions = (
        "You are improving an OnCue-style legal transcript. "
        "Use the provided XML transcript and the audio to correct ONLY: wording errors, punctuation, capitalization, and speaker labels. "
        "CRITICAL: You MUST preserve the EXACT start and end timestamps from the original - do NOT modify timing values. "
        "Keep the same number of lines and line order. Only fix text content and speaker names."
    )

    polish_schema = {
        "type": "array",
        "items": {
            "type": "object",
            "properties": {
                "speaker": {"type": "string"},
                "text": {"type": "string"},
                "start": {"type": "number"},
                "end": {"type": "number"},
            },
            "required": ["speaker", "text", "start", "end"],
        },
    }

    def wait_for_file_active(client: Any, file_name: str, *, timeout_seconds: int = 120) -> Any:
        deadline = time.time() + max(5, timeout_seconds)
        last_state = None
        while time.time() < deadline:
            fetched = client.files.get(name=file_name)
            state = getattr(fetched, "state", None)
            if state != last_state:
                logger.info("Gemini file %s state=%s", file_name, state)
                last_state = state
            if state == genai_types.FileState.ACTIVE:
                return fetched
            if state == genai_types.FileState.FAILED:
                err = getattr(fetched, "error", None)
                raise RuntimeError(f"Gemini file processing failed: {err}")
            time.sleep(2.0)
        raise TimeoutError("Timed out waiting for Gemini file to become ACTIVE")

    client = None
    uploaded = None
    try:
        client = genai.Client(
            api_key=api_key,
            http_options=genai_types.HttpOptions(timeout=600_000),
        )
        upload_config = genai_types.UploadFileConfig(
            mime_type=audio_mime,
            display_name=os.path.basename(audio_path),
        )
        try:
            uploaded = client.files.upload(file=audio_path, config=upload_config)
        except Exception as exc:
            logger.exception("Failed to upload media to Gemini")
            exc_text = str(exc)
            if "API_KEY_INVALID" in exc_text or "API key not valid" in exc_text:
                logger.error(
                    "Gemini rejected API key (len=%s). Check for quotes/whitespace and correct key source.",
                    len(api_key or ""),
                )
            raise HTTPException(
                status_code=502,
                detail=(
                    "Uploading media to Gemini failed. "
                    "If this is an API key error, ensure `GEMINI_API_KEY` (or `GOOGLE_API_KEY`) is set without quotes/whitespace "
                    "and is a valid Gemini Developer API key. "
                    f"({type(exc).__name__}: {exc})"
                ),
            ) from exc
        wait_timeout = int(os.getenv("GEMINI_FILE_ACTIVE_TIMEOUT_SECONDS", "120"))
        try:
            uploaded = wait_for_file_active(client, uploaded.name, timeout_seconds=wait_timeout)
        except Exception as exc:
            logger.exception("Uploaded file did not become ACTIVE")
            raise HTTPException(
                status_code=502,
                detail=f"Gemini file processing failed ({type(exc).__name__}: {exc})",
            ) from exc

        try:
            response = client.models.generate_content(
                model=model_name,
                contents=[
                    genai_types.Part.from_text(text=instructions),
                    genai_types.Part.from_text(
                        text=f"Total duration (seconds): {duration_hint:.2f}. Existing XML transcript follows:\n{xml_text}"
                    ),
                    genai_types.Part.from_uri(
                        file_uri=uploaded.uri,
                        mime_type=uploaded.mime_type or audio_mime,
                    ),
                ],
                config=genai_types.GenerateContentConfig(
                    temperature=0.15,
                    response_mime_type="application/json",
                    response_json_schema=polish_schema,
                    thinking_config=genai_types.ThinkingConfig(thinking_level="low"),
                ),
            )
        except Exception as exc:
            logger.exception("Gemini generation failed")
            raise HTTPException(
                status_code=502,
                detail=f"Gemini transcript refinement failed ({type(exc).__name__}: {exc})",
            ) from exc
    finally:
        if client and uploaded:
            try:
                client.files.delete(name=uploaded.name)
            except Exception:
                pass
        if client:
            try:
                client.close()
            except Exception:
                pass

    raw_text = getattr(response, "text", None) or getattr(response, "output_text", None)
    if not raw_text and getattr(response, "candidates", None):
        try:
            raw_text = response.candidates[0].content.parts[0].text
        except Exception:
            raw_text = None

    if not raw_text:
        logger.error("Gemini response missing text payload")
        raise HTTPException(status_code=502, detail="Gemini returned an empty response")

    try:
        parsed = json.loads(raw_text)
    except json.JSONDecodeError as exc:
        logger.error("Failed to parse Gemini JSON: %s", exc)
        raise HTTPException(status_code=502, detail="Gemini returned invalid JSON") from exc

    if not isinstance(parsed, list):
        raise HTTPException(status_code=502, detail="Gemini response must be a list of line objects")

    normalized = []
    for idx, item in enumerate(parsed):
        if not isinstance(item, dict):
            continue
        speaker = str(item.get("speaker", "")).strip() or f"SPEAKER {idx + 1}"
        text = str(item.get("text", "")).strip()
        start_val = float(item.get("start", 0.0))
        end_val = float(item.get("end", start_val))
        normalized.append(
            {
                "id": item.get("id") or f"gem-{idx}",
                "speaker": speaker.upper(),
                "text": text,
                "start": max(start_val, 0.0),
                "end": max(end_val, start_val),
                "is_continuation": False,
            }
        )

    if not normalized:
        raise HTTPException(status_code=502, detail="Gemini did not return any transcript lines")

    logger.info("Gemini polish completed with %d lines", len(normalized))
    return normalized


def transcribe_with_gemini(
    audio_path: str,
    audio_mime: str,
    duration_hint: float,
    speaker_name_list: Optional[List[str]] = None,
) -> List[dict]:
    """
    Transcribe audio using Gemini 3.0 Pro with thinking_level="low".

    Args:
        audio_path: Path to the audio file
        audio_mime: MIME type of the audio
        duration_hint: Approximate duration in seconds
        speaker_name_list: Optional list of speaker names to use

    Returns:
        List of transcript line objects with speaker, text, start, end fields
    """
    api_key = os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_API_KEY")
    if api_key:
        api_key = api_key.strip()
        if (api_key.startswith('"') and api_key.endswith('"')) or (api_key.startswith("'") and api_key.endswith("'")):
            api_key = api_key[1:-1].strip()
        if api_key in {"your-gemini-key-here", "YOUR_GEMINI_KEY_HERE"}:
            raise HTTPException(
                status_code=500,
                detail="GEMINI_API_KEY is still set to the placeholder value; update your Cloud Run env var.",
            )
    if not api_key:
        raise HTTPException(status_code=500, detail="GEMINI_API_KEY not configured")

    try:
        from google import genai
        from google.genai import types as genai_types
    except Exception as exc:
        logger.error("google-genai not available: %s", exc)
        raise HTTPException(status_code=500, detail="Gemini client library not installed") from exc

    model_name = os.getenv("GEMINI_MODEL_NAME", "gemini-3-pro-preview").strip()
    if not model_name:
        model_name = "gemini-3-pro-preview"

    # Build speaker instructions
    speaker_instructions = ""
    if speaker_name_list and len(speaker_name_list) > 0:
        speaker_instructions = (
            f"Use these speaker names in order of appearance: {', '.join(speaker_name_list)}. "
            f"Expected number of speakers: {len(speaker_name_list)}. "
        )
    else:
        speaker_instructions = (
            "Identify and label distinct speakers as SPEAKER A, SPEAKER B, SPEAKER C, etc. "
        )

    instructions = (
        "You are a professional legal transcriptionist. "
        "Transcribe the provided audio file into a legal transcript format with precise WORD-LEVEL timestamps. "
        f"{speaker_instructions}"
        "Each utterance must include the 'words' array with timing for EVERY word in the text. "
        "Ensure proper punctuation and capitalization. "
        "All timestamps should be accurate in seconds, with start < end, entries non-overlapping and chronological."
    )

    def wait_for_file_active(client: Any, file_name: str, *, timeout_seconds: int = 120) -> Any:
        deadline = time.time() + max(5, timeout_seconds)
        last_state = None
        while time.time() < deadline:
            fetched = client.files.get(name=file_name)
            state = getattr(fetched, "state", None)
            if state != last_state:
                logger.info("Gemini file %s state=%s", file_name, state)
                last_state = state
            if state == genai_types.FileState.ACTIVE:
                return fetched
            if state == genai_types.FileState.FAILED:
                err = getattr(fetched, "error", None)
                raise RuntimeError(f"Gemini file processing failed: {err}")
            time.sleep(2.0)
        raise TimeoutError("Timed out waiting for Gemini file to become ACTIVE")

    client = None
    uploaded = None
    try:
        client = genai.Client(
            api_key=api_key,
            http_options=genai_types.HttpOptions(timeout=600_000),
        )
        upload_config = genai_types.UploadFileConfig(
            mime_type=audio_mime,
            display_name=os.path.basename(audio_path),
        )
        try:
            uploaded = client.files.upload(file=audio_path, config=upload_config)
        except Exception as exc:
            logger.exception("Failed to upload media to Gemini")
            exc_text = str(exc)
            if "API_KEY_INVALID" in exc_text or "API key not valid" in exc_text:
                logger.error("Gemini rejected API key (len=%s). Check for quotes/whitespace.", len(api_key or ""))
            raise HTTPException(
                status_code=502,
                detail=(
                    "Uploading media to Gemini failed. "
                    f"({type(exc).__name__}: {exc})"
                ),
            ) from exc

        wait_timeout = int(os.getenv("GEMINI_FILE_ACTIVE_TIMEOUT_SECONDS", "120"))
        try:
            uploaded = wait_for_file_active(client, uploaded.name, timeout_seconds=wait_timeout)
        except Exception as exc:
            logger.exception("Uploaded file did not become ACTIVE")
            raise HTTPException(
                status_code=502,
                detail=f"Gemini file processing failed ({type(exc).__name__}: {exc})",
            ) from exc

        # Build the JSON schema for structured output
        utterance_schema = {
            "type": "array",
            "items": {
                "type": "object",
                "properties": {
                    "speaker": {"type": "string"},
                    "text": {"type": "string"},
                    "start": {"type": "number"},
                    "end": {"type": "number"},
                    "words": {
                        "type": "array",
                        "items": {
                            "type": "object",
                            "properties": {
                                "word": {"type": "string"},
                                "start": {"type": "number"},
                                "end": {"type": "number"},
                            },
                            "required": ["word", "start", "end"],
                        },
                    },
                },
                "required": ["speaker", "text", "start", "end", "words"],
            },
        }

        try:
            response = client.models.generate_content(
                model=model_name,
                contents=[
                    genai_types.Part.from_text(text=instructions),
                    genai_types.Part.from_text(
                        text=f"Total audio duration (seconds): {duration_hint:.2f}. Please transcribe the following audio:"
                    ),
                    genai_types.Part.from_uri(
                        file_uri=uploaded.uri,
                        mime_type=uploaded.mime_type or audio_mime,
                    ),
                ],
                config=genai_types.GenerateContentConfig(
                    temperature=0.15,
                    response_mime_type="application/json",
                    response_json_schema=utterance_schema,
                    thinking_config=genai_types.ThinkingConfig(thinking_level="low"),
                ),
            )
        except Exception as exc:
            logger.exception("Gemini transcription failed")
            raise HTTPException(
                status_code=502,
                detail=f"Gemini transcription failed ({type(exc).__name__}: {exc})",
            ) from exc
    finally:
        if client and uploaded:
            try:
                client.files.delete(name=uploaded.name)
            except Exception:
                pass
        if client:
            try:
                client.close()
            except Exception:
                pass

    raw_text = getattr(response, "text", None) or getattr(response, "output_text", None)
    if not raw_text and getattr(response, "candidates", None):
        try:
            raw_text = response.candidates[0].content.parts[0].text
        except Exception:
            raw_text = None

    if not raw_text:
        logger.error("Gemini response missing text payload")
        raise HTTPException(status_code=502, detail="Gemini returned an empty response")

    try:
        parsed = json.loads(raw_text)
    except json.JSONDecodeError as exc:
        logger.error("Failed to parse Gemini JSON: %s", exc)
        raise HTTPException(status_code=502, detail="Gemini returned invalid JSON") from exc

    if not isinstance(parsed, list):
        raise HTTPException(status_code=502, detail="Gemini response must be a list of utterance objects")

    speaker_mapping = {}
    if speaker_name_list:
        for i, name in enumerate(speaker_name_list):
            speaker_mapping[f"SPEAKER {chr(ord('A') + i)}"] = name.upper()
            speaker_mapping[chr(ord('A') + i)] = name.upper()

    normalized = []
    for idx, item in enumerate(parsed):
        if not isinstance(item, dict):
            logger.warning("Skipping non-dict item at index %d", idx)
            continue

        speaker = str(item.get("speaker", "")).strip().upper() or f"SPEAKER {chr(ord('A') + idx)}"

        if speaker in speaker_mapping:
            speaker = speaker_mapping[speaker]

        text = str(item.get("text", "")).strip()
        start_val = float(item.get("start", 0.0))
        end_val = float(item.get("end", start_val))

        raw_words = item.get("words", [])
        if not raw_words:
            logger.warning("Utterance at index %d missing words array", idx)

        words_data = []
        for word_item in raw_words:
            word_text = str(word_item.get("word", "")).strip()
            if not word_text:
                continue
            word_start = float(word_item.get("start", 0.0))
            word_end = float(word_item.get("end", word_start))
            words_data.append({
                "text": word_text,
                "start": max(word_start, 0.0),
                "end": max(word_end, word_start),
                "speaker": speaker,
            })

        line_data = {
            "id": item.get("id") or f"gem-{idx}",
            "speaker": speaker,
            "text": text,
            "start": max(start_val, 0.0),
            "end": max(end_val, start_val),
            "is_continuation": False,
            "words": words_data,
        }

        normalized.append(line_data)

    if not normalized:
        raise HTTPException(status_code=502, detail="Gemini did not return any transcript lines")

    prev_speaker = None
    for item in normalized:
        current_speaker = item.get("speaker", "").strip().upper()
        if prev_speaker is not None and current_speaker == prev_speaker:
            item["is_continuation"] = True
        else:
            item["is_continuation"] = False
        prev_speaker = current_speaker

    logger.info("Gemini transcription completed with %d utterances", len(normalized))
    return normalized
===== END FILE =====

===== FILE: backend/media_processing.py =====
import logging
import mimetypes
import os
import shutil
import subprocess
import tempfile
from typing import Optional, Tuple

from fastapi import HTTPException

try:
    from .storage import download_blob_to_path, upload_clip_file_to_cloud_storage, storage_client, BUCKET_NAME
except ImportError:
    try:
        from storage import download_blob_to_path, upload_clip_file_to_cloud_storage, storage_client, BUCKET_NAME
    except ImportError:
        import storage as storage_module
        download_blob_to_path = storage_module.download_blob_to_path
        upload_clip_file_to_cloud_storage = storage_module.upload_clip_file_to_cloud_storage
        storage_client = storage_module.storage_client
        BUCKET_NAME = storage_module.BUCKET_NAME

try:
    from .transcript_utils import slugify_filename
except ImportError:
    try:
        from transcript_utils import slugify_filename
    except ImportError:
        import transcript_utils as transcript_utils_module
        slugify_filename = transcript_utils_module.slugify_filename

try:
    from .transcriber import ffmpeg_executable_path, get_media_duration
except ImportError:
    try:
        from transcriber import ffmpeg_executable_path, get_media_duration
    except ImportError:
        import transcriber as transcriber_module
        ffmpeg_executable_path = transcriber_module.ffmpeg_executable_path
        get_media_duration = transcriber_module.get_media_duration


def get_ffmpeg_binary() -> str:
    if ffmpeg_executable_path and shutil.which(ffmpeg_executable_path):
        return ffmpeg_executable_path
    fallback = shutil.which("ffmpeg")
    if fallback:
        return fallback
    raise HTTPException(status_code=500, detail="FFmpeg binary not available on server")


def prepare_audio_for_gemini(blob_name: str, content_type: Optional[str]) -> Tuple[str, str, float, str]:
    """Download media, convert to audio if needed, and return (audio_path, mime_type, duration, original_path)."""
    media_path, detected_type = download_blob_to_path(blob_name)
    try:
        if os.path.getsize(media_path) <= 0:
            raise HTTPException(status_code=400, detail="Downloaded media file is empty")
    except OSError:
        raise HTTPException(status_code=500, detail="Unable to access downloaded media file")
    audio_path = media_path
    source_mime = (detected_type or content_type or "").lower().strip()
    if not source_mime:
        source_mime = (mimetypes.guess_type(media_path)[0] or "").lower().strip()

    def canonicalize_audio_mime(mime_value: str, file_path: str) -> str:
        mime_value = (mime_value or "").lower().strip()
        if mime_value in {"audio/mp3", "audio/mpeg", "audio/x-mp3", "audio/mpeg3"}:
            return "audio/mpeg"
        if mime_value in {"audio/x-wav"}:
            return "audio/wav"
        guessed = (mimetypes.guess_type(file_path)[0] or "").lower().strip()
        if guessed in {"audio/mpeg", "audio/mp3", "audio/x-mp3", "audio/mpeg3"}:
            return "audio/mpeg"
        if guessed == "audio/x-wav":
            return "audio/wav"
        return mime_value or guessed or "application/octet-stream"

    supported_audio_mimes = {
        "audio/mpeg",
        "audio/wav",
        "audio/aac",
        "audio/ogg",
        "audio/flac",
        "audio/mp4",
        "audio/aiff",
    }

    audio_mime = canonicalize_audio_mime(source_mime, media_path)
    needs_conversion = (source_mime.startswith("video/") or audio_mime not in supported_audio_mimes)
    if needs_conversion:
        ffmpeg_bin = get_ffmpeg_binary()
        temp_audio = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
        temp_audio.close()
        command = [
            ffmpeg_bin,
            "-y",
            "-i",
            media_path,
            "-vn",
            "-ac",
            "1",
            "-ar",
            "16000",
            "-b:a",
            "96k",
            temp_audio.name,
        ]
        process = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        if process.returncode != 0 or not os.path.exists(temp_audio.name):
            stderr = process.stderr.decode("utf-8", errors="ignore")
            logger = logging.getLogger(__name__)
            logger.error("FFmpeg conversion failed: %s", stderr)
            raise HTTPException(status_code=500, detail="Failed to convert media to audio")
        audio_path = temp_audio.name
        audio_mime = "audio/mpeg"

    max_upload_bytes = int(os.getenv("GEMINI_MAX_UPLOAD_BYTES", str(1024 * 1024 * 1024)))  # 1 GiB default
    try:
        audio_size = os.path.getsize(audio_path)
    except OSError:
        audio_size = None
    if audio_size is not None and max_upload_bytes > 0 and audio_size > max_upload_bytes:
        raise HTTPException(
            status_code=413,
            detail=f"Audio is too large for Gemini refinement ({audio_size} bytes > {max_upload_bytes} bytes)",
        )

    duration_seconds = get_media_duration(audio_path) or 0.0
    return audio_path, audio_mime, duration_seconds, media_path


def clip_media_segment(
    source_blob_name: Optional[str],
    clip_start: float,
    clip_end: float,
    content_type: Optional[str],
    clip_label: str,
    user_id: Optional[str] = None,
    parent_media_key: Optional[str] = None,
) -> Tuple[Optional[str], Optional[str]]:
    if not source_blob_name:
        return None, None

    if clip_end <= clip_start:
        raise HTTPException(status_code=400, detail="Clip duration must be greater than zero")

    bucket = storage_client.bucket(BUCKET_NAME)
    source_blob = bucket.blob(source_blob_name)
    if not source_blob.exists():
        raise HTTPException(status_code=404, detail="Original media for session is unavailable")

    extension = os.path.splitext(source_blob_name)[1]
    if not extension and content_type:
        guessed = mimetypes.guess_extension(content_type)
        extension = guessed or extension
    extension = extension or ".mp4"

    ffmpeg_bin = get_ffmpeg_binary()
    start_time = max(clip_start, 0.0)
    duration = max(clip_end - clip_start, 0.01)

    source_temp = tempfile.NamedTemporaryFile(suffix=extension, delete=False)
    output_temp = tempfile.NamedTemporaryFile(suffix=extension, delete=False)
    try:
        source_temp.close()
        output_temp.close()
        source_blob.download_to_filename(source_temp.name)

        command = [
            ffmpeg_bin,
            "-y",
            "-i",
            source_temp.name,
            "-ss",
            f"{start_time:.3f}",
            "-t",
            f"{duration:.3f}",
            "-c:v",
            "libx264",
            "-preset",
            "fast",
            "-crf",
            "18",
            "-c:a",
            "aac",
            "-b:a",
            "192k",
            "-avoid_negative_ts",
            "make_zero",
            output_temp.name,
        ]

        process = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        if process.returncode != 0:
            stderr = process.stderr.decode("utf-8", errors="ignore")
            logger = logging.getLogger(__name__)
            logger.error("FFmpeg clip command failed: %s", stderr)
            raise HTTPException(status_code=500, detail="FFmpeg failed to produce clip")

        with open(output_temp.name, "rb") as output_file:
            clip_bytes = output_file.read()

        filename_slug = slugify_filename(clip_label or "clip")
        clip_filename = f"{filename_slug}{extension}"
        clip_blob_name = upload_clip_file_to_cloud_storage(
            clip_bytes,
            clip_filename,
            content_type,
            user_id=user_id,
            parent_media_key=parent_media_key,
        )
        return clip_blob_name, content_type
    finally:
        for temp_path in (source_temp.name, output_temp.name):
            try:
                os.remove(temp_path)
            except OSError:
                pass
===== END FILE =====

===== FILE: backend/models.py =====
from typing import List, Optional
from pydantic import BaseModel


class WordTimestamp(BaseModel):
    """Represents a single word with precise timing information."""
    text: str
    start: float  # Start time in milliseconds
    end: float    # End time in milliseconds
    confidence: Optional[float] = None
    speaker: Optional[str] = None


class TranscriptTurn(BaseModel):
    speaker: str
    text: str
    timestamp: Optional[str] = None
    words: Optional[List[WordTimestamp]] = None  # Word-level timestamps for accurate line timing
    is_continuation: bool = False  # True if same speaker as previous turn (no speaker label needed)


class GeminiWordTiming(BaseModel):
    """Word-level timing from Gemini transcription."""
    word: str
    start: float
    end: float


class GeminiUtterance(BaseModel):
    """A single speaker utterance from Gemini transcription."""
    speaker: str
    text: str
    start: float
    end: float
    words: List[GeminiWordTiming]
===== END FILE =====

===== FILE: backend/rev_ai_sync.py =====
import copy
import os
import time
import logging
import requests
import re
import tempfile
from datetime import timedelta
from typing import List, Optional, Dict, Any, Tuple
from difflib import SequenceMatcher

from google.cloud import storage
from google import auth
from google.auth.transport import requests as google_requests
from google.auth import compute_engine
from google.auth.compute_engine import credentials as compute_credentials

# Import models with fallback pattern
try:
    from .models import TranscriptTurn, WordTimestamp
except ImportError:
    try:
        from models import TranscriptTurn, WordTimestamp
    except ImportError:
        import models
        TranscriptTurn = models.TranscriptTurn
        WordTimestamp = models.WordTimestamp

logger = logging.getLogger(__name__)

# Rev AI Alignment API (separate from speech-to-text API)
REV_AI_ALIGNMENT_BASE_URL = "https://api.rev.ai/alignment/v1"

# Cloud Storage bucket for temporary files
BUCKET_NAME = "transcribealpha-uploads-1750110926"

ALIGNMENT_SPLIT_RE = re.compile(r"[-â€“â€”/\\\\]")
ALIGNMENT_CLEAN_RE = re.compile(r"[^\w]+", re.UNICODE)


def normalize_alignment_token(token: str) -> List[str]:
    if not token:
        return []
    normalized = token.replace("â€™", "'").replace("â€˜", "'")
    normalized = normalized.replace("â€œ", "\"").replace("â€", "\"")
    normalized = ALIGNMENT_SPLIT_RE.sub(" ", normalized)
    parts = []
    for part in normalized.split():
        cleaned = ALIGNMENT_CLEAN_RE.sub("", part).lower().strip("_")
        if cleaned:
            parts.append(cleaned)
    return parts


class RevAIAligner:
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        self.storage_client = storage.Client()

        # Get credentials for signing URLs on Cloud Run
        self._signing_credentials = None
        self._service_account_email = None
        self._init_signing_credentials()

    def _init_signing_credentials(self):
        """Initialize credentials for signing URLs using IAM signBlob API."""
        try:
            # Get default credentials
            credentials, project = auth.default()

            # Refresh credentials to ensure token is valid
            auth_req = google_requests.Request()
            credentials.refresh(auth_req)

            # On Cloud Run, we need to get the service account email from metadata server
            # The credentials.service_account_email may just return "default"
            try:
                import urllib.request
                metadata_url = "http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/email"
                req = urllib.request.Request(metadata_url, headers={"Metadata-Flavor": "Google"})
                with urllib.request.urlopen(req, timeout=5) as response:
                    self._service_account_email = response.read().decode('utf-8').strip()
                logger.info("Got service account email from metadata: %s", self._service_account_email)
            except Exception as meta_err:
                logger.warning("Could not get SA email from metadata: %s", meta_err)
                # Fallback to credentials attribute
                if hasattr(credentials, 'service_account_email'):
                    self._service_account_email = credentials.service_account_email

            self._signing_credentials = credentials
            logger.info("Initialized signing credentials for: %s", self._service_account_email)
        except Exception as e:
            logger.warning("Could not initialize signing credentials: %s", e)

    def _create_signed_url(self, blob_name: str, expiration_minutes: int = 15) -> str:
        """Create a signed URL for a Cloud Storage blob using IAM signBlob API."""
        bucket = self.storage_client.bucket(BUCKET_NAME)
        blob = bucket.blob(blob_name)

        # Use IAM-based signing which works with Compute Engine credentials
        if self._service_account_email:
            url = blob.generate_signed_url(
                version="v4",
                expiration=timedelta(minutes=expiration_minutes),
                method="GET",
                service_account_email=self._service_account_email,
                access_token=self._signing_credentials.token,
            )
        else:
            # Fallback - try regular signing (works if running with service account key)
            url = blob.generate_signed_url(
                version="v4",
                expiration=timedelta(minutes=expiration_minutes),
                method="GET"
            )

        logger.info("Generated signed URL for %s (expires in %d min)", blob_name, expiration_minutes)
        return url

    def _upload_text_to_gcs(self, text: str, filename: str) -> str:
        """Upload transcript text to Cloud Storage and return blob name."""
        bucket = self.storage_client.bucket(BUCKET_NAME)
        blob_name = f"rev_ai_temp/{filename}"
        blob = bucket.blob(blob_name)

        blob.upload_from_string(text, content_type="text/plain")
        logger.info("Uploaded transcript to GCS: %s", blob_name)

        return blob_name

    def _upload_audio_to_gcs(self, audio_path: str) -> str:
        """Upload audio file to Cloud Storage and return blob name."""
        bucket = self.storage_client.bucket(BUCKET_NAME)
        filename = os.path.basename(audio_path)
        blob_name = f"rev_ai_temp/{int(time.time())}_{filename}"
        blob = bucket.blob(blob_name)

        blob.upload_from_filename(audio_path)
        logger.info("Uploaded audio to GCS: %s", blob_name)

        return blob_name

    def _cleanup_gcs_blob(self, blob_name: str):
        """Delete a temporary blob from Cloud Storage."""
        try:
            bucket = self.storage_client.bucket(BUCKET_NAME)
            blob = bucket.blob(blob_name)
            blob.delete()
            logger.info("Cleaned up GCS blob: %s", blob_name)
        except Exception as e:
            logger.warning("Failed to cleanup GCS blob %s: %s", blob_name, e)

    def submit_alignment_job(self, audio_url: str, transcript_url: str, metadata: str = "") -> str:
        """Submit alignment job to Rev AI using URLs."""
        url = f"{REV_AI_ALIGNMENT_BASE_URL}/jobs"

        payload = {
            "source_config": {
                "url": audio_url
            },
            "source_transcript_config": {
                "url": transcript_url
            }
        }

        if metadata:
            payload["metadata"] = metadata

        logger.info("Submitting alignment job to Rev AI: %s", url)
        logger.info("Audio URL: %s...", audio_url[:100])
        logger.info("Transcript URL: %s...", transcript_url[:100])

        response = requests.post(url, headers=self.headers, json=payload)

        logger.info("Rev AI response status: %s", response.status_code)
        logger.info("Rev AI response body: %s", response.text[:500] if response.text else 'empty')

        if response.status_code not in (200, 201):
            logger.error("Rev AI Job Submit Failed (HTTP %s): %s", response.status_code, response.text)
            raise Exception(f"Failed to submit alignment job (HTTP {response.status_code}): {response.text}")

        return response.json()['id']

    def get_job_details(self, job_id: str) -> Dict[str, Any]:
        """Get job status from Rev AI."""
        url = f"{REV_AI_ALIGNMENT_BASE_URL}/jobs/{job_id}"
        response = requests.get(url, headers=self.headers)
        response.raise_for_status()
        return response.json()

    def get_alignment_result(self, job_id: str) -> Dict[str, Any]:
        """Get alignment results from Rev AI."""
        url = f"{REV_AI_ALIGNMENT_BASE_URL}/jobs/{job_id}/transcript"
        headers = self.headers.copy()
        headers['Accept'] = 'application/vnd.rev.transcript.v1.0+json'

        response = requests.get(url, headers=headers)
        response.raise_for_status()
        return response.json()

    def wait_for_job(self, job_id: str, poll_interval: int = 3, max_wait: int = 600) -> Dict[str, Any]:
        """Poll for job completion."""
        start_time = time.time()

        while time.time() - start_time < max_wait:
            details = self.get_job_details(job_id)
            status = details.get("status")

            logger.info("Rev AI job %s status: %s", job_id, status)

            if status == "completed":
                return self.get_alignment_result(job_id)
            elif status == "failed":
                failure = details.get('failure', 'Unknown error')
                failure_detail = details.get('failure_detail', '')
                raise Exception(f"Alignment job failed: {failure} - {failure_detail}")

            time.sleep(poll_interval)

        raise Exception(f"Alignment job timed out after {max_wait} seconds")

    def align_transcript(
        self,
        turns: List[dict],
        audio_file_path: Optional[str] = None,
        audio_url: Optional[str] = None,
        source_turns: Optional[List[dict]] = None,
    ) -> List[dict]:
        """
        Align transcript with audio using Rev AI Forced Alignment API.

        Timestamp-only approach (preserves original text):
        1. Build plain text from turns for Rev AI alignment
        2. Also build a flat list of original words (with punctuation intact)
        3. Submit to Rev AI and get word-level timestamps
        4. Map Rev AI timestamps back to original words by position
        5. Update original turns with new timestamps, keeping original text
        """

        # Step 1: Build plain text for Rev AI AND track original words
        plain_text_words = []  # Cleaned words for Rev AI
        clean_word_to_original_idx = []
        original_words = []    # Original words with punctuation, indexed globally
        word_to_turn_idx = []  # Maps global word index to (turn_index, word_index_in_turn)
        turn_word_positions = [0] * len(turns)

        for turn_idx, turn in enumerate(turns):
            turn_text = turn.get('text', '')

            for token in turn_text.split():
                clean_parts = normalize_alignment_token(token)
                if not clean_parts:
                    continue
                original_idx = len(original_words)
                original_words.append(token)  # Keep original with punctuation
                word_to_turn_idx.append((turn_idx, turn_word_positions[turn_idx]))
                turn_word_positions[turn_idx] += 1

                for clean_part in clean_parts:
                    plain_text_words.append(clean_part)
                    clean_word_to_original_idx.append(original_idx)

        full_text_for_api = " ".join(plain_text_words)

        if not full_text_for_api.strip():
            logger.warning("No valid text found to align")
            return turns

        logger.info("Prepared %d words for alignment from %d turns", len(plain_text_words), len(turns))

        # Track blobs for cleanup
        temp_blobs = []

        try:
            # Step 2: Upload transcript text to GCS
            transcript_blob_name = self._upload_text_to_gcs(
                full_text_for_api,
                f"transcript_{int(time.time())}.txt"
            )
            temp_blobs.append(transcript_blob_name)
            transcript_url = self._create_signed_url(transcript_blob_name)

            # Handle audio - either use existing URL or upload file
            if audio_url:
                final_audio_url = audio_url
            elif audio_file_path and os.path.exists(audio_file_path):
                audio_blob_name = self._upload_audio_to_gcs(audio_file_path)
                temp_blobs.append(audio_blob_name)
                final_audio_url = self._create_signed_url(audio_blob_name)
            else:
                raise ValueError("Either audio_url or audio_file_path must be provided")

            # Submit job
            logger.info("Submitting alignment job with %d words", len(plain_text_words))
            job_id = self.submit_alignment_job(final_audio_url, transcript_url)
            logger.info("Alignment job submitted: %s", job_id)

            # Wait for result
            result = self.wait_for_job(job_id)

            # Step 3: Extract aligned words and timestamps from Rev AI response
            aligned_tokens = []
            timestamps = []
            last_end_ms = 0.0
            for monologue in result.get('monologues', []):
                for element in monologue.get('elements', []):
                    if element.get('type') != 'text':
                        continue
                    value = element.get('value') or element.get('text') or ''
                    token_parts = normalize_alignment_token(value)
                    if not token_parts:
                        continue

                    ts = element.get('ts')
                    end_ts = element.get('end_ts')
                    confidence = element.get('confidence', 1.0)

                    if ts is not None:
                        start_ms = ts * 1000.0
                    else:
                        start_ms = last_end_ms  # Fallback to end of previous word

                    if end_ts is not None:
                        end_ms = end_ts * 1000.0
                    else:
                        end_ms = start_ms  # Zero duration if unknown

                    for token in token_parts:
                        aligned_tokens.append(token)
                        timestamps.append({
                            'start': start_ms,
                            'end': end_ms,
                            'confidence': confidence,
                        })
                    last_end_ms = end_ms

            logger.info("Rev AI returned %d aligned words (expected %d)", len(aligned_tokens), len(plain_text_words))

            matcher = SequenceMatcher(None, plain_text_words, aligned_tokens, autojunk=False)
            word_matches = {}
            for tag, i1, i2, j1, j2 in matcher.get_opcodes():
                if tag != "equal":
                    continue
                for offset in range(i2 - i1):
                    word_matches[i1 + offset] = j1 + offset

            logger.info("Alignment matched %d/%d words", len(word_matches), len(plain_text_words))

            # Step 4.5: Build source (ASR/Gemini) timestamp map for fallback
            source_word_timestamps = {}
            if source_turns:
                source_words = []
                source_clean_tokens = []
                source_clean_to_word_idx = []
                for turn in source_turns:
                    for word in turn.get('words') or []:
                        word_text = str(word.get('text', '')).strip()
                        if not word_text:
                            continue
                        try:
                            start_ms = float(word.get('start', 0.0))
                            end_ms = float(word.get('end', start_ms))
                        except (TypeError, ValueError):
                            continue
                        source_words.append({
                            'text': word_text,
                            'start': start_ms,
                            'end': end_ms,
                            'confidence': word.get('confidence'),
                        })
                        source_idx = len(source_words) - 1
                        for part in normalize_alignment_token(word_text):
                            source_clean_tokens.append(part)
                            source_clean_to_word_idx.append(source_idx)

                if source_clean_tokens and plain_text_words:
                    source_matcher = SequenceMatcher(None, plain_text_words, source_clean_tokens, autojunk=False)
                    for tag, i1, i2, j1, j2 in source_matcher.get_opcodes():
                        if tag != "equal":
                            continue
                        for offset in range(i2 - i1):
                            current_clean_idx = i1 + offset
                            source_clean_idx = j1 + offset
                            if current_clean_idx >= len(clean_word_to_original_idx) or source_clean_idx >= len(source_clean_to_word_idx):
                                continue
                            original_idx = clean_word_to_original_idx[current_clean_idx]
                            source_word_idx = source_clean_to_word_idx[source_clean_idx]
                            source_word_timestamps.setdefault(original_idx, []).append(source_words[source_word_idx])

            # Step 5: Update original turns with new timestamps
            # Deep copy turns to avoid mutating input
            updated_turns = copy.deepcopy(turns)

            original_word_timestamps = {}
            for clean_idx, aligned_idx in word_matches.items():
                if clean_idx >= len(clean_word_to_original_idx) or aligned_idx >= len(timestamps):
                    continue
                original_idx = clean_word_to_original_idx[clean_idx]
                original_word_timestamps.setdefault(original_idx, []).append(timestamps[aligned_idx])

            rev_word_ranges = {}
            rev_word_confidence = {}
            for original_idx, ts_list in original_word_timestamps.items():
                start_ms = min(ts['start'] for ts in ts_list)
                end_ms = max(ts['end'] for ts in ts_list)
                confidence_values = [ts.get('confidence') for ts in ts_list if ts.get('confidence') is not None]
                confidence = min(confidence_values) if confidence_values else 1.0
                rev_word_ranges[original_idx] = (start_ms, end_ms)
                rev_word_confidence[original_idx] = confidence

            def find_adjacent_rev(idx: int, max_distance: int) -> Tuple[Optional[int], Optional[int]]:
                prev_idx = None
                next_idx = None
                for offset in range(1, max_distance + 1):
                    candidate = idx - offset
                    if candidate >= 0 and candidate in rev_word_ranges:
                        prev_idx = candidate
                        break
                for offset in range(1, max_distance + 1):
                    candidate = idx + offset
                    if candidate < len(original_words) and candidate in rev_word_ranges:
                        next_idx = candidate
                        break
                return prev_idx, next_idx

            turn_word_data = {i: [] for i in range(len(turns))}
            timed_originals = 0
            filled_adjacent = 0
            filled_source = 0
            filled_wide = 0
            missing_words = 0

            for original_idx, (turn_idx, _) in enumerate(word_to_turn_idx):
                original_word = original_words[original_idx]
                start_ms = None
                end_ms = None
                confidence = None

                if original_idx in rev_word_ranges:
                    start_ms, end_ms = rev_word_ranges[original_idx]
                    confidence = rev_word_confidence.get(original_idx)
                else:
                    prev_idx, next_idx = find_adjacent_rev(original_idx, 1)
                    if prev_idx is not None and next_idx is not None:
                        prev_end = rev_word_ranges[prev_idx][1]
                        next_start = rev_word_ranges[next_idx][0]
                        gap_ms = next_start - prev_end
                        if 0 <= gap_ms <= 3000:
                            midpoint = prev_end + gap_ms / 2.0
                            start_ms = midpoint
                            end_ms = midpoint
                            filled_adjacent += 1

                if start_ms is None:
                    ts_list = source_word_timestamps.get(original_idx)
                    if ts_list:
                        start_ms = min(ts['start'] for ts in ts_list)
                        end_ms = max(ts['end'] for ts in ts_list)
                        confidence_values = [ts.get('confidence') for ts in ts_list if ts.get('confidence') is not None]
                        confidence = min(confidence_values) if confidence_values else None
                        filled_source += 1

                if start_ms is None:
                    prev_idx, next_idx = find_adjacent_rev(original_idx, 3)
                    if prev_idx is not None and next_idx is not None:
                        prev_end = rev_word_ranges[prev_idx][1]
                        next_start = rev_word_ranges[next_idx][0]
                        gap_ms = next_start - prev_end
                        if 0 <= gap_ms <= 5500:
                            midpoint = prev_end + gap_ms / 2.0
                            start_ms = midpoint
                            end_ms = midpoint
                            filled_wide += 1

                if start_ms is None or end_ms is None:
                    start_ms = -1.0
                    end_ms = -1.0
                    missing_words += 1

                if start_ms >= 0 and end_ms >= 0:
                    timed_originals += 1

                turn_word_data[turn_idx].append({
                    'text': original_word,
                    'start': start_ms,
                    'end': end_ms,
                    'confidence': confidence,
                    'speaker': turns[turn_idx].get('speaker', 'UNKNOWN'),
                })

            logger.info(
                "Alignment timed %d/%d words (adjacent=%d, source=%d, widened=%d, missing=%d)",
                timed_originals,
                len(original_words),
                filled_adjacent,
                filled_source,
                filled_wide,
                missing_words,
            )

            # Update each turn with new word data and recalculate timestamp
            for turn_idx, turn in enumerate(updated_turns):
                words = turn_word_data.get(turn_idx, [])
                turn['words'] = words

                valid_words = [word for word in words if word.get('start', -1) >= 0 and word.get('end', -1) >= 0]
                if valid_words:
                    turn_start_sec = valid_words[0]['start'] / 1000.0
                    m, s = int(turn_start_sec // 60), int(turn_start_sec % 60)
                    turn['timestamp'] = f"[{m:02d}:{s:02d}]"

            logger.info("Updated %d turns with Rev AI timestamps (text preserved)", len(updated_turns))
            if updated_turns and updated_turns[0].get('words'):
                first_word = updated_turns[0]['words'][0]
                logger.info("Sample first word: text='%s', start=%.1f ms", first_word.get('text'), first_word.get('start'))

            return updated_turns

        finally:
            # Cleanup temporary GCS blobs
            for blob_name in temp_blobs:
                self._cleanup_gcs_blob(blob_name)
===== END FILE =====

===== FILE: backend/server.py =====
import logging
import os
import sys

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Add current directory and backend directory to path
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, current_dir)
sys.path.insert(0, parent_dir)

try:
    from .config import ALLOWED_ORIGINS
except ImportError:
    try:
        from config import ALLOWED_ORIGINS
    except ImportError:
        import config as config_module
        ALLOWED_ORIGINS = config_module.ALLOWED_ORIGINS

try:
    from .storage import cleanup_expired_clip_sessions, cleanup_old_files
except ImportError:
    try:
        from storage import cleanup_expired_clip_sessions, cleanup_old_files
    except ImportError:
        import storage as storage_module
        cleanup_expired_clip_sessions = storage_module.cleanup_expired_clip_sessions
        cleanup_old_files = storage_module.cleanup_old_files

try:
    from .api.auth import router as auth_router
except ImportError:
    try:
        from api.auth import router as auth_router
    except ImportError:
        import api.auth as auth_module
        auth_router = auth_module.router

try:
    from .api.transcripts import router as transcripts_router
except ImportError:
    try:
        from api.transcripts import router as transcripts_router
    except ImportError:
        import api.transcripts as transcripts_module
        transcripts_router = transcripts_module.router

try:
    from .api.clips import router as clips_router
except ImportError:
    try:
        from api.clips import router as clips_router
    except ImportError:
        import api.clips as clips_module
        clips_router = clips_module.router

try:
    from .api.media import router as media_router
except ImportError:
    try:
        from api.media import router as media_router
    except ImportError:
        import api.media as media_module
        media_router = media_module.router

try:
    from .api.health import router as health_router
except ImportError:
    try:
        from api.health import router as health_router
    except ImportError:
        import api.health as health_module
        health_router = health_module.router


app = FastAPI(
    title="TranscribeAlpha API",
    description="Professional Legal Transcript Generator using AssemblyAI",
    version="2.0.0",
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
)


@app.on_event("startup")
async def startup_event():
    """Run cleanup on startup and log Cloud Storage status."""
    logger.info("Starting TranscribeAlpha with Cloud Storage enabled")
    cleanup_old_files()
    cleanup_expired_clip_sessions()


app.include_router(auth_router)
app.include_router(transcripts_router)
app.include_router(clips_router)
app.include_router(media_router)
app.include_router(health_router)

# Mount static files LAST so API routes take precedence
frontend_dir = os.path.join(os.path.dirname(__file__), "..", "frontend")
app.mount("/", StaticFiles(directory=frontend_dir, html=True), name="frontend")


if __name__ == "__main__":
    # Cloud Run uses PORT environment variable, defaults to 8080
    port = int(os.getenv("PORT", 8080))
    host = os.getenv("HOST", "0.0.0.0")

    # Use Hypercorn for HTTP/2 support on Cloud Run
    import hypercorn.asyncio
    import hypercorn.config
    import asyncio

    config = hypercorn.config.Config()
    config.bind = [f"{host}:{port}"]
    config.application_path = "backend.server:app"

    # Enable HTTP/2 support
    config.h2 = True

    # Run the server
    asyncio.run(hypercorn.asyncio.serve(app, config))
===== END FILE =====

===== FILE: backend/storage.py =====
import io
import json
import logging
import os
import tempfile
import uuid
from datetime import datetime, timedelta, timezone
from typing import List, Optional, Tuple

from google.cloud import storage
from google.api_core import exceptions as gcs_exceptions
from fastapi import HTTPException

try:
    from .config import (
        BUCKET_NAME,
        CLIP_SESSION_PREFIX,
        CLIP_SESSION_TTL_DAYS,
        MEDIA_CLEANUP_PREFIXES,
        MEDIA_TTL_DAYS,
        SNAPSHOT_TTL_DAYS,
    )
except ImportError:
    try:
        from config import (
            BUCKET_NAME,
            CLIP_SESSION_PREFIX,
            CLIP_SESSION_TTL_DAYS,
            MEDIA_CLEANUP_PREFIXES,
            MEDIA_TTL_DAYS,
            SNAPSHOT_TTL_DAYS,
        )
    except ImportError:
        import config as config_module
        BUCKET_NAME = config_module.BUCKET_NAME
        CLIP_SESSION_PREFIX = config_module.CLIP_SESSION_PREFIX
        CLIP_SESSION_TTL_DAYS = config_module.CLIP_SESSION_TTL_DAYS
        MEDIA_CLEANUP_PREFIXES = config_module.MEDIA_CLEANUP_PREFIXES
        MEDIA_TTL_DAYS = config_module.MEDIA_TTL_DAYS
        SNAPSHOT_TTL_DAYS = config_module.SNAPSHOT_TTL_DAYS

logger = logging.getLogger(__name__)

storage_client = storage.Client()


def _clip_blob_name(clip_id: str) -> str:
    return f"{CLIP_SESSION_PREFIX}{clip_id}.json"


def save_current_transcript(media_key: str, transcript_data: dict) -> None:
    """Save current working state for a transcript using media_key as identifier."""
    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        blob_name = f"transcripts/{media_key}/current.json"
        blob = bucket.blob(blob_name)

        # Set TTL metadata
        created_at = transcript_data.get("created_at", datetime.now(timezone.utc).isoformat())
        expires_at = (datetime.now(timezone.utc) + timedelta(days=30)).isoformat()

        blob.metadata = {
            "media_key": media_key,
            "created_at": created_at,
            "expires_at": expires_at,
            "updated_at": datetime.now(timezone.utc).isoformat(),
            "user_id": transcript_data.get("user_id"),
        }
        blob.upload_from_string(json.dumps(transcript_data), content_type="application/json")
        logger.info("Saved current transcript for media_key %s", media_key)
    except Exception as e:
        logger.error("Failed to save current transcript for %s: %s", media_key, e)
        raise


def load_current_transcript(media_key: str) -> Optional[dict]:
    """Load current working state, with fallback to latest snapshot."""
    try:
        bucket = storage_client.bucket(BUCKET_NAME)

        # Try loading current.json
        blob = bucket.blob(f"transcripts/{media_key}/current.json")
        if blob.exists():
            try:
                blob.reload()
            except Exception:
                pass
            data = json.loads(blob.download_as_string())
            if not data.get("media_key"):
                data["media_key"] = media_key

            # Check expiration
            expires_at_str = blob.metadata.get("expires_at") if blob.metadata else None
            if expires_at_str:
                try:
                    expires_at = datetime.fromisoformat(expires_at_str.replace("Z", "+00:00"))
                    if datetime.now(timezone.utc) > expires_at:
                        # Expired, delete and fall through to history
                        blob.delete()
                        logger.info("Deleted expired current transcript for %s", media_key)
                    else:
                        return data
                except ValueError:
                    # If we can't parse expiration, return the data anyway
                    return data

        # Fallback: Load latest snapshot from history
        return load_latest_snapshot_for_media(media_key)

    except Exception as e:
        logger.error("Failed to load transcript for %s: %s", media_key, e)
        return None


def load_latest_snapshot_for_media(media_key: str, prefer_manual_save: bool = True) -> Optional[dict]:
    """Load most recent snapshot, prioritizing manual saves."""
    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        prefix = f"transcripts/{media_key}/history/"
        blobs = list(bucket.list_blobs(prefix=prefix))

        if not blobs:
            return None

        # Separate manual saves from auto-saves
        manual_saves = []
        auto_saves = []

        for blob in blobs:
            try:
                data = json.loads(blob.download_as_string())
                if data.get("is_manual_save"):
                    manual_saves.append((blob.time_created, data))
                else:
                    auto_saves.append((blob.time_created, data))
            except Exception:
                continue

        # Return newest manual save if exists and preferred
        if prefer_manual_save and manual_saves:
            manual_saves.sort(key=lambda x: x[0], reverse=True)
            snapshot = manual_saves[0][1]
            if not snapshot.get("media_key"):
                snapshot["media_key"] = media_key
            return snapshot

        # Otherwise return newest overall
        all_snapshots = manual_saves + auto_saves
        if all_snapshots:
            all_snapshots.sort(key=lambda x: x[0], reverse=True)
            snapshot = all_snapshots[0][1]
            if not snapshot.get("media_key"):
                snapshot["media_key"] = media_key
            return snapshot

        return None

    except Exception as e:
        logger.error("Failed to load snapshot for %s: %s", media_key, e)
        return None


def list_all_transcripts(user_id: str) -> List[dict]:
    """List all transcripts for a user, grouped by media_key."""
    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        prefix = "transcripts/"

        transcripts = []
        for blob in bucket.list_blobs(prefix=prefix):
            if blob.name.endswith("/current.json"):
                try:
                    data = json.loads(blob.download_as_string())

                    # Check user_id from JSON content (blob.metadata isn't populated by list_blobs)
                    if data.get("user_id") != user_id:
                        continue

                    media_key = blob.name.split("/")[1]

                    title_data = data.get("title_data", {})
                    transcripts.append({
                        "media_key": media_key,
                        "title_label": title_data.get("CASE_NAME") or title_data.get("FILE_NAME") or media_key,
                        "updated_at": blob.updated.isoformat() if blob.updated else None,
                        "line_count": len(data.get("lines", [])),
                    })
                except Exception:
                    continue

        return sorted(transcripts, key=lambda x: x["updated_at"] or "", reverse=True)

    except Exception as e:
        logger.error("Failed to list transcripts: %s", e)
        return []


def save_clip_session(clip_id: str, clip_data: dict) -> None:
    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        blob = bucket.blob(_clip_blob_name(clip_id))
        blob.metadata = {
            "clip_id": clip_id,
            "parent_media_key": clip_data.get("parent_media_key"),
            "created_at": clip_data.get("created_at"),
            "expires_at": clip_data.get("expires_at"),
            "user_id": clip_data.get("user_id"),
        }
        blob.upload_from_string(json.dumps(clip_data), content_type="application/json")
        logger.info("Saved clip session %s", clip_id)
    except Exception as exc:
        logger.error("Failed to save clip session %s: %s", clip_id, exc)
        raise


def load_clip_session(clip_id: str) -> Optional[dict]:
    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        blob = bucket.blob(_clip_blob_name(clip_id))
        if not blob.exists():
            return None
        return json.loads(blob.download_as_text())
    except Exception as exc:
        logger.error("Failed to load clip session %s: %s", clip_id, exc)
        return None


def delete_clip_session(clip_id: str) -> None:
    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        blob = bucket.blob(_clip_blob_name(clip_id))
        if blob.exists():
            blob.delete()
            logger.info("Deleted clip session %s", clip_id)
    except Exception as exc:
        logger.error("Failed to delete clip session %s: %s", clip_id, exc)


def prune_snapshots(media_key: str) -> None:
    """Prune snapshots to keep newest 10, preserving newest manual save."""
    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        limit = 10

        prefix = f"transcripts/{media_key}/history/"
        blobs = list(bucket.list_blobs(prefix=prefix))

        # Phase 1: Delete expired snapshots (14+ days old)
        cutoff = datetime.now(timezone.utc) - timedelta(days=SNAPSHOT_TTL_DAYS)
        for blob in blobs[:]:
            if blob.time_created and blob.time_created < cutoff:
                try:
                    blob.delete()
                    blobs.remove(blob)
                except Exception:
                    logger.warning("Failed to delete expired snapshot %s", blob.name)

        # Phase 2: Enforce per-media limit (10 snapshots)
        if len(blobs) <= limit:
            return

        # Load all snapshot data to check is_manual_save flag
        snapshot_info = []
        for blob in blobs:
            try:
                data = json.loads(blob.download_as_string())
                is_manual = data.get("is_manual_save", data.get("saved", False))
                snapshot_info.append({
                    "blob": blob,
                    "created_at": blob.time_created,
                    "is_manual_save": is_manual,
                })
            except Exception:
                continue

        # Sort by creation time (newest first)
        snapshot_info.sort(key=lambda x: x["created_at"] or datetime.min.replace(tzinfo=timezone.utc), reverse=True)

        # Find newest manual save
        newest_manual_save = next(
            (s for s in snapshot_info if s["is_manual_save"]),
            None
        )

        # Keep newest N snapshots
        to_keep = snapshot_info[:limit]

        # Ensure newest manual save is included
        if newest_manual_save and newest_manual_save not in to_keep:
            to_keep[-1] = newest_manual_save

        # Deduplicate and sort keep list again newest first
        keep_blob_names = []
        deduped_keep = []
        for item in to_keep:
            name = item["blob"].name
            if name in keep_blob_names:
                continue
            keep_blob_names.append(name)
            deduped_keep.append(item)
        deduped_keep.sort(key=lambda x: x["created_at"] or datetime.min.replace(tzinfo=timezone.utc), reverse=True)

        # Delete everything not in to_keep
        keep_names_set = {s["blob"].name for s in deduped_keep}
        for s in snapshot_info:
            if s["blob"].name not in keep_names_set:
                try:
                    s["blob"].delete()
                except Exception:
                    logger.warning("Failed to delete excess snapshot %s", s["blob"].name)

    except Exception as exc:
        logger.error("Snapshot pruning failed for %s: %s", media_key, exc)


def cleanup_expired_clip_sessions():
    """Delete stored clip sessions whose TTL has expired."""
    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        now = datetime.now(timezone.utc)
        for blob in bucket.list_blobs(prefix=CLIP_SESSION_PREFIX):
            try:
                raw = blob.download_as_text()
                clip_data = json.loads(raw)
            except Exception:
                continue

            expires_at = clip_data.get("expires_at")
            if not expires_at:
                continue

            try:
                expires_dt = datetime.fromisoformat(expires_at)
            except ValueError:
                try:
                    expires_dt = datetime.fromisoformat(expires_at.replace("Z", "+00:00"))
                except ValueError:
                    continue

            if expires_dt < now:
                try:
                    blob.delete()
                except Exception:
                    logger.warning("Failed to delete expired clip session %s", blob.name)
    except Exception as exc:
        logger.error("Error during clip session cleanup: %s", exc)


def cleanup_old_files():
    """Clean up media files older than MEDIA_TTL_DAYS from Cloud Storage to prevent billing issues."""
    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        cutoff_date = datetime.now(timezone.utc) - timedelta(days=MEDIA_TTL_DAYS)

        deleted_count = 0
        for prefix in MEDIA_CLEANUP_PREFIXES:
            for blob in bucket.list_blobs(prefix=prefix):
                if blob.time_created and blob.time_created < cutoff_date:
                    blob.delete()
                    deleted_count += 1
                    logger.info("Deleted old media file: %s", blob.name)

        logger.info("Media cleanup completed. Deleted %d files.", deleted_count)
    except Exception as e:
        logger.error("Error during cleanup: %s", str(e))


def _format_gcs_error(error: Exception) -> str:
    if isinstance(error, gcs_exceptions.GoogleAPIError):
        return f"{error.__class__.__name__}: {error.message}"
    return str(error)


def _upload_bytes_to_blob(blob: storage.Blob, file_bytes: bytes, content_type: Optional[str] = None) -> None:
    blob.chunk_size = 5 * 1024 * 1024  # 5MB chunking to support larger files consistently
    buffer = io.BytesIO(file_bytes)
    buffer.seek(0)
    blob.upload_from_file(buffer, size=len(file_bytes), content_type=content_type or "application/octet-stream")


def _upload_file_to_blob(blob: storage.Blob, file_path: str, content_type: Optional[str] = None) -> None:
    blob.chunk_size = 5 * 1024 * 1024  # 5MB chunking to support larger files consistently
    with open(file_path, "rb") as stream:
        blob.upload_from_file(stream, content_type=content_type or "application/octet-stream")


def get_blob_metadata(blob_name: str) -> dict:
    """Get metadata for a blob in Cloud Storage"""
    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        blob = bucket.blob(blob_name)
        if not blob.exists():
            return None

        blob.reload()
        metadata = blob.metadata or {}
        return {
            "filename": metadata.get("original_filename", blob_name.split("_")[-1]),
            "content_type": blob.content_type or metadata.get("content_type", "application/octet-stream"),
            "size": blob.size,
            "created": blob.time_created,
            "user_id": metadata.get("user_id"),
            "media_key": metadata.get("media_key"),
            "parent_media_key": metadata.get("parent_media_key"),
            "file_type": metadata.get("file_type"),
        }
    except Exception as e:
        logger.error("Error getting blob metadata: %s", str(e))
        return None


def upload_preview_file_to_cloud_storage(
    file_bytes: bytes,
    filename: str,
    content_type: Optional[str] = None,
    user_id: Optional[str] = None,
    media_key: Optional[str] = None,
) -> str:
    """Upload preview file to Cloud Storage with metadata."""
    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        blob_name = f"preview_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:8]}_{filename}"
        blob = bucket.blob(blob_name)

        metadata = {
            "original_filename": filename,
            "content_type": content_type or "application/octet-stream",
            "file_type": "preview",
        }
        if user_id:
            metadata["user_id"] = user_id
        if media_key:
            metadata["media_key"] = media_key

        blob.metadata = metadata
        if content_type:
            blob.content_type = content_type

        _upload_bytes_to_blob(blob, file_bytes, content_type)
        logger.info("Uploaded preview file %s to Cloud Storage as %s", filename, blob_name)
        return blob_name
    except Exception as e:
        logger.error("Error uploading preview file to Cloud Storage: %s", _format_gcs_error(e))
        raise


def upload_preview_file_to_cloud_storage_from_path(
    file_path: str,
    filename: str,
    content_type: Optional[str] = None,
    user_id: Optional[str] = None,
    media_key: Optional[str] = None,
) -> str:
    """Upload preview file to Cloud Storage from disk with metadata."""
    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        blob_name = f"preview_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:8]}_{filename}"
        blob = bucket.blob(blob_name)

        metadata = {
            "original_filename": filename,
            "content_type": content_type or "application/octet-stream",
            "file_type": "preview",
        }
        if user_id:
            metadata["user_id"] = user_id
        if media_key:
            metadata["media_key"] = media_key

        blob.metadata = metadata
        if content_type:
            blob.content_type = content_type

        _upload_file_to_blob(blob, file_path, content_type)
        logger.info("Uploaded preview file %s to Cloud Storage as %s", filename, blob_name)
        return blob_name
    except Exception as e:
        logger.error("Error uploading preview file to Cloud Storage: %s", _format_gcs_error(e))
        raise


def download_blob_to_path(blob_name: str) -> Tuple[str, Optional[str]]:
    """Download a blob to a temporary file and return the path and content type."""
    bucket = storage_client.bucket(BUCKET_NAME)
    blob = bucket.blob(blob_name)
    if not blob.exists():
        raise HTTPException(status_code=404, detail="Media blob not found")

    extension = os.path.splitext(blob.name)[1]
    suffix = extension or ".bin"
    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=suffix)
    temp_file.close()
    blob.download_to_filename(temp_file.name)
    return temp_file.name, blob.content_type


def upload_clip_file_to_cloud_storage(
    file_bytes: bytes,
    filename: str,
    content_type: Optional[str],
    user_id: Optional[str] = None,
    parent_media_key: Optional[str] = None,
) -> str:
    try:
        bucket = storage_client.bucket(BUCKET_NAME)
        safe_name = filename or "clip-output"
        blob_name = f"clip_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:8]}_{safe_name}"
        blob = bucket.blob(blob_name)
        metadata = {
            "original_filename": safe_name,
            "content_type": content_type or "application/octet-stream",
            "file_type": "clip",
        }
        if user_id:
            metadata["user_id"] = user_id
        if parent_media_key:
            metadata["parent_media_key"] = parent_media_key
        blob.metadata = metadata
        if content_type:
            blob.content_type = content_type
        _upload_bytes_to_blob(blob, file_bytes, content_type)
        logger.info("Uploaded clip media %s to Cloud Storage", blob_name)
        return blob_name
    except Exception as exc:
        logger.error("Error uploading clip media to Cloud Storage: %s", _format_gcs_error(exc))
        raise


async def save_upload_to_tempfile(upload) -> Tuple[str, int]:
    """Stream an UploadFile to disk and return (path, size)."""
    suffix = os.path.splitext(upload.filename or "")[1]
    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=suffix)
    size = 0
    try:
        while True:
            chunk = await upload.read(1024 * 1024)
            if not chunk:
                break
            size += len(chunk)
            temp_file.write(chunk)
    finally:
        temp_file.close()
    try:
        await upload.seek(0)
    except Exception:
        pass
    return temp_file.name, size
===== END FILE =====

===== FILE: backend/transcriber.py =====
import os
import io
import json
import time
import re
import tempfile
import logging
import shutil
from typing import List, Optional
import sys

# Python 3.9+ type hint compatibility
if sys.version_info >= (3, 9):
    from typing import Tuple
else:
    from typing import Tuple as typing_Tuple
    Tuple = typing_Tuple

import ffmpeg
from pydub import AudioSegment

try:
    from .models import TranscriptTurn, WordTimestamp
except ImportError:
    try:
        from models import TranscriptTurn, WordTimestamp
    except ImportError:
        import models
        TranscriptTurn = models.TranscriptTurn
        WordTimestamp = models.WordTimestamp

try:
    from .transcript_formatting import create_docx
except ImportError:
    try:
        from transcript_formatting import create_docx
    except ImportError:
        import transcript_formatting as transcript_formatting_module
        create_docx = transcript_formatting_module.create_docx

# AssemblyAI integration
try:
    import assemblyai as aai
    ASSEMBLYAI_AVAILABLE = True
except ImportError:
    ASSEMBLYAI_AVAILABLE = False
    logging.getLogger(__name__).warning("AssemblyAI SDK not installed. Run: pip install assemblyai")

# Configure both ffmpeg libraries to find ffmpeg
import subprocess
import platform

def find_executable_path(executable_name: str) -> Optional[str]:
    """Cross-platform executable finder"""
    # First try shutil.which (works on all platforms)
    path = shutil.which(executable_name)
    if path:
        return path
    
    # Platform-specific fallback commands
    system = platform.system().lower()
    if system == "windows":
        try:
            result = subprocess.run(['where', executable_name], capture_output=True, text=True, shell=True)
            if result.returncode == 0:
                return result.stdout.strip().split('\n')[0]
        except Exception:
            pass
    else:
        try:
            result = subprocess.run(['which', executable_name], capture_output=True, text=True)
            if result.returncode == 0:
                return result.stdout.strip()
        except Exception:
            pass
    
    return None

def get_ffprobe_path(ffmpeg_path: str) -> Optional[str]:
    """Get ffprobe path from ffmpeg path"""
    if not ffmpeg_path:
        return None
    
    # Get directory and base name
    ffmpeg_dir = os.path.dirname(ffmpeg_path)
    ffmpeg_name = os.path.basename(ffmpeg_path)
    
    # Replace ffmpeg with ffprobe, keeping the same extension
    if ffmpeg_name.endswith('.exe'):
        ffprobe_name = ffmpeg_name.replace('ffmpeg.exe', 'ffprobe.exe')
    else:
        ffprobe_name = ffmpeg_name.replace('ffmpeg', 'ffprobe')
    
    ffprobe_path = os.path.join(ffmpeg_dir, ffprobe_name)
    
    # Check if it exists
    if os.path.exists(ffprobe_path):
        return ffprobe_path
    
    # Try finding ffprobe independently
    return find_executable_path('ffprobe')

# Find ffmpeg and ffprobe
ffmpeg_executable_path = find_executable_path('ffmpeg')
ffprobe_executable_path = None

if ffmpeg_executable_path:
    ffprobe_executable_path = get_ffprobe_path(ffmpeg_executable_path)
    # Configure pydub
    AudioSegment.converter = ffmpeg_executable_path
    AudioSegment.ffmpeg = ffmpeg_executable_path
    if ffprobe_executable_path:
        AudioSegment.ffprobe = ffprobe_executable_path

SUPPORTED_VIDEO_TYPES = ["mp4", "mov", "avi", "mkv"]
SUPPORTED_AUDIO_TYPES = ["mp3", "wav", "m4a", "flac", "ogg", "aac", "aiff"]

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

ASSEMBLYAI_API_KEY = os.getenv("ASSEMBLYAI_API_KEY")
if ASSEMBLYAI_API_KEY and ASSEMBLYAI_AVAILABLE:
    aai.settings.api_key = ASSEMBLYAI_API_KEY
    logger.info("AssemblyAI client initialized successfully")
elif ASSEMBLYAI_AVAILABLE:
    logger.warning("ASSEMBLYAI_API_KEY environment variable not set")

def mark_continuation_turns(turns: List[TranscriptTurn]) -> List[TranscriptTurn]:
    """
    Mark turns as continuations when the same speaker has consecutive turns.

    The first turn of each speaker block gets is_continuation=False (shows speaker label).
    Subsequent turns with the same speaker get is_continuation=True (no speaker label).
    """
    if not turns:
        return turns

    prev_speaker = None
    for turn in turns:
        normalized_speaker = turn.speaker.strip().upper()
        if prev_speaker is not None and normalized_speaker == prev_speaker:
            turn.is_continuation = True
        else:
            turn.is_continuation = False
        prev_speaker = normalized_speaker

    return turns


def convert_video_to_audio(input_path: str, output_path: str, format: str = "mp3") -> Optional[str]:
    try:
        logger.info("Converting %s to %s", input_path, output_path)

        if ffmpeg_executable_path:
            cmd = [
                ffmpeg_executable_path,
                '-i', input_path,
                '-acodec', 'libmp3lame',
                '-y',
                output_path
            ]
            logger.debug("Running command: %s", ' '.join(cmd))
            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode == 0:
                logger.info("Successfully converted to %s", output_path)
                time.sleep(0.5)
                return output_path
            else:
                logger.error("ffmpeg failed with return code %d: %s", result.returncode, result.stderr)
                return None
        else:
            logger.debug("Using ffmpeg-python library as fallback")
            ffmpeg.input(input_path).output(output_path, format=format, acodec='libmp3lame').overwrite_output().run(quiet=True)
            return output_path
    except Exception as e:
        logger.error("Unexpected error in convert_video_to_audio: %s", e)
        return None


def get_audio_mime_type(ext: str) -> Optional[str]:
    mime_map = {
        "mp3": "audio/mpeg",
        "wav": "audio/wav",
        "aiff": "audio/aiff",
        "aac": "audio/aac",
        "ogg": "audio/ogg",
        "flac": "audio/flac",
    }
    return mime_map.get(ext.lower())


def transcribe_with_assemblyai(
    audio_path: str,
    speaker_name_list: Optional[List[str]] = None,
    include_timestamps: bool = True
) -> Optional[List[TranscriptTurn]]:
    """
    Transcribe audio using AssemblyAI with speaker diarization and word-level timestamps.

    Args:
        audio_path: Path to audio file (local file path)
        speaker_name_list: Optional list of speaker names to map to AssemblyAI's labels
        include_timestamps: Whether to include timestamps in output

    Returns:
        List of TranscriptTurn objects with word-level timing data, or None on failure

    Note:
        AssemblyAI labels speakers as "A", "B", "C", etc. This function maps them to
        provided speaker names or generates generic identifiers like "SPEAKER A".
    """
    if not ASSEMBLYAI_AVAILABLE:
        logger.error("AssemblyAI SDK not available")
        return None

    if not ASSEMBLYAI_API_KEY:
        logger.error("ASSEMBLYAI_API_KEY not configured")
        return None

    try:
        # Configure transcription with speaker diarization
        raw_config = aai.RawTranscriptionConfig(
            language_model="slam_1",
            acoustic_model="slam_1",
        )

        config = aai.TranscriptionConfig(
            speaker_labels=True,
            speakers_expected=len(speaker_name_list) if speaker_name_list else None,
            raw_transcription_config=raw_config,
        )

        logger.info(f"Starting AssemblyAI transcription for: {audio_path}")
        logger.info(
            "Speaker diarization enabled, expected speakers: %s",
            len(speaker_name_list) if speaker_name_list else "auto-detect",
        )

        # Transcribe audio file
        transcriber = aai.Transcriber()
        transcript = transcriber.transcribe(audio_path, config=config)

        # Check for errors
        if transcript.status == aai.TranscriptStatus.error:
            logger.error("AssemblyAI transcription failed: %s", transcript.error)
            return None

        logger.info("AssemblyAI transcription completed successfully")
        logger.info(
            "Found %s speaker turns",
            len(transcript.utterances) if transcript.utterances else 0,
        )

        # Convert AssemblyAI utterances to TranscriptTurn format
        turns: List[TranscriptTurn] = []

        for utterance in transcript.utterances or []:
            # Map AssemblyAI speaker labels (A, B, C...) to provided names
            speaker_label = utterance.speaker  # e.g., "A", "B", "C"

            if speaker_name_list and speaker_label:
                try:
                    speaker_idx = ord(speaker_label) - ord("A")
                    if 0 <= speaker_idx < len(speaker_name_list):
                        speaker_name = speaker_name_list[speaker_idx]
                    else:
                        speaker_name = f"SPEAKER {speaker_label}"
                except (TypeError, ValueError):
                    speaker_name = f"SPEAKER {speaker_label}"
            else:
                speaker_name = f"SPEAKER {speaker_label}" if speaker_label else "SPEAKER 1"

            # Convert timestamp from milliseconds to [MM:SS] format for consistency
            timestamp_str = None
            if include_timestamps and getattr(utterance, "start", None) is not None:
                start_ms = utterance.start
                start_seconds = start_ms / 1000.0
                minutes = int(start_seconds // 60)
                seconds = int(start_seconds % 60)
                timestamp_str = f"[{minutes:02d}:{seconds:02d}]"

            # Extract word-level timestamps from utterance
            word_timestamps: List[WordTimestamp] = []
            if hasattr(utterance, "words") and utterance.words:
                for word in utterance.words:
                    word_timestamps.append(
                        WordTimestamp(
                            text=word.text,
                            start=float(word.start),
                            end=float(word.end),
                            confidence=float(word.confidence)
                            if hasattr(word, "confidence") and word.confidence is not None
                            else None,
                            speaker=speaker_name,
                        )
                    )

            turns.append(
                TranscriptTurn(
                    speaker=speaker_name,
                    text=utterance.text,
                    timestamp=timestamp_str,
                    words=word_timestamps if word_timestamps else None,
                )
            )

        logger.info("Converted %s utterances to TranscriptTurn format", len(turns))
        # Mark continuation turns (same speaker as previous)
        turns = mark_continuation_turns(turns)
        return turns

    except Exception as e:
        logger.error("AssemblyAI transcription error: %s", str(e))
        import traceback

        logger.error(traceback.format_exc())
        return None


def get_media_duration(file_path: str) -> Optional[float]:
    """Return the duration of an audio/video file in **seconds** using ffprobe.
    
    Uses the cross-platform ffprobe path detection.
    """
    if not ffprobe_executable_path:
        return None  # ffprobe not available

    try:
        cmd = [
            ffprobe_executable_path,
            "-i",
            file_path,
            "-v",
            "error",
            "-show_entries",
            "format=duration",
            "-of",
            "default=noprint_wrappers=1:nokey=1",
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        duration_str = result.stdout.strip()
        if duration_str:
            return float(duration_str)
    except Exception as e:
        logger.debug("ffprobe duration extraction failed: %s", e)
    return None

def process_transcription(
    file_bytes: Optional[bytes],
    filename: str,
    speaker_names: Optional[List[str]],
    title_data: dict,
    input_path: Optional[str] = None,
):
    with tempfile.TemporaryDirectory() as temp_dir:
        if input_path:
            source_path = input_path
        else:
            if file_bytes is None:
                raise ValueError("file_bytes required when input_path is not provided")
            source_path = os.path.join(temp_dir, filename)
            with open(source_path, "wb") as f:
                f.write(file_bytes)

        ext = filename.split('.')[-1].lower()
        audio_path = None
        if ext in SUPPORTED_VIDEO_TYPES:
            output_audio_filename = f"{os.path.splitext(os.path.basename(filename))[0]}.mp3"
            output_path = os.path.join(temp_dir, output_audio_filename)
            audio_path = convert_video_to_audio(source_path, output_path)
            ext = "mp3"
        elif ext in SUPPORTED_AUDIO_TYPES:
            audio_path = source_path
        else:
            raise ValueError("Unsupported file type")

        mime_type = get_audio_mime_type(ext)

        # ------------------------------------------------------------------
        # Retrieve media duration â€“ prefer direct ffprobe for robustness
        # ------------------------------------------------------------------
        duration_seconds = get_media_duration(audio_path)

        if duration_seconds is None:
            # Fallback to pydub if ffprobe failed for some reason
            audio_segment = None
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    audio_segment = AudioSegment.from_file(audio_path)
                    break
                except (PermissionError, FileNotFoundError) as e:
                    if attempt < max_retries - 1:
                        logger.warning("Attempt %d failed to load audio file: %s. Retrying...", attempt + 1, e)
                        time.sleep(1)
                    else:
                        raise e
            if audio_segment is None:
                raise RuntimeError("Failed to load audio file after multiple attempts")

            duration_seconds = len(audio_segment) / 1000.0

        # ------------------------------------------------------------------
        # Format and store duration for title data
        # ------------------------------------------------------------------
        hours, rem = divmod(duration_seconds, 3600)
        minutes, seconds = divmod(rem, 60)
        file_duration_str = "{:0>2}:{:0>2}:{:0>2}".format(int(hours), int(minutes), int(round(seconds)))
        title_data["FILE_DURATION"] = file_duration_str

        # ------------------------------------------------------------------
        # Proceed with upload & transcription (AssemblyAI only)
        # ------------------------------------------------------------------
        logger.info("Using AssemblyAI transcription engine")

        if not ASSEMBLYAI_AVAILABLE:
            raise RuntimeError("AssemblyAI SDK not installed. Run: pip install assemblyai")

        if not ASSEMBLYAI_API_KEY:
            raise RuntimeError("ASSEMBLYAI_API_KEY environment variable not set")

        turns = transcribe_with_assemblyai(audio_path, speaker_names)

        if not turns:
            raise RuntimeError("AssemblyAI transcription failed")

        docx_bytes = create_docx(title_data, turns)

        return turns, docx_bytes, duration_seconds
===== END FILE =====

===== FILE: backend/transcript_formatting.py =====
import io
import logging
import os
import re
from typing import List, Optional, Tuple

from docx import Document
from docx.shared import Inches, Pt

try:
    from .models import TranscriptTurn, WordTimestamp
except ImportError:
    try:
        from models import TranscriptTurn, WordTimestamp
    except ImportError:
        import models
        TranscriptTurn = models.TranscriptTurn
        WordTimestamp = models.WordTimestamp

logger = logging.getLogger(__name__)


# Shared layout constants used for XML generation and editor exports
SPEAKER_PREFIX_SPACES = 10  # Leading spaces before speaker name in XML (visual simulation)
CONTINUATION_SPACES = 0     # Leading spaces for continuation lines in XML (visual simulation)
SPEAKER_COLON = ":   "      # Colon and spaces after speaker name (total 4 chars)
MAX_TOTAL_LINE_WIDTH = 64   # Maximum total characters per XML line for speaker lines
MAX_CONTINUATION_WIDTH = 64 # Maximum total characters per XML line for continuation lines
MIN_LINE_DURATION_SECONDS = 1.25

# OnCue XML constants
ONCUE_FIRST_PGLN = 101      # First page-line number (page 1, line 1 = 101)
DEFAULT_VIDEO_ID = "1"      # Default video ID for single-video transcripts


def timestamp_to_seconds(timestamp: Optional[str]) -> float:
    """Convert timestamp like '[MM:SS]' or 'MM:SS' to seconds."""
    if not timestamp:
        return 0.0
    ts = timestamp.strip('[]').strip()
    parts = ts.split(':')
    try:
        if len(parts) == 3:
            h, m, s = map(float, parts)
            return h * 3600 + m * 60 + s
        if len(parts) == 2:
            m, s = map(float, parts)
            return m * 60 + s
        return float(ts)
    except ValueError:
        return 0.0


def seconds_to_timestamp(seconds: float) -> str:
    """Convert seconds float to OnCue-style [MM:SS] or [HH:MM:SS] timestamp."""
    if seconds < 0:
        seconds = 0.0
    total_seconds = int(round(seconds))
    hours, remainder = divmod(total_seconds, 3600)
    minutes, secs = divmod(remainder, 60)
    if hours > 0:
        return f"[{hours:02d}:{minutes:02d}:{secs:02d}]"
    return f"[{minutes:02d}:{secs:02d}]"


def wrap_text_for_transcript(text: str, max_width: int) -> List[str]:
    """
    Wrap text to fit within max_width characters, preserving word boundaries.

    Args:
        text: The text to wrap
        max_width: Maximum characters per line of text content

    Returns:
        List of wrapped lines
    """
    if not text:
        return [""]

    if max_width <= 0:
        return [text]

    words = text.split()
    lines = []
    current_line = []
    current_length = 0

    for word in words:
        word_length = len(word)
        # +1 for space before word (except first word)
        space_needed = word_length + (1 if current_line else 0)

        if current_length + space_needed <= max_width:
            current_line.append(word)
            current_length += space_needed
        else:
            if current_line:
                lines.append(" ".join(current_line))
            current_line = [word]
            current_length = word_length

    if current_line:
        lines.append(" ".join(current_line))

    return lines if lines else [""]


def replace_placeholder_text(element, placeholder: str, replacement: str) -> None:
    if hasattr(element, "paragraphs"):
        for paragraph in element.paragraphs:
            replace_placeholder_text(paragraph, placeholder, replacement)
    if hasattr(element, "runs"):
        if placeholder in element.text:
            inline = element.runs
            for idx in range(len(inline)):
                if placeholder in inline[idx].text:
                    inline[idx].text = inline[idx].text.replace(placeholder, replacement)
    if hasattr(element, "tables"):
        for table in element.tables:
            for row in table.rows:
                for cell in row.cells:
                    replace_placeholder_text(cell, placeholder, replacement)


def _resolve_docx_template_path() -> Optional[str]:
    candidates = [
        os.path.join(os.path.dirname(__file__), "..", "transcript_template.docx"),
        os.path.join(os.getcwd(), "transcript_template.docx"),
    ]
    for path in candidates:
        if path and os.path.exists(path):
            return path
    return None


def _resolve_clip_template_path() -> Optional[str]:
    """Resolve path to clip-specific DOCX template."""
    candidates = [
        os.path.join(os.path.dirname(__file__), "..", "clip_template.docx"),
        os.path.join(os.getcwd(), "clip_template.docx"),
    ]
    for path in candidates:
        if path and os.path.exists(path):
            return path
    return None


def create_docx(title_data: dict, transcript_turns: List[TranscriptTurn]) -> bytes:
    """
    Create a DOCX transcript with template-based formatting.
    """
    template_path = _resolve_docx_template_path()
    if template_path:
        doc = Document(template_path)
    else:
        logger.warning("DOCX template not found; falling back to a blank document.")
        doc = Document()

    for key, value in title_data.items():
        placeholder = f"{{{{{key}}}}}"
        replace_placeholder_text(doc, placeholder, str(value) if value else "")

    body_placeholder = "{{TRANSCRIPT_BODY}}"
    placeholder_paragraph = None
    for paragraph in doc.paragraphs:
        if body_placeholder in paragraph.text:
            placeholder_paragraph = paragraph
            break

    if placeholder_paragraph:
        paragraph_element = placeholder_paragraph._element
        paragraph_element.getparent().remove(paragraph_element)
        for turn in transcript_turns:
            p = doc.add_paragraph()
            p.paragraph_format.left_indent = Inches(0.0)
            p.paragraph_format.first_line_indent = Inches(1.0)  # Standard legal transcript indent
            p.paragraph_format.line_spacing = 2.0
            p.paragraph_format.space_after = Pt(0)
            p.paragraph_format.widow_control = False

            if not turn.is_continuation:
                speaker_run = p.add_run(f"{turn.speaker.upper()}:   ")
                speaker_run.font.name = "Courier New"
            text_run = p.add_run(turn.text)
            text_run.font.name = "Courier New"
    else:
        for turn in transcript_turns:
            p = doc.add_paragraph()
            p.paragraph_format.left_indent = Inches(0.0)
            p.paragraph_format.first_line_indent = Inches(1.0)
            p.paragraph_format.line_spacing = 2.0
            p.paragraph_format.space_after = Pt(0)
            p.paragraph_format.widow_control = False

            if not turn.is_continuation:
                speaker_run = p.add_run(f"{turn.speaker.upper()}:   ")
                speaker_run.font.name = "Courier New"
            text_run = p.add_run(turn.text)
            text_run.font.name = "Courier New"

    buffer = io.BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer.read()


def create_clip_docx(title_data: dict, transcript_turns: List[TranscriptTurn], clip_title: str) -> bytes:
    """
    Create a DOCX transcript for a clip using the clip-specific template.

    Args:
        title_data: Session metadata (CASE_NAME, FILE_NAME, etc.)
        transcript_turns: The transcript content
        clip_title: The name/label for this clip

    Returns:
        DOCX file as bytes
    """
    template_path = _resolve_clip_template_path()
    if not template_path:
        logger.warning("Clip template not found; falling back to standard template.")
        template_path = _resolve_docx_template_path()

    if template_path:
        doc = Document(template_path)
    else:
        logger.warning("No DOCX template found; using blank document.")
        doc = Document()

    clip_title_data = dict(title_data)
    clip_title_data["CLIP_TITLE"] = clip_title

    for key, value in clip_title_data.items():
        placeholder = f"{{{{{key}}}}}"
        replace_placeholder_text(doc, placeholder, str(value) if value else "")

    body_placeholder = "{{TRANSCRIPT_BODY}}"
    placeholder_paragraph = None
    for paragraph in doc.paragraphs:
        if body_placeholder in paragraph.text:
            placeholder_paragraph = paragraph
            break

    if placeholder_paragraph:
        paragraph_element = placeholder_paragraph._element
        paragraph_element.getparent().remove(paragraph_element)
        for turn in transcript_turns:
            p = doc.add_paragraph()
            p.paragraph_format.left_indent = Inches(0.0)
            p.paragraph_format.first_line_indent = Inches(1.0)
            p.paragraph_format.line_spacing = 2.0
            p.paragraph_format.space_after = Pt(0)
            p.paragraph_format.widow_control = False

            if not turn.is_continuation:
                speaker_run = p.add_run(f"{turn.speaker.upper()}:   ")
                speaker_run.font.name = "Courier New"
            text_run = p.add_run(turn.text)
            text_run.font.name = "Courier New"
    else:
        for turn in transcript_turns:
            p = doc.add_paragraph()
            p.paragraph_format.left_indent = Inches(0.0)
            p.paragraph_format.first_line_indent = Inches(1.0)
            p.paragraph_format.line_spacing = 2.0
            p.paragraph_format.space_after = Pt(0)
            p.paragraph_format.widow_control = False

            if not turn.is_continuation:
                speaker_run = p.add_run(f"{turn.speaker.upper()}:   ")
                speaker_run.font.name = "Courier New"
            text_run = p.add_run(turn.text)
            text_run.font.name = "Courier New"

    buffer = io.BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer.read()


def parse_docx_to_turns(docx_bytes: bytes) -> List[dict]:
    """
    Parse a DOCX file (exported from TranscribeAlpha) back into transcript turns.

    Expected format per paragraph: "SPEAKER:   Text of what they said..."
    Returns list of dicts with 'speaker' and 'text' keys.

    Automatically skips title page content (Generated Transcript, Case Name, etc.)
    """
    buffer = io.BytesIO(docx_bytes)
    doc = Document(buffer)

    # Title page patterns to skip (case-insensitive)
    title_page_patterns = [
        r'^generated\s+transcript\s*$',
        r'^case\s+name:\s*',
        r'^case\s+number:\s*',
        r'^date:\s*',
        r'^time:\s*',
        r'^location:\s*',
        r'^original\s+file:\s*',
        r'^duration:\s*',
        r'^firm\s*(name|or\s+organization)?\s*:\s*',
    ]
    title_page_regex = re.compile('|'.join(title_page_patterns), re.IGNORECASE)

    turns = []
    for para in doc.paragraphs:
        text = para.text.strip()
        if not text:
            continue

        # Skip title page content
        if title_page_regex.match(text):
            continue

        # Look for speaker pattern: "SPEAKER:   text" (colon + spaces)
        # Handle various spacing patterns
        match = re.match(r'^([A-Z][A-Z0-9\s\-\.\']*?):\s{1,5}(.+)$', text, re.IGNORECASE)
        if match:
            speaker = match.group(1).strip().upper()
            content = match.group(2).strip()
            if speaker and content:
                # Check if same speaker as previous turn
                is_continuation = False
                if turns and turns[-1]['speaker'] == speaker:
                    is_continuation = True
                turns.append({
                    'speaker': speaker,
                    'text': content,
                    'is_continuation': is_continuation,
                })
        else:
            # No speaker pattern - this is a continuation of the previous speaker
            if turns and not text.startswith('['):
                # Create as separate continuation turn (inherits speaker from previous)
                turns.append({
                    'speaker': turns[-1]['speaker'],
                    'text': text,
                    'is_continuation': True,
                })
            elif text and not text.startswith('['):
                turns.append({
                    'speaker': 'UNKNOWN',
                    'text': text,
                    'is_continuation': False,
                })

    logger.info("Parsed %d turns from DOCX (skipped title page content)", len(turns))
    return turns


def calculate_line_timestamps_from_words(
    text_line: str,
    all_words: List[WordTimestamp],
    start_offset: int = 0,
) -> Tuple[float, float, int, bool]:
    """
    Calculate accurate start/stop timestamps for a wrapped line using word-level data.

    This function matches words in the text line to their precise timestamps from
    word-level data, eliminating the need for linear interpolation.

    Args:
        text_line: The text content of the line (without speaker prefix)
        all_words: List of WordTimestamp objects for the entire speaker turn
        start_offset: Index in all_words to start searching from (for continuation lines)

    Returns:
        Tuple of (start_seconds, stop_seconds, words_consumed, boundary_missing)
        - start_seconds: Start time of first word in line (seconds, float)
        - stop_seconds: End time of last word in line (seconds, float)
        - words_consumed: Number of words from all_words that were used
        - boundary_missing: True if the first or last word in the line lacks a valid timestamp
    """
    if not all_words or not text_line.strip():
        logger.debug("calculate_line_timestamps: empty words or text_line")
        return (0.0, 0.0, 0, True)

    line_text_clean = text_line.strip().lower()
    if not line_text_clean:
        return (0.0, 0.0, 0, True)

    raw_line_words = line_text_clean.split()

    def normalize_word_for_match(word: str) -> str:
        normalized = word.lower()
        normalized = normalized.replace("â€™", "'").replace("â€˜", "'")
        normalized = re.sub(r"[^\w]+", "", normalized)
        return normalized.strip("_")

    line_words = [word for word in raw_line_words if normalize_word_for_match(word)]
    if not line_words:
        return (0.0, 0.0, 0, True)

    # Matching words in order with flexible punctuation handling
    matched_words: List[WordTimestamp] = []
    word_idx = start_offset
    line_idx = 0

    while word_idx < len(all_words) and line_idx < len(line_words):
        line_word = normalize_word_for_match(line_words[line_idx])
        if not line_word:
            line_idx += 1
            continue

        current_word = all_words[word_idx]
        current_word_clean = normalize_word_for_match(current_word.text)

        if current_word_clean == line_word:
            matched_words.append(current_word)
            line_idx += 1
        else:
            if line_word in current_word_clean or current_word_clean in line_word:
                matched_words.append(current_word)
                line_idx += 1

        word_idx += 1

    if not matched_words:
        logger.debug("No words matched for line: %s", text_line)
        return (0.0, 0.0, 0, True)

    first_word = matched_words[0]
    last_word = matched_words[-1]

    start_seconds = (first_word.start or 0.0) / 1000.0
    stop_seconds = (last_word.end or 0.0) / 1000.0
    words_consumed = len(matched_words)

    boundary_missing = False
    if first_word.start is None or last_word.end is None:
        boundary_missing = True

    return (start_seconds, stop_seconds, words_consumed, boundary_missing)


def enforce_min_line_durations(
    line_entries: List[dict],
    audio_duration: float,
    min_duration: float = MIN_LINE_DURATION_SECONDS,
) -> List[dict]:
    if not line_entries or min_duration <= 0:
        return line_entries

    starts: List[float] = []
    ends: List[float] = []
    for entry in line_entries:
        try:
            start_val = float(entry.get("start", 0.0))
        except (TypeError, ValueError):
            start_val = 0.0
        try:
            end_val = float(entry.get("end", start_val))
        except (TypeError, ValueError):
            end_val = start_val
        if end_val < start_val:
            end_val = start_val
        starts.append(start_val)
        ends.append(end_val)

    count = len(line_entries)
    gaps: List[float] = []
    for idx in range(count - 1):
        gap = starts[idx + 1] - ends[idx]
        gaps.append(gap if gap > 0 else 0.0)

    left_gap = [0.0] * count
    right_gap = [0.0] * count

    left_gap[0] = starts[0] if starts[0] > 0 else 0.0
    for idx in range(1, count):
        left_gap[idx] = gaps[idx - 1]
    for idx in range(count - 1):
        right_gap[idx] = gaps[idx]
    if audio_duration and audio_duration > 0:
        right_gap[count - 1] = max(audio_duration - ends[count - 1], 0.0)
    else:
        right_gap[count - 1] = 0.0

    desired_left = [0.0] * count
    desired_right = [0.0] * count

    for idx in range(count):
        duration = ends[idx] - starts[idx]
        if duration >= min_duration:
            continue
        need = min_duration - duration
        half = need / 2.0
        left_take = min(half, left_gap[idx])
        right_take = min(half, right_gap[idx])
        remaining = need - (left_take + right_take)
        if remaining > 0:
            left_cap = max(left_gap[idx] - left_take, 0.0)
            right_cap = max(right_gap[idx] - right_take, 0.0)
            if right_cap > left_cap:
                extra_right = min(remaining, right_cap)
                right_take += extra_right
                remaining -= extra_right
            extra_left = min(remaining, left_cap)
            left_take += extra_left
        desired_left[idx] = left_take
        desired_right[idx] = right_take

    left_alloc = [0.0] * count
    right_alloc = [0.0] * count
    left_alloc[0] = min(desired_left[0], left_gap[0])
    right_alloc[count - 1] = min(desired_right[count - 1], right_gap[count - 1])

    for idx in range(count - 1):
        gap = gaps[idx]
        total = desired_right[idx] + desired_left[idx + 1]
        if total <= 0:
            right_alloc[idx] = 0.0
            left_alloc[idx + 1] = 0.0
        elif total <= gap:
            right_alloc[idx] = desired_right[idx]
            left_alloc[idx + 1] = desired_left[idx + 1]
        else:
            scale = gap / total if total > 0 else 0.0
            right_alloc[idx] = desired_right[idx] * scale
            left_alloc[idx + 1] = desired_left[idx + 1] * scale

    for idx, entry in enumerate(line_entries):
        new_start = starts[idx] - left_alloc[idx]
        new_end = ends[idx] + right_alloc[idx]
        if new_start < 0:
            new_start = 0.0
        if audio_duration and audio_duration > 0 and new_end > audio_duration:
            new_end = audio_duration
        if new_end < new_start:
            new_end = new_start
        entry["start"] = new_start
        entry["end"] = new_end

    return line_entries


def compute_transcript_line_entries(
    transcript_turns: List[TranscriptTurn],
    audio_duration: float,
    lines_per_page: int = 25,
    enforce_min_duration: bool = True,
) -> Tuple[List[dict], int]:
    """
    Build per-line timing/layout data from transcript turns for re-use in XML and editor exports.
    """
    line_entries: List[dict] = []
    page = 1
    line_in_page = 1
    last_pgln = ONCUE_FIRST_PGLN

    for turn_idx, turn in enumerate(transcript_turns):
        start_sec = timestamp_to_seconds(turn.timestamp)
        stop_sec: Optional[float] = None

        if turn.words:
            word_starts = [word.start for word in turn.words if word.start is not None and word.start >= 0]
            word_ends = [word.end for word in turn.words if word.end is not None and word.end >= 0]
            if word_starts and word_ends:
                start_sec = min(word_starts) / 1000.0
                stop_sec = max(word_ends) / 1000.0

        if stop_sec is None:
            if turn_idx < len(transcript_turns) - 1:
                stop_sec = timestamp_to_seconds(transcript_turns[turn_idx + 1].timestamp)
            else:
                stop_sec = audio_duration

        if stop_sec < start_sec:
            stop_sec = start_sec

        speaker_name = turn.speaker.upper()
        text = turn.text.strip()

        # Check if this turn is a continuation of the same speaker
        is_turn_continuation = getattr(turn, 'is_continuation', False)

        if is_turn_continuation:
            # Continuation turn: no speaker prefix, use continuation formatting
            speaker_prefix = ""
            max_first_line_text = MAX_CONTINUATION_WIDTH - CONTINUATION_SPACES
        else:
            # New speaker: include speaker prefix
            speaker_prefix = " " * SPEAKER_PREFIX_SPACES + speaker_name + SPEAKER_COLON
            max_first_line_text = MAX_TOTAL_LINE_WIDTH - len(speaker_prefix)

        wrapped_lines = wrap_text_for_transcript(text, max_first_line_text)
        if not wrapped_lines:
            wrapped_lines = [""]

        max_continuation_text = MAX_CONTINUATION_WIDTH - CONTINUATION_SPACES
        remaining_text = " ".join(wrapped_lines[1:])
        continuation_wrapped = []
        if remaining_text:
            continuation_wrapped = wrap_text_for_transcript(remaining_text, max_continuation_text)

        all_lines = [wrapped_lines[0]] + continuation_wrapped
        total_lines = len(all_lines)

        def interpolate_line_block(block_start: float, block_end: float, count: int) -> List[Tuple[float, float]]:
            if count <= 0:
                return []
            if block_end < block_start:
                block_end = block_start
            duration = block_end - block_start
            step = duration / count if count > 0 else duration
            return [(block_start + step * idx, block_start + step * (idx + 1)) for idx in range(count)]

        line_timings: List[Optional[Tuple[float, float]]] = []
        line_errors: List[bool] = []

        if turn.words:
            word_offset = 0

            for line_text in all_lines:
                line_start, line_stop, words_used, boundary_missing = calculate_line_timestamps_from_words(
                    line_text,
                    turn.words,
                    word_offset,
                )
                if words_used == 0:
                    line_timings.append(None)
                    line_errors.append(True)
                else:
                    line_timings.append((line_start, line_stop))
                    line_errors.append(boundary_missing)
                    word_offset += words_used
        else:
            logger.warning("Turn %d has NO word data, using interpolation", turn_idx)
            line_timings = [None for _ in range(total_lines)]
            line_errors = [True for _ in range(total_lines)]

        if any(timing is None for timing in line_timings):
            filled_timings: List[Tuple[float, float]] = []
            idx = 0
            prev_end = start_sec
            while idx < total_lines:
                timing = line_timings[idx]
                if timing is not None:
                    filled_timings.append(timing)
                    prev_end = timing[1]
                    idx += 1
                    continue

                next_idx = idx
                while next_idx < total_lines and line_timings[next_idx] is None:
                    next_idx += 1
                next_start = line_timings[next_idx][0] if next_idx < total_lines else stop_sec
                block = interpolate_line_block(prev_end, next_start, next_idx - idx)
                filled_timings.extend(block)
                if block:
                    prev_end = block[-1][1]
                idx = next_idx

            line_timings = [timing for timing in filled_timings]

        first_line_start, first_line_stop = line_timings[0] if line_timings else (start_sec, start_sec)
        continuation_timings: List[Tuple[float, float]] = []
        for cont_idx in range(1, total_lines):
            continuation_timings.append(line_timings[cont_idx])

        # First line of turn (with or without speaker prefix depending on continuation status)
        pgln = page * 100 + line_in_page
        last_pgln = pgln

        if is_turn_continuation:
            # Continuation turn: format like a continuation line (no speaker)
            rendered_first_line = " " * CONTINUATION_SPACES + wrapped_lines[0]
        else:
            # New speaker: include speaker prefix
            rendered_first_line = speaker_prefix + wrapped_lines[0]

        line_entries.append(
            {
                "id": f"{turn_idx}-0",
                "turn_index": turn_idx,
                "line_index": 0,
                "speaker": speaker_name,
                "text": wrapped_lines[0],
                "rendered_text": rendered_first_line,
                "start": first_line_start,
                "end": first_line_stop,
                "page": page,
                "line": line_in_page,
                "pgln": pgln,
                "is_continuation": is_turn_continuation,
                "total_lines_in_turn": total_lines,
                "timestamp_error": line_errors[0] if line_errors else False,
            }
        )

        line_in_page += 1
        if line_in_page > lines_per_page:
            page += 1
            line_in_page = 1

        # Continuation lines
        for cont_idx, continuation_text in enumerate(continuation_wrapped):
            line_start, line_stop = continuation_timings[cont_idx]

            pgln = page * 100 + line_in_page
            last_pgln = pgln
            line_entries.append(
                {
                    "id": f"{turn_idx}-{cont_idx + 1}",
                    "turn_index": turn_idx,
                    "line_index": cont_idx + 1,
                    "speaker": speaker_name,
                    "text": continuation_text,
                    "rendered_text": " " * CONTINUATION_SPACES + continuation_text,
                    "start": line_start,
                    "end": line_stop,
                    "page": page,
                    "line": line_in_page,
                    "pgln": pgln,
                    "is_continuation": True,
                    "total_lines_in_turn": total_lines,
                    "timestamp_error": line_errors[cont_idx + 1] if line_errors else False,
                }
            )

            line_in_page += 1
            if line_in_page > lines_per_page:
                page += 1
                line_in_page = 1

    if enforce_min_duration:
        enforce_min_line_durations(line_entries, audio_duration, MIN_LINE_DURATION_SECONDS)

    return line_entries, last_pgln


def generate_oncue_xml(
    transcript_turns: List[TranscriptTurn],
    metadata: dict,
    audio_duration: float,
    lines_per_page: int = 25,
    enforce_min_duration: bool = True,
) -> str:
    """
    Generate OnCue-compatible XML from transcript turns.

    This function breaks long utterances into multiple lines to match the DOCX formatting:
    - First line: 15 spaces + "SPEAKER:" (padded to ~21 chars) + text (max ~48 chars)
    - Continuation lines: 5 spaces + text (max ~57 chars)
    - Total line length: ~71 chars for speaker lines, ~62 chars for continuation lines
    """
    from xml.etree.ElementTree import Element, SubElement, tostring

    root = Element(
        "onCue",
        {
            "xmlns:xsd": "http://www.w3.org/2001/XMLSchema",
            "xmlns:xsi": "http://www.w3.org/2001/XMLSchema-instance",
        },
    )

    media_id = metadata.get("MEDIA_ID") or os.path.splitext(metadata.get("FILE_NAME", "deposition"))[0]
    depo_attrs = {
        "mediaId": str(media_id),
        "linesPerPage": str(lines_per_page),
    }
    if metadata.get("DATE"):
        depo_attrs["date"] = metadata["DATE"]

    deposition = SubElement(root, "deposition", depo_attrs)

    video_attrs = {
        "ID": DEFAULT_VIDEO_ID,
        "filename": metadata.get("FILE_NAME", "audio.mp3"),
        "startTime": "0",
        "stopTime": str(int(round(audio_duration))),
        "firstPGLN": str(ONCUE_FIRST_PGLN),
        "lastPGLN": "0",  # placeholder
        "startTuned": "no",
        "stopTuned": "no",
    }
    depo_video = SubElement(deposition, "depoVideo", video_attrs)

    line_entries, last_pgln = compute_transcript_line_entries(
        transcript_turns,
        audio_duration,
        lines_per_page,
        enforce_min_duration=enforce_min_duration,
    )

    for entry in line_entries:
        SubElement(
            depo_video,
            "depoLine",
            {
                "prefix": "",
                "text": entry["rendered_text"],
                "page": str(entry["page"]),
                "line": str(entry["line"]),
                "pgLN": str(entry["pgln"]),
                "videoID": DEFAULT_VIDEO_ID,
                "videoStart": f"{entry['start']:.2f}",
                "videoStop": f"{entry['end']:.2f}",
                "isEdited": "no",
                "isSynched": "yes",
                "isRedacted": "no",
            },
        )

    depo_video.set("lastPGLN", str(last_pgln))

    xml_bytes = tostring(root, encoding="utf-8", method="xml")
    xml_str = xml_bytes.decode("utf-8")
    xml_str = "".join(xml_str.splitlines())  # single line like sample
    return xml_str
===== END FILE =====

===== FILE: backend/transcript_utils.py =====
import base64
import json
import logging
import re
import xml.etree.ElementTree as ET
from datetime import datetime, timezone
from typing import Any, Dict, List, Optional, Tuple

from fastapi import HTTPException

try:
    from .config import DEFAULT_LINES_PER_PAGE
except ImportError:
    try:
        from config import DEFAULT_LINES_PER_PAGE
    except ImportError:
        import config as config_module
        DEFAULT_LINES_PER_PAGE = config_module.DEFAULT_LINES_PER_PAGE

try:
    from .models import TranscriptTurn, WordTimestamp
except ImportError:
    try:
        from models import TranscriptTurn, WordTimestamp
    except ImportError:
        import models
        TranscriptTurn = models.TranscriptTurn
        WordTimestamp = models.WordTimestamp

try:
    from .transcript_formatting import (
        create_docx,
        generate_oncue_xml,
        compute_transcript_line_entries,
        seconds_to_timestamp,
    )
except ImportError:
    try:
        from transcript_formatting import (
            create_docx,
            generate_oncue_xml,
            compute_transcript_line_entries,
            seconds_to_timestamp,
        )
    except ImportError:
        import transcript_formatting as transcript_formatting_module
        create_docx = transcript_formatting_module.create_docx
        generate_oncue_xml = transcript_formatting_module.generate_oncue_xml
        compute_transcript_line_entries = transcript_formatting_module.compute_transcript_line_entries
        seconds_to_timestamp = transcript_formatting_module.seconds_to_timestamp

logger = logging.getLogger(__name__)


def _extract_media_key(data: dict) -> str:
    """Extract media key from session/payload data using priority chain.

    Priority: media_key field > title_data.MEDIA_ID > XML mediaId > filename > blob name > "unknown"
    """
    title_data = data.get("title_data") or {}

    # Direct media_key field
    if data.get("media_key"):
        return str(data["media_key"])

    # MEDIA_ID from title data
    if title_data.get("MEDIA_ID"):
        return str(title_data["MEDIA_ID"])

    # Try to extract from OnCue XML
    xml_filename = title_data.get("FILE_NAME") or title_data.get("CASE_NAME")
    media_id_from_xml = None
    xml_b64 = data.get("oncue_xml_base64")
    if xml_b64:
        try:
            xml_text = base64.b64decode(xml_b64).decode("utf-8", errors="replace")
            root = ET.fromstring(xml_text)
            deposition = root.find(".//deposition")
            if deposition is not None:
                media_id_from_xml = deposition.get("mediaId") or deposition.get("mediaID")
        except Exception:
            media_id_from_xml = None

    # Fallback chain
    key = media_id_from_xml or xml_filename or data.get("media_blob_name") or "unknown"
    return str(key)


def snapshot_media_key(session_data: dict) -> str:
    """Extract media key from session data. Wrapper for backwards compatibility."""
    return _extract_media_key(session_data)


def derive_media_key_from_payload(payload: dict) -> str:
    """Extract media key from payload data. Wrapper for backwards compatibility."""
    return _extract_media_key(payload)


def serialize_transcript_turns(turns: List[TranscriptTurn]) -> List[dict]:
    serialized: List[dict] = []
    for turn in turns:
        turn_dict = turn.model_dump()
        if turn_dict.get("words"):
            sanitized_words = []
            for word in turn_dict["words"]:
                sanitized_words.append(
                    {
                        "text": word.get("text"),
                        "start": float(word.get("start", 0.0)),
                        "end": float(word.get("end", 0.0)),
                        "confidence": word.get("confidence"),
                        "speaker": word.get("speaker"),
                    }
                )
            turn_dict["words"] = sanitized_words
        serialized.append(turn_dict)
    return serialized


def format_transcript_text(turns: List[TranscriptTurn]) -> str:
    return "\n\n".join(
        [
            f"{(turn.timestamp + ' ') if turn.timestamp else ''}{turn.speaker.upper()}:\t\t{turn.text}"
            for turn in turns
        ]
    )


def serialize_line_entries(line_entries: List[dict]) -> List[dict]:
    """Convert line entry timestamps to float for JSON serialization."""
    serialized = []
    for entry in line_entries:
        serialized.append(
            {
                **entry,
                "start": float(entry.get("start", 0.0)),
                "end": float(entry.get("end", 0.0)),
                "timestamp_error": bool(entry.get("timestamp_error", False)),
            }
        )
    return serialized


def build_session_artifacts(
    turns: List[TranscriptTurn],
    title_data: dict,
    audio_duration: float,
    lines_per_page: int,
    enforce_min_line_duration: bool = True,
) -> Tuple[bytes, str, str, List[dict]]:
    """Generate DOCX, OnCue XML, transcript text, and line entries for a session."""
    docx_bytes = create_docx(title_data, turns)
    oncue_xml = generate_oncue_xml(
        turns,
        title_data,
        audio_duration,
        lines_per_page,
        enforce_min_duration=enforce_min_line_duration,
    )
    transcript_text = format_transcript_text(turns)
    line_entries, _ = compute_transcript_line_entries(
        turns,
        audio_duration,
        lines_per_page,
        enforce_min_duration=enforce_min_line_duration,
    )
    serialized_entries = serialize_line_entries(line_entries)
    return docx_bytes, oncue_xml, transcript_text, serialized_entries


def ensure_session_clip_list(session_data: dict) -> List[dict]:
    clips_list = session_data.get("clips")
    if not isinstance(clips_list, list):
        clips_list = []
        session_data["clips"] = clips_list
    return clips_list


def parse_timecode_to_seconds(value: Any) -> Optional[float]:
    if value is None:
        return None
    if isinstance(value, (int, float)):
        return float(value)

    text = str(value).strip()
    if not text:
        return None

    if ":" not in text:
        try:
            return float(text)
        except ValueError:
            return None

    parts = text.split(":")
    if len(parts) > 3:
        return None

    try:
        parts = [float(part) for part in parts]
    except ValueError:
        return None

    if len(parts) == 3:
        hours, minutes, seconds = parts
    elif len(parts) == 2:
        hours = 0.0
        minutes, seconds = parts
    else:
        hours = 0.0
        minutes = 0.0
        seconds = parts[0]

    return hours * 3600 + minutes * 60 + seconds


def parse_pgln(value: Any) -> Optional[int]:
    if value is None:
        return None
    if isinstance(value, int):
        return value
    if isinstance(value, float):
        return int(value)
    text = str(value).strip()
    if not text:
        return None
    try:
        return int(float(text))
    except ValueError:
        return None


def find_line_index_by_id(lines: List[dict], line_id: Any) -> Optional[int]:
    if line_id is None:
        return None
    for idx, line in enumerate(lines):
        if line.get("id") == line_id:
            return idx
    return None


def find_line_index_by_pgln(lines: List[dict], pgln: Optional[int]) -> Optional[int]:
    if pgln is None:
        return None
    for idx, line in enumerate(lines):
        if parse_pgln(line.get("pgln")) == pgln:
            return idx
    return None


def find_line_index_by_time(
    lines: List[dict],
    time_seconds: Optional[float],
    prefer_start: bool,
) -> Optional[int]:
    if time_seconds is None:
        return None
    best_idx = None
    best_delta = None
    for idx, line in enumerate(lines):
        start_val = float(line.get("start", 0.0) or 0.0)
        end_val = float(line.get("end", start_val) or start_val)
        target = start_val if prefer_start else end_val
        delta = abs(target - time_seconds)
        if best_delta is None or delta < best_delta:
            best_delta = delta
            best_idx = idx
    return best_idx


def resolve_line_index(
    lines: List[dict],
    line_id: Any,
    pgln: Optional[int],
    time_seconds: Optional[float],
    prefer_start: bool,
) -> Optional[int]:
    candidate = find_line_index_by_id(lines, line_id)
    if candidate is not None:
        return candidate

    candidate = find_line_index_by_pgln(lines, parse_pgln(pgln))
    if candidate is not None:
        return candidate

    candidate = find_line_index_by_time(lines, time_seconds, prefer_start)
    if candidate is not None:
        return candidate

    return None


def sanitize_clip_label(label: Optional[str], default_name: str) -> str:
    if not label:
        return default_name
    cleaned = str(label).strip()
    if not cleaned:
        return default_name
    # Collapse whitespace and limit length for storage
    cleaned = re.sub(r"\s+", " ", cleaned)
    if len(cleaned) > 120:
        cleaned = cleaned[:120].rstrip()
    return cleaned


def slugify_filename(name: str, default: str = "clip") -> str:
    cleaned = re.sub(r"[^A-Za-z0-9._-]+", "-", name.strip()) if name else ""
    cleaned = cleaned.strip("-._")
    return cleaned or default


def normalize_line_payloads(
    lines_payload: List[dict],
    duration_seconds: float,
) -> Tuple[List[dict], float]:
    normalized_lines = []
    max_end = duration_seconds

    for idx, line in enumerate(lines_payload):
        try:
            start_val = float(line.get("start", 0.0))
            end_val = float(line.get("end", start_val))
        except (TypeError, ValueError):
            raise HTTPException(status_code=400, detail=f"Invalid start/end for line index {idx}")

        if end_val < start_val:
            end_val = start_val

        if duration_seconds > 0:
            start_val = max(0.0, min(start_val, duration_seconds))
            end_val = max(0.0, min(end_val, duration_seconds))
        else:
            start_val = max(0.0, start_val)
            end_val = max(start_val, end_val)

        speaker_name = str(line.get("speaker", "")).strip() or "SPEAKER"
        text_value = str(line.get("text", "")).strip()

        normalized_line = {
            "id": line.get("id") or f"{idx}",
            "speaker": speaker_name.upper(),
            "text": text_value,
            "start": start_val,
            "end": end_val,
            "is_continuation": bool(line.get("is_continuation", False)),
            "timestamp_error": bool(line.get("timestamp_error", False)),
        }

        # Pass through word-level timestamps if present
        if "words" in line and isinstance(line["words"], list):
            normalized_line["words"] = line["words"]

        normalized_lines.append(normalized_line)

        max_end = max(max_end, end_val)

    if duration_seconds == 0 and max_end > 0:
        duration_seconds = max_end
    elif max_end > duration_seconds:
        duration_seconds = max_end

    if any(line.get("timestamp_error") for line in normalized_lines):
        return normalized_lines, duration_seconds

    normalized_lines = sorted(
        enumerate(normalized_lines),
        key=lambda item: (item[1]["start"], item[0]),
    )

    return [item[1] for item in normalized_lines], duration_seconds


def construct_turns_from_lines(normalized_lines: List[dict]) -> List[TranscriptTurn]:
    turns: List[TranscriptTurn] = []
    current_speaker: Optional[str] = None
    current_text_parts: List[str] = []
    current_words: List[WordTimestamp] = []
    current_start: Optional[float] = None

    def flush_turn():
        nonlocal current_speaker, current_text_parts, current_words, current_start
        if current_speaker is None:
            return
        full_text = " ".join([part for part in current_text_parts if part]).strip()
        timestamp_str = seconds_to_timestamp(current_start) if current_start is not None else None
        turns.append(
            TranscriptTurn(
                speaker=current_speaker,
                text=full_text,
                timestamp=timestamp_str,
                words=current_words if current_words else None,
            )
        )
        current_speaker = None
        current_text_parts = []
        current_words = []
        current_start = None

    for line in normalized_lines:
        speaker = str(line.get("speaker", "")).strip() or "SPEAKER"
        text_val = str(line.get("text", "")).strip()
        start_val = float(line.get("start", 0.0))
        end_val = float(line.get("end", start_val))

        should_start_new = current_speaker is None or speaker.upper() != current_speaker

        if should_start_new:
            flush_turn()
            current_speaker = speaker.upper()
            current_start = start_val

        current_text_parts.append(text_val)

        line_words = line.get("words")
        if isinstance(line_words, list) and len(line_words) > 0:
            for word_data in line_words:
                if not isinstance(word_data, dict):
                    continue
                word_text = str(word_data.get("text", "")).strip()
                if not word_text:
                    continue
                word_start = float(word_data.get("start", 0.0))
                word_end = float(word_data.get("end", word_start))
                current_words.append(
                    WordTimestamp(
                        text=word_text,
                        start=word_start * 1000.0,
                        end=max(word_end * 1000.0, word_start * 1000.0),
                        confidence=None,
                        speaker=current_speaker,
                    )
                )
        else:
            tokens = [tok for tok in text_val.split() if tok]
            if not tokens:
                continue
            line_duration = max(end_val - start_val, 0.01)
            word_count = len(tokens)
            for word_idx, token in enumerate(tokens):
                token_start = start_val + (line_duration * word_idx / word_count)
                if word_idx < word_count - 1:
                    token_end = start_val + (line_duration * (word_idx + 1) / word_count)
                else:
                    token_end = end_val
                current_words.append(
                    WordTimestamp(
                        text=token,
                        start=token_start * 1000.0,
                        end=token_end * 1000.0,
                        confidence=None,
                        speaker=current_speaker,
                    )
                )

    flush_turn()

    # Mark continuation turns (same speaker as previous)
    prev_speaker = None
    for turn in turns:
        if prev_speaker is not None and turn.speaker.strip().upper() == prev_speaker:
            turn.is_continuation = True
        else:
            turn.is_continuation = False
        prev_speaker = turn.speaker.strip().upper()

    return turns


def parse_oncue_xml(xml_text: str) -> Dict[str, Any]:
    try:
        root = ET.fromstring(xml_text)
    except ET.ParseError as exc:
        raise HTTPException(status_code=400, detail=f"Invalid OnCue XML: {exc}")

    deposition = root.find(".//deposition")
    depo_video = root.find(".//depoVideo")

    def first_attr(element: Optional[ET.Element], keys: List[str]) -> str:
        if element is None:
            return ""
        for key in keys:
            value = element.attrib.get(key)
            if value:
                return value.strip()
        return ""

    def first_text(keys: List[str]) -> str:
        for key in keys:
            node = root.find(f".//{key}")
            if node is not None and node.text:
                text_value = node.text.strip()
                if text_value:
                    return text_value
        return ""

    case_name = first_attr(deposition, ["caseName", "case", "case_name", "caption"]) or first_text(
        ["caseName", "case", "caption", "case_name"]
    )
    case_number = first_attr(deposition, ["caseNumber", "caseNo", "case_number"]) or first_text(
        ["caseNumber", "caseNo", "case_number"]
    )
    firm_name = first_attr(
        deposition,
        ["firm", "firmName", "organization", "organizationName", "firmOrOrganization"],
    ) or first_text(["firm", "firmName", "organization", "organizationName", "firmOrOrganization"])
    date_value = first_attr(deposition, ["date"]) or first_text(["date"])
    time_value = first_attr(deposition, ["time"]) or first_text(["time"])
    location_value = first_attr(deposition, ["location", "place"]) or first_text(["location", "place"])
    file_name = (
        first_attr(depo_video, ["filename"])
        or first_attr(deposition, ["filename", "fileName", "file_name"])
        or first_text(["FILE_NAME", "fileName", "file_name"])
    )

    title_data = {
        "CASE_NAME": case_name,
        "CASE_NUMBER": case_number,
        "FIRM_OR_ORGANIZATION_NAME": firm_name,
        "DATE": date_value,
        "TIME": time_value,
        "LOCATION": location_value,
        "FILE_NAME": file_name or "imported.xml",
        "FILE_DURATION": "",
    }

    lines: List[dict] = []
    current_speaker: Optional[str] = None
    max_end = 0.0

    for line_idx, line_elem in enumerate(root.findall(".//depoLine")):
        raw_text = line_elem.attrib.get("text", "")
        video_start = float(line_elem.attrib.get("videoStart", "0") or 0)
        video_stop = float(line_elem.attrib.get("videoStop", "0") or video_start)
        page = line_elem.attrib.get("page")
        line_number = line_elem.attrib.get("line")
        pgln = line_elem.attrib.get("pgLN")

        trimmed = raw_text.lstrip()
        speaker = current_speaker
        text_content = trimmed
        is_continuation = True

        if trimmed:
            if ":   " in trimmed:
                potential_speaker, remainder = trimmed.split(":   ", 1)
                if potential_speaker.strip():
                    speaker = potential_speaker.strip().upper()
                    text_content = remainder.strip()
                    is_continuation = False
            elif current_speaker is None:
                speaker = "SPEAKER"
                text_content = trimmed.strip()
                is_continuation = False
        else:
            text_content = ""

        if speaker is None:
            speaker = "SPEAKER"

        current_speaker = speaker
        max_end = max(max_end, video_stop)

        lines.append(
            {
                "id": line_elem.attrib.get("pgLN", f"{line_idx}"),
                "speaker": speaker,
                "text": text_content,
                "start": video_start,
                "end": video_stop,
                "page": int(page) if page and page.isdigit() else None,
                "line": int(line_number) if line_number and line_number.isdigit() else None,
                "pgln": int(pgln) if pgln and pgln.isdigit() else None,
                "is_continuation": is_continuation,
            }
        )

    duration_seconds = max_end
    hours, rem = divmod(duration_seconds, 3600)
    minutes, seconds = divmod(rem, 60)
    title_data["FILE_DURATION"] = "{:0>2}:{:0>2}:{:0>2}".format(int(hours), int(minutes), int(round(seconds)))

    return {
        "lines": lines,
        "title_data": title_data,
        "audio_duration": duration_seconds,
    }


def build_snapshot_payload(
    session_data: dict,
    lines_override: Optional[List[dict]] = None,
    title_override: Optional[dict] = None,
    is_manual_save: bool = False,
) -> dict:
    """Create a snapshot payload with XML + lines + media references."""
    xml_b64 = session_data.get("oncue_xml_base64")
    title_data = title_override or session_data.get("title_data") or {}
    lines_per_page = session_data.get("lines_per_page", DEFAULT_LINES_PER_PAGE)
    audio_duration = float(session_data.get("audio_duration") or 0.0)
    source_lines = lines_override if lines_override is not None else session_data.get("lines") or []

    # CRITICAL FIX: Always include media references for playback recovery
    media_blob_name = session_data.get("media_blob_name")
    media_content_type = session_data.get("media_content_type")

    if not xml_b64:
        # Rebuild XML from lines as a fallback
        normalized_lines, audio_duration = normalize_line_payloads(source_lines, audio_duration)
        turns = construct_turns_from_lines(normalized_lines)
        if not turns:
            raise HTTPException(status_code=400, detail="Unable to build snapshot XML from transcript lines")
        _, oncue_xml, _, updated_lines = build_session_artifacts(
            turns,
            title_data,
            audio_duration,
            lines_per_page,
            enforce_min_line_duration=False,
        )
        xml_b64 = base64.b64encode(oncue_xml.encode("utf-8")).decode()
        source_lines = updated_lines

    created_at = datetime.now(timezone.utc).isoformat()
    snapshot_payload = {
        "media_key": snapshot_media_key(session_data),
        "created_at": created_at,
        "title_data": title_data,
        "title_label": title_data.get("CASE_NAME") or title_data.get("FILE_NAME") or "",
        "audio_duration": audio_duration,
        "lines_per_page": lines_per_page,
        "lines": source_lines,
        "oncue_xml_base64": xml_b64,
        "line_count": len(source_lines),
        "is_manual_save": is_manual_save,
        "user_id": session_data.get("user_id"),
        # CRITICAL: Include media references for playback recovery
        "media_blob_name": media_blob_name,
        "media_content_type": media_content_type,
    }
    if session_data.get("source_turns"):
        snapshot_payload["source_turns"] = session_data["source_turns"]
    return snapshot_payload


def parse_iso_datetime(value: Optional[str]) -> Optional[datetime]:
    if not value:
        return None
    try:
        return datetime.fromisoformat(value)
    except ValueError:
        try:
            return datetime.fromisoformat(value.replace("Z", "+00:00"))
        except ValueError:
            return None
===== END FILE =====

===== FILE: clip_template.docx =====
[binary file omitted]
===== END FILE =====

===== FILE: cloudbuild.yaml =====
steps:
  # Build the container image
  - name: 'gcr.io/cloud-builders/docker'
    args: ['build', '-t', 'us-central1-docker.pkg.dev/$PROJECT_ID/transcribealpha/app:$COMMIT_SHA', '.']
  
  # Push the container image to Artifact Registry
  - name: 'gcr.io/cloud-builders/docker'
    args: ['push', 'us-central1-docker.pkg.dev/$PROJECT_ID/transcribealpha/app:$COMMIT_SHA']
  
  # Deploy container image to Cloud Run
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: gcloud
    args:
      - 'run'
      - 'deploy'
      - 'transcribealpha-assemblyai'
      - '--image'
      - 'us-central1-docker.pkg.dev/$PROJECT_ID/transcribealpha/app:$COMMIT_SHA'
      - '--region'
      - 'us-central1'
      - '--platform'
      - 'managed'
      - '--allow-unauthenticated'
      - '--memory'
      - '2Gi'
      - '--cpu'
      - '1'
      - '--max-instances'
      - '10'
      - '--port'
      - '8080'
      - '--use-http2'
      - '--set-env-vars'
      - 'ASSEMBLYAI_API_KEY=${_ASSEMBLYAI_API_KEY},GEMINI_API_KEY=${_GEMINI_API_KEY},GEMINI_MODEL_NAME=${_GEMINI_MODEL_NAME},JWT_SECRET_KEY=${_JWT_SECRET_KEY},REV_AI_API_KEY=${_REV_AI_API_KEY},ENVIRONMENT=production,GOOGLE_CLOUD_PROJECT=${PROJECT_ID}'

# Store images in Google Artifact Registry
images:
  - us-central1-docker.pkg.dev/$PROJECT_ID/transcribealpha/app:$COMMIT_SHA

# Substitution variables (set these in Cloud Build trigger)
substitutions:
  _ASSEMBLYAI_API_KEY: 'your-assemblyai-key-here'
  _GEMINI_API_KEY: 'your-gemini-key-here'
  _GEMINI_MODEL_NAME: 'models/gemini-3-pro-preview'
  _JWT_SECRET_KEY: 'your-jwt-secret-key-here-use-a-long-random-string'
  _REV_AI_API_KEY: 'your-rev-ai-key-here'

# Build options
options:
  logging: CLOUD_LOGGING_ONLY
  machineType: 'E2_HIGHCPU_8'

# Build timeout
timeout: '1200s'

# Trigger rebuild (no functional changes)
===== END FILE =====

===== FILE: frontend-next/.eslintrc.json =====
{
  "extends": "next/core-web-vitals"
}
===== END FILE =====

===== FILE: frontend-next/next-env.d.ts =====
/// <reference types="next" />
/// <reference types="next/image-types/global" />

// NOTE: This file should not be edited
// see https://nextjs.org/docs/basic-features/typescript for more information.
===== END FILE =====

===== FILE: frontend-next/next.config.js =====
/** @type {import('next').NextConfig} */
const nextConfig = {
  output: 'export',
  trailingSlash: true,
  images: {
    unoptimized: true
  },
  assetPrefix: '',
  basePath: '',
}

module.exports = nextConfig
===== END FILE =====

===== FILE: frontend-next/package-lock.json =====
{
  "name": "transcribealpha-frontend",
  "version": "1.0.0",
  "lockfileVersion": 3,
  "requires": true,
  "packages": {
    "": {
      "name": "transcribealpha-frontend",
      "version": "1.0.0",
      "dependencies": {
        "@types/node": "^20.0.0",
        "@types/react": "^18.2.0",
        "@types/react-dom": "^18.2.0",
        "next": "14.0.0",
        "react": "^18.2.0",
        "react-dom": "^18.2.0",
        "typescript": "^5.0.0"
      },
      "devDependencies": {
        "autoprefixer": "^10.4.0",
        "eslint": "^8.0.0",
        "eslint-config-next": "14.0.0",
        "postcss": "^8.4.0",
        "tailwindcss": "^3.3.0"
      }
    },
    "node_modules/@alloc/quick-lru": {
      "version": "5.2.0",
      "resolved": "https://registry.npmjs.org/@alloc/quick-lru/-/quick-lru-5.2.0.tgz",
      "integrity": "sha512-UrcABB+4bUrFABwbluTIBErXwvbsU/V7TZWfmbgJfbkwiBuziS9gxdODUyuiecfdGQ85jglMW6juS3+z5TsKLw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/@emnapi/core": {
      "version": "1.4.5",
      "resolved": "https://registry.npmjs.org/@emnapi/core/-/core-1.4.5.tgz",
      "integrity": "sha512-XsLw1dEOpkSX/WucdqUhPWP7hDxSvZiY+fsUC14h+FtQ2Ifni4znbBt8punRX+Uj2JG/uDb8nEHVKvrVlvdZ5Q==",
      "dev": true,
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "@emnapi/wasi-threads": "1.0.4",
        "tslib": "^2.4.0"
      }
    },
    "node_modules/@emnapi/runtime": {
      "version": "1.4.5",
      "resolved": "https://registry.npmjs.org/@emnapi/runtime/-/runtime-1.4.5.tgz",
      "integrity": "sha512-++LApOtY0pEEz1zrd9vy1/zXVaVJJ/EbAF3u0fXIzPJEDtnITsBGbbK0EkM72amhl/R5b+5xx0Y/QhcVOpuulg==",
      "dev": true,
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "tslib": "^2.4.0"
      }
    },
    "node_modules/@emnapi/wasi-threads": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/@emnapi/wasi-threads/-/wasi-threads-1.0.4.tgz",
      "integrity": "sha512-PJR+bOmMOPH8AtcTGAyYNiuJ3/Fcoj2XN/gBEWzDIKh254XO+mM9XoXHk5GNEhodxeMznbg7BlRojVbKN+gC6g==",
      "dev": true,
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "tslib": "^2.4.0"
      }
    },
    "node_modules/@eslint-community/eslint-utils": {
      "version": "4.7.0",
      "resolved": "https://registry.npmjs.org/@eslint-community/eslint-utils/-/eslint-utils-4.7.0.tgz",
      "integrity": "sha512-dyybb3AcajC7uha6CvhdVRJqaKyn7w2YKqKyAN37NKYgZT36w+iRb0Dymmc5qEJ549c/S31cMMSFd75bteCpCw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "eslint-visitor-keys": "^3.4.3"
      },
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      },
      "peerDependencies": {
        "eslint": "^6.0.0 || ^7.0.0 || >=8.0.0"
      }
    },
    "node_modules/@eslint-community/regexpp": {
      "version": "4.12.1",
      "resolved": "https://registry.npmjs.org/@eslint-community/regexpp/-/regexpp-4.12.1.tgz",
      "integrity": "sha512-CCZCDJuduB9OUkFkY2IgppNZMi2lBQgD2qzwXkEia16cge2pijY/aXi96CJMquDMn3nJdlPV1A5KrJEXwfLNzQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": "^12.0.0 || ^14.0.0 || >=16.0.0"
      }
    },
    "node_modules/@eslint/eslintrc": {
      "version": "2.1.4",
      "resolved": "https://registry.npmjs.org/@eslint/eslintrc/-/eslintrc-2.1.4.tgz",
      "integrity": "sha512-269Z39MS6wVJtsoUl10L60WdkhJVdPG24Q4eZTH3nnF6lpvSShEK3wQjDX9JRWAUPvPh7COouPpU9IrqaZFvtQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ajv": "^6.12.4",
        "debug": "^4.3.2",
        "espree": "^9.6.0",
        "globals": "^13.19.0",
        "ignore": "^5.2.0",
        "import-fresh": "^3.2.1",
        "js-yaml": "^4.1.0",
        "minimatch": "^3.1.2",
        "strip-json-comments": "^3.1.1"
      },
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      }
    },
    "node_modules/@eslint/js": {
      "version": "8.57.1",
      "resolved": "https://registry.npmjs.org/@eslint/js/-/js-8.57.1.tgz",
      "integrity": "sha512-d9zaMRSTIKDLhctzH12MtXvJKSSUhaHcjV+2Z+GK+EEY7XKpP5yR4x+N3TAcHTcu963nIr+TMcCb4DBCYX1z6Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      }
    },
    "node_modules/@humanwhocodes/config-array": {
      "version": "0.13.0",
      "resolved": "https://registry.npmjs.org/@humanwhocodes/config-array/-/config-array-0.13.0.tgz",
      "integrity": "sha512-DZLEEqFWQFiyK6h5YIeynKx7JlvCYWL0cImfSRXZ9l4Sg2efkFGTuFf6vzXjK1cq6IYkU+Eg/JizXw+TD2vRNw==",
      "deprecated": "Use @eslint/config-array instead",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "@humanwhocodes/object-schema": "^2.0.3",
        "debug": "^4.3.1",
        "minimatch": "^3.0.5"
      },
      "engines": {
        "node": ">=10.10.0"
      }
    },
    "node_modules/@humanwhocodes/module-importer": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/@humanwhocodes/module-importer/-/module-importer-1.0.1.tgz",
      "integrity": "sha512-bxveV4V8v5Yb4ncFTT3rPSgZBOpCkjfK0y4oVVVJwIuDVBRMDXrPyXRL988i5ap9m9bnyEEjWfm5WkBmtffLfA==",
      "dev": true,
      "license": "Apache-2.0",
      "engines": {
        "node": ">=12.22"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/nzakas"
      }
    },
    "node_modules/@humanwhocodes/object-schema": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/@humanwhocodes/object-schema/-/object-schema-2.0.3.tgz",
      "integrity": "sha512-93zYdMES/c1D69yZiKDBj0V24vqNzB/koF26KPaagAfd3P/4gUlh3Dys5ogAK+Exi9QyzlD8x/08Zt7wIKcDcA==",
      "deprecated": "Use @eslint/object-schema instead",
      "dev": true,
      "license": "BSD-3-Clause"
    },
    "node_modules/@isaacs/cliui": {
      "version": "8.0.2",
      "resolved": "https://registry.npmjs.org/@isaacs/cliui/-/cliui-8.0.2.tgz",
      "integrity": "sha512-O8jcjabXaleOG9DQ0+ARXWZBTfnP4WNAqzuiJK7ll44AmxGKv/J2M4TPjxjY3znBCfvBXFzucm1twdyFybFqEA==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "string-width": "^5.1.2",
        "string-width-cjs": "npm:string-width@^4.2.0",
        "strip-ansi": "^7.0.1",
        "strip-ansi-cjs": "npm:strip-ansi@^6.0.1",
        "wrap-ansi": "^8.1.0",
        "wrap-ansi-cjs": "npm:wrap-ansi@^7.0.0"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@isaacs/cliui/node_modules/ansi-regex": {
      "version": "6.1.0",
      "resolved": "https://registry.npmjs.org/ansi-regex/-/ansi-regex-6.1.0.tgz",
      "integrity": "sha512-7HSX4QQb4CspciLpVFwyRe79O3xsIZDDLER21kERQ71oaPodF8jL725AgJMFAYbooIqolJoRLuM81SpeUkpkvA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-regex?sponsor=1"
      }
    },
    "node_modules/@isaacs/cliui/node_modules/strip-ansi": {
      "version": "7.1.0",
      "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-7.1.0.tgz",
      "integrity": "sha512-iq6eVVI64nQQTRYq2KtEg2d2uU7LElhTJwsH4YzIHZshxlgZms/wIc4VoDQTlG/IvVIrBKG06CrZnp0qv7hkcQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-regex": "^6.0.1"
      },
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/strip-ansi?sponsor=1"
      }
    },
    "node_modules/@jridgewell/gen-mapping": {
      "version": "0.3.13",
      "resolved": "https://registry.npmjs.org/@jridgewell/gen-mapping/-/gen-mapping-0.3.13.tgz",
      "integrity": "sha512-2kkt/7niJ6MgEPxF0bYdQ6etZaA+fQvDcLKckhy1yIQOzaoKjBBjSj63/aLVjYE3qhRt5dvM+uUyfCg6UKCBbA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jridgewell/sourcemap-codec": "^1.5.0",
        "@jridgewell/trace-mapping": "^0.3.24"
      }
    },
    "node_modules/@jridgewell/resolve-uri": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/@jridgewell/resolve-uri/-/resolve-uri-3.1.2.tgz",
      "integrity": "sha512-bRISgCIjP20/tbWSPWMEi54QVPRZExkuD9lJL+UIxUKtwVJA8wW1Trb1jMs1RFXo1CBTNZ/5hpC9QvmKWdopKw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.0.0"
      }
    },
    "node_modules/@jridgewell/sourcemap-codec": {
      "version": "1.5.5",
      "resolved": "https://registry.npmjs.org/@jridgewell/sourcemap-codec/-/sourcemap-codec-1.5.5.tgz",
      "integrity": "sha512-cYQ9310grqxueWbl+WuIUIaiUaDcj7WOq5fVhEljNVgRfOUhY9fy2zTvfoqWsnebh8Sl70VScFbICvJnLKB0Og==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@jridgewell/trace-mapping": {
      "version": "0.3.30",
      "resolved": "https://registry.npmjs.org/@jridgewell/trace-mapping/-/trace-mapping-0.3.30.tgz",
      "integrity": "sha512-GQ7Nw5G2lTu/BtHTKfXhKHok2WGetd4XYcVKGx00SjAk8GMwgJM3zr6zORiPGuOE+/vkc90KtTosSSvaCjKb2Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jridgewell/resolve-uri": "^3.1.0",
        "@jridgewell/sourcemap-codec": "^1.4.14"
      }
    },
    "node_modules/@napi-rs/wasm-runtime": {
      "version": "0.2.12",
      "resolved": "https://registry.npmjs.org/@napi-rs/wasm-runtime/-/wasm-runtime-0.2.12.tgz",
      "integrity": "sha512-ZVWUcfwY4E/yPitQJl481FjFo3K22D6qF0DuFH6Y/nbnE11GY5uguDxZMGXPQ8WQ0128MXQD7TnfHyK4oWoIJQ==",
      "dev": true,
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "@emnapi/core": "^1.4.3",
        "@emnapi/runtime": "^1.4.3",
        "@tybys/wasm-util": "^0.10.0"
      }
    },
    "node_modules/@next/env": {
      "version": "14.0.0",
      "resolved": "https://registry.npmjs.org/@next/env/-/env-14.0.0.tgz",
      "integrity": "sha512-cIKhxkfVELB6hFjYsbtEeTus2mwrTC+JissfZYM0n+8Fv+g8ucUfOlm3VEDtwtwydZ0Nuauv3bl0qF82nnCAqA==",
      "license": "MIT"
    },
    "node_modules/@next/eslint-plugin-next": {
      "version": "14.0.0",
      "resolved": "https://registry.npmjs.org/@next/eslint-plugin-next/-/eslint-plugin-next-14.0.0.tgz",
      "integrity": "sha512-Ye37nNI09V3yt7pzuzSQtwlvuJ2CGzFszHXkcTHHZgNr7EhTMFLipn3VSJChy+e5+ahTdNApPphc3qCPUsn10A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "glob": "7.1.7"
      }
    },
    "node_modules/@next/swc-darwin-arm64": {
      "version": "14.0.0",
      "resolved": "https://registry.npmjs.org/@next/swc-darwin-arm64/-/swc-darwin-arm64-14.0.0.tgz",
      "integrity": "sha512-HQKi159jCz4SRsPesVCiNN6tPSAFUkOuSkpJsqYTIlbHLKr1mD6be/J0TvWV6fwJekj81bZV9V/Tgx3C2HO9lA==",
      "cpu": [
        "arm64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/swc-darwin-x64": {
      "version": "14.0.0",
      "resolved": "https://registry.npmjs.org/@next/swc-darwin-x64/-/swc-darwin-x64-14.0.0.tgz",
      "integrity": "sha512-4YyQLMSaCgX/kgC1jjF3s3xSoBnwHuDhnF6WA1DWNEYRsbOOPWjcYhv8TKhRe2ApdOam+VfQSffC4ZD+X4u1Cg==",
      "cpu": [
        "x64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/swc-linux-arm64-gnu": {
      "version": "14.0.0",
      "resolved": "https://registry.npmjs.org/@next/swc-linux-arm64-gnu/-/swc-linux-arm64-gnu-14.0.0.tgz",
      "integrity": "sha512-io7fMkJ28Glj7SH8yvnlD6naIhRDnDxeE55CmpQkj3+uaA2Hko6WGY2pT5SzpQLTnGGnviK85cy8EJ2qsETj/g==",
      "cpu": [
        "arm64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/swc-linux-arm64-musl": {
      "version": "14.0.0",
      "resolved": "https://registry.npmjs.org/@next/swc-linux-arm64-musl/-/swc-linux-arm64-musl-14.0.0.tgz",
      "integrity": "sha512-nC2h0l1Jt8LEzyQeSs/BKpXAMe0mnHIMykYALWaeddTqCv5UEN8nGO3BG8JAqW/Y8iutqJsaMe2A9itS0d/r8w==",
      "cpu": [
        "arm64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/swc-linux-x64-gnu": {
      "version": "14.0.0",
      "resolved": "https://registry.npmjs.org/@next/swc-linux-x64-gnu/-/swc-linux-x64-gnu-14.0.0.tgz",
      "integrity": "sha512-Wf+WjXibJQ7hHXOdNOmSMW5bxeJHVf46Pwb3eLSD2L76NrytQlif9NH7JpHuFlYKCQGfKfgSYYre5rIfmnSwQw==",
      "cpu": [
        "x64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/swc-linux-x64-musl": {
      "version": "14.0.0",
      "resolved": "https://registry.npmjs.org/@next/swc-linux-x64-musl/-/swc-linux-x64-musl-14.0.0.tgz",
      "integrity": "sha512-WTZb2G7B+CTsdigcJVkRxfcAIQj7Lf0ipPNRJ3vlSadU8f0CFGv/ST+sJwF5eSwIe6dxKoX0DG6OljDBaad+rg==",
      "cpu": [
        "x64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/swc-win32-arm64-msvc": {
      "version": "14.0.0",
      "resolved": "https://registry.npmjs.org/@next/swc-win32-arm64-msvc/-/swc-win32-arm64-msvc-14.0.0.tgz",
      "integrity": "sha512-7R8/x6oQODmNpnWVW00rlWX90sIlwluJwcvMT6GXNIBOvEf01t3fBg0AGURNKdTJg2xNuP7TyLchCL7Lh2DTiw==",
      "cpu": [
        "arm64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/swc-win32-ia32-msvc": {
      "version": "14.0.0",
      "resolved": "https://registry.npmjs.org/@next/swc-win32-ia32-msvc/-/swc-win32-ia32-msvc-14.0.0.tgz",
      "integrity": "sha512-RLK1nELvhCnxaWPF07jGU4x3tjbyx2319q43loZELqF0+iJtKutZ+Lk8SVmf/KiJkYBc7Cragadz7hb3uQvz4g==",
      "cpu": [
        "ia32"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/swc-win32-x64-msvc": {
      "version": "14.0.0",
      "resolved": "https://registry.npmjs.org/@next/swc-win32-x64-msvc/-/swc-win32-x64-msvc-14.0.0.tgz",
      "integrity": "sha512-g6hLf1SUko+hnnaywQQZzzb3BRecQsoKkF3o/C+F+dOA4w/noVAJngUVkfwF0+2/8FzNznM7ofM6TGZO9svn7w==",
      "cpu": [
        "x64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@nodelib/fs.scandir": {
      "version": "2.1.5",
      "resolved": "https://registry.npmjs.org/@nodelib/fs.scandir/-/fs.scandir-2.1.5.tgz",
      "integrity": "sha512-vq24Bq3ym5HEQm2NKCr3yXDwjc7vTsEThRDnkp2DK9p1uqLR+DHurm/NOTo0KG7HYHU7eppKZj3MyqYuMBf62g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@nodelib/fs.stat": "2.0.5",
        "run-parallel": "^1.1.9"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/@nodelib/fs.stat": {
      "version": "2.0.5",
      "resolved": "https://registry.npmjs.org/@nodelib/fs.stat/-/fs.stat-2.0.5.tgz",
      "integrity": "sha512-RkhPPp2zrqDAQA/2jNhnztcPAlv64XdhIp7a7454A5ovI7Bukxgt7MX7udwAu3zg1DcpPU0rz3VV1SeaqvY4+A==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/@nodelib/fs.walk": {
      "version": "1.2.8",
      "resolved": "https://registry.npmjs.org/@nodelib/fs.walk/-/fs.walk-1.2.8.tgz",
      "integrity": "sha512-oGB+UxlgWcgQkgwo8GcEGwemoTFt3FIO9ababBmaGwXIoBKZ+GTy0pP185beGg7Llih/NSHSV2XAs1lnznocSg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@nodelib/fs.scandir": "2.1.5",
        "fastq": "^1.6.0"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/@nolyfill/is-core-module": {
      "version": "1.0.39",
      "resolved": "https://registry.npmjs.org/@nolyfill/is-core-module/-/is-core-module-1.0.39.tgz",
      "integrity": "sha512-nn5ozdjYQpUCZlWGuxcJY/KpxkWQs4DcbMCmKojjyrYDEAGy4Ce19NN4v5MduafTwJlbKc99UA8YhSVqq9yPZA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=12.4.0"
      }
    },
    "node_modules/@pkgjs/parseargs": {
      "version": "0.11.0",
      "resolved": "https://registry.npmjs.org/@pkgjs/parseargs/-/parseargs-0.11.0.tgz",
      "integrity": "sha512-+1VkjdD0QBLPodGrJUeqarH8VAIvQODIbwh9XpP5Syisf7YoQgsJKPNFoqqLQlu+VQ/tVSshMR6loPMn8U+dPg==",
      "dev": true,
      "license": "MIT",
      "optional": true,
      "engines": {
        "node": ">=14"
      }
    },
    "node_modules/@rtsao/scc": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/@rtsao/scc/-/scc-1.1.0.tgz",
      "integrity": "sha512-zt6OdqaDoOnJ1ZYsCYGt9YmWzDXl4vQdKTyJev62gFhRGKdx7mcT54V9KIjg+d2wi9EXsPvAPKe7i7WjfVWB8g==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@rushstack/eslint-patch": {
      "version": "1.12.0",
      "resolved": "https://registry.npmjs.org/@rushstack/eslint-patch/-/eslint-patch-1.12.0.tgz",
      "integrity": "sha512-5EwMtOqvJMMa3HbmxLlF74e+3/HhwBTMcvt3nqVJgGCozO6hzIPOBlwm8mGVNR9SN2IJpxSnlxczyDjcn7qIyw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@swc/helpers": {
      "version": "0.5.2",
      "resolved": "https://registry.npmjs.org/@swc/helpers/-/helpers-0.5.2.tgz",
      "integrity": "sha512-E4KcWTpoLHqwPHLxidpOqQbcrZVgi0rsmmZXUle1jXmJfuIf/UWpczUJ7MZZ5tlxytgJXyp0w4PGkkeLiuIdZw==",
      "license": "Apache-2.0",
      "dependencies": {
        "tslib": "^2.4.0"
      }
    },
    "node_modules/@tybys/wasm-util": {
      "version": "0.10.0",
      "resolved": "https://registry.npmjs.org/@tybys/wasm-util/-/wasm-util-0.10.0.tgz",
      "integrity": "sha512-VyyPYFlOMNylG45GoAe0xDoLwWuowvf92F9kySqzYh8vmYm7D2u4iUJKa1tOUpS70Ku13ASrOkS4ScXFsTaCNQ==",
      "dev": true,
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "tslib": "^2.4.0"
      }
    },
    "node_modules/@types/json5": {
      "version": "0.0.29",
      "resolved": "https://registry.npmjs.org/@types/json5/-/json5-0.0.29.tgz",
      "integrity": "sha512-dRLjCWHYg4oaA77cxO64oO+7JwCwnIzkZPdrrC71jQmQtlhM556pwKo5bUzqvZndkVbeFLIIi+9TC40JNF5hNQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@types/node": {
      "version": "20.19.10",
      "resolved": "https://registry.npmjs.org/@types/node/-/node-20.19.10.tgz",
      "integrity": "sha512-iAFpG6DokED3roLSP0K+ybeDdIX6Bc0Vd3mLW5uDqThPWtNos3E+EqOM11mPQHKzfWHqEBuLjIlsBQQ8CsISmQ==",
      "license": "MIT",
      "dependencies": {
        "undici-types": "~6.21.0"
      }
    },
    "node_modules/@types/prop-types": {
      "version": "15.7.15",
      "resolved": "https://registry.npmjs.org/@types/prop-types/-/prop-types-15.7.15.tgz",
      "integrity": "sha512-F6bEyamV9jKGAFBEmlQnesRPGOQqS2+Uwi0Em15xenOxHaf2hv6L8YCVn3rPdPJOiJfPiCnLIRyvwVaqMY3MIw==",
      "license": "MIT"
    },
    "node_modules/@types/react": {
      "version": "18.3.23",
      "resolved": "https://registry.npmjs.org/@types/react/-/react-18.3.23.tgz",
      "integrity": "sha512-/LDXMQh55EzZQ0uVAZmKKhfENivEvWz6E+EYzh+/MCjMhNsotd+ZHhBGIjFDTi6+fz0OhQQQLbTgdQIxxCsC0w==",
      "license": "MIT",
      "dependencies": {
        "@types/prop-types": "*",
        "csstype": "^3.0.2"
      }
    },
    "node_modules/@types/react-dom": {
      "version": "18.3.7",
      "resolved": "https://registry.npmjs.org/@types/react-dom/-/react-dom-18.3.7.tgz",
      "integrity": "sha512-MEe3UeoENYVFXzoXEWsvcpg6ZvlrFNlOQ7EOsvhI3CfAXwzPfO8Qwuxd40nepsYKqyyVQnTdEfv68q91yLcKrQ==",
      "license": "MIT",
      "peerDependencies": {
        "@types/react": "^18.0.0"
      }
    },
    "node_modules/@typescript-eslint/parser": {
      "version": "6.21.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/parser/-/parser-6.21.0.tgz",
      "integrity": "sha512-tbsV1jPne5CkFQCgPBcDOt30ItF7aJoZL997JSF7MhGQqOeT3svWRYxiqlfA5RUdlHN6Fi+EI9bxqbdyAUZjYQ==",
      "dev": true,
      "license": "BSD-2-Clause",
      "dependencies": {
        "@typescript-eslint/scope-manager": "6.21.0",
        "@typescript-eslint/types": "6.21.0",
        "@typescript-eslint/typescript-estree": "6.21.0",
        "@typescript-eslint/visitor-keys": "6.21.0",
        "debug": "^4.3.4"
      },
      "engines": {
        "node": "^16.0.0 || >=18.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      },
      "peerDependencies": {
        "eslint": "^7.0.0 || ^8.0.0"
      },
      "peerDependenciesMeta": {
        "typescript": {
          "optional": true
        }
      }
    },
    "node_modules/@typescript-eslint/scope-manager": {
      "version": "6.21.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/scope-manager/-/scope-manager-6.21.0.tgz",
      "integrity": "sha512-OwLUIWZJry80O99zvqXVEioyniJMa+d2GrqpUTqi5/v5D5rOrppJVBPa0yKCblcigC0/aYAzxxqQ1B+DS2RYsg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@typescript-eslint/types": "6.21.0",
        "@typescript-eslint/visitor-keys": "6.21.0"
      },
      "engines": {
        "node": "^16.0.0 || >=18.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      }
    },
    "node_modules/@typescript-eslint/types": {
      "version": "6.21.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/types/-/types-6.21.0.tgz",
      "integrity": "sha512-1kFmZ1rOm5epu9NZEZm1kckCDGj5UJEf7P1kliH4LKu/RkwpsfqqGmY2OOcUs18lSlQBKLDYBOGxRVtrMN5lpg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": "^16.0.0 || >=18.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      }
    },
    "node_modules/@typescript-eslint/typescript-estree": {
      "version": "6.21.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/typescript-estree/-/typescript-estree-6.21.0.tgz",
      "integrity": "sha512-6npJTkZcO+y2/kr+z0hc4HwNfrrP4kNYh57ek7yCNlrBjWQ1Y0OS7jiZTkgumrvkX5HkEKXFZkkdFNkaW2wmUQ==",
      "dev": true,
      "license": "BSD-2-Clause",
      "dependencies": {
        "@typescript-eslint/types": "6.21.0",
        "@typescript-eslint/visitor-keys": "6.21.0",
        "debug": "^4.3.4",
        "globby": "^11.1.0",
        "is-glob": "^4.0.3",
        "minimatch": "9.0.3",
        "semver": "^7.5.4",
        "ts-api-utils": "^1.0.1"
      },
      "engines": {
        "node": "^16.0.0 || >=18.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      },
      "peerDependenciesMeta": {
        "typescript": {
          "optional": true
        }
      }
    },
    "node_modules/@typescript-eslint/typescript-estree/node_modules/brace-expansion": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/brace-expansion/-/brace-expansion-2.0.2.tgz",
      "integrity": "sha512-Jt0vHyM+jmUBqojB7E1NIYadt0vI0Qxjxd2TErW94wDz+E2LAm5vKMXXwg6ZZBTHPuUlDgQHKXvjGBdfcF1ZDQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "balanced-match": "^1.0.0"
      }
    },
    "node_modules/@typescript-eslint/typescript-estree/node_modules/minimatch": {
      "version": "9.0.3",
      "resolved": "https://registry.npmjs.org/minimatch/-/minimatch-9.0.3.tgz",
      "integrity": "sha512-RHiac9mvaRw0x3AYRgDC1CxAP7HTcNrrECeA8YYJeWnpo+2Q5CegtZjaotWTWxDG3UeGA1coE05iH1mPjT/2mg==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "brace-expansion": "^2.0.1"
      },
      "engines": {
        "node": ">=16 || 14 >=14.17"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/@typescript-eslint/visitor-keys": {
      "version": "6.21.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/visitor-keys/-/visitor-keys-6.21.0.tgz",
      "integrity": "sha512-JJtkDduxLi9bivAB+cYOVMtbkqdPOhZ+ZI5LC47MIRrDV4Yn2o+ZnW10Nkmr28xRpSpdJ6Sm42Hjf2+REYXm0A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@typescript-eslint/types": "6.21.0",
        "eslint-visitor-keys": "^3.4.1"
      },
      "engines": {
        "node": "^16.0.0 || >=18.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      }
    },
    "node_modules/@ungap/structured-clone": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/@ungap/structured-clone/-/structured-clone-1.3.0.tgz",
      "integrity": "sha512-WmoN8qaIAo7WTYWbAZuG8PYEhn5fkz7dZrqTBZ7dtt//lL2Gwms1IcnQ5yHqjDfX8Ft5j4YzDM23f87zBfDe9g==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/@unrs/resolver-binding-android-arm-eabi": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-android-arm-eabi/-/resolver-binding-android-arm-eabi-1.11.1.tgz",
      "integrity": "sha512-ppLRUgHVaGRWUx0R0Ut06Mjo9gBaBkg3v/8AxusGLhsIotbBLuRk51rAzqLC8gq6NyyAojEXglNjzf6R948DNw==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "android"
      ]
    },
    "node_modules/@unrs/resolver-binding-android-arm64": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-android-arm64/-/resolver-binding-android-arm64-1.11.1.tgz",
      "integrity": "sha512-lCxkVtb4wp1v+EoN+HjIG9cIIzPkX5OtM03pQYkG+U5O/wL53LC4QbIeazgiKqluGeVEeBlZahHalCaBvU1a2g==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "android"
      ]
    },
    "node_modules/@unrs/resolver-binding-darwin-arm64": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-darwin-arm64/-/resolver-binding-darwin-arm64-1.11.1.tgz",
      "integrity": "sha512-gPVA1UjRu1Y/IsB/dQEsp2V1pm44Of6+LWvbLc9SDk1c2KhhDRDBUkQCYVWe6f26uJb3fOK8saWMgtX8IrMk3g==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ]
    },
    "node_modules/@unrs/resolver-binding-darwin-x64": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-darwin-x64/-/resolver-binding-darwin-x64-1.11.1.tgz",
      "integrity": "sha512-cFzP7rWKd3lZaCsDze07QX1SC24lO8mPty9vdP+YVa3MGdVgPmFc59317b2ioXtgCMKGiCLxJ4HQs62oz6GfRQ==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ]
    },
    "node_modules/@unrs/resolver-binding-freebsd-x64": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-freebsd-x64/-/resolver-binding-freebsd-x64-1.11.1.tgz",
      "integrity": "sha512-fqtGgak3zX4DCB6PFpsH5+Kmt/8CIi4Bry4rb1ho6Av2QHTREM+47y282Uqiu3ZRF5IQioJQ5qWRV6jduA+iGw==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "freebsd"
      ]
    },
    "node_modules/@unrs/resolver-binding-linux-arm-gnueabihf": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-linux-arm-gnueabihf/-/resolver-binding-linux-arm-gnueabihf-1.11.1.tgz",
      "integrity": "sha512-u92mvlcYtp9MRKmP+ZvMmtPN34+/3lMHlyMj7wXJDeXxuM0Vgzz0+PPJNsro1m3IZPYChIkn944wW8TYgGKFHw==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@unrs/resolver-binding-linux-arm-musleabihf": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-linux-arm-musleabihf/-/resolver-binding-linux-arm-musleabihf-1.11.1.tgz",
      "integrity": "sha512-cINaoY2z7LVCrfHkIcmvj7osTOtm6VVT16b5oQdS4beibX2SYBwgYLmqhBjA1t51CarSaBuX5YNsWLjsqfW5Cw==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@unrs/resolver-binding-linux-arm64-gnu": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-linux-arm64-gnu/-/resolver-binding-linux-arm64-gnu-1.11.1.tgz",
      "integrity": "sha512-34gw7PjDGB9JgePJEmhEqBhWvCiiWCuXsL9hYphDF7crW7UgI05gyBAi6MF58uGcMOiOqSJ2ybEeCvHcq0BCmQ==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@unrs/resolver-binding-linux-arm64-musl": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-linux-arm64-musl/-/resolver-binding-linux-arm64-musl-1.11.1.tgz",
      "integrity": "sha512-RyMIx6Uf53hhOtJDIamSbTskA99sPHS96wxVE/bJtePJJtpdKGXO1wY90oRdXuYOGOTuqjT8ACccMc4K6QmT3w==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@unrs/resolver-binding-linux-ppc64-gnu": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-linux-ppc64-gnu/-/resolver-binding-linux-ppc64-gnu-1.11.1.tgz",
      "integrity": "sha512-D8Vae74A4/a+mZH0FbOkFJL9DSK2R6TFPC9M+jCWYia/q2einCubX10pecpDiTmkJVUH+y8K3BZClycD8nCShA==",
      "cpu": [
        "ppc64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@unrs/resolver-binding-linux-riscv64-gnu": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-linux-riscv64-gnu/-/resolver-binding-linux-riscv64-gnu-1.11.1.tgz",
      "integrity": "sha512-frxL4OrzOWVVsOc96+V3aqTIQl1O2TjgExV4EKgRY09AJ9leZpEg8Ak9phadbuX0BA4k8U5qtvMSQQGGmaJqcQ==",
      "cpu": [
        "riscv64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@unrs/resolver-binding-linux-riscv64-musl": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-linux-riscv64-musl/-/resolver-binding-linux-riscv64-musl-1.11.1.tgz",
      "integrity": "sha512-mJ5vuDaIZ+l/acv01sHoXfpnyrNKOk/3aDoEdLO/Xtn9HuZlDD6jKxHlkN8ZhWyLJsRBxfv9GYM2utQ1SChKew==",
      "cpu": [
        "riscv64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@unrs/resolver-binding-linux-s390x-gnu": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-linux-s390x-gnu/-/resolver-binding-linux-s390x-gnu-1.11.1.tgz",
      "integrity": "sha512-kELo8ebBVtb9sA7rMe1Cph4QHreByhaZ2QEADd9NzIQsYNQpt9UkM9iqr2lhGr5afh885d/cB5QeTXSbZHTYPg==",
      "cpu": [
        "s390x"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@unrs/resolver-binding-linux-x64-gnu": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-linux-x64-gnu/-/resolver-binding-linux-x64-gnu-1.11.1.tgz",
      "integrity": "sha512-C3ZAHugKgovV5YvAMsxhq0gtXuwESUKc5MhEtjBpLoHPLYM+iuwSj3lflFwK3DPm68660rZ7G8BMcwSro7hD5w==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@unrs/resolver-binding-linux-x64-musl": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-linux-x64-musl/-/resolver-binding-linux-x64-musl-1.11.1.tgz",
      "integrity": "sha512-rV0YSoyhK2nZ4vEswT/QwqzqQXw5I6CjoaYMOX0TqBlWhojUf8P94mvI7nuJTeaCkkds3QE4+zS8Ko+GdXuZtA==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@unrs/resolver-binding-wasm32-wasi": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-wasm32-wasi/-/resolver-binding-wasm32-wasi-1.11.1.tgz",
      "integrity": "sha512-5u4RkfxJm+Ng7IWgkzi3qrFOvLvQYnPBmjmZQ8+szTK/b31fQCnleNl1GgEt7nIsZRIf5PLhPwT0WM+q45x/UQ==",
      "cpu": [
        "wasm32"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "@napi-rs/wasm-runtime": "^0.2.11"
      },
      "engines": {
        "node": ">=14.0.0"
      }
    },
    "node_modules/@unrs/resolver-binding-win32-arm64-msvc": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-win32-arm64-msvc/-/resolver-binding-win32-arm64-msvc-1.11.1.tgz",
      "integrity": "sha512-nRcz5Il4ln0kMhfL8S3hLkxI85BXs3o8EYoattsJNdsX4YUU89iOkVn7g0VHSRxFuVMdM4Q1jEpIId1Ihim/Uw==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ]
    },
    "node_modules/@unrs/resolver-binding-win32-ia32-msvc": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-win32-ia32-msvc/-/resolver-binding-win32-ia32-msvc-1.11.1.tgz",
      "integrity": "sha512-DCEI6t5i1NmAZp6pFonpD5m7i6aFrpofcp4LA2i8IIq60Jyo28hamKBxNrZcyOwVOZkgsRp9O2sXWBWP8MnvIQ==",
      "cpu": [
        "ia32"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ]
    },
    "node_modules/@unrs/resolver-binding-win32-x64-msvc": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-win32-x64-msvc/-/resolver-binding-win32-x64-msvc-1.11.1.tgz",
      "integrity": "sha512-lrW200hZdbfRtztbygyaq/6jP6AKE8qQN2KvPcJ+x7wiD038YtnYtZ82IMNJ69GJibV7bwL3y9FgK+5w/pYt6g==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ]
    },
    "node_modules/acorn": {
      "version": "8.15.0",
      "resolved": "https://registry.npmjs.org/acorn/-/acorn-8.15.0.tgz",
      "integrity": "sha512-NZyJarBfL7nWwIq+FDL6Zp/yHEhePMNnnJ0y3qfieCrmNvYct8uvtiV41UvlSe6apAfk0fY1FbWx+NwfmpvtTg==",
      "dev": true,
      "license": "MIT",
      "bin": {
        "acorn": "bin/acorn"
      },
      "engines": {
        "node": ">=0.4.0"
      }
    },
    "node_modules/acorn-jsx": {
      "version": "5.3.2",
      "resolved": "https://registry.npmjs.org/acorn-jsx/-/acorn-jsx-5.3.2.tgz",
      "integrity": "sha512-rq9s+JNhf0IChjtDXxllJ7g41oZk5SlXtp0LHwyA5cejwn7vKmKp4pPri6YEePv2PU65sAsegbXtIinmDFDXgQ==",
      "dev": true,
      "license": "MIT",
      "peerDependencies": {
        "acorn": "^6.0.0 || ^7.0.0 || ^8.0.0"
      }
    },
    "node_modules/ajv": {
      "version": "6.12.6",
      "resolved": "https://registry.npmjs.org/ajv/-/ajv-6.12.6.tgz",
      "integrity": "sha512-j3fVLgvTo527anyYyJOGTYJbG+vnnQYvE0m5mmkc1TK+nxAppkCLMIL0aZ4dblVCNoGShhm+kzE4ZUykBoMg4g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "fast-deep-equal": "^3.1.1",
        "fast-json-stable-stringify": "^2.0.0",
        "json-schema-traverse": "^0.4.1",
        "uri-js": "^4.2.2"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/epoberezkin"
      }
    },
    "node_modules/ansi-regex": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/ansi-regex/-/ansi-regex-5.0.1.tgz",
      "integrity": "sha512-quJQXlTSUGL2LH9SUXo8VwsY4soanhgo6LNSm84E1LBcE8s3O0wpdiRzyR9z/ZZJMlMWv37qOOb9pdJlMUEKFQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/ansi-styles": {
      "version": "4.3.0",
      "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-4.3.0.tgz",
      "integrity": "sha512-zbB9rCJAT1rbjiVDb2hqKFHNYLxgtk8NURxZ3IZwD3F6NtxbXZQCnnSi1Lkx+IDohdPlFp222wVALIheZJQSEg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "color-convert": "^2.0.1"
      },
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-styles?sponsor=1"
      }
    },
    "node_modules/any-promise": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/any-promise/-/any-promise-1.3.0.tgz",
      "integrity": "sha512-7UvmKalWRt1wgjL1RrGxoSJW/0QZFIegpeGvZG9kjp8vrRu55XTHbwnqq2GpXm9uLbcuhxm3IqX9OB4MZR1b2A==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/anymatch": {
      "version": "3.1.3",
      "resolved": "https://registry.npmjs.org/anymatch/-/anymatch-3.1.3.tgz",
      "integrity": "sha512-KMReFUr0B4t+D+OBkjR3KYqvocp2XaSzO55UcB6mgQMd3KbcE+mWTyvVV7D/zsdEbNnV6acZUutkiHQXvTr1Rw==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "normalize-path": "^3.0.0",
        "picomatch": "^2.0.4"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/arg": {
      "version": "5.0.2",
      "resolved": "https://registry.npmjs.org/arg/-/arg-5.0.2.tgz",
      "integrity": "sha512-PYjyFOLKQ9y57JvQ6QLo8dAgNqswh8M1RMJYdQduT6xbWSgK36P/Z/v+p888pM69jMMfS8Xd8F6I1kQ/I9HUGg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/argparse": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/argparse/-/argparse-2.0.1.tgz",
      "integrity": "sha512-8+9WqebbFzpX9OR+Wa6O29asIogeRMzcGtAINdpMHHyAg10f05aSFVBbcEqGf/PXw1EjAZ+q2/bEBg3DvurK3Q==",
      "dev": true,
      "license": "Python-2.0"
    },
    "node_modules/aria-query": {
      "version": "5.3.2",
      "resolved": "https://registry.npmjs.org/aria-query/-/aria-query-5.3.2.tgz",
      "integrity": "sha512-COROpnaoap1E2F000S62r6A60uHZnmlvomhfyT2DlTcrY1OrBKn2UhH7qn5wTC9zMvD0AY7csdPSNwKP+7WiQw==",
      "dev": true,
      "license": "Apache-2.0",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/array-buffer-byte-length": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/array-buffer-byte-length/-/array-buffer-byte-length-1.0.2.tgz",
      "integrity": "sha512-LHE+8BuR7RYGDKvnrmcuSq3tDcKv9OFEXQt/HpbZhY7V6h0zlUXutnAD82GiFx9rdieCMjkvtcsPqBwgUl1Iiw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "is-array-buffer": "^3.0.5"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/array-includes": {
      "version": "3.1.9",
      "resolved": "https://registry.npmjs.org/array-includes/-/array-includes-3.1.9.tgz",
      "integrity": "sha512-FmeCCAenzH0KH381SPT5FZmiA/TmpndpcaShhfgEN9eCVjnFBqq3l1xrI42y8+PPLI6hypzou4GXw00WHmPBLQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.4",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.24.0",
        "es-object-atoms": "^1.1.1",
        "get-intrinsic": "^1.3.0",
        "is-string": "^1.1.1",
        "math-intrinsics": "^1.1.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/array-union": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/array-union/-/array-union-2.1.0.tgz",
      "integrity": "sha512-HGyxoOTYUyCM6stUe6EJgnd4EoewAI7zMdfqO+kGjnlZmBDz/cR5pf8r/cR4Wq60sL/p0IkcjUEEPwS3GFrIyw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/array.prototype.findlast": {
      "version": "1.2.5",
      "resolved": "https://registry.npmjs.org/array.prototype.findlast/-/array.prototype.findlast-1.2.5.tgz",
      "integrity": "sha512-CVvd6FHg1Z3POpBLxO6E6zr+rSKEQ9L6rZHAaY7lLfhKsWYUBBOuMs0e9o24oopj6H+geRCX0YJ+TJLBK2eHyQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.7",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.2",
        "es-errors": "^1.3.0",
        "es-object-atoms": "^1.0.0",
        "es-shim-unscopables": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/array.prototype.findlastindex": {
      "version": "1.2.6",
      "resolved": "https://registry.npmjs.org/array.prototype.findlastindex/-/array.prototype.findlastindex-1.2.6.tgz",
      "integrity": "sha512-F/TKATkzseUExPlfvmwQKGITM3DGTK+vkAsCZoDc5daVygbJBnjEUCbgkAvVFsgfXfX4YIqZ/27G3k3tdXrTxQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.4",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.9",
        "es-errors": "^1.3.0",
        "es-object-atoms": "^1.1.1",
        "es-shim-unscopables": "^1.1.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/array.prototype.flat": {
      "version": "1.3.3",
      "resolved": "https://registry.npmjs.org/array.prototype.flat/-/array.prototype.flat-1.3.3.tgz",
      "integrity": "sha512-rwG/ja1neyLqCuGZ5YYrznA62D4mZXg0i1cIskIUKSiqF3Cje9/wXAls9B9s1Wa2fomMsIv8czB8jZcPmxCXFg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.5",
        "es-shim-unscopables": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/array.prototype.flatmap": {
      "version": "1.3.3",
      "resolved": "https://registry.npmjs.org/array.prototype.flatmap/-/array.prototype.flatmap-1.3.3.tgz",
      "integrity": "sha512-Y7Wt51eKJSyi80hFrJCePGGNo5ktJCslFuboqJsbf57CCPcm5zztluPlc4/aD8sWsKvlwatezpV4U1efk8kpjg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.5",
        "es-shim-unscopables": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/array.prototype.tosorted": {
      "version": "1.1.4",
      "resolved": "https://registry.npmjs.org/array.prototype.tosorted/-/array.prototype.tosorted-1.1.4.tgz",
      "integrity": "sha512-p6Fx8B7b7ZhL/gmUsAy0D15WhvDccw3mnGNbZpi3pmeJdxtWsj2jEaI4Y6oo3XiHfzuSgPwKc04MYt6KgvC/wA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.7",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.3",
        "es-errors": "^1.3.0",
        "es-shim-unscopables": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/arraybuffer.prototype.slice": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/arraybuffer.prototype.slice/-/arraybuffer.prototype.slice-1.0.4.tgz",
      "integrity": "sha512-BNoCY6SXXPQ7gF2opIP4GBE+Xw7U+pHMYKuzjgCN3GwiaIR09UUeKfheyIry77QtrCBlC0KK0q5/TER/tYh3PQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "array-buffer-byte-length": "^1.0.1",
        "call-bind": "^1.0.8",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.5",
        "es-errors": "^1.3.0",
        "get-intrinsic": "^1.2.6",
        "is-array-buffer": "^3.0.4"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/ast-types-flow": {
      "version": "0.0.8",
      "resolved": "https://registry.npmjs.org/ast-types-flow/-/ast-types-flow-0.0.8.tgz",
      "integrity": "sha512-OH/2E5Fg20h2aPrbe+QL8JZQFko0YZaF+j4mnQ7BGhfavO7OpSLa8a0y9sBwomHdSbkhTS8TQNayBfnW5DwbvQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/async-function": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/async-function/-/async-function-1.0.0.tgz",
      "integrity": "sha512-hsU18Ae8CDTR6Kgu9DYf0EbCr/a5iGL0rytQDobUcdpYOKokk8LEjVphnXkDkgpi0wYVsqrXuP0bZxJaTqdgoA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/autoprefixer": {
      "version": "10.4.21",
      "resolved": "https://registry.npmjs.org/autoprefixer/-/autoprefixer-10.4.21.tgz",
      "integrity": "sha512-O+A6LWV5LDHSJD3LjHYoNi4VLsj/Whi7k6zG12xTYaU4cQ8oxQGckXNX8cRHK5yOZ/ppVHe0ZBXGzSV9jXdVbQ==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/postcss/"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/autoprefixer"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "browserslist": "^4.24.4",
        "caniuse-lite": "^1.0.30001702",
        "fraction.js": "^4.3.7",
        "normalize-range": "^0.1.2",
        "picocolors": "^1.1.1",
        "postcss-value-parser": "^4.2.0"
      },
      "bin": {
        "autoprefixer": "bin/autoprefixer"
      },
      "engines": {
        "node": "^10 || ^12 || >=14"
      },
      "peerDependencies": {
        "postcss": "^8.1.0"
      }
    },
    "node_modules/available-typed-arrays": {
      "version": "1.0.7",
      "resolved": "https://registry.npmjs.org/available-typed-arrays/-/available-typed-arrays-1.0.7.tgz",
      "integrity": "sha512-wvUjBtSGN7+7SjNpq/9M2Tg350UZD3q62IFZLbRAR1bSMlCo1ZaeW+BJ+D090e4hIIZLBcTDWe4Mh4jvUDajzQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "possible-typed-array-names": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/axe-core": {
      "version": "4.10.3",
      "resolved": "https://registry.npmjs.org/axe-core/-/axe-core-4.10.3.tgz",
      "integrity": "sha512-Xm7bpRXnDSX2YE2YFfBk2FnF0ep6tmG7xPh8iHee8MIcrgq762Nkce856dYtJYLkuIoYZvGfTs/PbZhideTcEg==",
      "dev": true,
      "license": "MPL-2.0",
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/axobject-query": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/axobject-query/-/axobject-query-4.1.0.tgz",
      "integrity": "sha512-qIj0G9wZbMGNLjLmg1PT6v2mE9AH2zlnADJD/2tC6E00hgmhUOfEB6greHPAfLRSufHqROIUTkw6E+M3lH0PTQ==",
      "dev": true,
      "license": "Apache-2.0",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/balanced-match": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/balanced-match/-/balanced-match-1.0.2.tgz",
      "integrity": "sha512-3oSeUO0TMV67hN1AmbXsK4yaqU7tjiHlbxRDZOpH0KW9+CeX4bRAaX0Anxt0tx2MrpRpWwQaPwIlISEJhYU5Pw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/binary-extensions": {
      "version": "2.3.0",
      "resolved": "https://registry.npmjs.org/binary-extensions/-/binary-extensions-2.3.0.tgz",
      "integrity": "sha512-Ceh+7ox5qe7LJuLHoY0feh3pHuUDHAcRUeyL2VYghZwfpkNIy/+8Ocg0a3UuSoYzavmylwuLWQOf3hl0jjMMIw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/brace-expansion": {
      "version": "1.1.12",
      "resolved": "https://registry.npmjs.org/brace-expansion/-/brace-expansion-1.1.12.tgz",
      "integrity": "sha512-9T9UjW3r0UW5c1Q7GTwllptXwhvYmEzFhzMfZ9H7FQWt+uZePjZPjBP/W1ZEyZ1twGWom5/56TF4lPcqjnDHcg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "balanced-match": "^1.0.0",
        "concat-map": "0.0.1"
      }
    },
    "node_modules/braces": {
      "version": "3.0.3",
      "resolved": "https://registry.npmjs.org/braces/-/braces-3.0.3.tgz",
      "integrity": "sha512-yQbXgO/OSZVD2IsiLlro+7Hf6Q18EJrKSEsdoMzKePKXct3gvD8oLcOQdIzGupr5Fj+EDe8gO/lxc1BzfMpxvA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "fill-range": "^7.1.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/browserslist": {
      "version": "4.25.2",
      "resolved": "https://registry.npmjs.org/browserslist/-/browserslist-4.25.2.tgz",
      "integrity": "sha512-0si2SJK3ooGzIawRu61ZdPCO1IncZwS8IzuX73sPZsXW6EQ/w/DAfPyKI8l1ETTCr2MnvqWitmlCUxgdul45jA==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/browserslist"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/browserslist"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "caniuse-lite": "^1.0.30001733",
        "electron-to-chromium": "^1.5.199",
        "node-releases": "^2.0.19",
        "update-browserslist-db": "^1.1.3"
      },
      "bin": {
        "browserslist": "cli.js"
      },
      "engines": {
        "node": "^6 || ^7 || ^8 || ^9 || ^10 || ^11 || ^12 || >=13.7"
      }
    },
    "node_modules/busboy": {
      "version": "1.6.0",
      "resolved": "https://registry.npmjs.org/busboy/-/busboy-1.6.0.tgz",
      "integrity": "sha512-8SFQbg/0hQ9xy3UNTB0YEnsNBbWfhf7RtnzpL7TkBiTBRfrQ9Fxcnz7VJsleJpyp6rVLvXiuORqjlHi5q+PYuA==",
      "dependencies": {
        "streamsearch": "^1.1.0"
      },
      "engines": {
        "node": ">=10.16.0"
      }
    },
    "node_modules/call-bind": {
      "version": "1.0.8",
      "resolved": "https://registry.npmjs.org/call-bind/-/call-bind-1.0.8.tgz",
      "integrity": "sha512-oKlSFMcMwpUg2ednkhQ454wfWiU/ul3CkJe/PEHcTKuiX6RpbehUiFMXu13HalGZxfUwCQzZG747YXBn1im9ww==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind-apply-helpers": "^1.0.0",
        "es-define-property": "^1.0.0",
        "get-intrinsic": "^1.2.4",
        "set-function-length": "^1.2.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/call-bind-apply-helpers": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/call-bind-apply-helpers/-/call-bind-apply-helpers-1.0.2.tgz",
      "integrity": "sha512-Sp1ablJ0ivDkSzjcaJdxEunN5/XvksFJ2sMBFfq6x0ryhQV/2b/KwFe21cMpmHtPOSij8K99/wSfoEuTObmuMQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0",
        "function-bind": "^1.1.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/call-bound": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/call-bound/-/call-bound-1.0.4.tgz",
      "integrity": "sha512-+ys997U96po4Kx/ABpBCqhA9EuxJaQWDQg7295H4hBphv3IZg0boBKuwYpt4YXp6MZ5AmZQnU/tyMTlRpaSejg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind-apply-helpers": "^1.0.2",
        "get-intrinsic": "^1.3.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/callsites": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/callsites/-/callsites-3.1.0.tgz",
      "integrity": "sha512-P8BjAsXvZS+VIDUI11hHCQEv74YT67YUi5JJFNWIqL235sBmjX4+qx9Muvls5ivyNENctx46xQLQ3aTuE7ssaQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/camelcase-css": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/camelcase-css/-/camelcase-css-2.0.1.tgz",
      "integrity": "sha512-QOSvevhslijgYwRx6Rv7zKdMF8lbRmx+uQGx2+vDc+KI/eBnsy9kit5aj23AgGu3pa4t9AgwbnXWqS+iOY+2aA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/caniuse-lite": {
      "version": "1.0.30001735",
      "resolved": "https://registry.npmjs.org/caniuse-lite/-/caniuse-lite-1.0.30001735.tgz",
      "integrity": "sha512-EV/laoX7Wq2J9TQlyIXRxTJqIw4sxfXS4OYgudGxBYRuTv0q7AM6yMEpU/Vo1I94thg9U6EZ2NfZx9GJq83u7w==",
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/browserslist"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/caniuse-lite"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "CC-BY-4.0"
    },
    "node_modules/chalk": {
      "version": "4.1.2",
      "resolved": "https://registry.npmjs.org/chalk/-/chalk-4.1.2.tgz",
      "integrity": "sha512-oKnbhFyRIXpUuez8iBMmyEa4nbj4IOQyuhc/wy9kY7/WVPcwIO9VA668Pu8RkO7+0G76SLROeyw9CpQ061i4mA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-styles": "^4.1.0",
        "supports-color": "^7.1.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/chalk/chalk?sponsor=1"
      }
    },
    "node_modules/chokidar": {
      "version": "3.6.0",
      "resolved": "https://registry.npmjs.org/chokidar/-/chokidar-3.6.0.tgz",
      "integrity": "sha512-7VT13fmjotKpGipCW9JEQAusEPE+Ei8nl6/g4FBAmIm0GOOLMua9NDDo/DWp0ZAxCr3cPq5ZpBqmPAQgDda2Pw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "anymatch": "~3.1.2",
        "braces": "~3.0.2",
        "glob-parent": "~5.1.2",
        "is-binary-path": "~2.1.0",
        "is-glob": "~4.0.1",
        "normalize-path": "~3.0.0",
        "readdirp": "~3.6.0"
      },
      "engines": {
        "node": ">= 8.10.0"
      },
      "funding": {
        "url": "https://paulmillr.com/funding/"
      },
      "optionalDependencies": {
        "fsevents": "~2.3.2"
      }
    },
    "node_modules/chokidar/node_modules/glob-parent": {
      "version": "5.1.2",
      "resolved": "https://registry.npmjs.org/glob-parent/-/glob-parent-5.1.2.tgz",
      "integrity": "sha512-AOIgSQCepiJYwP3ARnGx+5VnTu2HBYdzbGP45eLw1vr3zB3vZLeyed1sC9hnbcOc9/SrMyM5RPQrkGz4aS9Zow==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "is-glob": "^4.0.1"
      },
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/client-only": {
      "version": "0.0.1",
      "resolved": "https://registry.npmjs.org/client-only/-/client-only-0.0.1.tgz",
      "integrity": "sha512-IV3Ou0jSMzZrd3pZ48nLkT9DA7Ag1pnPzaiQhpW7c3RbcqqzvzzVu+L8gfqMp/8IM2MQtSiqaCxrrcfu8I8rMA==",
      "license": "MIT"
    },
    "node_modules/color-convert": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/color-convert/-/color-convert-2.0.1.tgz",
      "integrity": "sha512-RRECPsj7iu/xb5oKYcsFHSppFNnsj/52OVTRKb4zP5onXwVF3zVmmToNcOfGC+CRDpfK/U584fMg38ZHCaElKQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "color-name": "~1.1.4"
      },
      "engines": {
        "node": ">=7.0.0"
      }
    },
    "node_modules/color-name": {
      "version": "1.1.4",
      "resolved": "https://registry.npmjs.org/color-name/-/color-name-1.1.4.tgz",
      "integrity": "sha512-dOy+3AuW3a2wNbZHIuMZpTcgjGuLU/uBL/ubcZF9OXbDo8ff4O8yVp5Bf0efS8uEoYo5q4Fx7dY9OgQGXgAsQA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/commander": {
      "version": "4.1.1",
      "resolved": "https://registry.npmjs.org/commander/-/commander-4.1.1.tgz",
      "integrity": "sha512-NOKm8xhkzAjzFx8B2v5OAHT+u5pRQc2UCa2Vq9jYL/31o2wi9mxBA7LIFs3sV5VSC49z6pEhfbMULvShKj26WA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/concat-map": {
      "version": "0.0.1",
      "resolved": "https://registry.npmjs.org/concat-map/-/concat-map-0.0.1.tgz",
      "integrity": "sha512-/Srv4dswyQNBfohGpz9o6Yb3Gz3SrUDqBH5rTuhGR7ahtlbYKnVxw2bCFMRljaA7EXHaXZ8wsHdodFvbkhKmqg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/cross-spawn": {
      "version": "7.0.6",
      "resolved": "https://registry.npmjs.org/cross-spawn/-/cross-spawn-7.0.6.tgz",
      "integrity": "sha512-uV2QOWP2nWzsy2aMp8aRibhi9dlzF5Hgh5SHaB9OiTGEyDTiJJyx0uy51QXdyWbtAHNua4XJzUKca3OzKUd3vA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "path-key": "^3.1.0",
        "shebang-command": "^2.0.0",
        "which": "^2.0.1"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/cssesc": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/cssesc/-/cssesc-3.0.0.tgz",
      "integrity": "sha512-/Tb/JcjK111nNScGob5MNtsntNM1aCNUDipB/TkwZFhyDrrE47SOx/18wF2bbjgc3ZzCSKW1T5nt5EbFoAz/Vg==",
      "dev": true,
      "license": "MIT",
      "bin": {
        "cssesc": "bin/cssesc"
      },
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/csstype": {
      "version": "3.1.3",
      "resolved": "https://registry.npmjs.org/csstype/-/csstype-3.1.3.tgz",
      "integrity": "sha512-M1uQkMl8rQK/szD0LNhtqxIPLpimGm8sOBwU7lLnCpSbTyY3yeU1Vc7l4KT5zT4s/yOxHH5O7tIuuLOCnLADRw==",
      "license": "MIT"
    },
    "node_modules/damerau-levenshtein": {
      "version": "1.0.8",
      "resolved": "https://registry.npmjs.org/damerau-levenshtein/-/damerau-levenshtein-1.0.8.tgz",
      "integrity": "sha512-sdQSFB7+llfUcQHUQO3+B8ERRj0Oa4w9POWMI/puGtuf7gFywGmkaLCElnudfTiKZV+NvHqL0ifzdrI8Ro7ESA==",
      "dev": true,
      "license": "BSD-2-Clause"
    },
    "node_modules/data-view-buffer": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/data-view-buffer/-/data-view-buffer-1.0.2.tgz",
      "integrity": "sha512-EmKO5V3OLXh1rtK2wgXRansaK1/mtVdTUEiEI0W8RkvgT05kfxaH29PliLnpLP73yYO6142Q72QNa8Wx/A5CqQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "es-errors": "^1.3.0",
        "is-data-view": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/data-view-byte-length": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/data-view-byte-length/-/data-view-byte-length-1.0.2.tgz",
      "integrity": "sha512-tuhGbE6CfTM9+5ANGf+oQb72Ky/0+s3xKUpHvShfiz2RxMFgFPjsXuRLBVMtvMs15awe45SRb83D6wH4ew6wlQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "es-errors": "^1.3.0",
        "is-data-view": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/inspect-js"
      }
    },
    "node_modules/data-view-byte-offset": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/data-view-byte-offset/-/data-view-byte-offset-1.0.1.tgz",
      "integrity": "sha512-BS8PfmtDGnrgYdOonGZQdLZslWIeCGFP9tpan0hi1Co2Zr2NKADsvGYA8XxuG/4UWgJ6Cjtv+YJnB6MM69QGlQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.2",
        "es-errors": "^1.3.0",
        "is-data-view": "^1.0.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/debug": {
      "version": "4.4.1",
      "resolved": "https://registry.npmjs.org/debug/-/debug-4.4.1.tgz",
      "integrity": "sha512-KcKCqiftBJcZr++7ykoDIEwSa3XWowTfNPo92BYxjXiyYEVrUQh2aLyhxBCwww+heortUFxEJYcRzosstTEBYQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ms": "^2.1.3"
      },
      "engines": {
        "node": ">=6.0"
      },
      "peerDependenciesMeta": {
        "supports-color": {
          "optional": true
        }
      }
    },
    "node_modules/deep-is": {
      "version": "0.1.4",
      "resolved": "https://registry.npmjs.org/deep-is/-/deep-is-0.1.4.tgz",
      "integrity": "sha512-oIPzksmTg4/MriiaYGO+okXDT7ztn/w3Eptv/+gSIdMdKsJo0u4CfYNFJPy+4SKMuCqGw2wxnA+URMg3t8a/bQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/define-data-property": {
      "version": "1.1.4",
      "resolved": "https://registry.npmjs.org/define-data-property/-/define-data-property-1.1.4.tgz",
      "integrity": "sha512-rBMvIzlpA8v6E+SJZoo++HAYqsLrkg7MSfIinMPFhmkorw7X+dOXVJQs+QT69zGkzMyfDnIMN2Wid1+NbL3T+A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "es-define-property": "^1.0.0",
        "es-errors": "^1.3.0",
        "gopd": "^1.0.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/define-properties": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/define-properties/-/define-properties-1.2.1.tgz",
      "integrity": "sha512-8QmQKqEASLd5nx0U1B1okLElbUuuttJ/AnYmRXbbbGDWh6uS208EjD4Xqq/I9wK7u0v6O08XhTWnt5XtEbR6Dg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "define-data-property": "^1.0.1",
        "has-property-descriptors": "^1.0.0",
        "object-keys": "^1.1.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/didyoumean": {
      "version": "1.2.2",
      "resolved": "https://registry.npmjs.org/didyoumean/-/didyoumean-1.2.2.tgz",
      "integrity": "sha512-gxtyfqMg7GKyhQmb056K7M3xszy/myH8w+B4RT+QXBQsvAOdc3XymqDDPHx1BgPgsdAA5SIifona89YtRATDzw==",
      "dev": true,
      "license": "Apache-2.0"
    },
    "node_modules/dir-glob": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/dir-glob/-/dir-glob-3.0.1.tgz",
      "integrity": "sha512-WkrWp9GR4KXfKGYzOLmTuGVi1UWFfws377n9cc55/tb6DuqyF6pcQ5AbiHEshaDpY9v6oaSr2XCDidGmMwdzIA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "path-type": "^4.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/dlv": {
      "version": "1.1.3",
      "resolved": "https://registry.npmjs.org/dlv/-/dlv-1.1.3.tgz",
      "integrity": "sha512-+HlytyjlPKnIG8XuRG8WvmBP8xs8P71y+SKKS6ZXWoEgLuePxtDoUEiH7WkdePWrQ5JBpE6aoVqfZfJUQkjXwA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/doctrine": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/doctrine/-/doctrine-3.0.0.tgz",
      "integrity": "sha512-yS+Q5i3hBf7GBkd4KG8a7eBNNWNGLTaEwwYWUijIYM7zrlYDM0BFXHjjPWlWZ1Rg7UaddZeIDmi9jF3HmqiQ2w==",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "esutils": "^2.0.2"
      },
      "engines": {
        "node": ">=6.0.0"
      }
    },
    "node_modules/dunder-proto": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/dunder-proto/-/dunder-proto-1.0.1.tgz",
      "integrity": "sha512-KIN/nDJBQRcXw0MLVhZE9iQHmG68qAVIBg9CqmUYjmQIhgij9U5MFvrqkUL5FbtyyzZuOeOt0zdeRe4UY7ct+A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind-apply-helpers": "^1.0.1",
        "es-errors": "^1.3.0",
        "gopd": "^1.2.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/eastasianwidth": {
      "version": "0.2.0",
      "resolved": "https://registry.npmjs.org/eastasianwidth/-/eastasianwidth-0.2.0.tgz",
      "integrity": "sha512-I88TYZWc9XiYHRQ4/3c5rjjfgkjhLyW2luGIheGERbNQ6OY7yTybanSpDXZa8y7VUP9YmDcYa+eyq4ca7iLqWA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/electron-to-chromium": {
      "version": "1.5.201",
      "resolved": "https://registry.npmjs.org/electron-to-chromium/-/electron-to-chromium-1.5.201.tgz",
      "integrity": "sha512-ZG65vsrLClodGqywuigc+7m0gr4ISoTQttfVh7nfpLv0M7SIwF4WbFNEOywcqTiujs12AUeeXbFyQieDICAIxg==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/emoji-regex": {
      "version": "9.2.2",
      "resolved": "https://registry.npmjs.org/emoji-regex/-/emoji-regex-9.2.2.tgz",
      "integrity": "sha512-L18DaJsXSUk2+42pv8mLs5jJT2hqFkFE4j21wOmgbUqsZ2hL72NsUU785g9RXgo3s0ZNgVl42TiHp3ZtOv/Vyg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/es-abstract": {
      "version": "1.24.0",
      "resolved": "https://registry.npmjs.org/es-abstract/-/es-abstract-1.24.0.tgz",
      "integrity": "sha512-WSzPgsdLtTcQwm4CROfS5ju2Wa1QQcVeT37jFjYzdFz1r9ahadC8B8/a4qxJxM+09F18iumCdRmlr96ZYkQvEg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "array-buffer-byte-length": "^1.0.2",
        "arraybuffer.prototype.slice": "^1.0.4",
        "available-typed-arrays": "^1.0.7",
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.4",
        "data-view-buffer": "^1.0.2",
        "data-view-byte-length": "^1.0.2",
        "data-view-byte-offset": "^1.0.1",
        "es-define-property": "^1.0.1",
        "es-errors": "^1.3.0",
        "es-object-atoms": "^1.1.1",
        "es-set-tostringtag": "^2.1.0",
        "es-to-primitive": "^1.3.0",
        "function.prototype.name": "^1.1.8",
        "get-intrinsic": "^1.3.0",
        "get-proto": "^1.0.1",
        "get-symbol-description": "^1.1.0",
        "globalthis": "^1.0.4",
        "gopd": "^1.2.0",
        "has-property-descriptors": "^1.0.2",
        "has-proto": "^1.2.0",
        "has-symbols": "^1.1.0",
        "hasown": "^2.0.2",
        "internal-slot": "^1.1.0",
        "is-array-buffer": "^3.0.5",
        "is-callable": "^1.2.7",
        "is-data-view": "^1.0.2",
        "is-negative-zero": "^2.0.3",
        "is-regex": "^1.2.1",
        "is-set": "^2.0.3",
        "is-shared-array-buffer": "^1.0.4",
        "is-string": "^1.1.1",
        "is-typed-array": "^1.1.15",
        "is-weakref": "^1.1.1",
        "math-intrinsics": "^1.1.0",
        "object-inspect": "^1.13.4",
        "object-keys": "^1.1.1",
        "object.assign": "^4.1.7",
        "own-keys": "^1.0.1",
        "regexp.prototype.flags": "^1.5.4",
        "safe-array-concat": "^1.1.3",
        "safe-push-apply": "^1.0.0",
        "safe-regex-test": "^1.1.0",
        "set-proto": "^1.0.0",
        "stop-iteration-iterator": "^1.1.0",
        "string.prototype.trim": "^1.2.10",
        "string.prototype.trimend": "^1.0.9",
        "string.prototype.trimstart": "^1.0.8",
        "typed-array-buffer": "^1.0.3",
        "typed-array-byte-length": "^1.0.3",
        "typed-array-byte-offset": "^1.0.4",
        "typed-array-length": "^1.0.7",
        "unbox-primitive": "^1.1.0",
        "which-typed-array": "^1.1.19"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/es-define-property": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/es-define-property/-/es-define-property-1.0.1.tgz",
      "integrity": "sha512-e3nRfgfUZ4rNGL232gUgX06QNyyez04KdjFrF+LTRoOXmrOgFKDg4BCdsjW8EnT69eqdYGmRpJwiPVYNrCaW3g==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-errors": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/es-errors/-/es-errors-1.3.0.tgz",
      "integrity": "sha512-Zf5H2Kxt2xjTvbJvP2ZWLEICxA6j+hAmMzIlypy4xcBg1vKVnx89Wy0GbS+kf5cwCVFFzdCFh2XSCFNULS6csw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-iterator-helpers": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/es-iterator-helpers/-/es-iterator-helpers-1.2.1.tgz",
      "integrity": "sha512-uDn+FE1yrDzyC0pCo961B2IHbdM8y/ACZsKD4dG6WqrjV53BADjwa7D+1aom2rsNVfLyDgU/eigvlJGJ08OQ4w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.3",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.6",
        "es-errors": "^1.3.0",
        "es-set-tostringtag": "^2.0.3",
        "function-bind": "^1.1.2",
        "get-intrinsic": "^1.2.6",
        "globalthis": "^1.0.4",
        "gopd": "^1.2.0",
        "has-property-descriptors": "^1.0.2",
        "has-proto": "^1.2.0",
        "has-symbols": "^1.1.0",
        "internal-slot": "^1.1.0",
        "iterator.prototype": "^1.1.4",
        "safe-array-concat": "^1.1.3"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-object-atoms": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/es-object-atoms/-/es-object-atoms-1.1.1.tgz",
      "integrity": "sha512-FGgH2h8zKNim9ljj7dankFPcICIK9Cp5bm+c2gQSYePhpaG5+esrLODihIorn+Pe6FGJzWhXQotPv73jTaldXA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-set-tostringtag": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/es-set-tostringtag/-/es-set-tostringtag-2.1.0.tgz",
      "integrity": "sha512-j6vWzfrGVfyXxge+O0x5sh6cvxAog0a/4Rdd2K36zCMV5eJ+/+tOAngRO8cODMNWbVRdVlmGZQL2YS3yR8bIUA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0",
        "get-intrinsic": "^1.2.6",
        "has-tostringtag": "^1.0.2",
        "hasown": "^2.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-shim-unscopables": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/es-shim-unscopables/-/es-shim-unscopables-1.1.0.tgz",
      "integrity": "sha512-d9T8ucsEhh8Bi1woXCf+TIKDIROLG5WCkxg8geBCbvk22kzwC5G2OnXVMO6FUsvQlgUUXQ2itephWDLqDzbeCw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "hasown": "^2.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-to-primitive": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/es-to-primitive/-/es-to-primitive-1.3.0.tgz",
      "integrity": "sha512-w+5mJ3GuFL+NjVtJlvydShqE1eN3h3PbI7/5LAsYJP/2qtuMXjfL2LpHSRqo4b4eSF5K/DH1JXKUAHSB2UW50g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-callable": "^1.2.7",
        "is-date-object": "^1.0.5",
        "is-symbol": "^1.0.4"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/escalade": {
      "version": "3.2.0",
      "resolved": "https://registry.npmjs.org/escalade/-/escalade-3.2.0.tgz",
      "integrity": "sha512-WUj2qlxaQtO4g6Pq5c29GTcWGDyd8itL8zTlipgECz3JesAiiOKotd8JU6otB3PACgG6xkJUyVhboMS+bje/jA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/escape-string-regexp": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/escape-string-regexp/-/escape-string-regexp-4.0.0.tgz",
      "integrity": "sha512-TtpcNJ3XAzx3Gq8sWRzJaVajRs0uVxA2YAkdb1jm2YkPz4G6egUFAyA3n5vtEIZefPk5Wa4UXbKuS5fKkJWdgA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/eslint": {
      "version": "8.57.1",
      "resolved": "https://registry.npmjs.org/eslint/-/eslint-8.57.1.tgz",
      "integrity": "sha512-ypowyDxpVSYpkXr9WPv2PAZCtNip1Mv5KTW0SCurXv/9iOpcrH9PaqUElksqEB6pChqHGDRCFTyrZlGhnLNGiA==",
      "deprecated": "This version is no longer supported. Please see https://eslint.org/version-support for other options.",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@eslint-community/eslint-utils": "^4.2.0",
        "@eslint-community/regexpp": "^4.6.1",
        "@eslint/eslintrc": "^2.1.4",
        "@eslint/js": "8.57.1",
        "@humanwhocodes/config-array": "^0.13.0",
        "@humanwhocodes/module-importer": "^1.0.1",
        "@nodelib/fs.walk": "^1.2.8",
        "@ungap/structured-clone": "^1.2.0",
        "ajv": "^6.12.4",
        "chalk": "^4.0.0",
        "cross-spawn": "^7.0.2",
        "debug": "^4.3.2",
        "doctrine": "^3.0.0",
        "escape-string-regexp": "^4.0.0",
        "eslint-scope": "^7.2.2",
        "eslint-visitor-keys": "^3.4.3",
        "espree": "^9.6.1",
        "esquery": "^1.4.2",
        "esutils": "^2.0.2",
        "fast-deep-equal": "^3.1.3",
        "file-entry-cache": "^6.0.1",
        "find-up": "^5.0.0",
        "glob-parent": "^6.0.2",
        "globals": "^13.19.0",
        "graphemer": "^1.4.0",
        "ignore": "^5.2.0",
        "imurmurhash": "^0.1.4",
        "is-glob": "^4.0.0",
        "is-path-inside": "^3.0.3",
        "js-yaml": "^4.1.0",
        "json-stable-stringify-without-jsonify": "^1.0.1",
        "levn": "^0.4.1",
        "lodash.merge": "^4.6.2",
        "minimatch": "^3.1.2",
        "natural-compare": "^1.4.0",
        "optionator": "^0.9.3",
        "strip-ansi": "^6.0.1",
        "text-table": "^0.2.0"
      },
      "bin": {
        "eslint": "bin/eslint.js"
      },
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      }
    },
    "node_modules/eslint-config-next": {
      "version": "14.0.0",
      "resolved": "https://registry.npmjs.org/eslint-config-next/-/eslint-config-next-14.0.0.tgz",
      "integrity": "sha512-jtXeE+/pGQ3h9n11QyyuPN50kO13GO5XvjU5ZRq6W+XTpOMjyobWmK2s7aowy0FtzA49krJzYzEU9s1RMwoJ6g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@next/eslint-plugin-next": "14.0.0",
        "@rushstack/eslint-patch": "^1.3.3",
        "@typescript-eslint/parser": "^5.4.2 || ^6.0.0",
        "eslint-import-resolver-node": "^0.3.6",
        "eslint-import-resolver-typescript": "^3.5.2",
        "eslint-plugin-import": "^2.28.1",
        "eslint-plugin-jsx-a11y": "^6.7.1",
        "eslint-plugin-react": "^7.33.2",
        "eslint-plugin-react-hooks": "^4.5.0 || 5.0.0-canary-7118f5dd7-20230705"
      },
      "peerDependencies": {
        "eslint": "^7.23.0 || ^8.0.0",
        "typescript": ">=3.3.1"
      },
      "peerDependenciesMeta": {
        "typescript": {
          "optional": true
        }
      }
    },
    "node_modules/eslint-import-resolver-node": {
      "version": "0.3.9",
      "resolved": "https://registry.npmjs.org/eslint-import-resolver-node/-/eslint-import-resolver-node-0.3.9.tgz",
      "integrity": "sha512-WFj2isz22JahUv+B788TlO3N6zL3nNJGU8CcZbPZvVEkBPaJdCV4vy5wyghty5ROFbCRnm132v8BScu5/1BQ8g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "debug": "^3.2.7",
        "is-core-module": "^2.13.0",
        "resolve": "^1.22.4"
      }
    },
    "node_modules/eslint-import-resolver-node/node_modules/debug": {
      "version": "3.2.7",
      "resolved": "https://registry.npmjs.org/debug/-/debug-3.2.7.tgz",
      "integrity": "sha512-CFjzYYAi4ThfiQvizrFQevTTXHtnCqWfe7x1AhgEscTz6ZbLbfoLRLPugTQyBth6f8ZERVUSyWHFD/7Wu4t1XQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ms": "^2.1.1"
      }
    },
    "node_modules/eslint-import-resolver-typescript": {
      "version": "3.10.1",
      "resolved": "https://registry.npmjs.org/eslint-import-resolver-typescript/-/eslint-import-resolver-typescript-3.10.1.tgz",
      "integrity": "sha512-A1rHYb06zjMGAxdLSkN2fXPBwuSaQ0iO5M/hdyS0Ajj1VBaRp0sPD3dn1FhME3c/JluGFbwSxyCfqdSbtQLAHQ==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "@nolyfill/is-core-module": "1.0.39",
        "debug": "^4.4.0",
        "get-tsconfig": "^4.10.0",
        "is-bun-module": "^2.0.0",
        "stable-hash": "^0.0.5",
        "tinyglobby": "^0.2.13",
        "unrs-resolver": "^1.6.2"
      },
      "engines": {
        "node": "^14.18.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint-import-resolver-typescript"
      },
      "peerDependencies": {
        "eslint": "*",
        "eslint-plugin-import": "*",
        "eslint-plugin-import-x": "*"
      },
      "peerDependenciesMeta": {
        "eslint-plugin-import": {
          "optional": true
        },
        "eslint-plugin-import-x": {
          "optional": true
        }
      }
    },
    "node_modules/eslint-module-utils": {
      "version": "2.12.1",
      "resolved": "https://registry.npmjs.org/eslint-module-utils/-/eslint-module-utils-2.12.1.tgz",
      "integrity": "sha512-L8jSWTze7K2mTg0vos/RuLRS5soomksDPoJLXIslC7c8Wmut3bx7CPpJijDcBZtxQ5lrbUdM+s0OlNbz0DCDNw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "debug": "^3.2.7"
      },
      "engines": {
        "node": ">=4"
      },
      "peerDependenciesMeta": {
        "eslint": {
          "optional": true
        }
      }
    },
    "node_modules/eslint-module-utils/node_modules/debug": {
      "version": "3.2.7",
      "resolved": "https://registry.npmjs.org/debug/-/debug-3.2.7.tgz",
      "integrity": "sha512-CFjzYYAi4ThfiQvizrFQevTTXHtnCqWfe7x1AhgEscTz6ZbLbfoLRLPugTQyBth6f8ZERVUSyWHFD/7Wu4t1XQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ms": "^2.1.1"
      }
    },
    "node_modules/eslint-plugin-import": {
      "version": "2.32.0",
      "resolved": "https://registry.npmjs.org/eslint-plugin-import/-/eslint-plugin-import-2.32.0.tgz",
      "integrity": "sha512-whOE1HFo/qJDyX4SnXzP4N6zOWn79WhnCUY/iDR0mPfQZO8wcYE4JClzI2oZrhBnnMUCBCHZhO6VQyoBU95mZA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@rtsao/scc": "^1.1.0",
        "array-includes": "^3.1.9",
        "array.prototype.findlastindex": "^1.2.6",
        "array.prototype.flat": "^1.3.3",
        "array.prototype.flatmap": "^1.3.3",
        "debug": "^3.2.7",
        "doctrine": "^2.1.0",
        "eslint-import-resolver-node": "^0.3.9",
        "eslint-module-utils": "^2.12.1",
        "hasown": "^2.0.2",
        "is-core-module": "^2.16.1",
        "is-glob": "^4.0.3",
        "minimatch": "^3.1.2",
        "object.fromentries": "^2.0.8",
        "object.groupby": "^1.0.3",
        "object.values": "^1.2.1",
        "semver": "^6.3.1",
        "string.prototype.trimend": "^1.0.9",
        "tsconfig-paths": "^3.15.0"
      },
      "engines": {
        "node": ">=4"
      },
      "peerDependencies": {
        "eslint": "^2 || ^3 || ^4 || ^5 || ^6 || ^7.2.0 || ^8 || ^9"
      }
    },
    "node_modules/eslint-plugin-import/node_modules/debug": {
      "version": "3.2.7",
      "resolved": "https://registry.npmjs.org/debug/-/debug-3.2.7.tgz",
      "integrity": "sha512-CFjzYYAi4ThfiQvizrFQevTTXHtnCqWfe7x1AhgEscTz6ZbLbfoLRLPugTQyBth6f8ZERVUSyWHFD/7Wu4t1XQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ms": "^2.1.1"
      }
    },
    "node_modules/eslint-plugin-import/node_modules/doctrine": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/doctrine/-/doctrine-2.1.0.tgz",
      "integrity": "sha512-35mSku4ZXK0vfCuHEDAwt55dg2jNajHZ1odvF+8SSr82EsZY4QmXfuWso8oEd8zRhVObSN18aM0CjSdoBX7zIw==",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "esutils": "^2.0.2"
      },
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/eslint-plugin-import/node_modules/semver": {
      "version": "6.3.1",
      "resolved": "https://registry.npmjs.org/semver/-/semver-6.3.1.tgz",
      "integrity": "sha512-BR7VvDCVHO+q2xBEWskxS6DJE1qRnb7DxzUrogb71CWoSficBxYsiAGd+Kl0mmq/MprG9yArRkyrQxTO6XjMzA==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "semver": "bin/semver.js"
      }
    },
    "node_modules/eslint-plugin-jsx-a11y": {
      "version": "6.10.2",
      "resolved": "https://registry.npmjs.org/eslint-plugin-jsx-a11y/-/eslint-plugin-jsx-a11y-6.10.2.tgz",
      "integrity": "sha512-scB3nz4WmG75pV8+3eRUQOHZlNSUhFNq37xnpgRkCCELU3XMvXAxLk1eqWWyE22Ki4Q01Fnsw9BA3cJHDPgn2Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "aria-query": "^5.3.2",
        "array-includes": "^3.1.8",
        "array.prototype.flatmap": "^1.3.2",
        "ast-types-flow": "^0.0.8",
        "axe-core": "^4.10.0",
        "axobject-query": "^4.1.0",
        "damerau-levenshtein": "^1.0.8",
        "emoji-regex": "^9.2.2",
        "hasown": "^2.0.2",
        "jsx-ast-utils": "^3.3.5",
        "language-tags": "^1.0.9",
        "minimatch": "^3.1.2",
        "object.fromentries": "^2.0.8",
        "safe-regex-test": "^1.0.3",
        "string.prototype.includes": "^2.0.1"
      },
      "engines": {
        "node": ">=4.0"
      },
      "peerDependencies": {
        "eslint": "^3 || ^4 || ^5 || ^6 || ^7 || ^8 || ^9"
      }
    },
    "node_modules/eslint-plugin-react": {
      "version": "7.37.5",
      "resolved": "https://registry.npmjs.org/eslint-plugin-react/-/eslint-plugin-react-7.37.5.tgz",
      "integrity": "sha512-Qteup0SqU15kdocexFNAJMvCJEfa2xUKNV4CC1xsVMrIIqEy3SQ/rqyxCWNzfrd3/ldy6HMlD2e0JDVpDg2qIA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "array-includes": "^3.1.8",
        "array.prototype.findlast": "^1.2.5",
        "array.prototype.flatmap": "^1.3.3",
        "array.prototype.tosorted": "^1.1.4",
        "doctrine": "^2.1.0",
        "es-iterator-helpers": "^1.2.1",
        "estraverse": "^5.3.0",
        "hasown": "^2.0.2",
        "jsx-ast-utils": "^2.4.1 || ^3.0.0",
        "minimatch": "^3.1.2",
        "object.entries": "^1.1.9",
        "object.fromentries": "^2.0.8",
        "object.values": "^1.2.1",
        "prop-types": "^15.8.1",
        "resolve": "^2.0.0-next.5",
        "semver": "^6.3.1",
        "string.prototype.matchall": "^4.0.12",
        "string.prototype.repeat": "^1.0.0"
      },
      "engines": {
        "node": ">=4"
      },
      "peerDependencies": {
        "eslint": "^3 || ^4 || ^5 || ^6 || ^7 || ^8 || ^9.7"
      }
    },
    "node_modules/eslint-plugin-react-hooks": {
      "version": "5.0.0-canary-7118f5dd7-20230705",
      "resolved": "https://registry.npmjs.org/eslint-plugin-react-hooks/-/eslint-plugin-react-hooks-5.0.0-canary-7118f5dd7-20230705.tgz",
      "integrity": "sha512-AZYbMo/NW9chdL7vk6HQzQhT+PvTAEVqWk9ziruUoW2kAOcN5qNyelv70e0F1VNQAbvutOC9oc+xfWycI9FxDw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "peerDependencies": {
        "eslint": "^3.0.0 || ^4.0.0 || ^5.0.0 || ^6.0.0 || ^7.0.0 || ^8.0.0-0"
      }
    },
    "node_modules/eslint-plugin-react/node_modules/doctrine": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/doctrine/-/doctrine-2.1.0.tgz",
      "integrity": "sha512-35mSku4ZXK0vfCuHEDAwt55dg2jNajHZ1odvF+8SSr82EsZY4QmXfuWso8oEd8zRhVObSN18aM0CjSdoBX7zIw==",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "esutils": "^2.0.2"
      },
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/eslint-plugin-react/node_modules/resolve": {
      "version": "2.0.0-next.5",
      "resolved": "https://registry.npmjs.org/resolve/-/resolve-2.0.0-next.5.tgz",
      "integrity": "sha512-U7WjGVG9sH8tvjW5SmGbQuui75FiyjAX72HX15DwBBwF9dNiQZRQAg9nnPhYy+TUnE0+VcrttuvNI8oSxZcocA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-core-module": "^2.13.0",
        "path-parse": "^1.0.7",
        "supports-preserve-symlinks-flag": "^1.0.0"
      },
      "bin": {
        "resolve": "bin/resolve"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/eslint-plugin-react/node_modules/semver": {
      "version": "6.3.1",
      "resolved": "https://registry.npmjs.org/semver/-/semver-6.3.1.tgz",
      "integrity": "sha512-BR7VvDCVHO+q2xBEWskxS6DJE1qRnb7DxzUrogb71CWoSficBxYsiAGd+Kl0mmq/MprG9yArRkyrQxTO6XjMzA==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "semver": "bin/semver.js"
      }
    },
    "node_modules/eslint-scope": {
      "version": "7.2.2",
      "resolved": "https://registry.npmjs.org/eslint-scope/-/eslint-scope-7.2.2.tgz",
      "integrity": "sha512-dOt21O7lTMhDM+X9mB4GX+DZrZtCUJPL/wlcTqxyrx5IvO0IYtILdtrQGQp+8n5S0gwSVmOf9NQrjMOgfQZlIg==",
      "dev": true,
      "license": "BSD-2-Clause",
      "dependencies": {
        "esrecurse": "^4.3.0",
        "estraverse": "^5.2.0"
      },
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      }
    },
    "node_modules/eslint-visitor-keys": {
      "version": "3.4.3",
      "resolved": "https://registry.npmjs.org/eslint-visitor-keys/-/eslint-visitor-keys-3.4.3.tgz",
      "integrity": "sha512-wpc+LXeiyiisxPlEkUzU6svyS1frIO3Mgxj1fdy7Pm8Ygzguax2N3Fa/D/ag1WqbOprdI+uY6wMUl8/a2G+iag==",
      "dev": true,
      "license": "Apache-2.0",
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      }
    },
    "node_modules/espree": {
      "version": "9.6.1",
      "resolved": "https://registry.npmjs.org/espree/-/espree-9.6.1.tgz",
      "integrity": "sha512-oruZaFkjorTpF32kDSI5/75ViwGeZginGGy2NoOSg3Q9bnwlnmDm4HLnkl0RE3n+njDXR037aY1+x58Z/zFdwQ==",
      "dev": true,
      "license": "BSD-2-Clause",
      "dependencies": {
        "acorn": "^8.9.0",
        "acorn-jsx": "^5.3.2",
        "eslint-visitor-keys": "^3.4.1"
      },
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      }
    },
    "node_modules/esquery": {
      "version": "1.6.0",
      "resolved": "https://registry.npmjs.org/esquery/-/esquery-1.6.0.tgz",
      "integrity": "sha512-ca9pw9fomFcKPvFLXhBKUK90ZvGibiGOvRJNbjljY7s7uq/5YO4BOzcYtJqExdx99rF6aAcnRxHmcUHcz6sQsg==",
      "dev": true,
      "license": "BSD-3-Clause",
      "dependencies": {
        "estraverse": "^5.1.0"
      },
      "engines": {
        "node": ">=0.10"
      }
    },
    "node_modules/esrecurse": {
      "version": "4.3.0",
      "resolved": "https://registry.npmjs.org/esrecurse/-/esrecurse-4.3.0.tgz",
      "integrity": "sha512-KmfKL3b6G+RXvP8N1vr3Tq1kL/oCFgn2NYXEtqP8/L3pKapUA4G8cFVaoF3SU323CD4XypR/ffioHmkti6/Tag==",
      "dev": true,
      "license": "BSD-2-Clause",
      "dependencies": {
        "estraverse": "^5.2.0"
      },
      "engines": {
        "node": ">=4.0"
      }
    },
    "node_modules/estraverse": {
      "version": "5.3.0",
      "resolved": "https://registry.npmjs.org/estraverse/-/estraverse-5.3.0.tgz",
      "integrity": "sha512-MMdARuVEQziNTeJD8DgMqmhwR11BRQ/cBP+pLtYdSTnf3MIO8fFeiINEbX36ZdNlfU/7A9f3gUw49B3oQsvwBA==",
      "dev": true,
      "license": "BSD-2-Clause",
      "engines": {
        "node": ">=4.0"
      }
    },
    "node_modules/esutils": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/esutils/-/esutils-2.0.3.tgz",
      "integrity": "sha512-kVscqXk4OCp68SZ0dkgEKVi6/8ij300KBWTJq32P/dYeWTSwK41WyTxalN1eRmA5Z9UU/LX9D7FWSmV9SAYx6g==",
      "dev": true,
      "license": "BSD-2-Clause",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/fast-deep-equal": {
      "version": "3.1.3",
      "resolved": "https://registry.npmjs.org/fast-deep-equal/-/fast-deep-equal-3.1.3.tgz",
      "integrity": "sha512-f3qQ9oQy9j2AhBe/H9VC91wLmKBCCU/gDOnKNAYG5hswO7BLKj09Hc5HYNz9cGI++xlpDCIgDaitVs03ATR84Q==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/fast-glob": {
      "version": "3.3.3",
      "resolved": "https://registry.npmjs.org/fast-glob/-/fast-glob-3.3.3.tgz",
      "integrity": "sha512-7MptL8U0cqcFdzIzwOTHoilX9x5BrNqye7Z/LuC7kCMRio1EMSyqRK3BEAUD7sXRq4iT4AzTVuZdhgQ2TCvYLg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@nodelib/fs.stat": "^2.0.2",
        "@nodelib/fs.walk": "^1.2.3",
        "glob-parent": "^5.1.2",
        "merge2": "^1.3.0",
        "micromatch": "^4.0.8"
      },
      "engines": {
        "node": ">=8.6.0"
      }
    },
    "node_modules/fast-glob/node_modules/glob-parent": {
      "version": "5.1.2",
      "resolved": "https://registry.npmjs.org/glob-parent/-/glob-parent-5.1.2.tgz",
      "integrity": "sha512-AOIgSQCepiJYwP3ARnGx+5VnTu2HBYdzbGP45eLw1vr3zB3vZLeyed1sC9hnbcOc9/SrMyM5RPQrkGz4aS9Zow==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "is-glob": "^4.0.1"
      },
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/fast-json-stable-stringify": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/fast-json-stable-stringify/-/fast-json-stable-stringify-2.1.0.tgz",
      "integrity": "sha512-lhd/wF+Lk98HZoTCtlVraHtfh5XYijIjalXck7saUtuanSDyLMxnHhSXEDJqHxD7msR8D0uCmqlkwjCV8xvwHw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/fast-levenshtein": {
      "version": "2.0.6",
      "resolved": "https://registry.npmjs.org/fast-levenshtein/-/fast-levenshtein-2.0.6.tgz",
      "integrity": "sha512-DCXu6Ifhqcks7TZKY3Hxp3y6qphY5SJZmrWMDrKcERSOXWQdMhU9Ig/PYrzyw/ul9jOIyh0N4M0tbC5hodg8dw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/fastq": {
      "version": "1.19.1",
      "resolved": "https://registry.npmjs.org/fastq/-/fastq-1.19.1.tgz",
      "integrity": "sha512-GwLTyxkCXjXbxqIhTsMI2Nui8huMPtnxg7krajPJAjnEG/iiOS7i+zCtWGZR9G0NBKbXKh6X9m9UIsYX/N6vvQ==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "reusify": "^1.0.4"
      }
    },
    "node_modules/file-entry-cache": {
      "version": "6.0.1",
      "resolved": "https://registry.npmjs.org/file-entry-cache/-/file-entry-cache-6.0.1.tgz",
      "integrity": "sha512-7Gps/XWymbLk2QLYK4NzpMOrYjMhdIxXuIvy2QBsLE6ljuodKvdkWs/cpyJJ3CVIVpH0Oi1Hvg1ovbMzLdFBBg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "flat-cache": "^3.0.4"
      },
      "engines": {
        "node": "^10.12.0 || >=12.0.0"
      }
    },
    "node_modules/fill-range": {
      "version": "7.1.1",
      "resolved": "https://registry.npmjs.org/fill-range/-/fill-range-7.1.1.tgz",
      "integrity": "sha512-YsGpe3WHLK8ZYi4tWDg2Jy3ebRz2rXowDxnld4bkQB00cc/1Zw9AWnC0i9ztDJitivtQvaI9KaLyKrc+hBW0yg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "to-regex-range": "^5.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/find-up": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/find-up/-/find-up-5.0.0.tgz",
      "integrity": "sha512-78/PXT1wlLLDgTzDs7sjq9hzz0vXD+zn+7wypEe4fXQxCmdmqfGsEPQxmiCSQI3ajFV91bVSsvNtrJRiW6nGng==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "locate-path": "^6.0.0",
        "path-exists": "^4.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/flat-cache": {
      "version": "3.2.0",
      "resolved": "https://registry.npmjs.org/flat-cache/-/flat-cache-3.2.0.tgz",
      "integrity": "sha512-CYcENa+FtcUKLmhhqyctpclsq7QF38pKjZHsGNiSQF5r4FtoKDWabFDl3hzaEQMvT1LHEysw5twgLvpYYb4vbw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "flatted": "^3.2.9",
        "keyv": "^4.5.3",
        "rimraf": "^3.0.2"
      },
      "engines": {
        "node": "^10.12.0 || >=12.0.0"
      }
    },
    "node_modules/flatted": {
      "version": "3.3.3",
      "resolved": "https://registry.npmjs.org/flatted/-/flatted-3.3.3.tgz",
      "integrity": "sha512-GX+ysw4PBCz0PzosHDepZGANEuFCMLrnRTiEy9McGjmkCQYwRq4A/X786G/fjM/+OjsWSU1ZrY5qyARZmO/uwg==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/for-each": {
      "version": "0.3.5",
      "resolved": "https://registry.npmjs.org/for-each/-/for-each-0.3.5.tgz",
      "integrity": "sha512-dKx12eRCVIzqCxFGplyFKJMPvLEWgmNtUrpTiJIR5u97zEhRG8ySrtboPHZXx7daLxQVrl643cTzbab2tkQjxg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-callable": "^1.2.7"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/foreground-child": {
      "version": "3.3.1",
      "resolved": "https://registry.npmjs.org/foreground-child/-/foreground-child-3.3.1.tgz",
      "integrity": "sha512-gIXjKqtFuWEgzFRJA9WCQeSJLZDjgJUOMCMzxtvFq/37KojM1BFGufqsCy0r4qSQmYLsZYMeyRqzIWOMup03sw==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "cross-spawn": "^7.0.6",
        "signal-exit": "^4.0.1"
      },
      "engines": {
        "node": ">=14"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/fraction.js": {
      "version": "4.3.7",
      "resolved": "https://registry.npmjs.org/fraction.js/-/fraction.js-4.3.7.tgz",
      "integrity": "sha512-ZsDfxO51wGAXREY55a7la9LScWpwv9RxIrYABrlvOFBlH/ShPnrtsXeuUIfXKKOVicNxQ+o8JTbJvjS4M89yew==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": "*"
      },
      "funding": {
        "type": "patreon",
        "url": "https://github.com/sponsors/rawify"
      }
    },
    "node_modules/fs.realpath": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/fs.realpath/-/fs.realpath-1.0.0.tgz",
      "integrity": "sha512-OO0pH2lK6a0hZnAdau5ItzHPI6pUlvI7jMVnxUQRtw4owF2wk8lOSabtGDCTP4Ggrg2MbGnWO9X8K1t4+fGMDw==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/fsevents": {
      "version": "2.3.3",
      "resolved": "https://registry.npmjs.org/fsevents/-/fsevents-2.3.3.tgz",
      "integrity": "sha512-5xoDfX+fL7faATnagmWPpbFtwh/R77WmMMqqHGS65C3vvB0YHrgF+B1YmZ3441tMj5n63k0212XNoJwzlhffQw==",
      "dev": true,
      "hasInstallScript": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": "^8.16.0 || ^10.6.0 || >=11.0.0"
      }
    },
    "node_modules/function-bind": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/function-bind/-/function-bind-1.1.2.tgz",
      "integrity": "sha512-7XHNxH7qX9xG5mIwxkhumTox/MIRNcOgDrxWsMt2pAr23WHp6MrRlN7FBSFpCpr+oVO0F744iUgR82nJMfG2SA==",
      "dev": true,
      "license": "MIT",
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/function.prototype.name": {
      "version": "1.1.8",
      "resolved": "https://registry.npmjs.org/function.prototype.name/-/function.prototype.name-1.1.8.tgz",
      "integrity": "sha512-e5iwyodOHhbMr/yNrc7fDYG4qlbIvI5gajyzPnb5TCwyhjApznQh1BMFou9b30SevY43gCJKXycoCBjMbsuW0Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.3",
        "define-properties": "^1.2.1",
        "functions-have-names": "^1.2.3",
        "hasown": "^2.0.2",
        "is-callable": "^1.2.7"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/functions-have-names": {
      "version": "1.2.3",
      "resolved": "https://registry.npmjs.org/functions-have-names/-/functions-have-names-1.2.3.tgz",
      "integrity": "sha512-xckBUXyTIqT97tq2x2AMb+g163b5JFysYk0x4qxNFwbfQkmNZoiRHb6sPzI9/QV33WeuvVYBUIiD4NzNIyqaRQ==",
      "dev": true,
      "license": "MIT",
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/get-intrinsic": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/get-intrinsic/-/get-intrinsic-1.3.0.tgz",
      "integrity": "sha512-9fSjSaos/fRIVIp+xSJlE6lfwhES7LNtKaCBIamHsjr2na1BiABJPo0mOjjz8GJDURarmCPGqaiVg5mfjb98CQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind-apply-helpers": "^1.0.2",
        "es-define-property": "^1.0.1",
        "es-errors": "^1.3.0",
        "es-object-atoms": "^1.1.1",
        "function-bind": "^1.1.2",
        "get-proto": "^1.0.1",
        "gopd": "^1.2.0",
        "has-symbols": "^1.1.0",
        "hasown": "^2.0.2",
        "math-intrinsics": "^1.1.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/get-proto": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/get-proto/-/get-proto-1.0.1.tgz",
      "integrity": "sha512-sTSfBjoXBp89JvIKIefqw7U2CCebsc74kiY6awiGogKtoSGbgjYE/G/+l9sF3MWFPNc9IcoOC4ODfKHfxFmp0g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "dunder-proto": "^1.0.1",
        "es-object-atoms": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/get-symbol-description": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/get-symbol-description/-/get-symbol-description-1.1.0.tgz",
      "integrity": "sha512-w9UMqWwJxHNOvoNzSJ2oPF5wvYcvP7jUvYzhp67yEhTi17ZDBBC1z9pTdGuzjD+EFIqLSYRweZjqfiPzQ06Ebg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "es-errors": "^1.3.0",
        "get-intrinsic": "^1.2.6"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/get-tsconfig": {
      "version": "4.10.1",
      "resolved": "https://registry.npmjs.org/get-tsconfig/-/get-tsconfig-4.10.1.tgz",
      "integrity": "sha512-auHyJ4AgMz7vgS8Hp3N6HXSmlMdUyhSUrfBF16w153rxtLIEOE+HGqaBppczZvnHLqQJfiHotCYpNhl0lUROFQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "resolve-pkg-maps": "^1.0.0"
      },
      "funding": {
        "url": "https://github.com/privatenumber/get-tsconfig?sponsor=1"
      }
    },
    "node_modules/glob": {
      "version": "7.1.7",
      "resolved": "https://registry.npmjs.org/glob/-/glob-7.1.7.tgz",
      "integrity": "sha512-OvD9ENzPLbegENnYP5UUfJIirTg4+XwMWGaQfQTY0JenxNvvIKP3U3/tAQSPIu/lHxXYSZmpXlUHeqAIdKzBLQ==",
      "deprecated": "Glob versions prior to v9 are no longer supported",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "fs.realpath": "^1.0.0",
        "inflight": "^1.0.4",
        "inherits": "2",
        "minimatch": "^3.0.4",
        "once": "^1.3.0",
        "path-is-absolute": "^1.0.0"
      },
      "engines": {
        "node": "*"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/glob-parent": {
      "version": "6.0.2",
      "resolved": "https://registry.npmjs.org/glob-parent/-/glob-parent-6.0.2.tgz",
      "integrity": "sha512-XxwI8EOhVQgWp6iDL+3b0r86f4d6AX6zSU55HfB4ydCEuXLXc5FcYeOu+nnGftS4TEju/11rt4KJPTMgbfmv4A==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "is-glob": "^4.0.3"
      },
      "engines": {
        "node": ">=10.13.0"
      }
    },
    "node_modules/glob-to-regexp": {
      "version": "0.4.1",
      "resolved": "https://registry.npmjs.org/glob-to-regexp/-/glob-to-regexp-0.4.1.tgz",
      "integrity": "sha512-lkX1HJXwyMcprw/5YUZc2s7DrpAiHB21/V+E1rHUrVNokkvB6bqMzT0VfV6/86ZNabt1k14YOIaT7nDvOX3Iiw==",
      "license": "BSD-2-Clause"
    },
    "node_modules/globals": {
      "version": "13.24.0",
      "resolved": "https://registry.npmjs.org/globals/-/globals-13.24.0.tgz",
      "integrity": "sha512-AhO5QUcj8llrbG09iWhPU2B204J1xnPeL8kQmVorSsy+Sjj1sk8gIyh6cUocGmH4L0UuhAJy+hJMRA4mgA4mFQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "type-fest": "^0.20.2"
      },
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/globalthis": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/globalthis/-/globalthis-1.0.4.tgz",
      "integrity": "sha512-DpLKbNU4WylpxJykQujfCcwYWiV/Jhm50Goo0wrVILAv5jOr9d+H+UR3PhSCD2rCCEIg0uc+G+muBTwD54JhDQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "define-properties": "^1.2.1",
        "gopd": "^1.0.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/globby": {
      "version": "11.1.0",
      "resolved": "https://registry.npmjs.org/globby/-/globby-11.1.0.tgz",
      "integrity": "sha512-jhIXaOzy1sb8IyocaruWSn1TjmnBVs8Ayhcy83rmxNJ8q2uWKCAj3CnJY+KpGSXCueAPc0i05kVvVKtP1t9S3g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "array-union": "^2.1.0",
        "dir-glob": "^3.0.1",
        "fast-glob": "^3.2.9",
        "ignore": "^5.2.0",
        "merge2": "^1.4.1",
        "slash": "^3.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/gopd": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/gopd/-/gopd-1.2.0.tgz",
      "integrity": "sha512-ZUKRh6/kUFoAiTAtTYPZJ3hw9wNxx+BIBOijnlG9PnrJsCcSjs1wyyD6vJpaYtgnzDrKYRSqf3OO6Rfa93xsRg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/graceful-fs": {
      "version": "4.2.11",
      "resolved": "https://registry.npmjs.org/graceful-fs/-/graceful-fs-4.2.11.tgz",
      "integrity": "sha512-RbJ5/jmFcNNCcDV5o9eTnBLJ/HszWV0P73bc+Ff4nS/rJj+YaS6IGyiOL0VoBYX+l1Wrl3k63h/KrH+nhJ0XvQ==",
      "license": "ISC"
    },
    "node_modules/graphemer": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/graphemer/-/graphemer-1.4.0.tgz",
      "integrity": "sha512-EtKwoO6kxCL9WO5xipiHTZlSzBm7WLT627TqC/uVRd0HKmq8NXyebnNYxDoBi7wt8eTWrUrKXCOVaFq9x1kgag==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/has-bigints": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/has-bigints/-/has-bigints-1.1.0.tgz",
      "integrity": "sha512-R3pbpkcIqv2Pm3dUwgjclDRVmWpTJW2DcMzcIhEXEx1oh/CEMObMm3KLmRJOdvhM7o4uQBnwr8pzRK2sJWIqfg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/has-flag": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/has-flag/-/has-flag-4.0.0.tgz",
      "integrity": "sha512-EykJT/Q1KjTWctppgIAgfSO0tKVuZUjhgMr17kqTumMl6Afv3EISleU7qZUzoXDFTAHTDC4NOoG/ZxU3EvlMPQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/has-property-descriptors": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/has-property-descriptors/-/has-property-descriptors-1.0.2.tgz",
      "integrity": "sha512-55JNKuIW+vq4Ke1BjOTjM2YctQIvCT7GFzHwmfZPGo5wnrgkid0YQtnAleFSqumZm4az3n2BS+erby5ipJdgrg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "es-define-property": "^1.0.0"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/has-proto": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/has-proto/-/has-proto-1.2.0.tgz",
      "integrity": "sha512-KIL7eQPfHQRC8+XluaIw7BHUwwqL19bQn4hzNgdr+1wXoU0KKj6rufu47lhY7KbJR2C6T6+PfyN0Ea7wkSS+qQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "dunder-proto": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/has-symbols": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/has-symbols/-/has-symbols-1.1.0.tgz",
      "integrity": "sha512-1cDNdwJ2Jaohmb3sg4OmKaMBwuC48sYni5HUw2DvsC8LjGTLK9h+eb1X6RyuOHe4hT0ULCW68iomhjUoKUqlPQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/has-tostringtag": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/has-tostringtag/-/has-tostringtag-1.0.2.tgz",
      "integrity": "sha512-NqADB8VjPFLM2V0VvHUewwwsw0ZWBaIdgo+ieHtK3hasLz4qeCRjYcqfB6AQrBggRKppKF8L52/VqdVsO47Dlw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "has-symbols": "^1.0.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/hasown": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/hasown/-/hasown-2.0.2.tgz",
      "integrity": "sha512-0hJU9SCPvmMzIBdZFqNPXWa6dqh7WdH0cII9y+CyS8rG3nL48Bclra9HmKhVVUHyPWNH5Y7xDwAB7bfgSjkUMQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "function-bind": "^1.1.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/ignore": {
      "version": "5.3.2",
      "resolved": "https://registry.npmjs.org/ignore/-/ignore-5.3.2.tgz",
      "integrity": "sha512-hsBTNUqQTDwkWtcdYI2i06Y/nUBEsNEDJKjWdigLvegy8kDuJAS8uRlpkkcQpyEXL0Z/pjDy5HBmMjRCJ2gq+g==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 4"
      }
    },
    "node_modules/import-fresh": {
      "version": "3.3.1",
      "resolved": "https://registry.npmjs.org/import-fresh/-/import-fresh-3.3.1.tgz",
      "integrity": "sha512-TR3KfrTZTYLPB6jUjfx6MF9WcWrHL9su5TObK4ZkYgBdWKPOFoSoQIdEuTuR82pmtxH2spWG9h6etwfr1pLBqQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "parent-module": "^1.0.0",
        "resolve-from": "^4.0.0"
      },
      "engines": {
        "node": ">=6"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/imurmurhash": {
      "version": "0.1.4",
      "resolved": "https://registry.npmjs.org/imurmurhash/-/imurmurhash-0.1.4.tgz",
      "integrity": "sha512-JmXMZ6wuvDmLiHEml9ykzqO6lwFbof0GG4IkcGaENdCRDDmMVnny7s5HsIgHCbaq0w2MyPhDqkhTUgS2LU2PHA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.8.19"
      }
    },
    "node_modules/inflight": {
      "version": "1.0.6",
      "resolved": "https://registry.npmjs.org/inflight/-/inflight-1.0.6.tgz",
      "integrity": "sha512-k92I/b08q4wvFscXCLvqfsHCrjrF7yiXsQuIVvVE7N82W3+aqpzuUdBbfhWcy/FZR3/4IgflMgKLOsvPDrGCJA==",
      "deprecated": "This module is not supported, and leaks memory. Do not use it. Check out lru-cache if you want a good and tested way to coalesce async requests by a key value, which is much more comprehensive and powerful.",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "once": "^1.3.0",
        "wrappy": "1"
      }
    },
    "node_modules/inherits": {
      "version": "2.0.4",
      "resolved": "https://registry.npmjs.org/inherits/-/inherits-2.0.4.tgz",
      "integrity": "sha512-k/vGaX4/Yla3WzyMCvTQOXYeIHvqOKtnqBduzTHpzpQZzAskKMhZ2K+EnBiSM9zGSoIFeMpXKxa4dYeZIQqewQ==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/internal-slot": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/internal-slot/-/internal-slot-1.1.0.tgz",
      "integrity": "sha512-4gd7VpWNQNB4UKKCFFVcp1AVv+FMOgs9NKzjHKusc8jTMhd5eL1NqQqOpE0KzMds804/yHlglp3uxgluOqAPLw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0",
        "hasown": "^2.0.2",
        "side-channel": "^1.1.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/is-array-buffer": {
      "version": "3.0.5",
      "resolved": "https://registry.npmjs.org/is-array-buffer/-/is-array-buffer-3.0.5.tgz",
      "integrity": "sha512-DDfANUiiG2wC1qawP66qlTugJeL5HyzMpfr8lLK+jMQirGzNod0B12cFB/9q838Ru27sBwfw78/rdoU7RERz6A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.3",
        "get-intrinsic": "^1.2.6"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-async-function": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/is-async-function/-/is-async-function-2.1.1.tgz",
      "integrity": "sha512-9dgM/cZBnNvjzaMYHVoxxfPj2QXt22Ev7SuuPrs+xav0ukGB0S6d4ydZdEiM48kLx5kDV+QBPrpVnFyefL8kkQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "async-function": "^1.0.0",
        "call-bound": "^1.0.3",
        "get-proto": "^1.0.1",
        "has-tostringtag": "^1.0.2",
        "safe-regex-test": "^1.1.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-bigint": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/is-bigint/-/is-bigint-1.1.0.tgz",
      "integrity": "sha512-n4ZT37wG78iz03xPRKJrHTdZbe3IicyucEtdRsV5yglwc3GyUfbAfpSeD0FJ41NbUNSt5wbhqfp1fS+BgnvDFQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "has-bigints": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-binary-path": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/is-binary-path/-/is-binary-path-2.1.0.tgz",
      "integrity": "sha512-ZMERYes6pDydyuGidse7OsHxtbI7WVeUEozgR/g7rd0xUimYNlvZRE/K2MgZTjWy725IfelLeVcEM97mmtRGXw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "binary-extensions": "^2.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/is-boolean-object": {
      "version": "1.2.2",
      "resolved": "https://registry.npmjs.org/is-boolean-object/-/is-boolean-object-1.2.2.tgz",
      "integrity": "sha512-wa56o2/ElJMYqjCjGkXri7it5FbebW5usLw/nPmCMs5DeZ7eziSYZhSmPRn0txqeW4LnAmQQU7FgqLpsEFKM4A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "has-tostringtag": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-bun-module": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/is-bun-module/-/is-bun-module-2.0.0.tgz",
      "integrity": "sha512-gNCGbnnnnFAUGKeZ9PdbyeGYJqewpmc2aKHUEMO5nQPWU9lOmv7jcmQIv+qHD8fXW6W7qfuCwX4rY9LNRjXrkQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "semver": "^7.7.1"
      }
    },
    "node_modules/is-callable": {
      "version": "1.2.7",
      "resolved": "https://registry.npmjs.org/is-callable/-/is-callable-1.2.7.tgz",
      "integrity": "sha512-1BC0BVFhS/p0qtw6enp8e+8OD0UrK0oFLztSjNzhcKA3WDuJxxAPXzPuPtKkjEY9UUoEWlX/8fgKeu2S8i9JTA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-core-module": {
      "version": "2.16.1",
      "resolved": "https://registry.npmjs.org/is-core-module/-/is-core-module-2.16.1.tgz",
      "integrity": "sha512-UfoeMA6fIJ8wTYFEUjelnaGI67v6+N7qXJEvQuIGa99l4xsCruSYOVSQ0uPANn4dAzm8lkYPaKLrrijLq7x23w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "hasown": "^2.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-data-view": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/is-data-view/-/is-data-view-1.0.2.tgz",
      "integrity": "sha512-RKtWF8pGmS87i2D6gqQu/l7EYRlVdfzemCJN/P3UOs//x1QE7mfhvzHIApBTRf7axvT6DMGwSwBXYCT0nfB9xw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.2",
        "get-intrinsic": "^1.2.6",
        "is-typed-array": "^1.1.13"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-date-object": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/is-date-object/-/is-date-object-1.1.0.tgz",
      "integrity": "sha512-PwwhEakHVKTdRNVOw+/Gyh0+MzlCl4R6qKvkhuvLtPMggI1WAHt9sOwZxQLSGpUaDnrdyDsomoRgNnCfKNSXXg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.2",
        "has-tostringtag": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-extglob": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/is-extglob/-/is-extglob-2.1.1.tgz",
      "integrity": "sha512-SbKbANkN603Vi4jEZv49LeVJMn4yGwsbzZworEoyEiutsN3nJYdbO36zfhGJ6QEDpOZIFkDtnq5JRxmvl3jsoQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/is-finalizationregistry": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/is-finalizationregistry/-/is-finalizationregistry-1.1.1.tgz",
      "integrity": "sha512-1pC6N8qWJbWoPtEjgcL2xyhQOP491EQjeUo3qTKcmV8YSDDJrOepfG8pcC7h/QgnQHYSv0mJ3Z/ZWxmatVrysg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-fullwidth-code-point": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/is-fullwidth-code-point/-/is-fullwidth-code-point-3.0.0.tgz",
      "integrity": "sha512-zymm5+u+sCsSWyD9qNaejV3DFvhCKclKdizYaJUuHA83RLjb7nSuGnddCHGv0hk+KY7BMAlsWeK4Ueg6EV6XQg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/is-generator-function": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/is-generator-function/-/is-generator-function-1.1.0.tgz",
      "integrity": "sha512-nPUB5km40q9e8UfN/Zc24eLlzdSf9OfKByBw9CIdw4H1giPMeA0OIJvbchsCu4npfI2QcMVBsGEBHKZ7wLTWmQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "get-proto": "^1.0.0",
        "has-tostringtag": "^1.0.2",
        "safe-regex-test": "^1.1.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-glob": {
      "version": "4.0.3",
      "resolved": "https://registry.npmjs.org/is-glob/-/is-glob-4.0.3.tgz",
      "integrity": "sha512-xelSayHH36ZgE7ZWhli7pW34hNbNl8Ojv5KVmkJD4hBdD3th8Tfk9vYasLM+mXWOZhFkgZfxhLSnrwRr4elSSg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-extglob": "^2.1.1"
      },
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/is-map": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/is-map/-/is-map-2.0.3.tgz",
      "integrity": "sha512-1Qed0/Hr2m+YqxnM09CjA2d/i6YZNfF6R2oRAOj36eUdS6qIV/huPJNSEpKbupewFs+ZsJlxsjjPbc0/afW6Lw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-negative-zero": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/is-negative-zero/-/is-negative-zero-2.0.3.tgz",
      "integrity": "sha512-5KoIu2Ngpyek75jXodFvnafB6DJgr3u8uuK0LEZJjrU19DrMD3EVERaR8sjz8CCGgpZvxPl9SuE1GMVPFHx1mw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-number": {
      "version": "7.0.0",
      "resolved": "https://registry.npmjs.org/is-number/-/is-number-7.0.0.tgz",
      "integrity": "sha512-41Cifkg6e8TylSpdtTpeLVMqvSBEVzTttHvERD741+pnZ8ANv0004MRL43QKPDlK9cGvNp6NZWZUBlbGXYxxng==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.12.0"
      }
    },
    "node_modules/is-number-object": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/is-number-object/-/is-number-object-1.1.1.tgz",
      "integrity": "sha512-lZhclumE1G6VYD8VHe35wFaIif+CTy5SJIi5+3y4psDgWu4wPDoBhF8NxUOinEc7pHgiTsT6MaBb92rKhhD+Xw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "has-tostringtag": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-path-inside": {
      "version": "3.0.3",
      "resolved": "https://registry.npmjs.org/is-path-inside/-/is-path-inside-3.0.3.tgz",
      "integrity": "sha512-Fd4gABb+ycGAmKou8eMftCupSir5lRxqf4aD/vd0cD2qc4HL07OjCeuHMr8Ro4CoMaeCKDB0/ECBOVWjTwUvPQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/is-regex": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/is-regex/-/is-regex-1.2.1.tgz",
      "integrity": "sha512-MjYsKHO5O7mCsmRGxWcLWheFqN9DJ/2TmngvjKXihe6efViPqc274+Fx/4fYj/r03+ESvBdTXK0V6tA3rgez1g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.2",
        "gopd": "^1.2.0",
        "has-tostringtag": "^1.0.2",
        "hasown": "^2.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-set": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/is-set/-/is-set-2.0.3.tgz",
      "integrity": "sha512-iPAjerrse27/ygGLxw+EBR9agv9Y6uLeYVJMu+QNCoouJ1/1ri0mGrcWpfCqFZuzzx3WjtwxG098X+n4OuRkPg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-shared-array-buffer": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/is-shared-array-buffer/-/is-shared-array-buffer-1.0.4.tgz",
      "integrity": "sha512-ISWac8drv4ZGfwKl5slpHG9OwPNty4jOWPRIhBpxOoD+hqITiwuipOQ2bNthAzwA3B4fIjO4Nln74N0S9byq8A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-string": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/is-string/-/is-string-1.1.1.tgz",
      "integrity": "sha512-BtEeSsoaQjlSPBemMQIrY1MY0uM6vnS1g5fmufYOtnxLGUZM2178PKbhsk7Ffv58IX+ZtcvoGwccYsh0PglkAA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "has-tostringtag": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-symbol": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/is-symbol/-/is-symbol-1.1.1.tgz",
      "integrity": "sha512-9gGx6GTtCQM73BgmHQXfDmLtfjjTUDSyoxTCbp5WtoixAhfgsDirWIcVQ/IHpvI5Vgd5i/J5F7B9cN/WlVbC/w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.2",
        "has-symbols": "^1.1.0",
        "safe-regex-test": "^1.1.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-typed-array": {
      "version": "1.1.15",
      "resolved": "https://registry.npmjs.org/is-typed-array/-/is-typed-array-1.1.15.tgz",
      "integrity": "sha512-p3EcsicXjit7SaskXHs1hA91QxgTw46Fv6EFKKGS5DRFLD8yKnohjF3hxoju94b/OcMZoQukzpPpBE9uLVKzgQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "which-typed-array": "^1.1.16"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-weakmap": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/is-weakmap/-/is-weakmap-2.0.2.tgz",
      "integrity": "sha512-K5pXYOm9wqY1RgjpL3YTkF39tni1XajUIkawTLUo9EZEVUFga5gSQJF8nNS7ZwJQ02y+1YCNYcMh+HIf1ZqE+w==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-weakref": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/is-weakref/-/is-weakref-1.1.1.tgz",
      "integrity": "sha512-6i9mGWSlqzNMEqpCp93KwRS1uUOodk2OJ6b+sq7ZPDSy2WuI5NFIxp/254TytR8ftefexkWn5xNiHUNpPOfSew==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-weakset": {
      "version": "2.0.4",
      "resolved": "https://registry.npmjs.org/is-weakset/-/is-weakset-2.0.4.tgz",
      "integrity": "sha512-mfcwb6IzQyOKTs84CQMrOwW4gQcaTOAWJ0zzJCl2WSPDrWk/OzDaImWFH3djXhb24g4eudZfLRozAvPGw4d9hQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "get-intrinsic": "^1.2.6"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/isarray": {
      "version": "2.0.5",
      "resolved": "https://registry.npmjs.org/isarray/-/isarray-2.0.5.tgz",
      "integrity": "sha512-xHjhDr3cNBK0BzdUJSPXZntQUx/mwMS5Rw4A7lPJ90XGAO6ISP/ePDNuo0vhqOZU+UD5JoodwCAAoZQd3FeAKw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/isexe": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/isexe/-/isexe-2.0.0.tgz",
      "integrity": "sha512-RHxMLp9lnKHGHRng9QFhRCMbYAcVpn69smSGcq3f36xjgVVWThj4qqLbTLlq7Ssj8B+fIQ1EuCEGI2lKsyQeIw==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/iterator.prototype": {
      "version": "1.1.5",
      "resolved": "https://registry.npmjs.org/iterator.prototype/-/iterator.prototype-1.1.5.tgz",
      "integrity": "sha512-H0dkQoCa3b2VEeKQBOxFph+JAbcrQdE7KC0UkqwpLmv2EC4P41QXP+rqo9wYodACiG5/WM5s9oDApTU8utwj9g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "define-data-property": "^1.1.4",
        "es-object-atoms": "^1.0.0",
        "get-intrinsic": "^1.2.6",
        "get-proto": "^1.0.0",
        "has-symbols": "^1.1.0",
        "set-function-name": "^2.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/jackspeak": {
      "version": "3.4.3",
      "resolved": "https://registry.npmjs.org/jackspeak/-/jackspeak-3.4.3.tgz",
      "integrity": "sha512-OGlZQpz2yfahA/Rd1Y8Cd9SIEsqvXkLVoSw/cgwhnhFMDbsQFeZYoJJ7bIZBS9BcamUW96asq/npPWugM+RQBw==",
      "dev": true,
      "license": "BlueOak-1.0.0",
      "dependencies": {
        "@isaacs/cliui": "^8.0.2"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      },
      "optionalDependencies": {
        "@pkgjs/parseargs": "^0.11.0"
      }
    },
    "node_modules/jiti": {
      "version": "1.21.7",
      "resolved": "https://registry.npmjs.org/jiti/-/jiti-1.21.7.tgz",
      "integrity": "sha512-/imKNG4EbWNrVjoNC/1H5/9GFy+tqjGBHCaSsN+P2RnPqjsLmv6UD3Ej+Kj8nBWaRAwyk7kK5ZUc+OEatnTR3A==",
      "dev": true,
      "license": "MIT",
      "bin": {
        "jiti": "bin/jiti.js"
      }
    },
    "node_modules/js-tokens": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/js-tokens/-/js-tokens-4.0.0.tgz",
      "integrity": "sha512-RdJUflcE3cUzKiMqQgsCu06FPu9UdIJO0beYbPhHN4k6apgJtifcoCtT9bcxOpYBtpD2kCM6Sbzg4CausW/PKQ==",
      "license": "MIT"
    },
    "node_modules/js-yaml": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/js-yaml/-/js-yaml-4.1.0.tgz",
      "integrity": "sha512-wpxZs9NoxZaJESJGIZTyDEaYpl0FKSA+FB9aJiyemKhMwkxQg63h4T1KJgUGHpTqPDNRcmmYLugrRjJlBtWvRA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "argparse": "^2.0.1"
      },
      "bin": {
        "js-yaml": "bin/js-yaml.js"
      }
    },
    "node_modules/json-buffer": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/json-buffer/-/json-buffer-3.0.1.tgz",
      "integrity": "sha512-4bV5BfR2mqfQTJm+V5tPPdf+ZpuhiIvTuAB5g8kcrXOZpTT/QwwVRWBywX1ozr6lEuPdbHxwaJlm9G6mI2sfSQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/json-schema-traverse": {
      "version": "0.4.1",
      "resolved": "https://registry.npmjs.org/json-schema-traverse/-/json-schema-traverse-0.4.1.tgz",
      "integrity": "sha512-xbbCH5dCYU5T8LcEhhuh7HJ88HXuW3qsI3Y0zOZFKfZEHcpWiHU/Jxzk629Brsab/mMiHQti9wMP+845RPe3Vg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/json-stable-stringify-without-jsonify": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/json-stable-stringify-without-jsonify/-/json-stable-stringify-without-jsonify-1.0.1.tgz",
      "integrity": "sha512-Bdboy+l7tA3OGW6FjyFHWkP5LuByj1Tk33Ljyq0axyzdk9//JSi2u3fP1QSmd1KNwq6VOKYGlAu87CisVir6Pw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/json5": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/json5/-/json5-1.0.2.tgz",
      "integrity": "sha512-g1MWMLBiz8FKi1e4w0UyVL3w+iJceWAFBAaBnnGKOpNa5f8TLktkbre1+s6oICydWAm+HRUGTmI+//xv2hvXYA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "minimist": "^1.2.0"
      },
      "bin": {
        "json5": "lib/cli.js"
      }
    },
    "node_modules/jsx-ast-utils": {
      "version": "3.3.5",
      "resolved": "https://registry.npmjs.org/jsx-ast-utils/-/jsx-ast-utils-3.3.5.tgz",
      "integrity": "sha512-ZZow9HBI5O6EPgSJLUb8n2NKgmVWTwCvHGwFuJlMjvLFqlGG6pjirPhtdsseaLZjSibD8eegzmYpUZwoIlj2cQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "array-includes": "^3.1.6",
        "array.prototype.flat": "^1.3.1",
        "object.assign": "^4.1.4",
        "object.values": "^1.1.6"
      },
      "engines": {
        "node": ">=4.0"
      }
    },
    "node_modules/keyv": {
      "version": "4.5.4",
      "resolved": "https://registry.npmjs.org/keyv/-/keyv-4.5.4.tgz",
      "integrity": "sha512-oxVHkHR/EJf2CNXnWxRLW6mg7JyCCUcG0DtEGmL2ctUo1PNTin1PUil+r/+4r5MpVgC/fn1kjsx7mjSujKqIpw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "json-buffer": "3.0.1"
      }
    },
    "node_modules/language-subtag-registry": {
      "version": "0.3.23",
      "resolved": "https://registry.npmjs.org/language-subtag-registry/-/language-subtag-registry-0.3.23.tgz",
      "integrity": "sha512-0K65Lea881pHotoGEa5gDlMxt3pctLi2RplBb7Ezh4rRdLEOtgi7n4EwK9lamnUCkKBqaeKRVebTq6BAxSkpXQ==",
      "dev": true,
      "license": "CC0-1.0"
    },
    "node_modules/language-tags": {
      "version": "1.0.9",
      "resolved": "https://registry.npmjs.org/language-tags/-/language-tags-1.0.9.tgz",
      "integrity": "sha512-MbjN408fEndfiQXbFQ1vnd+1NoLDsnQW41410oQBXiyXDMYH5z505juWa4KUE1LqxRC7DgOgZDbKLxHIwm27hA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "language-subtag-registry": "^0.3.20"
      },
      "engines": {
        "node": ">=0.10"
      }
    },
    "node_modules/levn": {
      "version": "0.4.1",
      "resolved": "https://registry.npmjs.org/levn/-/levn-0.4.1.tgz",
      "integrity": "sha512-+bT2uH4E5LGE7h/n3evcS/sQlJXCpIp6ym8OWJ5eV6+67Dsql/LaaT7qJBAt2rzfoa/5QBGBhxDix1dMt2kQKQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "prelude-ls": "^1.2.1",
        "type-check": "~0.4.0"
      },
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/lilconfig": {
      "version": "3.1.3",
      "resolved": "https://registry.npmjs.org/lilconfig/-/lilconfig-3.1.3.tgz",
      "integrity": "sha512-/vlFKAoH5Cgt3Ie+JLhRbwOsCQePABiU3tJ1egGvyQ+33R/vcwM2Zl2QR/LzjsBeItPt3oSVXapn+m4nQDvpzw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=14"
      },
      "funding": {
        "url": "https://github.com/sponsors/antonk52"
      }
    },
    "node_modules/lines-and-columns": {
      "version": "1.2.4",
      "resolved": "https://registry.npmjs.org/lines-and-columns/-/lines-and-columns-1.2.4.tgz",
      "integrity": "sha512-7ylylesZQ/PV29jhEDl3Ufjo6ZX7gCqJr5F7PKrqc93v7fzSymt1BpwEU8nAUXs8qzzvqhbjhK5QZg6Mt/HkBg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/locate-path": {
      "version": "6.0.0",
      "resolved": "https://registry.npmjs.org/locate-path/-/locate-path-6.0.0.tgz",
      "integrity": "sha512-iPZK6eYjbxRu3uB4/WZ3EsEIMJFMqAoopl3R+zuq0UjcAm/MO6KCweDgPfP3elTztoKP3KtnVHxTn2NHBSDVUw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "p-locate": "^5.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/lodash.merge": {
      "version": "4.6.2",
      "resolved": "https://registry.npmjs.org/lodash.merge/-/lodash.merge-4.6.2.tgz",
      "integrity": "sha512-0KpjqXRVvrYyCsX1swR/XTK0va6VQkQM6MNo7PqW77ByjAhoARA8EfrP1N4+KlKj8YS0ZUCtRT/YUuhyYDujIQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/loose-envify": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/loose-envify/-/loose-envify-1.4.0.tgz",
      "integrity": "sha512-lyuxPGr/Wfhrlem2CL/UcnUc1zcqKAImBDzukY7Y5F/yQiNdko6+fRLevlw1HgMySw7f611UIY408EtxRSoK3Q==",
      "license": "MIT",
      "dependencies": {
        "js-tokens": "^3.0.0 || ^4.0.0"
      },
      "bin": {
        "loose-envify": "cli.js"
      }
    },
    "node_modules/lru-cache": {
      "version": "10.4.3",
      "resolved": "https://registry.npmjs.org/lru-cache/-/lru-cache-10.4.3.tgz",
      "integrity": "sha512-JNAzZcXrCt42VGLuYz0zfAzDfAvJWW6AfYlDBQyDV5DClI2m5sAmK+OIO7s59XfsRsWHp02jAJrRadPRGTt6SQ==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/math-intrinsics": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/math-intrinsics/-/math-intrinsics-1.1.0.tgz",
      "integrity": "sha512-/IXtbwEk5HTPyEwyKX6hGkYXxM9nbj64B+ilVJnC/R6B0pH5G4V3b0pVbL7DBj4tkhBAppbQUlf6F6Xl9LHu1g==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/merge2": {
      "version": "1.4.1",
      "resolved": "https://registry.npmjs.org/merge2/-/merge2-1.4.1.tgz",
      "integrity": "sha512-8q7VEgMJW4J8tcfVPy8g09NcQwZdbwFEqhe/WZkoIzjn/3TGDwtOCYtXGxA3O8tPzpczCCDgv+P2P5y00ZJOOg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/micromatch": {
      "version": "4.0.8",
      "resolved": "https://registry.npmjs.org/micromatch/-/micromatch-4.0.8.tgz",
      "integrity": "sha512-PXwfBhYu0hBCPw8Dn0E+WDYb7af3dSLVWKi3HGv84IdF4TyFoC0ysxFd0Goxw7nSv4T/PzEJQxsYsEiFCKo2BA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "braces": "^3.0.3",
        "picomatch": "^2.3.1"
      },
      "engines": {
        "node": ">=8.6"
      }
    },
    "node_modules/minimatch": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/minimatch/-/minimatch-3.1.2.tgz",
      "integrity": "sha512-J7p63hRiAjw1NDEww1W7i37+ByIrOWO5XQQAzZ3VOcL0PNybwpfmV/N05zFAzwQ9USyEcX6t3UO+K5aqBQOIHw==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "brace-expansion": "^1.1.7"
      },
      "engines": {
        "node": "*"
      }
    },
    "node_modules/minimist": {
      "version": "1.2.8",
      "resolved": "https://registry.npmjs.org/minimist/-/minimist-1.2.8.tgz",
      "integrity": "sha512-2yyAR8qBkN3YuheJanUpWC5U3bb5osDywNB8RzDVlDwDHbocAJveqqj1u8+SVD7jkWT4yvsHCpWqqWqAxb0zCA==",
      "dev": true,
      "license": "MIT",
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/minipass": {
      "version": "7.1.2",
      "resolved": "https://registry.npmjs.org/minipass/-/minipass-7.1.2.tgz",
      "integrity": "sha512-qOOzS1cBTWYF4BH8fVePDBOO9iptMnGUEZwNc/cMWnTV2nVLZ7VoNWEPHkYczZA0pdoA7dl6e7FL659nX9S2aw==",
      "dev": true,
      "license": "ISC",
      "engines": {
        "node": ">=16 || 14 >=14.17"
      }
    },
    "node_modules/ms": {
      "version": "2.1.3",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.3.tgz",
      "integrity": "sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/mz": {
      "version": "2.7.0",
      "resolved": "https://registry.npmjs.org/mz/-/mz-2.7.0.tgz",
      "integrity": "sha512-z81GNO7nnYMEhrGh9LeymoE4+Yr0Wn5McHIZMK5cfQCl+NDX08sCZgUc9/6MHni9IWuFLm1Z3HTCXu2z9fN62Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "any-promise": "^1.0.0",
        "object-assign": "^4.0.1",
        "thenify-all": "^1.0.0"
      }
    },
    "node_modules/nanoid": {
      "version": "3.3.11",
      "resolved": "https://registry.npmjs.org/nanoid/-/nanoid-3.3.11.tgz",
      "integrity": "sha512-N8SpfPUnUp1bK+PMYW8qSWdl9U+wwNWI4QKxOYDy9JAro3WMX7p2OeVRF9v+347pnakNevPmiHhNmZ2HbFA76w==",
      "funding": [
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "bin": {
        "nanoid": "bin/nanoid.cjs"
      },
      "engines": {
        "node": "^10 || ^12 || ^13.7 || ^14 || >=15.0.1"
      }
    },
    "node_modules/napi-postinstall": {
      "version": "0.3.3",
      "resolved": "https://registry.npmjs.org/napi-postinstall/-/napi-postinstall-0.3.3.tgz",
      "integrity": "sha512-uTp172LLXSxuSYHv/kou+f6KW3SMppU9ivthaVTXian9sOt3XM/zHYHpRZiLgQoxeWfYUnslNWQHF1+G71xcow==",
      "dev": true,
      "license": "MIT",
      "bin": {
        "napi-postinstall": "lib/cli.js"
      },
      "engines": {
        "node": "^12.20.0 || ^14.18.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/napi-postinstall"
      }
    },
    "node_modules/natural-compare": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/natural-compare/-/natural-compare-1.4.0.tgz",
      "integrity": "sha512-OWND8ei3VtNC9h7V60qff3SVobHr996CTwgxubgyQYEpg290h9J0buyECNNJexkFm5sOajh5G116RYA1c8ZMSw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/next": {
      "version": "14.0.0",
      "resolved": "https://registry.npmjs.org/next/-/next-14.0.0.tgz",
      "integrity": "sha512-J0jHKBJpB9zd4+c153sair0sz44mbaCHxggs8ryVXSFBuBqJ8XdE9/ozoV85xGh2VnSjahwntBZZgsihL9QznA==",
      "license": "MIT",
      "dependencies": {
        "@next/env": "14.0.0",
        "@swc/helpers": "0.5.2",
        "busboy": "1.6.0",
        "caniuse-lite": "^1.0.30001406",
        "postcss": "8.4.31",
        "styled-jsx": "5.1.1",
        "watchpack": "2.4.0"
      },
      "bin": {
        "next": "dist/bin/next"
      },
      "engines": {
        "node": ">=18.17.0"
      },
      "optionalDependencies": {
        "@next/swc-darwin-arm64": "14.0.0",
        "@next/swc-darwin-x64": "14.0.0",
        "@next/swc-linux-arm64-gnu": "14.0.0",
        "@next/swc-linux-arm64-musl": "14.0.0",
        "@next/swc-linux-x64-gnu": "14.0.0",
        "@next/swc-linux-x64-musl": "14.0.0",
        "@next/swc-win32-arm64-msvc": "14.0.0",
        "@next/swc-win32-ia32-msvc": "14.0.0",
        "@next/swc-win32-x64-msvc": "14.0.0"
      },
      "peerDependencies": {
        "@opentelemetry/api": "^1.1.0",
        "react": "^18.2.0",
        "react-dom": "^18.2.0",
        "sass": "^1.3.0"
      },
      "peerDependenciesMeta": {
        "@opentelemetry/api": {
          "optional": true
        },
        "sass": {
          "optional": true
        }
      }
    },
    "node_modules/next/node_modules/postcss": {
      "version": "8.4.31",
      "resolved": "https://registry.npmjs.org/postcss/-/postcss-8.4.31.tgz",
      "integrity": "sha512-PS08Iboia9mts/2ygV3eLpY5ghnUcfLV/EXTOW1E2qYxJKGGBUtNjN76FYHnMs36RmARn41bC0AZmn+rR0OVpQ==",
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/postcss/"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/postcss"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "nanoid": "^3.3.6",
        "picocolors": "^1.0.0",
        "source-map-js": "^1.0.2"
      },
      "engines": {
        "node": "^10 || ^12 || >=14"
      }
    },
    "node_modules/node-releases": {
      "version": "2.0.19",
      "resolved": "https://registry.npmjs.org/node-releases/-/node-releases-2.0.19.tgz",
      "integrity": "sha512-xxOWJsBKtzAq7DY0J+DTzuz58K8e7sJbdgwkbMWQe8UYB6ekmsQ45q0M/tJDsGaZmbC+l7n57UV8Hl5tHxO9uw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/normalize-path": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/normalize-path/-/normalize-path-3.0.0.tgz",
      "integrity": "sha512-6eZs5Ls3WtCisHWp9S2GUy8dqkpGi4BVSz3GaqiE6ezub0512ESztXUwUB6C6IKbQkY2Pnb/mD4WYojCRwcwLA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/normalize-range": {
      "version": "0.1.2",
      "resolved": "https://registry.npmjs.org/normalize-range/-/normalize-range-0.1.2.tgz",
      "integrity": "sha512-bdok/XvKII3nUpklnV6P2hxtMNrCboOjAcyBuQnWEhO665FwrSNRxU+AqpsyvO6LgGYPspN+lu5CLtw4jPRKNA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/object-assign": {
      "version": "4.1.1",
      "resolved": "https://registry.npmjs.org/object-assign/-/object-assign-4.1.1.tgz",
      "integrity": "sha512-rJgTQnkUnH1sFw8yT6VSU3zD3sWmu6sZhIseY8VX+GRu3P6F7Fu+JNDoXfklElbLJSnc3FUQHVe4cU5hj+BcUg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/object-hash": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/object-hash/-/object-hash-3.0.0.tgz",
      "integrity": "sha512-RSn9F68PjH9HqtltsSnqYC1XXoWe9Bju5+213R98cNGttag9q9yAOTzdbsqvIa7aNm5WffBZFpWYr2aWrklWAw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/object-inspect": {
      "version": "1.13.4",
      "resolved": "https://registry.npmjs.org/object-inspect/-/object-inspect-1.13.4.tgz",
      "integrity": "sha512-W67iLl4J2EXEGTbfeHCffrjDfitvLANg0UlX3wFUUSTx92KXRFegMHUVgSqE+wvhAbi4WqjGg9czysTV2Epbew==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/object-keys": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/object-keys/-/object-keys-1.1.1.tgz",
      "integrity": "sha512-NuAESUOUMrlIXOfHKzD6bpPu3tYt3xvjNdRIQ+FeT0lNb4K8WR70CaDxhuNguS2XG+GjkyMwOzsN5ZktImfhLA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/object.assign": {
      "version": "4.1.7",
      "resolved": "https://registry.npmjs.org/object.assign/-/object.assign-4.1.7.tgz",
      "integrity": "sha512-nK28WOo+QIjBkDduTINE4JkF/UJJKyf2EJxvJKfblDpyg0Q+pkOHNTL0Qwy6NP6FhE/EnzV73BxxqcJaXY9anw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.3",
        "define-properties": "^1.2.1",
        "es-object-atoms": "^1.0.0",
        "has-symbols": "^1.1.0",
        "object-keys": "^1.1.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/object.entries": {
      "version": "1.1.9",
      "resolved": "https://registry.npmjs.org/object.entries/-/object.entries-1.1.9.tgz",
      "integrity": "sha512-8u/hfXFRBD1O0hPUjioLhoWFHRmt6tKA4/vZPyckBr18l1KE9uHrFaFaUi8MDRTpi4uak2goyPTSNJLXX2k2Hw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.4",
        "define-properties": "^1.2.1",
        "es-object-atoms": "^1.1.1"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/object.fromentries": {
      "version": "2.0.8",
      "resolved": "https://registry.npmjs.org/object.fromentries/-/object.fromentries-2.0.8.tgz",
      "integrity": "sha512-k6E21FzySsSK5a21KRADBd/NGneRegFO5pLHfdQLpRDETUNJueLXs3WCzyQ3tFRDYgbq3KHGXfTbi2bs8WQ6rQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.7",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.2",
        "es-object-atoms": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/object.groupby": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/object.groupby/-/object.groupby-1.0.3.tgz",
      "integrity": "sha512-+Lhy3TQTuzXI5hevh8sBGqbmurHbbIjAi0Z4S63nthVLmLxfbj4T54a4CfZrXIrt9iP4mVAPYMo/v99taj3wjQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.7",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/object.values": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/object.values/-/object.values-1.2.1.tgz",
      "integrity": "sha512-gXah6aZrcUxjWg2zR2MwouP2eHlCBzdV4pygudehaKXSGW4v2AsRQUK+lwwXhii6KFZcunEnmSUoYp5CXibxtA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.3",
        "define-properties": "^1.2.1",
        "es-object-atoms": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/once": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/once/-/once-1.4.0.tgz",
      "integrity": "sha512-lNaJgI+2Q5URQBkccEKHTQOPaXdUxnZZElQTZY0MFUAuaEqe1E+Nyvgdz/aIyNi6Z9MzO5dv1H8n58/GELp3+w==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "wrappy": "1"
      }
    },
    "node_modules/optionator": {
      "version": "0.9.4",
      "resolved": "https://registry.npmjs.org/optionator/-/optionator-0.9.4.tgz",
      "integrity": "sha512-6IpQ7mKUxRcZNLIObR0hz7lxsapSSIYNZJwXPGeF0mTVqGKFIXj1DQcMoT22S3ROcLyY/rz0PWaWZ9ayWmad9g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "deep-is": "^0.1.3",
        "fast-levenshtein": "^2.0.6",
        "levn": "^0.4.1",
        "prelude-ls": "^1.2.1",
        "type-check": "^0.4.0",
        "word-wrap": "^1.2.5"
      },
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/own-keys": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/own-keys/-/own-keys-1.0.1.tgz",
      "integrity": "sha512-qFOyK5PjiWZd+QQIh+1jhdb9LpxTF0qs7Pm8o5QHYZ0M3vKqSqzsZaEB6oWlxZ+q2sJBMI/Ktgd2N5ZwQoRHfg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "get-intrinsic": "^1.2.6",
        "object-keys": "^1.1.1",
        "safe-push-apply": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/p-limit": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/p-limit/-/p-limit-3.1.0.tgz",
      "integrity": "sha512-TYOanM3wGwNGsZN2cVTYPArw454xnXj5qmWF1bEoAc4+cU/ol7GVh7odevjp1FNHduHc3KZMcFduxU5Xc6uJRQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "yocto-queue": "^0.1.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/p-locate": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/p-locate/-/p-locate-5.0.0.tgz",
      "integrity": "sha512-LaNjtRWUBY++zB5nE/NwcaoMylSPk+S+ZHNB1TzdbMJMny6dynpAGt7X/tl/QYq3TIeE6nxHppbo2LGymrG5Pw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "p-limit": "^3.0.2"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/package-json-from-dist": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/package-json-from-dist/-/package-json-from-dist-1.0.1.tgz",
      "integrity": "sha512-UEZIS3/by4OC8vL3P2dTXRETpebLI2NiI5vIrjaD/5UtrkFX/tNbwjTSRAGC/+7CAo2pIcBaRgWmcBBHcsaCIw==",
      "dev": true,
      "license": "BlueOak-1.0.0"
    },
    "node_modules/parent-module": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/parent-module/-/parent-module-1.0.1.tgz",
      "integrity": "sha512-GQ2EWRpQV8/o+Aw8YqtfZZPfNRWZYkbidE9k5rpl/hC3vtHHBfGm2Ifi6qWV+coDGkrUKZAxE3Lot5kcsRlh+g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "callsites": "^3.0.0"
      },
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/path-exists": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/path-exists/-/path-exists-4.0.0.tgz",
      "integrity": "sha512-ak9Qy5Q7jYb2Wwcey5Fpvg2KoAc/ZIhLSLOSBmRmygPsGwkVVt0fZa0qrtMz+m6tJTAHfZQ8FnmB4MG4LWy7/w==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/path-is-absolute": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/path-is-absolute/-/path-is-absolute-1.0.1.tgz",
      "integrity": "sha512-AVbw3UJ2e9bq64vSaS9Am0fje1Pa8pbGqTTsmXfaIiMpnr5DlDhfJOuLj9Sf95ZPVDAUerDfEk88MPmPe7UCQg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/path-key": {
      "version": "3.1.1",
      "resolved": "https://registry.npmjs.org/path-key/-/path-key-3.1.1.tgz",
      "integrity": "sha512-ojmeN0qd+y0jszEtoY48r0Peq5dwMEkIlCOu6Q5f41lfkswXuKtYrhgoTpLnyIcHm24Uhqx+5Tqm2InSwLhE6Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/path-parse": {
      "version": "1.0.7",
      "resolved": "https://registry.npmjs.org/path-parse/-/path-parse-1.0.7.tgz",
      "integrity": "sha512-LDJzPVEEEPR+y48z93A0Ed0yXb8pAByGWo/k5YYdYgpY2/2EsOsksJrq7lOHxryrVOn1ejG6oAp8ahvOIQD8sw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/path-scurry": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/path-scurry/-/path-scurry-1.11.1.tgz",
      "integrity": "sha512-Xa4Nw17FS9ApQFJ9umLiJS4orGjm7ZzwUrwamcGQuHSzDyth9boKDaycYdDcZDuqYATXw4HFXgaqWTctW/v1HA==",
      "dev": true,
      "license": "BlueOak-1.0.0",
      "dependencies": {
        "lru-cache": "^10.2.0",
        "minipass": "^5.0.0 || ^6.0.2 || ^7.0.0"
      },
      "engines": {
        "node": ">=16 || 14 >=14.18"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/path-type": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/path-type/-/path-type-4.0.0.tgz",
      "integrity": "sha512-gDKb8aZMDeD/tZWs9P6+q0J9Mwkdl6xMV8TjnGP3qJVJ06bdMgkbBlLU8IdfOsIsFz2BW1rNVT3XuNEl8zPAvw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/picocolors": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/picocolors/-/picocolors-1.1.1.tgz",
      "integrity": "sha512-xceH2snhtb5M9liqDsmEw56le376mTZkEX/jEb/RxNFyegNul7eNslCXP9FDj/Lcu0X8KEyMceP2ntpaHrDEVA==",
      "license": "ISC"
    },
    "node_modules/picomatch": {
      "version": "2.3.1",
      "resolved": "https://registry.npmjs.org/picomatch/-/picomatch-2.3.1.tgz",
      "integrity": "sha512-JU3teHTNjmE2VCGFzuY8EXzCDVwEqB2a8fsIvwaStHhAWJEeVd1o1QD80CU6+ZdEXXSLbSsuLwJjkCBWqRQUVA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8.6"
      },
      "funding": {
        "url": "https://github.com/sponsors/jonschlinkert"
      }
    },
    "node_modules/pify": {
      "version": "2.3.0",
      "resolved": "https://registry.npmjs.org/pify/-/pify-2.3.0.tgz",
      "integrity": "sha512-udgsAY+fTnvv7kI7aaxbqwWNb0AHiB0qBO89PZKPkoTmGOgdbrHDKD+0B2X4uTfJ/FT1R09r9gTsjUjNJotuog==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/pirates": {
      "version": "4.0.7",
      "resolved": "https://registry.npmjs.org/pirates/-/pirates-4.0.7.tgz",
      "integrity": "sha512-TfySrs/5nm8fQJDcBDuUng3VOUKsd7S+zqvbOTiGXHfxX4wK31ard+hoNuvkicM/2YFzlpDgABOevKSsB4G/FA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/possible-typed-array-names": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/possible-typed-array-names/-/possible-typed-array-names-1.1.0.tgz",
      "integrity": "sha512-/+5VFTchJDoVj3bhoqi6UeymcD00DAwb1nJwamzPvHEszJ4FpF6SNNbUbOS8yI56qHzdV8eK0qEfOSiodkTdxg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/postcss": {
      "version": "8.5.6",
      "resolved": "https://registry.npmjs.org/postcss/-/postcss-8.5.6.tgz",
      "integrity": "sha512-3Ybi1tAuwAP9s0r1UQ2J4n5Y0G05bJkpUIO0/bI9MhwmD70S5aTWbXGBwxHrelT+XM1k6dM0pk+SwNkpTRN7Pg==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/postcss/"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/postcss"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "nanoid": "^3.3.11",
        "picocolors": "^1.1.1",
        "source-map-js": "^1.2.1"
      },
      "engines": {
        "node": "^10 || ^12 || >=14"
      }
    },
    "node_modules/postcss-import": {
      "version": "15.1.0",
      "resolved": "https://registry.npmjs.org/postcss-import/-/postcss-import-15.1.0.tgz",
      "integrity": "sha512-hpr+J05B2FVYUAXHeK1YyI267J/dDDhMU6B6civm8hSY1jYJnBXxzKDKDswzJmtLHryrjhnDjqqp/49t8FALew==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "postcss-value-parser": "^4.0.0",
        "read-cache": "^1.0.0",
        "resolve": "^1.1.7"
      },
      "engines": {
        "node": ">=14.0.0"
      },
      "peerDependencies": {
        "postcss": "^8.0.0"
      }
    },
    "node_modules/postcss-js": {
      "version": "4.0.1",
      "resolved": "https://registry.npmjs.org/postcss-js/-/postcss-js-4.0.1.tgz",
      "integrity": "sha512-dDLF8pEO191hJMtlHFPRa8xsizHaM82MLfNkUHdUtVEV3tgTp5oj+8qbEqYM57SLfc74KSbw//4SeJma2LRVIw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "camelcase-css": "^2.0.1"
      },
      "engines": {
        "node": "^12 || ^14 || >= 16"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/postcss/"
      },
      "peerDependencies": {
        "postcss": "^8.4.21"
      }
    },
    "node_modules/postcss-nested": {
      "version": "6.2.0",
      "resolved": "https://registry.npmjs.org/postcss-nested/-/postcss-nested-6.2.0.tgz",
      "integrity": "sha512-HQbt28KulC5AJzG+cZtj9kvKB93CFCdLvog1WFLf1D+xmMvPGlBstkpTEZfK5+AN9hfJocyBFCNiqyS48bpgzQ==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/postcss/"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "postcss-selector-parser": "^6.1.1"
      },
      "engines": {
        "node": ">=12.0"
      },
      "peerDependencies": {
        "postcss": "^8.2.14"
      }
    },
    "node_modules/postcss-selector-parser": {
      "version": "6.1.2",
      "resolved": "https://registry.npmjs.org/postcss-selector-parser/-/postcss-selector-parser-6.1.2.tgz",
      "integrity": "sha512-Q8qQfPiZ+THO/3ZrOrO0cJJKfpYCagtMUkXbnEfmgUjwXg6z/WBeOyS9APBBPCTSiDV+s4SwQGu8yFsiMRIudg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "cssesc": "^3.0.0",
        "util-deprecate": "^1.0.2"
      },
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/postcss-value-parser": {
      "version": "4.2.0",
      "resolved": "https://registry.npmjs.org/postcss-value-parser/-/postcss-value-parser-4.2.0.tgz",
      "integrity": "sha512-1NNCs6uurfkVbeXG4S8JFT9t19m45ICnif8zWLd5oPSZ50QnwMfK+H3jv408d4jw/7Bttv5axS5IiHoLaVNHeQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/prelude-ls": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/prelude-ls/-/prelude-ls-1.2.1.tgz",
      "integrity": "sha512-vkcDPrRZo1QZLbn5RLGPpg/WmIQ65qoWWhcGKf/b5eplkkarX0m9z8ppCat4mlOqUsWpyNuYgO3VRyrYHSzX5g==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/prop-types": {
      "version": "15.8.1",
      "resolved": "https://registry.npmjs.org/prop-types/-/prop-types-15.8.1.tgz",
      "integrity": "sha512-oj87CgZICdulUohogVAR7AjlC0327U4el4L6eAvOqCeudMDVU0NThNaV+b9Df4dXgSP1gXMTnPdhfe/2qDH5cg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "loose-envify": "^1.4.0",
        "object-assign": "^4.1.1",
        "react-is": "^16.13.1"
      }
    },
    "node_modules/punycode": {
      "version": "2.3.1",
      "resolved": "https://registry.npmjs.org/punycode/-/punycode-2.3.1.tgz",
      "integrity": "sha512-vYt7UD1U9Wg6138shLtLOvdAu+8DsC/ilFtEVHcH+wydcSpNE20AfSOduf6MkRFahL5FY7X1oU7nKVZFtfq8Fg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/queue-microtask": {
      "version": "1.2.3",
      "resolved": "https://registry.npmjs.org/queue-microtask/-/queue-microtask-1.2.3.tgz",
      "integrity": "sha512-NuaNSa6flKT5JaSYQzJok04JzTL1CA6aGhv5rfLW3PgqA+M2ChpZQnAC8h8i4ZFkBS8X5RqkDBHA7r4hej3K9A==",
      "dev": true,
      "funding": [
        {
          "type": "github",
          "url": "https://github.com/sponsors/feross"
        },
        {
          "type": "patreon",
          "url": "https://www.patreon.com/feross"
        },
        {
          "type": "consulting",
          "url": "https://feross.org/support"
        }
      ],
      "license": "MIT"
    },
    "node_modules/react": {
      "version": "18.3.1",
      "resolved": "https://registry.npmjs.org/react/-/react-18.3.1.tgz",
      "integrity": "sha512-wS+hAgJShR0KhEvPJArfuPVN1+Hz1t0Y6n5jLrGQbkb4urgPE/0Rve+1kMB1v/oWgHgm4WIcV+i7F2pTVj+2iQ==",
      "license": "MIT",
      "dependencies": {
        "loose-envify": "^1.1.0"
      },
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/react-dom": {
      "version": "18.3.1",
      "resolved": "https://registry.npmjs.org/react-dom/-/react-dom-18.3.1.tgz",
      "integrity": "sha512-5m4nQKp+rZRb09LNH59GM4BxTh9251/ylbKIbpe7TpGxfJ+9kv6BLkLBXIjjspbgbnIBNqlI23tRnTWT0snUIw==",
      "license": "MIT",
      "dependencies": {
        "loose-envify": "^1.1.0",
        "scheduler": "^0.23.2"
      },
      "peerDependencies": {
        "react": "^18.3.1"
      }
    },
    "node_modules/react-is": {
      "version": "16.13.1",
      "resolved": "https://registry.npmjs.org/react-is/-/react-is-16.13.1.tgz",
      "integrity": "sha512-24e6ynE2H+OKt4kqsOvNd8kBpV65zoxbA4BVsEOB3ARVWQki/DHzaUoC5KuON/BiccDaCCTZBuOcfZs70kR8bQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/read-cache": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/read-cache/-/read-cache-1.0.0.tgz",
      "integrity": "sha512-Owdv/Ft7IjOgm/i0xvNDZ1LrRANRfew4b2prF3OWMQLxLfu3bS8FVhCsrSCMK4lR56Y9ya+AThoTpDCTxCmpRA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "pify": "^2.3.0"
      }
    },
    "node_modules/readdirp": {
      "version": "3.6.0",
      "resolved": "https://registry.npmjs.org/readdirp/-/readdirp-3.6.0.tgz",
      "integrity": "sha512-hOS089on8RduqdbhvQ5Z37A0ESjsqz6qnRcffsMU3495FuTdqSm+7bhJ29JvIOsBDEEnan5DPu9t3To9VRlMzA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "picomatch": "^2.2.1"
      },
      "engines": {
        "node": ">=8.10.0"
      }
    },
    "node_modules/reflect.getprototypeof": {
      "version": "1.0.10",
      "resolved": "https://registry.npmjs.org/reflect.getprototypeof/-/reflect.getprototypeof-1.0.10.tgz",
      "integrity": "sha512-00o4I+DVrefhv+nX0ulyi3biSHCPDe+yLv5o/p6d/UVlirijB8E16FtfwSAi4g3tcqrQ4lRAqQSoFEZJehYEcw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.9",
        "es-errors": "^1.3.0",
        "es-object-atoms": "^1.0.0",
        "get-intrinsic": "^1.2.7",
        "get-proto": "^1.0.1",
        "which-builtin-type": "^1.2.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/regexp.prototype.flags": {
      "version": "1.5.4",
      "resolved": "https://registry.npmjs.org/regexp.prototype.flags/-/regexp.prototype.flags-1.5.4.tgz",
      "integrity": "sha512-dYqgNSZbDwkaJ2ceRd9ojCGjBq+mOm9LmtXnAnEGyHhN/5R7iDW2TRw3h+o/jCFxus3P2LfWIIiwowAjANm7IA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "define-properties": "^1.2.1",
        "es-errors": "^1.3.0",
        "get-proto": "^1.0.1",
        "gopd": "^1.2.0",
        "set-function-name": "^2.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/resolve": {
      "version": "1.22.10",
      "resolved": "https://registry.npmjs.org/resolve/-/resolve-1.22.10.tgz",
      "integrity": "sha512-NPRy+/ncIMeDlTAsuqwKIiferiawhefFJtkNSW0qZJEqMEb+qBt/77B/jGeeek+F0uOeN05CDa6HXbbIgtVX4w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-core-module": "^2.16.0",
        "path-parse": "^1.0.7",
        "supports-preserve-symlinks-flag": "^1.0.0"
      },
      "bin": {
        "resolve": "bin/resolve"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/resolve-from": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/resolve-from/-/resolve-from-4.0.0.tgz",
      "integrity": "sha512-pb/MYmXstAkysRFx8piNI1tGFNQIFA3vkE3Gq4EuA1dF6gHp/+vgZqsCGJapvy8N3Q+4o7FwvquPJcnZ7RYy4g==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/resolve-pkg-maps": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/resolve-pkg-maps/-/resolve-pkg-maps-1.0.0.tgz",
      "integrity": "sha512-seS2Tj26TBVOC2NIc2rOe2y2ZO7efxITtLZcGSOnHHNOQ7CkiUBfw0Iw2ck6xkIhPwLhKNLS8BO+hEpngQlqzw==",
      "dev": true,
      "license": "MIT",
      "funding": {
        "url": "https://github.com/privatenumber/resolve-pkg-maps?sponsor=1"
      }
    },
    "node_modules/reusify": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/reusify/-/reusify-1.1.0.tgz",
      "integrity": "sha512-g6QUff04oZpHs0eG5p83rFLhHeV00ug/Yf9nZM6fLeUrPguBTkTQOdpAWWspMh55TZfVQDPaN3NQJfbVRAxdIw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "iojs": ">=1.0.0",
        "node": ">=0.10.0"
      }
    },
    "node_modules/rimraf": {
      "version": "3.0.2",
      "resolved": "https://registry.npmjs.org/rimraf/-/rimraf-3.0.2.tgz",
      "integrity": "sha512-JZkJMZkAGFFPP2YqXZXPbMlMBgsxzE8ILs4lMIX/2o0L9UBw9O/Y3o6wFw/i9YLapcUJWwqbi3kdxIPdC62TIA==",
      "deprecated": "Rimraf versions prior to v4 are no longer supported",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "glob": "^7.1.3"
      },
      "bin": {
        "rimraf": "bin.js"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/run-parallel": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/run-parallel/-/run-parallel-1.2.0.tgz",
      "integrity": "sha512-5l4VyZR86LZ/lDxZTR6jqL8AFE2S0IFLMP26AbjsLVADxHdhB/c0GUsH+y39UfCi3dzz8OlQuPmnaJOMoDHQBA==",
      "dev": true,
      "funding": [
        {
          "type": "github",
          "url": "https://github.com/sponsors/feross"
        },
        {
          "type": "patreon",
          "url": "https://www.patreon.com/feross"
        },
        {
          "type": "consulting",
          "url": "https://feross.org/support"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "queue-microtask": "^1.2.2"
      }
    },
    "node_modules/safe-array-concat": {
      "version": "1.1.3",
      "resolved": "https://registry.npmjs.org/safe-array-concat/-/safe-array-concat-1.1.3.tgz",
      "integrity": "sha512-AURm5f0jYEOydBj7VQlVvDrjeFgthDdEF5H1dP+6mNpoXOMo1quQqJ4wvJDyRZ9+pO3kGWoOdmV08cSv2aJV6Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.2",
        "get-intrinsic": "^1.2.6",
        "has-symbols": "^1.1.0",
        "isarray": "^2.0.5"
      },
      "engines": {
        "node": ">=0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/safe-push-apply": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/safe-push-apply/-/safe-push-apply-1.0.0.tgz",
      "integrity": "sha512-iKE9w/Z7xCzUMIZqdBsp6pEQvwuEebH4vdpjcDWnyzaI6yl6O9FHvVpmGelvEHNsoY6wGblkxR6Zty/h00WiSA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0",
        "isarray": "^2.0.5"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/safe-regex-test": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/safe-regex-test/-/safe-regex-test-1.1.0.tgz",
      "integrity": "sha512-x/+Cz4YrimQxQccJf5mKEbIa1NzeCRNI5Ecl/ekmlYaampdNLPalVyIcCZNNH3MvmqBugV5TMYZXv0ljslUlaw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.2",
        "es-errors": "^1.3.0",
        "is-regex": "^1.2.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/scheduler": {
      "version": "0.23.2",
      "resolved": "https://registry.npmjs.org/scheduler/-/scheduler-0.23.2.tgz",
      "integrity": "sha512-UOShsPwz7NrMUqhR6t0hWjFduvOzbtv7toDH1/hIrfRNIDBnnBWd0CwJTGvTpngVlmwGCdP9/Zl/tVrDqcuYzQ==",
      "license": "MIT",
      "dependencies": {
        "loose-envify": "^1.1.0"
      }
    },
    "node_modules/semver": {
      "version": "7.7.2",
      "resolved": "https://registry.npmjs.org/semver/-/semver-7.7.2.tgz",
      "integrity": "sha512-RF0Fw+rO5AMf9MAyaRXI4AV0Ulj5lMHqVxxdSgiVbixSCXoEmmX/jk0CuJw4+3SqroYO9VoUh+HcuJivvtJemA==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "semver": "bin/semver.js"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/set-function-length": {
      "version": "1.2.2",
      "resolved": "https://registry.npmjs.org/set-function-length/-/set-function-length-1.2.2.tgz",
      "integrity": "sha512-pgRc4hJ4/sNjWCSS9AmnS40x3bNMDTknHgL5UaMBTMyJnU90EgWh1Rz+MC9eFu4BuN/UwZjKQuY/1v3rM7HMfg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "define-data-property": "^1.1.4",
        "es-errors": "^1.3.0",
        "function-bind": "^1.1.2",
        "get-intrinsic": "^1.2.4",
        "gopd": "^1.0.1",
        "has-property-descriptors": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/set-function-name": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/set-function-name/-/set-function-name-2.0.2.tgz",
      "integrity": "sha512-7PGFlmtwsEADb0WYyvCMa1t+yke6daIG4Wirafur5kcf+MhUnPms1UeR0CKQdTZD81yESwMHbtn+TR+dMviakQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "define-data-property": "^1.1.4",
        "es-errors": "^1.3.0",
        "functions-have-names": "^1.2.3",
        "has-property-descriptors": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/set-proto": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/set-proto/-/set-proto-1.0.0.tgz",
      "integrity": "sha512-RJRdvCo6IAnPdsvP/7m6bsQqNnn1FCBX5ZNtFL98MmFF/4xAIJTIg1YbHW5DC2W5SKZanrC6i4HsJqlajw/dZw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "dunder-proto": "^1.0.1",
        "es-errors": "^1.3.0",
        "es-object-atoms": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/shebang-command": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/shebang-command/-/shebang-command-2.0.0.tgz",
      "integrity": "sha512-kHxr2zZpYtdmrN1qDjrrX/Z1rR1kG8Dx+gkpK1G4eXmvXswmcE1hTWBWYUzlraYw1/yZp6YuDY77YtvbN0dmDA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "shebang-regex": "^3.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/shebang-regex": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/shebang-regex/-/shebang-regex-3.0.0.tgz",
      "integrity": "sha512-7++dFhtcx3353uBaq8DDR4NuxBetBzC7ZQOhmTQInHEd6bSrXdiEyzCvG07Z44UYdLShWUyXt5M/yhz8ekcb1A==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/side-channel": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/side-channel/-/side-channel-1.1.0.tgz",
      "integrity": "sha512-ZX99e6tRweoUXqR+VBrslhda51Nh5MTQwou5tnUDgbtyM0dBgmhEDtWGP/xbKn6hqfPRHujUNwz5fy/wbbhnpw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0",
        "object-inspect": "^1.13.3",
        "side-channel-list": "^1.0.0",
        "side-channel-map": "^1.0.1",
        "side-channel-weakmap": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/side-channel-list": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/side-channel-list/-/side-channel-list-1.0.0.tgz",
      "integrity": "sha512-FCLHtRD/gnpCiCHEiJLOwdmFP+wzCmDEkc9y7NsYxeF4u7Btsn1ZuwgwJGxImImHicJArLP4R0yX4c2KCrMrTA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0",
        "object-inspect": "^1.13.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/side-channel-map": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/side-channel-map/-/side-channel-map-1.0.1.tgz",
      "integrity": "sha512-VCjCNfgMsby3tTdo02nbjtM/ewra6jPHmpThenkTYh8pG9ucZ/1P8So4u4FGBek/BjpOVsDCMoLA/iuBKIFXRA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.2",
        "es-errors": "^1.3.0",
        "get-intrinsic": "^1.2.5",
        "object-inspect": "^1.13.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/side-channel-weakmap": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/side-channel-weakmap/-/side-channel-weakmap-1.0.2.tgz",
      "integrity": "sha512-WPS/HvHQTYnHisLo9McqBHOJk2FkHO/tlpvldyrnem4aeQp4hai3gythswg6p01oSoTl58rcpiFAjF2br2Ak2A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.2",
        "es-errors": "^1.3.0",
        "get-intrinsic": "^1.2.5",
        "object-inspect": "^1.13.3",
        "side-channel-map": "^1.0.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/signal-exit": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/signal-exit/-/signal-exit-4.1.0.tgz",
      "integrity": "sha512-bzyZ1e88w9O1iNJbKnOlvYTrWPDl46O1bG0D3XInv+9tkPrxrN8jUUTiFlDkkmKWgn1M6CfIA13SuGqOa9Korw==",
      "dev": true,
      "license": "ISC",
      "engines": {
        "node": ">=14"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/slash": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/slash/-/slash-3.0.0.tgz",
      "integrity": "sha512-g9Q1haeby36OSStwb4ntCGGGaKsaVSjQ68fBxoQcutl5fS1vuY18H3wSt3jFyFtrkx+Kz0V1G85A4MyAdDMi2Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/source-map-js": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/source-map-js/-/source-map-js-1.2.1.tgz",
      "integrity": "sha512-UXWMKhLOwVKb728IUtQPXxfYU+usdybtUrK/8uGE8CQMvrhOpwvzDBwj0QhSL7MQc7vIsISBG8VQ8+IDQxpfQA==",
      "license": "BSD-3-Clause",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/stable-hash": {
      "version": "0.0.5",
      "resolved": "https://registry.npmjs.org/stable-hash/-/stable-hash-0.0.5.tgz",
      "integrity": "sha512-+L3ccpzibovGXFK+Ap/f8LOS0ahMrHTf3xu7mMLSpEGU0EO9ucaysSylKo9eRDFNhWve/y275iPmIZ4z39a9iA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/stop-iteration-iterator": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/stop-iteration-iterator/-/stop-iteration-iterator-1.1.0.tgz",
      "integrity": "sha512-eLoXW/DHyl62zxY4SCaIgnRhuMr6ri4juEYARS8E6sCEqzKpOiE521Ucofdx+KnDZl5xmvGYaaKCk5FEOxJCoQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0",
        "internal-slot": "^1.1.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/streamsearch": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/streamsearch/-/streamsearch-1.1.0.tgz",
      "integrity": "sha512-Mcc5wHehp9aXz1ax6bZUyY5afg9u2rv5cqQI3mRrYkGC8rW2hM02jWuwjtL++LS5qinSyhj2QfLyNsuc+VsExg==",
      "engines": {
        "node": ">=10.0.0"
      }
    },
    "node_modules/string-width": {
      "version": "5.1.2",
      "resolved": "https://registry.npmjs.org/string-width/-/string-width-5.1.2.tgz",
      "integrity": "sha512-HnLOCR3vjcY8beoNLtcjZ5/nxn2afmME6lhrDrebokqMap+XbeW8n9TXpPDOqdGK5qcI3oT0GKTW6wC7EMiVqA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "eastasianwidth": "^0.2.0",
        "emoji-regex": "^9.2.2",
        "strip-ansi": "^7.0.1"
      },
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/string-width-cjs": {
      "name": "string-width",
      "version": "4.2.3",
      "resolved": "https://registry.npmjs.org/string-width/-/string-width-4.2.3.tgz",
      "integrity": "sha512-wKyQRQpjJ0sIp62ErSZdGsjMJWsap5oRNihHhu6G7JVO/9jIB6UyevL+tXuOqrng8j/cxKTWyWUwvSTriiZz/g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "emoji-regex": "^8.0.0",
        "is-fullwidth-code-point": "^3.0.0",
        "strip-ansi": "^6.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/string-width-cjs/node_modules/emoji-regex": {
      "version": "8.0.0",
      "resolved": "https://registry.npmjs.org/emoji-regex/-/emoji-regex-8.0.0.tgz",
      "integrity": "sha512-MSjYzcWNOA0ewAHpz0MxpYFvwg6yjy1NG3xteoqz644VCo/RPgnr1/GGt+ic3iJTzQ8Eu3TdM14SawnVUmGE6A==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/string-width/node_modules/ansi-regex": {
      "version": "6.1.0",
      "resolved": "https://registry.npmjs.org/ansi-regex/-/ansi-regex-6.1.0.tgz",
      "integrity": "sha512-7HSX4QQb4CspciLpVFwyRe79O3xsIZDDLER21kERQ71oaPodF8jL725AgJMFAYbooIqolJoRLuM81SpeUkpkvA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-regex?sponsor=1"
      }
    },
    "node_modules/string-width/node_modules/strip-ansi": {
      "version": "7.1.0",
      "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-7.1.0.tgz",
      "integrity": "sha512-iq6eVVI64nQQTRYq2KtEg2d2uU7LElhTJwsH4YzIHZshxlgZms/wIc4VoDQTlG/IvVIrBKG06CrZnp0qv7hkcQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-regex": "^6.0.1"
      },
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/strip-ansi?sponsor=1"
      }
    },
    "node_modules/string.prototype.includes": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/string.prototype.includes/-/string.prototype.includes-2.0.1.tgz",
      "integrity": "sha512-o7+c9bW6zpAdJHTtujeePODAhkuicdAryFsfVKwA+wGw89wJ4GTY484WTucM9hLtDEOpOvI+aHnzqnC5lHp4Rg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.7",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.3"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/string.prototype.matchall": {
      "version": "4.0.12",
      "resolved": "https://registry.npmjs.org/string.prototype.matchall/-/string.prototype.matchall-4.0.12.tgz",
      "integrity": "sha512-6CC9uyBL+/48dYizRf7H7VAYCMCNTBeM78x/VTUe9bFEaxBepPJDa1Ow99LqI/1yF7kuy7Q3cQsYMrcjGUcskA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.3",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.6",
        "es-errors": "^1.3.0",
        "es-object-atoms": "^1.0.0",
        "get-intrinsic": "^1.2.6",
        "gopd": "^1.2.0",
        "has-symbols": "^1.1.0",
        "internal-slot": "^1.1.0",
        "regexp.prototype.flags": "^1.5.3",
        "set-function-name": "^2.0.2",
        "side-channel": "^1.1.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/string.prototype.repeat": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/string.prototype.repeat/-/string.prototype.repeat-1.0.0.tgz",
      "integrity": "sha512-0u/TldDbKD8bFCQ/4f5+mNRrXwZ8hg2w7ZR8wa16e8z9XpePWl3eGEcUD0OXpEH/VJH/2G3gjUtR3ZOiBe2S/w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "define-properties": "^1.1.3",
        "es-abstract": "^1.17.5"
      }
    },
    "node_modules/string.prototype.trim": {
      "version": "1.2.10",
      "resolved": "https://registry.npmjs.org/string.prototype.trim/-/string.prototype.trim-1.2.10.tgz",
      "integrity": "sha512-Rs66F0P/1kedk5lyYyH9uBzuiI/kNRmwJAR9quK6VOtIpZ2G+hMZd+HQbbv25MgCA6gEffoMZYxlTod4WcdrKA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.2",
        "define-data-property": "^1.1.4",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.5",
        "es-object-atoms": "^1.0.0",
        "has-property-descriptors": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/string.prototype.trimend": {
      "version": "1.0.9",
      "resolved": "https://registry.npmjs.org/string.prototype.trimend/-/string.prototype.trimend-1.0.9.tgz",
      "integrity": "sha512-G7Ok5C6E/j4SGfyLCloXTrngQIQU3PWtXGst3yM7Bea9FRURf1S42ZHlZZtsNque2FN2PoUhfZXYLNWwEr4dLQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.2",
        "define-properties": "^1.2.1",
        "es-object-atoms": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/string.prototype.trimstart": {
      "version": "1.0.8",
      "resolved": "https://registry.npmjs.org/string.prototype.trimstart/-/string.prototype.trimstart-1.0.8.tgz",
      "integrity": "sha512-UXSH262CSZY1tfu3G3Secr6uGLCFVPMhIqHjlgCUtCCcgihYc/xKs9djMTMUOb2j1mVSeU8EU6NWc/iQKU6Gfg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.7",
        "define-properties": "^1.2.1",
        "es-object-atoms": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/strip-ansi": {
      "version": "6.0.1",
      "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-6.0.1.tgz",
      "integrity": "sha512-Y38VPSHcqkFrCpFnQ9vuSXmquuv5oXOKpGeT6aGrr3o3Gc9AlVa6JBfUSOCnbxGGZF+/0ooI7KrPuUSztUdU5A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-regex": "^5.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/strip-ansi-cjs": {
      "name": "strip-ansi",
      "version": "6.0.1",
      "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-6.0.1.tgz",
      "integrity": "sha512-Y38VPSHcqkFrCpFnQ9vuSXmquuv5oXOKpGeT6aGrr3o3Gc9AlVa6JBfUSOCnbxGGZF+/0ooI7KrPuUSztUdU5A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-regex": "^5.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/strip-bom": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/strip-bom/-/strip-bom-3.0.0.tgz",
      "integrity": "sha512-vavAMRXOgBVNF6nyEEmL3DBK19iRpDcoIwW+swQ+CbGiu7lju6t+JklA1MHweoWtadgt4ISVUsXLyDq34ddcwA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/strip-json-comments": {
      "version": "3.1.1",
      "resolved": "https://registry.npmjs.org/strip-json-comments/-/strip-json-comments-3.1.1.tgz",
      "integrity": "sha512-6fPc+R4ihwqP6N/aIv2f1gMH8lOVtWQHoqC4yK6oSDVVocumAsfCqjkXnqiYMhmMwS/mEHLp7Vehlt3ql6lEig==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/styled-jsx": {
      "version": "5.1.1",
      "resolved": "https://registry.npmjs.org/styled-jsx/-/styled-jsx-5.1.1.tgz",
      "integrity": "sha512-pW7uC1l4mBZ8ugbiZrcIsiIvVx1UmTfw7UkC3Um2tmfUq9Bhk8IiyEIPl6F8agHgjzku6j0xQEZbfA5uSgSaCw==",
      "license": "MIT",
      "dependencies": {
        "client-only": "0.0.1"
      },
      "engines": {
        "node": ">= 12.0.0"
      },
      "peerDependencies": {
        "react": ">= 16.8.0 || 17.x.x || ^18.0.0-0"
      },
      "peerDependenciesMeta": {
        "@babel/core": {
          "optional": true
        },
        "babel-plugin-macros": {
          "optional": true
        }
      }
    },
    "node_modules/sucrase": {
      "version": "3.35.0",
      "resolved": "https://registry.npmjs.org/sucrase/-/sucrase-3.35.0.tgz",
      "integrity": "sha512-8EbVDiu9iN/nESwxeSxDKe0dunta1GOlHufmSSXxMD2z2/tMZpDMpvXQGsc+ajGo8y2uYUmixaSRUc/QPoQ0GA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jridgewell/gen-mapping": "^0.3.2",
        "commander": "^4.0.0",
        "glob": "^10.3.10",
        "lines-and-columns": "^1.1.6",
        "mz": "^2.7.0",
        "pirates": "^4.0.1",
        "ts-interface-checker": "^0.1.9"
      },
      "bin": {
        "sucrase": "bin/sucrase",
        "sucrase-node": "bin/sucrase-node"
      },
      "engines": {
        "node": ">=16 || 14 >=14.17"
      }
    },
    "node_modules/sucrase/node_modules/brace-expansion": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/brace-expansion/-/brace-expansion-2.0.2.tgz",
      "integrity": "sha512-Jt0vHyM+jmUBqojB7E1NIYadt0vI0Qxjxd2TErW94wDz+E2LAm5vKMXXwg6ZZBTHPuUlDgQHKXvjGBdfcF1ZDQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "balanced-match": "^1.0.0"
      }
    },
    "node_modules/sucrase/node_modules/glob": {
      "version": "10.4.5",
      "resolved": "https://registry.npmjs.org/glob/-/glob-10.4.5.tgz",
      "integrity": "sha512-7Bv8RF0k6xjo7d4A/PxYLbUCfb6c+Vpd2/mB2yRDlew7Jb5hEXiCD9ibfO7wpk8i4sevK6DFny9h7EYbM3/sHg==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "foreground-child": "^3.1.0",
        "jackspeak": "^3.1.2",
        "minimatch": "^9.0.4",
        "minipass": "^7.1.2",
        "package-json-from-dist": "^1.0.0",
        "path-scurry": "^1.11.1"
      },
      "bin": {
        "glob": "dist/esm/bin.mjs"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/sucrase/node_modules/minimatch": {
      "version": "9.0.5",
      "resolved": "https://registry.npmjs.org/minimatch/-/minimatch-9.0.5.tgz",
      "integrity": "sha512-G6T0ZX48xgozx7587koeX9Ys2NYy6Gmv//P89sEte9V9whIapMNF4idKxnW2QtCcLiTWlb/wfCabAtAFWhhBow==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "brace-expansion": "^2.0.1"
      },
      "engines": {
        "node": ">=16 || 14 >=14.17"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/supports-color": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/supports-color/-/supports-color-7.2.0.tgz",
      "integrity": "sha512-qpCAvRl9stuOHveKsn7HncJRvv501qIacKzQlO/+Lwxc9+0q2wLyv4Dfvt80/DPn2pqOBsJdDiogXGR9+OvwRw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "has-flag": "^4.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/supports-preserve-symlinks-flag": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/supports-preserve-symlinks-flag/-/supports-preserve-symlinks-flag-1.0.0.tgz",
      "integrity": "sha512-ot0WnXS9fgdkgIcePe6RHNk1WA8+muPa6cSjeR3V8K27q9BB1rTE3R1p7Hv0z1ZyAc8s6Vvv8DIyWf681MAt0w==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/tailwindcss": {
      "version": "3.4.17",
      "resolved": "https://registry.npmjs.org/tailwindcss/-/tailwindcss-3.4.17.tgz",
      "integrity": "sha512-w33E2aCvSDP0tW9RZuNXadXlkHXqFzSkQew/aIa2i/Sj8fThxwovwlXHSPXTbAHwEIhBFXAedUhP2tueAKP8Og==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@alloc/quick-lru": "^5.2.0",
        "arg": "^5.0.2",
        "chokidar": "^3.6.0",
        "didyoumean": "^1.2.2",
        "dlv": "^1.1.3",
        "fast-glob": "^3.3.2",
        "glob-parent": "^6.0.2",
        "is-glob": "^4.0.3",
        "jiti": "^1.21.6",
        "lilconfig": "^3.1.3",
        "micromatch": "^4.0.8",
        "normalize-path": "^3.0.0",
        "object-hash": "^3.0.0",
        "picocolors": "^1.1.1",
        "postcss": "^8.4.47",
        "postcss-import": "^15.1.0",
        "postcss-js": "^4.0.1",
        "postcss-load-config": "^4.0.2",
        "postcss-nested": "^6.2.0",
        "postcss-selector-parser": "^6.1.2",
        "resolve": "^1.22.8",
        "sucrase": "^3.35.0"
      },
      "bin": {
        "tailwind": "lib/cli.js",
        "tailwindcss": "lib/cli.js"
      },
      "engines": {
        "node": ">=14.0.0"
      }
    },
    "node_modules/tailwindcss/node_modules/postcss-load-config": {
      "version": "4.0.2",
      "resolved": "https://registry.npmjs.org/postcss-load-config/-/postcss-load-config-4.0.2.tgz",
      "integrity": "sha512-bSVhyJGL00wMVoPUzAVAnbEoWyqRxkjv64tUl427SKnPrENtq6hJwUojroMz2VB+Q1edmi4IfrAPpami5VVgMQ==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/postcss/"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "lilconfig": "^3.0.0",
        "yaml": "^2.3.4"
      },
      "engines": {
        "node": ">= 14"
      },
      "peerDependencies": {
        "postcss": ">=8.0.9",
        "ts-node": ">=9.0.0"
      },
      "peerDependenciesMeta": {
        "postcss": {
          "optional": true
        },
        "ts-node": {
          "optional": true
        }
      }
    },
    "node_modules/text-table": {
      "version": "0.2.0",
      "resolved": "https://registry.npmjs.org/text-table/-/text-table-0.2.0.tgz",
      "integrity": "sha512-N+8UisAXDGk8PFXP4HAzVR9nbfmVJ3zYLAWiTIoqC5v5isinhr+r5uaO8+7r3BMfuNIufIsA7RdpVgacC2cSpw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/thenify": {
      "version": "3.3.1",
      "resolved": "https://registry.npmjs.org/thenify/-/thenify-3.3.1.tgz",
      "integrity": "sha512-RVZSIV5IG10Hk3enotrhvz0T9em6cyHBLkH/YAZuKqd8hRkKhSfCGIcP2KUY0EPxndzANBmNllzWPwak+bheSw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "any-promise": "^1.0.0"
      }
    },
    "node_modules/thenify-all": {
      "version": "1.6.0",
      "resolved": "https://registry.npmjs.org/thenify-all/-/thenify-all-1.6.0.tgz",
      "integrity": "sha512-RNxQH/qI8/t3thXJDwcstUO4zeqo64+Uy/+sNVRBx4Xn2OX+OZ9oP+iJnNFqplFra2ZUVeKCSa2oVWi3T4uVmA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "thenify": ">= 3.1.0 < 4"
      },
      "engines": {
        "node": ">=0.8"
      }
    },
    "node_modules/tinyglobby": {
      "version": "0.2.14",
      "resolved": "https://registry.npmjs.org/tinyglobby/-/tinyglobby-0.2.14.tgz",
      "integrity": "sha512-tX5e7OM1HnYr2+a2C/4V0htOcSQcoSTH9KgJnVvNm5zm/cyEWKJ7j7YutsH9CxMdtOkkLFy2AHrMci9IM8IPZQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "fdir": "^6.4.4",
        "picomatch": "^4.0.2"
      },
      "engines": {
        "node": ">=12.0.0"
      },
      "funding": {
        "url": "https://github.com/sponsors/SuperchupuDev"
      }
    },
    "node_modules/tinyglobby/node_modules/fdir": {
      "version": "6.5.0",
      "resolved": "https://registry.npmjs.org/fdir/-/fdir-6.5.0.tgz",
      "integrity": "sha512-tIbYtZbucOs0BRGqPJkshJUYdL+SDH7dVM8gjy+ERp3WAUjLEFJE+02kanyHtwjWOnwrKYBiwAmM0p4kLJAnXg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=12.0.0"
      },
      "peerDependencies": {
        "picomatch": "^3 || ^4"
      },
      "peerDependenciesMeta": {
        "picomatch": {
          "optional": true
        }
      }
    },
    "node_modules/tinyglobby/node_modules/picomatch": {
      "version": "4.0.3",
      "resolved": "https://registry.npmjs.org/picomatch/-/picomatch-4.0.3.tgz",
      "integrity": "sha512-5gTmgEY/sqK6gFXLIsQNH19lWb4ebPDLA4SdLP7dsWkIXHWlG66oPuVvXSGFPppYZz8ZDZq0dYYrbHfBCVUb1Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/sponsors/jonschlinkert"
      }
    },
    "node_modules/to-regex-range": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/to-regex-range/-/to-regex-range-5.0.1.tgz",
      "integrity": "sha512-65P7iz6X5yEr1cwcgvQxbbIw7Uk3gOy5dIdtZ4rDveLqhrdJP+Li/Hx6tyK0NEb+2GCyneCMJiGqrADCSNk8sQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-number": "^7.0.0"
      },
      "engines": {
        "node": ">=8.0"
      }
    },
    "node_modules/ts-api-utils": {
      "version": "1.4.3",
      "resolved": "https://registry.npmjs.org/ts-api-utils/-/ts-api-utils-1.4.3.tgz",
      "integrity": "sha512-i3eMG77UTMD0hZhgRS562pv83RC6ukSAC2GMNWc+9dieh/+jDM5u5YG+NHX6VNDRHQcHwmsTHctP9LhbC3WxVw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=16"
      },
      "peerDependencies": {
        "typescript": ">=4.2.0"
      }
    },
    "node_modules/ts-interface-checker": {
      "version": "0.1.13",
      "resolved": "https://registry.npmjs.org/ts-interface-checker/-/ts-interface-checker-0.1.13.tgz",
      "integrity": "sha512-Y/arvbn+rrz3JCKl9C4kVNfTfSm2/mEp5FSz5EsZSANGPSlQrpRI5M4PKF+mJnE52jOO90PnPSc3Ur3bTQw0gA==",
      "dev": true,
      "license": "Apache-2.0"
    },
    "node_modules/tsconfig-paths": {
      "version": "3.15.0",
      "resolved": "https://registry.npmjs.org/tsconfig-paths/-/tsconfig-paths-3.15.0.tgz",
      "integrity": "sha512-2Ac2RgzDe/cn48GvOe3M+o82pEFewD3UPbyoUHHdKasHwJKjds4fLXWf/Ux5kATBKN20oaFGu+jbElp1pos0mg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@types/json5": "^0.0.29",
        "json5": "^1.0.2",
        "minimist": "^1.2.6",
        "strip-bom": "^3.0.0"
      }
    },
    "node_modules/tslib": {
      "version": "2.8.1",
      "resolved": "https://registry.npmjs.org/tslib/-/tslib-2.8.1.tgz",
      "integrity": "sha512-oJFu94HQb+KVduSUQL7wnpmqnfmLsOA/nAh6b6EH0wCEoK0/mPeXU6c3wKDV83MkOuHPRHtSXKKU99IBazS/2w==",
      "license": "0BSD"
    },
    "node_modules/type-check": {
      "version": "0.4.0",
      "resolved": "https://registry.npmjs.org/type-check/-/type-check-0.4.0.tgz",
      "integrity": "sha512-XleUoc9uwGXqjWwXaUTZAmzMcFZ5858QA2vvx1Ur5xIcixXIP+8LnFDgRplU30us6teqdlskFfu+ae4K79Ooew==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "prelude-ls": "^1.2.1"
      },
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/type-fest": {
      "version": "0.20.2",
      "resolved": "https://registry.npmjs.org/type-fest/-/type-fest-0.20.2.tgz",
      "integrity": "sha512-Ne+eE4r0/iWnpAxD852z3A+N0Bt5RN//NjJwRd2VFHEmrywxf5vsZlh4R6lixl6B+wz/8d+maTSAkN1FIkI3LQ==",
      "dev": true,
      "license": "(MIT OR CC0-1.0)",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/typed-array-buffer": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/typed-array-buffer/-/typed-array-buffer-1.0.3.tgz",
      "integrity": "sha512-nAYYwfY3qnzX30IkA6AQZjVbtK6duGontcQm1WSG1MD94YLqK0515GNApXkoxKOWMusVssAHWLh9SeaoefYFGw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "es-errors": "^1.3.0",
        "is-typed-array": "^1.1.14"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/typed-array-byte-length": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/typed-array-byte-length/-/typed-array-byte-length-1.0.3.tgz",
      "integrity": "sha512-BaXgOuIxz8n8pIq3e7Atg/7s+DpiYrxn4vdot3w9KbnBhcRQq6o3xemQdIfynqSeXeDrF32x+WvfzmOjPiY9lg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "for-each": "^0.3.3",
        "gopd": "^1.2.0",
        "has-proto": "^1.2.0",
        "is-typed-array": "^1.1.14"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/typed-array-byte-offset": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/typed-array-byte-offset/-/typed-array-byte-offset-1.0.4.tgz",
      "integrity": "sha512-bTlAFB/FBYMcuX81gbL4OcpH5PmlFHqlCCpAl8AlEzMz5k53oNDvN8p1PNOWLEmI2x4orp3raOFB51tv9X+MFQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "available-typed-arrays": "^1.0.7",
        "call-bind": "^1.0.8",
        "for-each": "^0.3.3",
        "gopd": "^1.2.0",
        "has-proto": "^1.2.0",
        "is-typed-array": "^1.1.15",
        "reflect.getprototypeof": "^1.0.9"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/typed-array-length": {
      "version": "1.0.7",
      "resolved": "https://registry.npmjs.org/typed-array-length/-/typed-array-length-1.0.7.tgz",
      "integrity": "sha512-3KS2b+kL7fsuk/eJZ7EQdnEmQoaho/r6KUef7hxvltNA5DR8NAUM+8wJMbJyZ4G9/7i3v5zPBIMN5aybAh2/Jg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.7",
        "for-each": "^0.3.3",
        "gopd": "^1.0.1",
        "is-typed-array": "^1.1.13",
        "possible-typed-array-names": "^1.0.0",
        "reflect.getprototypeof": "^1.0.6"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/typescript": {
      "version": "5.9.2",
      "resolved": "https://registry.npmjs.org/typescript/-/typescript-5.9.2.tgz",
      "integrity": "sha512-CWBzXQrc/qOkhidw1OzBTQuYRbfyxDXJMVJ1XNwUHGROVmuaeiEm3OslpZ1RV96d7SKKjZKrSJu3+t/xlw3R9A==",
      "license": "Apache-2.0",
      "bin": {
        "tsc": "bin/tsc",
        "tsserver": "bin/tsserver"
      },
      "engines": {
        "node": ">=14.17"
      }
    },
    "node_modules/unbox-primitive": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/unbox-primitive/-/unbox-primitive-1.1.0.tgz",
      "integrity": "sha512-nWJ91DjeOkej/TA8pXQ3myruKpKEYgqvpw9lz4OPHj/NWFNluYrjbz9j01CJ8yKQd2g4jFoOkINCTW2I5LEEyw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "has-bigints": "^1.0.2",
        "has-symbols": "^1.1.0",
        "which-boxed-primitive": "^1.1.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/undici-types": {
      "version": "6.21.0",
      "resolved": "https://registry.npmjs.org/undici-types/-/undici-types-6.21.0.tgz",
      "integrity": "sha512-iwDZqg0QAGrg9Rav5H4n0M64c3mkR59cJ6wQp+7C4nI0gsmExaedaYLNO44eT4AtBBwjbTiGPMlt2Md0T9H9JQ==",
      "license": "MIT"
    },
    "node_modules/unrs-resolver": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/unrs-resolver/-/unrs-resolver-1.11.1.tgz",
      "integrity": "sha512-bSjt9pjaEBnNiGgc9rUiHGKv5l4/TGzDmYw3RhnkJGtLhbnnA/5qJj7x3dNDCRx/PJxu774LlH8lCOlB4hEfKg==",
      "dev": true,
      "hasInstallScript": true,
      "license": "MIT",
      "dependencies": {
        "napi-postinstall": "^0.3.0"
      },
      "funding": {
        "url": "https://opencollective.com/unrs-resolver"
      },
      "optionalDependencies": {
        "@unrs/resolver-binding-android-arm-eabi": "1.11.1",
        "@unrs/resolver-binding-android-arm64": "1.11.1",
        "@unrs/resolver-binding-darwin-arm64": "1.11.1",
        "@unrs/resolver-binding-darwin-x64": "1.11.1",
        "@unrs/resolver-binding-freebsd-x64": "1.11.1",
        "@unrs/resolver-binding-linux-arm-gnueabihf": "1.11.1",
        "@unrs/resolver-binding-linux-arm-musleabihf": "1.11.1",
        "@unrs/resolver-binding-linux-arm64-gnu": "1.11.1",
        "@unrs/resolver-binding-linux-arm64-musl": "1.11.1",
        "@unrs/resolver-binding-linux-ppc64-gnu": "1.11.1",
        "@unrs/resolver-binding-linux-riscv64-gnu": "1.11.1",
        "@unrs/resolver-binding-linux-riscv64-musl": "1.11.1",
        "@unrs/resolver-binding-linux-s390x-gnu": "1.11.1",
        "@unrs/resolver-binding-linux-x64-gnu": "1.11.1",
        "@unrs/resolver-binding-linux-x64-musl": "1.11.1",
        "@unrs/resolver-binding-wasm32-wasi": "1.11.1",
        "@unrs/resolver-binding-win32-arm64-msvc": "1.11.1",
        "@unrs/resolver-binding-win32-ia32-msvc": "1.11.1",
        "@unrs/resolver-binding-win32-x64-msvc": "1.11.1"
      }
    },
    "node_modules/update-browserslist-db": {
      "version": "1.1.3",
      "resolved": "https://registry.npmjs.org/update-browserslist-db/-/update-browserslist-db-1.1.3.tgz",
      "integrity": "sha512-UxhIZQ+QInVdunkDAaiazvvT/+fXL5Osr0JZlJulepYu6Jd7qJtDZjlur0emRlT71EN3ScPoE7gvsuIKKNavKw==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/browserslist"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/browserslist"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "escalade": "^3.2.0",
        "picocolors": "^1.1.1"
      },
      "bin": {
        "update-browserslist-db": "cli.js"
      },
      "peerDependencies": {
        "browserslist": ">= 4.21.0"
      }
    },
    "node_modules/uri-js": {
      "version": "4.4.1",
      "resolved": "https://registry.npmjs.org/uri-js/-/uri-js-4.4.1.tgz",
      "integrity": "sha512-7rKUyy33Q1yc98pQ1DAmLtwX109F7TIfWlW1Ydo8Wl1ii1SeHieeh0HHfPeL2fMXK6z0s8ecKs9frCuLJvndBg==",
      "dev": true,
      "license": "BSD-2-Clause",
      "dependencies": {
        "punycode": "^2.1.0"
      }
    },
    "node_modules/util-deprecate": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/util-deprecate/-/util-deprecate-1.0.2.tgz",
      "integrity": "sha512-EPD5q1uXyFxJpCrLnCc1nHnq3gOa6DZBocAIiI2TaSCA7VCJ1UJDMagCzIkXNsUYfD1daK//LTEQ8xiIbrHtcw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/watchpack": {
      "version": "2.4.0",
      "resolved": "https://registry.npmjs.org/watchpack/-/watchpack-2.4.0.tgz",
      "integrity": "sha512-Lcvm7MGST/4fup+ifyKi2hjyIAwcdI4HRgtvTpIUxBRhB+RFtUh8XtDOxUfctVCnhVi+QQj49i91OyvzkJl6cg==",
      "license": "MIT",
      "dependencies": {
        "glob-to-regexp": "^0.4.1",
        "graceful-fs": "^4.1.2"
      },
      "engines": {
        "node": ">=10.13.0"
      }
    },
    "node_modules/which": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/which/-/which-2.0.2.tgz",
      "integrity": "sha512-BLI3Tl1TW3Pvl70l3yq3Y64i+awpwXqsGBYWkkqMtnbXgrMD+yj7rhW0kuEDxzJaYXGjEW5ogapKNMEKNMjibA==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "isexe": "^2.0.0"
      },
      "bin": {
        "node-which": "bin/node-which"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/which-boxed-primitive": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/which-boxed-primitive/-/which-boxed-primitive-1.1.1.tgz",
      "integrity": "sha512-TbX3mj8n0odCBFVlY8AxkqcHASw3L60jIuF8jFP78az3C2YhmGvqbHBpAjTRH2/xqYunrJ9g1jSyjCjpoWzIAA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-bigint": "^1.1.0",
        "is-boolean-object": "^1.2.1",
        "is-number-object": "^1.1.1",
        "is-string": "^1.1.1",
        "is-symbol": "^1.1.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/which-builtin-type": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/which-builtin-type/-/which-builtin-type-1.2.1.tgz",
      "integrity": "sha512-6iBczoX+kDQ7a3+YJBnh3T+KZRxM/iYNPXicqk66/Qfm1b93iu+yOImkg0zHbj5LNOcNv1TEADiZ0xa34B4q6Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.2",
        "function.prototype.name": "^1.1.6",
        "has-tostringtag": "^1.0.2",
        "is-async-function": "^2.0.0",
        "is-date-object": "^1.1.0",
        "is-finalizationregistry": "^1.1.0",
        "is-generator-function": "^1.0.10",
        "is-regex": "^1.2.1",
        "is-weakref": "^1.0.2",
        "isarray": "^2.0.5",
        "which-boxed-primitive": "^1.1.0",
        "which-collection": "^1.0.2",
        "which-typed-array": "^1.1.16"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/which-collection": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/which-collection/-/which-collection-1.0.2.tgz",
      "integrity": "sha512-K4jVyjnBdgvc86Y6BkaLZEN933SwYOuBFkdmBu9ZfkcAbdVbpITnDmjvZ/aQjRXQrv5EPkTnD1s39GiiqbngCw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-map": "^2.0.3",
        "is-set": "^2.0.3",
        "is-weakmap": "^2.0.2",
        "is-weakset": "^2.0.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/which-typed-array": {
      "version": "1.1.19",
      "resolved": "https://registry.npmjs.org/which-typed-array/-/which-typed-array-1.1.19.tgz",
      "integrity": "sha512-rEvr90Bck4WZt9HHFC4DJMsjvu7x+r6bImz0/BrbWb7A2djJ8hnZMrWnHo9F8ssv0OMErasDhftrfROTyqSDrw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "available-typed-arrays": "^1.0.7",
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.4",
        "for-each": "^0.3.5",
        "get-proto": "^1.0.1",
        "gopd": "^1.2.0",
        "has-tostringtag": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/word-wrap": {
      "version": "1.2.5",
      "resolved": "https://registry.npmjs.org/word-wrap/-/word-wrap-1.2.5.tgz",
      "integrity": "sha512-BN22B5eaMMI9UMtjrGd5g5eCYPpCPDUy0FJXbYsaT5zYxjFOckS53SQDE3pWkVoWpHXVb3BrYcEN4Twa55B5cA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/wrap-ansi": {
      "version": "8.1.0",
      "resolved": "https://registry.npmjs.org/wrap-ansi/-/wrap-ansi-8.1.0.tgz",
      "integrity": "sha512-si7QWI6zUMq56bESFvagtmzMdGOtoxfR+Sez11Mobfc7tm+VkUckk9bW2UeffTGVUbOksxmSw0AA2gs8g71NCQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-styles": "^6.1.0",
        "string-width": "^5.0.1",
        "strip-ansi": "^7.0.1"
      },
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/wrap-ansi?sponsor=1"
      }
    },
    "node_modules/wrap-ansi-cjs": {
      "name": "wrap-ansi",
      "version": "7.0.0",
      "resolved": "https://registry.npmjs.org/wrap-ansi/-/wrap-ansi-7.0.0.tgz",
      "integrity": "sha512-YVGIj2kamLSTxw6NsZjoBxfSwsn0ycdesmc4p+Q21c5zPuZ1pl+NfxVdxPtdHvmNVOQ6XSYG4AUtyt/Fi7D16Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-styles": "^4.0.0",
        "string-width": "^4.1.0",
        "strip-ansi": "^6.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/chalk/wrap-ansi?sponsor=1"
      }
    },
    "node_modules/wrap-ansi-cjs/node_modules/emoji-regex": {
      "version": "8.0.0",
      "resolved": "https://registry.npmjs.org/emoji-regex/-/emoji-regex-8.0.0.tgz",
      "integrity": "sha512-MSjYzcWNOA0ewAHpz0MxpYFvwg6yjy1NG3xteoqz644VCo/RPgnr1/GGt+ic3iJTzQ8Eu3TdM14SawnVUmGE6A==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/wrap-ansi-cjs/node_modules/string-width": {
      "version": "4.2.3",
      "resolved": "https://registry.npmjs.org/string-width/-/string-width-4.2.3.tgz",
      "integrity": "sha512-wKyQRQpjJ0sIp62ErSZdGsjMJWsap5oRNihHhu6G7JVO/9jIB6UyevL+tXuOqrng8j/cxKTWyWUwvSTriiZz/g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "emoji-regex": "^8.0.0",
        "is-fullwidth-code-point": "^3.0.0",
        "strip-ansi": "^6.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/wrap-ansi/node_modules/ansi-regex": {
      "version": "6.1.0",
      "resolved": "https://registry.npmjs.org/ansi-regex/-/ansi-regex-6.1.0.tgz",
      "integrity": "sha512-7HSX4QQb4CspciLpVFwyRe79O3xsIZDDLER21kERQ71oaPodF8jL725AgJMFAYbooIqolJoRLuM81SpeUkpkvA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-regex?sponsor=1"
      }
    },
    "node_modules/wrap-ansi/node_modules/ansi-styles": {
      "version": "6.2.1",
      "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-6.2.1.tgz",
      "integrity": "sha512-bN798gFfQX+viw3R7yrGWRqnrN2oRkEkUjjl4JNn4E8GxxbjtG3FbrEIIY3l8/hrwUwIeCZvi4QuOTP4MErVug==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-styles?sponsor=1"
      }
    },
    "node_modules/wrap-ansi/node_modules/strip-ansi": {
      "version": "7.1.0",
      "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-7.1.0.tgz",
      "integrity": "sha512-iq6eVVI64nQQTRYq2KtEg2d2uU7LElhTJwsH4YzIHZshxlgZms/wIc4VoDQTlG/IvVIrBKG06CrZnp0qv7hkcQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-regex": "^6.0.1"
      },
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/strip-ansi?sponsor=1"
      }
    },
    "node_modules/wrappy": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/wrappy/-/wrappy-1.0.2.tgz",
      "integrity": "sha512-l4Sp/DRseor9wL6EvV2+TuQn63dMkPjZ/sp9XkghTEbV9KlPS1xUsZ3u7/IQO4wxtcFB4bgpQPRcR3QCvezPcQ==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/yaml": {
      "version": "2.8.1",
      "resolved": "https://registry.npmjs.org/yaml/-/yaml-2.8.1.tgz",
      "integrity": "sha512-lcYcMxX2PO9XMGvAJkJ3OsNMw+/7FKes7/hgerGUYWIoWu5j/+YQqcZr5JnPZWzOsEBgMbSbiSTn/dv/69Mkpw==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "yaml": "bin.mjs"
      },
      "engines": {
        "node": ">= 14.6"
      }
    },
    "node_modules/yocto-queue": {
      "version": "0.1.0",
      "resolved": "https://registry.npmjs.org/yocto-queue/-/yocto-queue-0.1.0.tgz",
      "integrity": "sha512-rVksvsnNCdJ/ohGc6xgPwyN8eheCxsiLM8mxuE/t/mOVqJewPuO1miLpTHQiRgTKCLexL4MeAFVagts7HmNZ2Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    }
  }
}
===== END FILE =====

===== FILE: frontend-next/package.json =====
{
  "name": "transcribealpha-frontend",
  "version": "1.0.0",
  "private": true,
  "scripts": {
    "dev": "next dev",
    "build": "next build",
    "start": "next start",
    "lint": "next lint"
  },
  "dependencies": {
    "next": "14.0.0",
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "@types/node": "^20.0.0",
    "@types/react": "^18.2.0",
    "@types/react-dom": "^18.2.0",
    "typescript": "^5.0.0"
  },
  "devDependencies": {
    "tailwindcss": "^3.3.0",
    "postcss": "^8.4.0",
    "autoprefixer": "^10.4.0",
    "eslint": "^8.0.0",
    "eslint-config-next": "14.0.0"
  }
}
===== END FILE =====

===== FILE: frontend-next/postcss.config.js =====
module.exports = {
  plugins: {
    tailwindcss: {},
    autoprefixer: {},
  },
}
===== END FILE =====

===== FILE: frontend-next/src/app/globals.css =====
@tailwind base;
@tailwind components;
@tailwind utilities;

@import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');

@layer base {
  html,
  body {
    @apply font-sans antialiased text-primary-900 bg-primary-50;
  }
}

@layer components {
  .btn-primary {
    @apply bg-primary-900 text-white px-6 py-3 rounded-lg font-medium hover:bg-primary-800 transition-all duration-200 disabled:opacity-50 disabled:cursor-not-allowed shadow-lg hover:shadow-xl;
  }
  
  .btn-secondary {
    @apply bg-white text-primary-900 border-2 border-primary-300 px-6 py-3 rounded-lg font-medium hover:border-primary-400 hover:bg-primary-100 transition-all duration-200 shadow-sm;
  }

  .btn-outline {
    @apply border border-primary-400 text-primary-700 px-4 py-2 rounded-lg font-medium bg-white hover:bg-primary-100 transition-all duration-200 disabled:opacity-50 disabled:cursor-not-allowed;
  }

  .input {
    @apply w-full px-3 py-2 border border-primary-300 rounded-md focus:ring-2 focus:ring-primary-500 focus:border-primary-500 bg-white text-sm;
  }

  .textarea {
    @apply w-full px-3 py-2 border border-primary-300 rounded-md focus:ring-2 focus:ring-primary-500 focus:border-primary-500 bg-white text-sm;
  }
  
  .input-field {
    @apply w-full px-4 py-3 border border-primary-300 rounded-lg focus:ring-2 focus:ring-primary-500 focus:border-primary-500 transition-all duration-200 bg-white shadow-sm;
  }
  
  .card {
    @apply bg-white border border-primary-200 rounded-xl shadow-lg hover:shadow-xl transition-shadow duration-200;
  }
  
  .card-header {
    @apply px-6 py-4 border-b border-primary-200 bg-primary-700 text-white rounded-t-xl;
  }
  
  .card-body {
    @apply px-6 py-6;
  }
}
===== END FILE =====

===== FILE: frontend-next/src/app/layout.tsx =====
import type { Metadata } from 'next'
import './globals.css'
import AuthProvider from '@/components/AuthProvider'

export const metadata: Metadata = {
  title: 'TranscribeAlpha - Legal Transcript Generator',
  description: 'Professional legal transcript generation using AssemblyAI',
}

export default function RootLayout({
  children,
}: {
  children: React.ReactNode
}) {
  return (
    <html lang="en">
      <body>
        <AuthProvider>
          {children}
        </AuthProvider>
      </body>
    </html>
  )
}
===== END FILE =====

===== FILE: frontend-next/src/app/page.tsx =====
import TranscribeForm from '@/components/TranscribeForm'

export default function Home() {
  return <TranscribeForm />
}
===== END FILE =====

===== FILE: frontend-next/src/components/AuthProvider.tsx =====
"use client";

import React, { useEffect, useState } from 'react';
import LoginModal from './LoginModal';
import { isAuthenticated, initializeTokenRefresh, logout, getCurrentUser } from '@/utils/auth';

interface AuthProviderProps {
  children: React.ReactNode;
}

export default function AuthProvider({ children }: AuthProviderProps) {
  const [isAuth, setIsAuth] = useState(false);
  const [isLoading, setIsLoading] = useState(true);
  const [user, setUser] = useState<{ username: string; role: string } | null>(null);

  useEffect(() => {
    // Check authentication status on mount
    const authenticated = isAuthenticated();
    setIsAuth(authenticated);

    if (authenticated) {
      setUser(getCurrentUser());
      // Initialize automatic token refresh
      initializeTokenRefresh();
    }

    setIsLoading(false);
  }, []);

  const handleLoginSuccess = () => {
    setIsAuth(true);
    setUser(getCurrentUser());
    initializeTokenRefresh();
  };

  const handleLogout = () => {
    logout();
    setIsAuth(false);
    setUser(null);
  };

  if (isLoading) {
    return (
      <div className="min-h-screen bg-primary-50 flex items-center justify-center">
        <div className="text-center">
          <div className="inline-block animate-spin rounded-full h-12 w-12 border-b-2 border-primary-900"></div>
          <p className="mt-4 text-primary-600">Loading...</p>
        </div>
      </div>
    );
  }

  if (!isAuth) {
    return <LoginModal onLoginSuccess={handleLoginSuccess} />;
  }

  return (
    <>
      {/* User info bar */}
      <div className="bg-primary-800 text-white px-4 py-2 flex justify-between items-center shadow-md">
        <div className="text-sm">
          Signed in as <span className="font-semibold">{user?.username}</span>
        </div>
        <button
          onClick={handleLogout}
          className="text-sm bg-red-600 hover:bg-red-500 px-4 py-1.5 rounded font-medium transition-colors shadow-sm"
        >
          Sign Out
        </button>
      </div>
      {children}
    </>
  );
}
===== END FILE =====

===== FILE: frontend-next/src/components/ClipCreator.tsx =====
'use client'

import { FormEvent, useCallback, useEffect, useMemo, useRef, useState } from 'react'
import type { EditorSessionResponse, ClipSummary } from '@/components/TranscriptEditor'
import { appendAccessTokenToMediaUrl, authenticatedFetch } from '@/utils/auth'

interface ClipCreatorProps {
  session: EditorSessionResponse | null
  mediaKey: string | null
  mediaUrl?: string
  mediaType?: string
  onSessionRefresh: (session: EditorSessionResponse) => void
  onDownload: (base64Data: string, filename: string, mimeType: string) => void
  buildFilename: (baseName: string, extension: string) => string
  onOpenHistory?: () => void
}

interface ClipLineEntry {
  id: string
  speaker: string
  text: string
  start: number
  end: number
  page?: number | null
  line?: number | null
  pgln?: number | null
  is_continuation?: boolean
}

interface ClipDetailResponse {
  clip_id: string
  name: string
  created_at: string
  duration: number
  start_time: number
  end_time: number
  start_pgln?: number | null
  end_pgln?: number | null
  start_page?: number | null
  start_line_number?: number | null
  end_page?: number | null
  end_line_number?: number | null
  docx_base64: string
  oncue_xml_base64: string
  transcript: string
  lines: ClipLineEntry[]
  title_data: Record<string, string>
  lines_per_page: number
  media_blob_name?: string | null
  media_content_type?: string | null
  summary?: ClipSummary
}

interface EditorLine {
  id: string
  speaker: string
  text: string
  start: number
  end: number
  page?: number | null
  line?: number | null
  pgln?: number | null
  is_continuation?: boolean
}

type SelectionMode = 'time' | 'pageLine' | 'manual'

const formatSeconds = (value: number | undefined | null) => {
  if (value === undefined || value === null || Number.isNaN(value)) {
    return '0:00.000'
  }
  const totalMillis = Math.max(0, Math.round(value * 1000))
  const totalSeconds = Math.floor(totalMillis / 1000)
  const millis = totalMillis % 1000
  const hours = Math.floor(totalSeconds / 3600)
  const minutes = Math.floor((totalSeconds % 3600) / 60)
  const seconds = totalSeconds % 60
  const secondsPart = seconds.toString().padStart(2, '0')
  const millisPart = millis.toString().padStart(3, '0')
  if (hours > 0) {
    return `${hours}:${minutes.toString().padStart(2, '0')}:${secondsPart}.${millisPart}`
  }
  return `${minutes}:${secondsPart}.${millisPart}`
}

const parseTimeInput = (value: string): number | null => {
  const trimmed = value.trim()
  if (!trimmed) {
    return null
  }
  const parts = trimmed.split(':')
  let seconds = 0
  let multiplier = 1
  for (let index = parts.length - 1; index >= 0; index -= 1) {
    const component = parts[index].trim()
    if (!component) {
      return null
    }
    const numeric = Number(component)
    if (Number.isNaN(numeric)) {
      return null
    }
    seconds += numeric * multiplier
    multiplier *= 60
  }
  return seconds
}

const selectionButtonClasses = (active: boolean) =>
  `px-3 py-2 rounded-lg text-sm font-medium transition ${
    active ? 'bg-primary-900 text-white shadow-md' : 'bg-primary-100 text-primary-700 hover:bg-primary-200'
  }`

const cardSectionTitle = (label: string) => (
  <h3 className="text-lg font-medium text-primary-900 mb-3">{label}</h3>
)

export default function ClipCreator({
  session,
  mediaKey,
  mediaUrl,
  mediaType,
  onSessionRefresh,
  onDownload,
  buildFilename,
  onOpenHistory,
}: ClipCreatorProps) {
  const lines = useMemo<EditorLine[]>(() => session?.lines ?? [], [session])
  const clipHistory = useMemo<ClipSummary[]>(() => session?.clips ?? [], [session])

  const [selectionMode, setSelectionMode] = useState<SelectionMode>('time')
  const [timeStart, setTimeStart] = useState('')
  const [timeEnd, setTimeEnd] = useState('')
  const [pageStart, setPageStart] = useState('')
  const [lineStart, setLineStart] = useState('')
  const [pageEnd, setPageEnd] = useState('')
  const [lineEnd, setLineEnd] = useState('')
  const [manualStartId, setManualStartId] = useState<string | null>(null)
  const [manualEndId, setManualEndId] = useState<string | null>(null)
  const [clipName, setClipName] = useState('')
  const [creationError, setCreationError] = useState<string | null>(null)
  const [creationMessage, setCreationMessage] = useState<string | null>(null)
  const [isSubmitting, setIsSubmitting] = useState(false)
  const [clipCache, setClipCache] = useState<Record<string, ClipDetailResponse>>({})
  const [activeClip, setActiveClip] = useState<ClipDetailResponse | null>(null)
  const [historyLoadingId, setHistoryLoadingId] = useState<string | null>(null)
  const [previewing, setPreviewing] = useState(false)
  const [importXmlFile, setImportXmlFile] = useState<File | null>(null)
  const [importMediaFile, setImportMediaFile] = useState<File | null>(null)
  const [importing, setImporting] = useState(false)
  const [importError, setImportError] = useState<string | null>(null)
  const [importMessage, setImportMessage] = useState<string | null>(null)
  const [importResetKey, setImportResetKey] = useState(0)
  const [importExpanded, setImportExpanded] = useState(true)

  const effectiveMediaUrl = useMemo(() => {
    if (activeClip?.media_blob_name) {
      return appendAccessTokenToMediaUrl(`/api/media/${activeClip.media_blob_name}`)
    }
    if (mediaUrl && mediaUrl.trim()) {
      return appendAccessTokenToMediaUrl(mediaUrl)
    }
    const blobName = session?.media_blob_name
    if (blobName && blobName.trim()) {
      return appendAccessTokenToMediaUrl(`/api/media/${blobName}`)
    }
    return null
  }, [mediaUrl, session?.media_blob_name, activeClip?.media_blob_name])

  const effectiveMediaType = useMemo(() => {
    if (mediaType && mediaType.trim()) {
      return mediaType
    }
    const sessionType = session?.media_content_type
    return sessionType && sessionType.trim() ? sessionType : undefined
  }, [mediaType, session?.media_content_type])

  const isVideo = useMemo(() => (effectiveMediaType ?? '').startsWith('video/'), [effectiveMediaType])
  const videoRef = useRef<HTMLVideoElement>(null)
  const audioRef = useRef<HTMLAudioElement>(null)
  const playerRef = isVideo ? videoRef : audioRef

  useEffect(() => {
    if (!effectiveMediaUrl) {
      setPreviewing(false)
    }
  }, [effectiveMediaUrl])

  useEffect(() => {
    if (!session) {
      setClipName('')
      setTimeStart('')
      setTimeEnd('')
      setPageStart('')
      setLineStart('')
      setPageEnd('')
      setLineEnd('')
      setManualStartId(null)
      setManualEndId(null)
      setActiveClip(null)
      setClipCache({})
      return
    }

    setActiveClip(null)
    setClipCache({})
    const defaultName = `Clip ${(session.clips?.length ?? 0) + 1}`
    setClipName(defaultName)
    setSelectionMode('time')
  }, [session])

  useEffect(() => {
    setImportExpanded(!session)
  }, [session])

  useEffect(() => {
    if (!session) {
      return
    }
    const sessionLines = session.lines ?? []
    if (!sessionLines.length) {
      return
    }
    const first = sessionLines[0]
    const last = sessionLines[sessionLines.length - 1]
    setTimeStart(formatSeconds(first.start))
    setTimeEnd(formatSeconds(last.end))
    setPageStart(first.page != null ? String(first.page) : '')
    setLineStart(first.line != null ? String(first.line) : '')
    setPageEnd(last.page != null ? String(last.page) : '')
    setLineEnd(last.line != null ? String(last.line) : '')
    setManualStartId(first.id)
    setManualEndId(last.id)
  }, [session])

  const parsePageInput = (value: string) => {
    const trimmed = value.trim()
    if (!trimmed) return null
    const parsed = Number(trimmed)
    return Number.isFinite(parsed) ? parsed : null
  }

  const findLineIndexById = useCallback(
    (id: string | null) => {
      if (!id) return null
      const index = lines.findIndex((line) => line.id === id)
      return index >= 0 ? index : null
    },
    [lines],
  )

  const findLineIndexByPageLine = useCallback(
    (pageStr: string, lineStr: string) => {
      const page = parsePageInput(pageStr)
      const line = parsePageInput(lineStr)
      if (page === null || line === null) {
        return null
      }
      const index = lines.findIndex((entry) => entry.page === page && entry.line === line)
      return index >= 0 ? index : null
    },
    [lines],
  )

  const findLineIndexByTime = useCallback(
    (input: string, preferStart: boolean) => {
      const seconds = parseTimeInput(input)
      if (seconds === null) return null
      if (!lines.length) return null
      if (preferStart) {
        for (let idx = 0; idx < lines.length; idx += 1) {
          const entry = lines[idx]
          if (seconds <= entry.start) return idx
          if (seconds >= entry.start && seconds <= Math.max(entry.end, entry.start)) return idx
        }
        return lines.length - 1
      }
      for (let idx = lines.length - 1; idx >= 0; idx -= 1) {
        const entry = lines[idx]
        if (seconds >= entry.end) return idx
        if (seconds >= entry.start && seconds <= Math.max(entry.end, entry.start)) return idx
      }
      return 0
    },
    [lines],
  )

  const selectedRange = useMemo(() => {
    if (!lines.length) return null

    let startIndex: number | null = null
    let endIndex: number | null = null

    if (selectionMode === 'manual') {
      startIndex = findLineIndexById(manualStartId)
      endIndex = findLineIndexById(manualEndId)
    } else if (selectionMode === 'pageLine') {
      startIndex = findLineIndexByPageLine(pageStart, lineStart)
      endIndex = findLineIndexByPageLine(pageEnd, lineEnd)
    } else {
      startIndex = findLineIndexByTime(timeStart, true)
      endIndex = findLineIndexByTime(timeEnd, false)
    }

    if (startIndex === null || endIndex === null) {
      return null
    }

    const start = Math.min(startIndex, endIndex)
    const end = Math.max(startIndex, endIndex)
    return { startIndex: start, endIndex: end }
  }, [
    lines,
    selectionMode,
    manualStartId,
    manualEndId,
    pageStart,
    lineStart,
    pageEnd,
    lineEnd,
    timeStart,
    timeEnd,
    findLineIndexById,
    findLineIndexByPageLine,
    findLineIndexByTime,
  ])

  const selectedLines = useMemo(() => {
    if (!selectedRange) return []
    return lines.slice(selectedRange.startIndex, selectedRange.endIndex + 1)
  }, [lines, selectedRange])

  const clipBounds = useMemo(() => {
    if (!selectedRange || selectedLines.length === 0) return null
    const first = selectedLines[0]
    const last = selectedLines[selectedLines.length - 1]
    return {
      start: Math.max(0, first.start),
      end: Math.max(first.start + 0.01, last.end),
    }
  }, [selectedRange, selectedLines])

  useEffect(() => {
    if (!clipBounds || !selectedRange || !lines.length) return

    const startLine = lines[selectedRange.startIndex]
    const endLine = lines[selectedRange.endIndex]
    if (!startLine || !endLine) return

    setTimeStart(formatSeconds(startLine.start))
    setTimeEnd(formatSeconds(endLine.end))

    if (startLine.page != null && startLine.line != null) {
      setPageStart(String(startLine.page))
      setLineStart(String(startLine.line))
    }
    if (endLine.page != null && endLine.line != null) {
      setPageEnd(String(endLine.page))
      setLineEnd(String(endLine.line))
    }

    setManualStartId(startLine.id)
    setManualEndId(endLine.id)
  }, [selectedRange])

  useEffect(() => {
    if (!previewing) {
      return
    }
    const bounds = clipBounds
    if (!bounds) {
      setPreviewing(false)
      return
    }
    const player = playerRef.current
    if (!player) {
      setPreviewing(false)
      return
    }

    const handleTimeUpdate = () => {
      if (player.currentTime >= bounds.end) {
        player.pause()
        player.currentTime = bounds.start
        setPreviewing(false)
      }
    }

    player.currentTime = bounds.start
    const playPromise = player.play()
    if (playPromise) {
      playPromise.catch(() => setPreviewing(false))
    }
    player.addEventListener('timeupdate', handleTimeUpdate)

    return () => {
      player.removeEventListener('timeupdate', handleTimeUpdate)
    }
  }, [previewing, clipBounds, playerRef])

  const handleManualStart = (lineId: string) => {
    setSelectionMode('manual')
    setManualStartId(lineId)
  }

  const handleManualEnd = (lineId: string) => {
    setSelectionMode('manual')
    setManualEndId(lineId)
  }

  const handlePreviewClip = () => {
    if (!clipBounds || !effectiveMediaUrl) return
    setPreviewing(true)
  }

  const fetchClipDetail = useCallback(
    async (clipId: string): Promise<ClipDetailResponse | null> => {
      if (clipCache[clipId]) {
        return clipCache[clipId]
      }
      try {
        setHistoryLoadingId(clipId)
        const response = await authenticatedFetch(`/api/clips/${clipId}`)
        if (!response.ok) {
          return null
        }
        const data: ClipDetailResponse = await response.json()
        setClipCache((prev) => ({ ...prev, [clipId]: data }))
        return data
      } catch (err) {
        console.warn('Failed to load clip detail', err)
        return null
      } finally {
        setHistoryLoadingId(null)
      }
    },
    [clipCache],
  )

  const handleSelectClip = useCallback(
    async (clipId: string) => {
      const detail = await fetchClipDetail(clipId)
      if (detail) {
        setActiveClip(detail)
      }
    },
    [fetchClipDetail],
  )

  const handleDownloadDocx = useCallback(
    async (clipId: string) => {
      const detail = await fetchClipDetail(clipId)
      if (!detail) return
      const filename = buildFilename(detail.name.replace(/\s+/g, '-').toLowerCase(), '.docx')
      onDownload(detail.docx_base64, filename, 'application/vnd.openxmlformats-officedocument.wordprocessingml.document')
    },
    [buildFilename, fetchClipDetail, onDownload],
  )

  const handleDownloadXml = useCallback(
    async (clipId: string) => {
      const detail = await fetchClipDetail(clipId)
      if (!detail) return
      const filename = buildFilename(detail.name.replace(/\s+/g, '-').toLowerCase(), '.xml')
      onDownload(detail.oncue_xml_base64, filename, 'application/xml')
    },
    [buildFilename, fetchClipDetail, onDownload],
  )

  const handleCreateClip = useCallback(async () => {
    if (!mediaKey || !session) {
      setCreationError('Load or generate a transcript before creating clips.')
      return
    }
    if (!selectedRange) {
      setCreationError('Select a valid start and end point for the clip.')
      return
    }

    const startLine = lines[selectedRange.startIndex]
    const endLine = lines[selectedRange.endIndex]
    if (!startLine || !endLine) {
      setCreationError('Unable to resolve selected transcript lines.')
      return
    }

    const payload = {
      media_key: mediaKey,
      clip_label: clipName.trim() || undefined,
      start_line_id: startLine.id,
      end_line_id: endLine.id,
      start_pgln: startLine.pgln ?? undefined,
      end_pgln: endLine.pgln ?? undefined,
      start_page: startLine.page ?? undefined,
      start_line: startLine.line ?? undefined,
      end_page: endLine.page ?? undefined,
      end_line: endLine.line ?? undefined,
      start_time: startLine.start,
      end_time: endLine.end,
      lines_per_page: session.lines_per_page,
      selection_source: selectionMode,
    }

    setIsSubmitting(true)
    setCreationError(null)
    setCreationMessage(null)

    try {
      const response = await authenticatedFetch('/api/clips', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(payload),
      })

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({ detail: 'Clip creation failed' }))
        throw new Error(errorData.detail || 'Clip creation failed')
      }

      const data = await response.json()
      const clip: ClipDetailResponse = data.clip
      setClipCache((prev) => ({ ...prev, [clip.clip_id]: clip }))
      setActiveClip(clip)
      setCreationMessage('Clip created successfully. Downloads are ready below.')

      const refreshedSession = (data.transcript || data.session) as EditorSessionResponse | undefined
      if (refreshedSession) {
        onSessionRefresh(refreshedSession)
        const nextCount = Array.isArray(refreshedSession.clips) ? refreshedSession.clips.length + 1 : 1
        setClipName(`Clip ${nextCount}`)
      }
    } catch (err: any) {
      const message = typeof err?.message === 'string' ? err.message : 'Clip creation failed'
      setCreationError(message)
    } finally {
      setIsSubmitting(false)
    }
  }, [clipName, lines, mediaKey, onSessionRefresh, selectedRange, selectionMode, session])

  const handleImportTranscript = useCallback(
    async (event: FormEvent<HTMLFormElement>) => {
      event.preventDefault()
      if (!importXmlFile) {
        setImportError('Select an OnCue XML file to import.')
        return
      }
      setImporting(true)
      setImportError(null)
      setImportMessage(null)
      try {
        const formData = new FormData()
        formData.append('xml_file', importXmlFile)
        if (importMediaFile) {
          formData.append('media_file', importMediaFile)
        }

        const response = await authenticatedFetch('/api/transcripts/import', {
          method: 'POST',
          body: formData,
        })
        if (!response.ok) {
          const detail = await response.json().catch(() => ({}))
          throw new Error(detail?.detail || 'Failed to import transcript')
        }
        const data: EditorSessionResponse = await response.json()
        onSessionRefresh(data)
        setImportMessage('Transcript imported successfully. Clip builder is ready.')
        setImportXmlFile(null)
        setImportMediaFile(null)
        setImportResetKey((value) => value + 1)
      } catch (err: any) {
        const message = typeof err?.message === 'string' ? err.message : 'Failed to import transcript'
        setImportError(message)
      } finally {
        setImporting(false)
      }
    },
    [importXmlFile, importMediaFile, onSessionRefresh],
  )

  const renderLineRow = (line: EditorLine, index: number) => {
    const isSelected =
      selectedRange && index >= selectedRange.startIndex && index <= selectedRange.endIndex
    const pageLabel = line.page != null && line.line != null ? `Pg ${line.page} Ln ${line.line}` : ''
    return (
      <div
        key={line.id}
        className={`border rounded-lg p-3 mb-2 transition ${
          isSelected ? 'bg-primary-100 border-primary-400' : 'bg-white border-primary-200'
        }`}
      >
        <div className="flex flex-wrap items-center justify-between gap-2">
          <div className="flex items-center gap-3">
            <span className="text-xs font-semibold text-primary-600 bg-primary-200 px-2 py-1 rounded-full">
              {formatSeconds(line.start)}
            </span>
            <span className="text-xs text-primary-500">{pageLabel || 'â€”'}</span>
          </div>
          <div className="flex gap-2">
            <button type="button" className="btn-outline text-xs" onClick={() => handleManualStart(line.id)}>
              Start here
            </button>
            <button type="button" className="btn-outline text-xs" onClick={() => handleManualEnd(line.id)}>
              End here
            </button>
          </div>
        </div>
        <div className="mt-2 text-sm text-primary-900">
          <span className="font-semibold">{line.speaker}:</span> {line.text}
        </div>
      </div>
    )
  }

  const renderHistoryRow = (summary: ClipSummary) => {
    const isActive = activeClip?.clip_id === summary.clip_id
    return (
      <div
        key={summary.clip_id}
        className={`border rounded-lg p-4 transition ${
          isActive ? 'border-primary-500 bg-primary-50' : 'border-primary-200 bg-white'
        }`}
      >
        <div className="flex flex-wrap justify-between gap-3">
          <div>
            <div className="font-semibold text-primary-900">{summary.name}</div>
            <div className="text-xs text-primary-600">
              Created {new Date(summary.created_at).toLocaleString()} â€¢ {formatSeconds(summary.duration)}
            </div>
            <div className="text-xs text-primary-500 mt-1">
              {summary.start_time != null && summary.end_time != null && (
                <>
                  Source {formatSeconds(summary.start_time)} â€“ {formatSeconds(summary.end_time)}
                </>
              )}
            </div>
          </div>
          <div className="flex flex-wrap gap-2 items-center justify-center md:justify-end">
            <button
              type="button"
              className="btn-outline text-xs"
              onClick={() => handleSelectClip(summary.clip_id)}
              disabled={historyLoadingId === summary.clip_id}
            >
              {historyLoadingId === summary.clip_id ? 'Loadingâ€¦' : 'View'}
            </button>
            <button
              type="button"
              className="btn-outline text-xs"
              onClick={() => handleDownloadDocx(summary.clip_id)}
            >
              DOCX
            </button>
            <button
              type="button"
              className="btn-outline text-xs"
              onClick={() => handleDownloadXml(summary.clip_id)}
            >
              XML
            </button>
            {summary.media_blob_name && (
              <a
                href={appendAccessTokenToMediaUrl(`/api/media/${summary.media_blob_name}`)}
                className="btn-outline text-xs"
                target="_blank"
                rel="noopener noreferrer"
              >
                Media
              </a>
            )}
          </div>
        </div>
      </div>
    )
  }

  const hasSession = Boolean(mediaKey && session)
  const hasLines = hasSession && lines.length > 0

  return (
    <div className="space-y-8">
      {onOpenHistory && (
        <div className="flex justify-end">
          <button className="btn-outline text-sm" onClick={onOpenHistory}>
            History
          </button>
        </div>
      )}
      <div className="card">
        <div
          className="card-header cursor-pointer flex justify-between items-center"
          onClick={() => setImportExpanded(!importExpanded)}
        >
          <h2 className="text-xl font-medium">Import Transcript</h2>
          <svg
            className={`w-5 h-5 text-primary-500 transition-transform ${importExpanded ? 'rotate-180' : ''}`}
            fill="none"
            stroke="currentColor"
            viewBox="0 0 24 24"
          >
            <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M19 9l-7 7-7-7" />
          </svg>
        </div>
        {importExpanded && (
          <div className="card-body space-y-4">
            <p className="text-sm text-primary-700">
              Bring an existing OnCue XML transcript into the clip builder. Optionally include the corresponding media file
              for preview and clip exports.
            </p>
            {importError && (
              <div className="rounded-lg border border-red-200 bg-red-50 px-3 py-2 text-sm text-red-700">{importError}</div>
            )}
            {importMessage && (
              <div className="rounded-lg border border-green-200 bg-green-50 px-3 py-2 text-sm text-green-700">{importMessage}</div>
            )}
            <form className="grid grid-cols-1 gap-4 md:grid-cols-2" onSubmit={handleImportTranscript}>
              <div className="space-y-2">
                <label className="block text-xs font-medium uppercase tracking-wide text-primary-700">OnCue XML *</label>
                <input
                  key={`import-xml-${importResetKey}`}
                  type="file"
                  accept=".xml"
                  onChange={(event) => setImportXmlFile(event.target.files?.[0] ?? null)}
                  className="mt-1 w-full text-sm text-primary-700 file:mr-3 file:rounded file:border-0 file:bg-primary-100 file:px-3 file:py-2 file:text-primary-800"
                />
                <p className="text-xs text-primary-500">Select the transcript exported from OnCue.</p>
              </div>
              <div className="space-y-2">
                <label className="block text-xs font-medium uppercase tracking-wide text-primary-700">Media *</label>
                <input
                  key={`import-media-${importResetKey}`}
                  type="file"
                  accept="audio/*,video/*"
                  onChange={(event) => setImportMediaFile(event.target.files?.[0] ?? null)}
                  className="mt-1 w-full text-sm text-primary-700 file:mr-3 file:rounded file:border-0 file:bg-primary-100 file:px-3 file:py-2 file:text-primary-800"
                />
                <p className="text-xs text-primary-500">Required. The corresponding video or audio file for clip extraction and preview.</p>
              </div>
              <div className="md:col-span-2">
                <button type="submit" className="btn-outline w-full md:w-auto" disabled={importing}>
                  {importing ? 'Importingâ€¦' : 'Import transcript'}
                </button>
              </div>
            </form>
          </div>
        )}
      </div>

      {!hasSession ? (
        <div className="card">
          <div className="card-header">
            <h2 className="text-xl font-medium">Clip Creator</h2>
          </div>
          <div className="card-body space-y-3 text-primary-700">
            <p>Import a transcript above or generate one from the Transcription tab to start building clips.</p>
          </div>
        </div>
      ) : !hasLines ? (
        <div className="card">
          <div className="card-header">
            <h2 className="text-xl font-medium">Clip Creator</h2>
          </div>
          <div className="card-body space-y-3 text-primary-700">
            <p>
              This session does not have any transcript lines yet. Complete the transcription or import process before
              generating clips.
            </p>
          </div>
        </div>
      ) : (
        <>
          <div className="card">
            <div className="card-header">
              <h2 className="text-xl font-medium">Build a Clip</h2>
            </div>
            <div className="card-body space-y-6">
              <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
                <div>
                  {cardSectionTitle('Clip name')}
                  <input
                    type="text"
                    value={clipName}
                    onChange={(event) => setClipName(event.target.value)}
                    className="input-field"
                    placeholder="e.g., Opening statement"
                  />
                </div>
                <div>
                  {cardSectionTitle('Selection mode')}
                  <div className="flex gap-2 flex-wrap">
                    <button type="button" className={selectionButtonClasses(selectionMode === 'time')} onClick={() => setSelectionMode('time')}>
                      Timecodes
                    </button>
                    <button type="button" className={selectionButtonClasses(selectionMode === 'pageLine')} onClick={() => setSelectionMode('pageLine')}>
                      Page & Line
                    </button>
                    <button type="button" className={selectionButtonClasses(selectionMode === 'manual')} onClick={() => setSelectionMode('manual')}>
                      Transcript Picker
                    </button>
                  </div>
                </div>
              </div>

              {selectionMode === 'time' && (
                <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
                  <div>
                    <label className="block text-sm font-medium text-primary-700 mb-1">
                      Start time <span className="font-normal text-primary-500">(snaps to line)</span>
                    </label>
                    <input
                      type="text"
                      className="input-field"
                      value={timeStart}
                      onChange={(event) => setTimeStart(event.target.value)}
                      placeholder="0:00.000"
                    />
                  </div>
                  <div>
                    <label className="block text-sm font-medium text-primary-700 mb-1">
                      End time <span className="font-normal text-primary-500">(snaps to line)</span>
                    </label>
                    <input
                      type="text"
                      className="input-field"
                      value={timeEnd}
                      onChange={(event) => setTimeEnd(event.target.value)}
                      placeholder="0:30.000"
                    />
                  </div>
                </div>
                <p className="text-xs text-primary-500 md:col-span-2">
                  Clips include complete transcript lines. Times will adjust to line boundaries.
                </p>
              )}

              {selectionMode === 'pageLine' && (
                <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
                  <div className="grid grid-cols-2 gap-3">
                    <div>
                      <label className="block text-sm font-medium text-primary-700 mb-1">Start page</label>
                      <input type="text" className="input-field" value={pageStart} onChange={(event) => setPageStart(event.target.value)} />
                    </div>
                    <div>
                      <label className="block text-sm font-medium text-primary-700 mb-1">Start line</label>
                      <input type="text" className="input-field" value={lineStart} onChange={(event) => setLineStart(event.target.value)} />
                    </div>
                  </div>
                  <div className="grid grid-cols-2 gap-3">
                    <div>
                      <label className="block text-sm font-medium text-primary-700 mb-1">End page</label>
                      <input type="text" className="input-field" value={pageEnd} onChange={(event) => setPageEnd(event.target.value)} />
                    </div>
                    <div>
                      <label className="block text-sm font-medium text-primary-700 mb-1">End line</label>
                      <input type="text" className="input-field" value={lineEnd} onChange={(event) => setLineEnd(event.target.value)} />
                    </div>
                  </div>
                </div>
              )}

              {selectionMode === 'manual' && (
                <p className="text-sm text-primary-700">
                  Click â€œStart hereâ€ and â€œEnd hereâ€ on the transcript lines below to define your clip. You can still fine-tune using
                  timecodes or page numbers afterwards.
                </p>
              )}

              <div>
                {cardSectionTitle('Transcript lines')}
                <div className="max-h-96 overflow-y-auto pr-1">
                  {lines.map((line, index) => renderLineRow(line, index))}
                </div>
              </div>

              <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
                <div className="space-y-2">
                  <div className="text-sm text-primary-700">
                    <span className="font-semibold">Clip span:</span>{' '}
                    {clipBounds ? `${formatSeconds(clipBounds.start)} â€“ ${formatSeconds(clipBounds.end)}` : 'Select lines to calculate'}
                  </div>
                  <div className="text-sm text-primary-600">
                    <span className="font-semibold">Duration:</span>{' '}
                    {clipBounds ? formatSeconds(clipBounds.end - clipBounds.start) : 'â€”'}
                  </div>
                </div>
                <div className="flex items-center gap-3">
                  <button
                    type="button"
                    className="btn-outline"
                    onClick={handlePreviewClip}
                    disabled={!clipBounds || !effectiveMediaUrl || isSubmitting}
                  >
                    {previewing ? 'Previewingâ€¦' : 'Preview clip'}
                  </button>
                  <button type="button" className="btn-primary" onClick={handleCreateClip} disabled={isSubmitting || !selectedRange}>
                    {isSubmitting ? 'Creatingâ€¦' : 'Create clip'}
                  </button>
                </div>
              </div>

              {creationError && <div className="bg-red-50 border border-red-200 text-red-700 px-4 py-3 rounded">{creationError}</div>}
              {creationMessage && <div className="bg-green-50 border border-green-200 text-green-700 px-4 py-3 rounded">{creationMessage}</div>}
            </div>
          </div>

          <div className="grid grid-cols-1 xl:grid-cols-2 gap-8">
            <div className="card">
              <div className="card-header">
                <h2 className="text-xl font-medium">Media preview</h2>
              </div>
              <div className="card-body space-y-4">
                {effectiveMediaUrl ? (
                  <>
                    <div className="bg-primary-900 rounded-lg p-4">
                      {isVideo ? (
                        <video ref={videoRef} src={effectiveMediaUrl} controls preload="metadata" className="w-full rounded" />
                      ) : (
                        <audio ref={audioRef} src={effectiveMediaUrl} controls preload="metadata" className="w-full" />
                      )}
                    </div>
                    {clipBounds && session?.audio_duration && !activeClip && (
                      <div className="mt-3">
                        <div className="text-xs text-primary-500 mb-1">Clip region</div>
                        <div className="h-2 bg-primary-200 rounded-full relative overflow-hidden">
                          <div
                            className="absolute h-full bg-primary-500 rounded-full"
                            style={{
                              left: `${(clipBounds.start / session.audio_duration) * 100}%`,
                              width: `${((clipBounds.end - clipBounds.start) / session.audio_duration) * 100}%`,
                            }}
                          />
                        </div>
                        <div className="flex justify-between text-xs text-primary-400 mt-1">
                          <span>0:00</span>
                          <span>{formatSeconds(session.audio_duration)}</span>
                        </div>
                      </div>
                    )}
                  </>
                ) : (
                  <p className="text-primary-700">No media preview available for this session.</p>
                )}
                {clipBounds && (
                  <div className="text-xs text-primary-600">
                    Clip will run from {formatSeconds(clipBounds.start)} to {formatSeconds(clipBounds.end)}.
                  </div>
                )}
              </div>
            </div>

            <div className="card">
              <div className="card-header">
                <h2 className="text-xl font-medium">Clip history</h2>
              </div>
              <div className="card-body space-y-4">
                {clipHistory.length === 0 && <p className="text-primary-700">No clips yet. Create your first clip to see it here.</p>}
                {clipHistory.map((summary) => renderHistoryRow(summary))}
              </div>
            </div>
          </div>

          {activeClip && (
            <div className="card">
              <div className="card-header flex justify-between items-center">
                <h2 className="text-xl font-medium">Selected clip</h2>
                <button
                  type="button"
                  className="text-primary-500 hover:text-primary-700 text-sm"
                  onClick={() => setActiveClip(null)}
                >
                  Clear selection
                </button>
              </div>
              <div className="card-body space-y-4">
                <div>
                  <div className="text-lg font-semibold text-primary-900">{activeClip.name}</div>
                  <div className="text-sm text-primary-600">
                    Duration: {formatSeconds(activeClip.duration)}
                  </div>
                  <div className="text-sm text-primary-500">
                    Source: {formatSeconds(activeClip.start_time)} â€“ {formatSeconds(activeClip.end_time)}
                  </div>
                </div>
                <div>
                  {cardSectionTitle('Transcript preview')}
                  <div className="bg-primary-50 border border-primary-200 rounded-lg p-4 max-h-64 overflow-y-auto">
                    {activeClip.lines.map((line) => (
                      <div key={line.id} className="text-sm text-primary-800 mb-2">
                        <span className="font-semibold">{line.speaker}</span>: {line.text}
                      </div>
                    ))}
                  </div>
                </div>
              </div>
            </div>
          )}
        </>
      )}
    </div>
  )
}
===== END FILE =====

===== FILE: frontend-next/src/components/LoginModal.tsx =====
"use client";

import React, { useState } from 'react';

interface LoginModalProps {
  onLoginSuccess: () => void;
}

export default function LoginModal({ onLoginSuccess }: LoginModalProps) {
  const [username, setUsername] = useState('');
  const [password, setPassword] = useState('');
  const [error, setError] = useState('');
  const [isLoading, setIsLoading] = useState(false);

  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault();
    setError('');
    setIsLoading(true);

    try {
      const response = await fetch('/api/auth/login', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({ username, password }),
      });

      if (!response.ok) {
        const errorData = await response.json();
        throw new Error(errorData.detail || 'Login failed');
      }

      const data = await response.json();

      // Store tokens in localStorage
      localStorage.setItem('access_token', data.access_token);
      localStorage.setItem('refresh_token', data.refresh_token);
      localStorage.setItem('user', JSON.stringify(data.user));

      // Call success callback
      onLoginSuccess();
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Login failed. Please try again.');
    } finally {
      setIsLoading(false);
    }
  };

  return (
    <div className="fixed inset-0 bg-black bg-opacity-50 flex items-center justify-center z-50">
      <div className="bg-white rounded-lg shadow-2xl p-8 max-w-md w-full mx-4">
        <div className="mb-6">
          <h2 className="text-3xl font-bold text-primary-900 mb-2">
            TranscribeAlpha
          </h2>
          <p className="text-primary-600">
            Please sign in to continue
          </p>
        </div>

        <form onSubmit={handleSubmit} className="space-y-4">
          <div>
            <label htmlFor="username" className="block text-sm font-medium text-primary-700 mb-2">
              Username
            </label>
            <input
              type="text"
              id="username"
              value={username}
              onChange={(e) => setUsername(e.target.value)}
              className="w-full px-4 py-3 border border-primary-300 rounded-lg focus:outline-none focus:ring-2 focus:ring-primary-500 focus:border-transparent shadow-sm"
              placeholder="Enter your username"
              required
              disabled={isLoading}
              autoComplete="username"
            />
          </div>

          <div>
            <label htmlFor="password" className="block text-sm font-medium text-primary-700 mb-2">
              Password
            </label>
            <input
              type="password"
              id="password"
              value={password}
              onChange={(e) => setPassword(e.target.value)}
              className="w-full px-4 py-3 border border-primary-300 rounded-lg focus:outline-none focus:ring-2 focus:ring-primary-500 focus:border-transparent shadow-sm"
              placeholder="Enter your password"
              required
              disabled={isLoading}
              autoComplete="current-password"
            />
          </div>

          {error && (
            <div className="bg-red-50 border border-red-200 text-red-700 px-4 py-3 rounded-lg text-sm">
              {error}
            </div>
          )}

          <button
            type="submit"
            disabled={isLoading}
            className="w-full bg-primary-900 text-white py-3 px-6 rounded-lg font-medium hover:bg-primary-800 focus:outline-none focus:ring-2 focus:ring-primary-500 focus:ring-offset-2 shadow-lg disabled:opacity-50 disabled:cursor-not-allowed transition-colors"
          >
            {isLoading ? 'Signing in...' : 'Sign In'}
          </button>
        </form>

        <div className="mt-6 text-center text-sm text-primary-600">
          <p>
            Need help? Contact your administrator.
          </p>
        </div>
      </div>
    </div>
  );
}
===== END FILE =====

===== FILE: frontend-next/src/components/TranscribeForm.tsx =====
'use client'

import { useCallback, useEffect, useRef, useState } from 'react'
import TranscriptEditor, { EditorSaveResponse, EditorSessionResponse } from '@/components/TranscriptEditor'
import ClipCreator from '@/components/ClipCreator'
import { appendAccessTokenToMediaUrl, authenticatedFetch, getAuthHeaders } from '@/utils/auth'

interface FormData {
  case_name: string
  case_number: string
  firm_name: string
  input_date: string
  input_time: string
  location: string
  speaker_names: string
  transcription_model: 'assemblyai' | 'gemini'
}

type TranscriptData = EditorSessionResponse & {
  transcript?: string | null
  transcript_text?: string | null
}

interface TranscriptListItem {
  media_key: string
  title_label: string
  updated_at?: string | null
  line_count?: number
}

interface SnapshotListItem {
  snapshot_id: string
  created_at?: string
  is_manual_save?: boolean
  line_count?: number
  title_label?: string
}

interface HistoryGroup extends TranscriptListItem {
  snapshots: SnapshotListItem[]
}

type AppTab = 'transcribe' | 'editor' | 'clip'

export default function TranscribeForm() {
  const [formData, setFormData] = useState<FormData>({
    case_name: '',
    case_number: '',
    firm_name: '',
    input_date: '',
    input_time: '',
    location: '',
    speaker_names: '',
    transcription_model: 'assemblyai',
  })

  const [activeTab, setActiveTab] = useState<AppTab>('transcribe')
  const [selectedFile, setSelectedFile] = useState<File | null>(null)
  const [mediaKey, setMediaKey] = useState<string | null>(null)
  const [transcriptData, setTranscriptData] = useState<TranscriptData | null>(null)
  const [isLoading, setIsLoading] = useState(false)
  const [loadingStage, setLoadingStage] = useState<string | null>(null)
  const [error, setError] = useState<string>('')
  const [mediaPreviewUrl, setMediaPreviewUrl] = useState<string>('')
  const [mediaContentType, setMediaContentType] = useState<string | undefined>(undefined)
  const [mediaIsLocal, setMediaIsLocal] = useState(false)
  const [showHistoryModal, setShowHistoryModal] = useState(false)
  const [historyGroups, setHistoryGroups] = useState<HistoryGroup[]>([])
  const [historyModalLoading, setHistoryModalLoading] = useState(false)
  const [historyModalError, setHistoryModalError] = useState<string | null>(null)
  const [selectedHistoryKey, setSelectedHistoryKey] = useState<string | null>(null)
  const [restoringSnapshotId, setRestoringSnapshotId] = useState<string | null>(null)
  const [geminiBusy, setGeminiBusy] = useState(false)
  const [geminiError, setGeminiError] = useState<string | null>(null)

  const fileInputRef = useRef<HTMLInputElement>(null)
  const stageTimerRef = useRef<number | null>(null)

  const updateMediaPreview = useCallback(
    (blobName?: string | null, contentType?: string | null) => {
      if (!blobName) return
      if (mediaPreviewUrl && mediaIsLocal) {
        URL.revokeObjectURL(mediaPreviewUrl)
      }
      setMediaPreviewUrl(appendAccessTokenToMediaUrl(`/api/media/${blobName}`))
      setMediaContentType(contentType ?? undefined)
      setMediaIsLocal(false)
    },
    [mediaIsLocal, mediaPreviewUrl],
  )

  const hydrateTranscript = useCallback(
    (data: TranscriptData) => {
      setTranscriptData((previous) => {
        const prevKey = previous?.media_key ?? previous?.title_data?.MEDIA_ID ?? null
        const nextKey = data.media_key ?? data.title_data?.MEDIA_ID ?? null
        const sameKey = Boolean(prevKey && nextKey && prevKey === nextKey)
        const merged: TranscriptData = {
          ...(sameKey ? previous : {}),
          ...data,
          docx_base64: data.docx_base64 ?? (sameKey ? previous?.docx_base64 : undefined),
          oncue_xml_base64: data.oncue_xml_base64 ?? (sameKey ? previous?.oncue_xml_base64 : undefined),
          media_blob_name: data.media_blob_name ?? (sameKey ? previous?.media_blob_name : undefined),
          media_content_type: data.media_content_type ?? (sameKey ? previous?.media_content_type : undefined),
          audio_duration: data.audio_duration ?? (sameKey ? previous?.audio_duration : undefined) ?? 0,
          lines_per_page: data.lines_per_page ?? (sameKey ? previous?.lines_per_page : undefined) ?? 25,
          title_data: data.title_data ?? (sameKey ? previous?.title_data : undefined) ?? {},
          lines: data.lines ?? (sameKey ? previous?.lines : undefined) ?? [],
          clips: data.clips ?? (sameKey ? previous?.clips : undefined) ?? [],
          transcript: data.transcript
            ?? data.transcript_text
            ?? (sameKey ? previous?.transcript ?? previous?.transcript_text : null)
            ?? null,
          transcript_text: data.transcript_text
            ?? data.transcript
            ?? (sameKey ? previous?.transcript_text ?? previous?.transcript : null)
            ?? null,
        }
        return merged
      })

      const resolvedKey = data.media_key ?? data.title_data?.MEDIA_ID ?? null
      setMediaKey(resolvedKey ?? null)
      setError('')

      if (data.media_blob_name) {
        updateMediaPreview(data.media_blob_name, data.media_content_type ?? undefined)
      }
    },
    [updateMediaPreview],
  )

  useEffect(() => {
    return () => {
      if (mediaPreviewUrl && mediaIsLocal) {
        URL.revokeObjectURL(mediaPreviewUrl)
      }
    }
  }, [mediaPreviewUrl, mediaIsLocal])

  const handleSessionChange = useCallback(
    (session: EditorSessionResponse) => {
      hydrateTranscript(session as TranscriptData)
    },
    [hydrateTranscript],
  )

  const handleInputChange = (event: React.ChangeEvent<HTMLInputElement | HTMLSelectElement>) => {
    const { name, value, type } = event.target
    setFormData((prev) => ({
      ...prev,
      [name]: type === 'checkbox' ? (event.target as HTMLInputElement).checked : value,
    }))
  }

  const handleFileChange = (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0]
    if (!file) return

    if (mediaPreviewUrl && mediaIsLocal) {
      URL.revokeObjectURL(mediaPreviewUrl)
    }

    setSelectedFile(file)
    setError('')
    setTranscriptData(null)
    setMediaKey(null)
    setActiveTab('transcribe')

    const previewUrl = URL.createObjectURL(file)
    setMediaPreviewUrl(previewUrl)
    setMediaContentType(file.type)
    setMediaIsLocal(true)
  }

  const fetchTranscriptByKey = useCallback(
    async (key: string) => {
      try {
        const response = await authenticatedFetch(`/api/transcripts/by-key/${encodeURIComponent(key)}`)
        if (!response.ok) {
          if (response.status === 404) {
            try {
              localStorage.removeItem('active_media_key')
            } catch {
              /* ignore */
            }
          }
          const detail = await response.json().catch(() => ({}))
          throw new Error(detail?.detail || 'Failed to load transcript')
        }
        const data: TranscriptData = await response.json()
        hydrateTranscript(data)
        return data
      } catch (err: any) {
        throw new Error(err?.message || 'Failed to load transcript')
      }
    },
    [hydrateTranscript],
  )

  const trimSnapshotsToLimit = useCallback((snapshots: SnapshotListItem[]) => {
    const sorted = [...snapshots].sort((a, b) => {
      const aTime = a.created_at ? new Date(a.created_at).getTime() : 0
      const bTime = b.created_at ? new Date(b.created_at).getTime() : 0
      return bTime - aTime
    })
    const manual = sorted.find((snap) => snap.is_manual_save)
    let limited = sorted.slice(0, 10)
    if (manual && !limited.some((snap) => snap.snapshot_id === manual.snapshot_id)) {
      if (limited.length >= 10) {
        limited[limited.length - 1] = manual
      } else {
        limited.push(manual)
      }
      limited = [...limited].sort((a, b) => {
        const aTime = a.created_at ? new Date(a.created_at).getTime() : 0
        const bTime = b.created_at ? new Date(b.created_at).getTime() : 0
        return bTime - aTime
      })
    }
    return limited
  }, [])

  const loadHistoryModal = useCallback(async () => {
    setShowHistoryModal(true)
    setHistoryModalLoading(true)
    setHistoryModalError(null)
    try {
      const response = await authenticatedFetch('/api/transcripts')
      if (!response.ok) {
        const detail = await response.json().catch(() => ({}))
        throw new Error(detail?.detail || 'Failed to load history')
      }
      const payload = await response.json()
      const transcripts: TranscriptListItem[] = payload.transcripts || []

      const groups: HistoryGroup[] = await Promise.all(
        transcripts.map(async (item) => {
          try {
            const historyResponse = await authenticatedFetch(
              `/api/transcripts/by-key/${encodeURIComponent(item.media_key)}/history`,
            )
            let snapshots: SnapshotListItem[] = []
            if (historyResponse.ok) {
              const historyData = await historyResponse.json()
              snapshots = trimSnapshotsToLimit(
                (historyData.snapshots || []).map((snap: any) => ({
                  ...snap,
                  media_key: item.media_key,
                })),
              )
            }
            return {
              ...item,
              snapshots,
            }
          } catch {
            return {
              ...item,
              snapshots: [],
            }
          }
        }),
      )

      let finalGroups = groups

      // Fallback: if no transcripts listed but we have an active key, still attempt to load its history
      if (!finalGroups.length && (transcriptData?.media_key || mediaKey)) {
        const fallbackKey = transcriptData?.media_key ?? mediaKey!
        try {
          const historyResponse = await authenticatedFetch(
            `/api/transcripts/by-key/${encodeURIComponent(fallbackKey)}/history`,
          )
          const historyData = historyResponse.ok ? await historyResponse.json() : { snapshots: [] }
          finalGroups = [
            {
              media_key: fallbackKey,
              title_label: fallbackKey,
              updated_at: null,
              line_count: 0,
              snapshots: trimSnapshotsToLimit(
                (historyData.snapshots || []).map((snap: any) => ({
                  ...snap,
                  media_key: fallbackKey,
                })),
              ),
            },
          ]
        } catch {
          finalGroups = []
        }
      }

      const preferredKey = transcriptData?.media_key ?? mediaKey
      const initialKey =
        preferredKey && finalGroups.some((group) => group.media_key === preferredKey)
          ? preferredKey
          : finalGroups[0]?.media_key ?? null

      setHistoryGroups(finalGroups)
      setSelectedHistoryKey(initialKey)
    } catch (err: any) {
      setHistoryModalError(err?.message || 'Failed to load history')
    } finally {
      setHistoryModalLoading(false)
    }
  }, [mediaKey, transcriptData?.media_key, trimSnapshotsToLimit])

  const handleRestoreSnapshot = useCallback(
    async (key: string, snapshotId: string) => {
      setRestoringSnapshotId(`${key}:${snapshotId}`)
      setHistoryModalError(null)
      try {
        const response = await authenticatedFetch(
          `/api/transcripts/by-key/${encodeURIComponent(key)}/restore/${snapshotId}`,
          {
            method: 'POST',
          },
        )
        if (!response.ok) {
          const detail = await response.json().catch(() => ({}))
          throw new Error(detail?.detail || 'Failed to restore snapshot')
        }
        const data: TranscriptData = await response.json()
        hydrateTranscript(data)
        setActiveTab('editor')
        setShowHistoryModal(false)
      } catch (err: any) {
        setHistoryModalError(err?.message || 'Failed to restore snapshot')
      } finally {
        setRestoringSnapshotId(null)
      }
    },
    [hydrateTranscript],
  )

  const handleSubmit = async (event: React.FormEvent) => {
    event.preventDefault()

    if (!selectedFile) {
      setError('Please select a file to transcribe')
      return
    }

    setIsLoading(true)
    setLoadingStage('Uploading media...')
    setError('')
    setTranscriptData(null)
    setMediaKey(null)

    const clearStageTimer = () => {
      if (stageTimerRef.current) {
        window.clearTimeout(stageTimerRef.current)
        stageTimerRef.current = null
      }
    }

    try {
      const submitFormData = new FormData()
      submitFormData.append('file', selectedFile)
      Object.entries(formData).forEach(([key, value]) => {
        submitFormData.append(key, value.toString())
      })

      const isVideoFile =
        (selectedFile.type || '').startsWith('video/') ||
        /\.(mp4|mov|avi|mkv)$/i.test(selectedFile.name)

      const data: TranscriptData = await new Promise((resolve, reject) => {
        const request = new XMLHttpRequest()
        request.open('POST', '/api/transcribe', true)
        const authHeaders = getAuthHeaders()
        Object.entries(authHeaders).forEach(([key, value]) => {
          request.setRequestHeader(key, String(value))
        })
        request.responseType = 'json'

        request.upload.onprogress = () => {
          setLoadingStage('Uploading media...')
        }

        request.upload.onload = () => {
          clearStageTimer()
          if (isVideoFile) {
            setLoadingStage('Converting to audio...')
            stageTimerRef.current = window.setTimeout(() => {
              setLoadingStage('Transcribing (this could take a few minutes)...')
              stageTimerRef.current = null
            }, 1200)
          } else {
            setLoadingStage('Transcribing (this could take a few minutes)...')
          }
        }

        request.onload = () => {
          clearStageTimer()
          const responseData =
            request.response ??
            (() => {
              try {
                return JSON.parse(request.responseText)
              } catch {
                return null
              }
            })()

          if (request.status >= 200 && request.status < 300) {
            setLoadingStage('Producing transcript...')
            resolve(responseData as TranscriptData)
            return
          }

          const detail = responseData?.detail || 'Transcription failed'
          reject(new Error(detail))
        }

        request.onerror = () => {
          clearStageTimer()
          reject(new Error('Upload failed. Please try again.'))
        }

        request.send(submitFormData)
      })

      hydrateTranscript(data)
    } catch (err: any) {
      console.error('Transcription error:', err)
      setError(err.message || 'Transcription failed')
    } finally {
      clearStageTimer()
      setIsLoading(false)
      setLoadingStage(null)
    }
  }

  const downloadFile = (base64Data: string, filename: string, mimeType: string) => {
    const byteCharacters = atob(base64Data)
    const byteNumbers = new Array(byteCharacters.length)
    for (let i = 0; i < byteCharacters.length; i++) {
      byteNumbers[i] = byteCharacters.charCodeAt(i)
    }
    const byteArray = new Uint8Array(byteNumbers)
    const blob = new Blob([byteArray], { type: mimeType })

    const link = document.createElement('a')
    link.href = URL.createObjectURL(blob)
    link.download = filename
    document.body.appendChild(link)
    link.click()
    document.body.removeChild(link)
    URL.revokeObjectURL(link.href)
  }

  const generateFilename = (baseName: string, extension: string) => {
    let filename = ''

    if (formData.case_name.trim()) {
      const sanitizedCase = formData.case_name
        .trim()
        .replace(/[^a-zA-Z0-9\s-]/g, '')
        .replace(/\s+/g, '-')
        .replace(/-+/g, '-')
        .replace(/^-|-$/g, '')

      if (sanitizedCase) {
        filename += sanitizedCase + '-'
      }
    }

    filename += baseName

    if (formData.input_date) {
      filename += '-' + formData.input_date
    }

    return filename + extension
  }

  const handleEditorSave = (data: EditorSaveResponse) => {
    hydrateTranscript(data as TranscriptData)
  }

  const handleGeminiRefine = useCallback(async () => {
    if (!mediaKey) {
      setGeminiError('No transcript available for Gemini.')
      return
    }
    setGeminiBusy(true)
    setGeminiError(null)
    try {
      const response = await authenticatedFetch(`/api/transcripts/by-key/${encodeURIComponent(mediaKey)}/gemini-refine`, {
        method: 'POST',
      })
      if (!response.ok) {
        const detail = await response.json().catch(() => ({}))
        throw new Error(detail?.detail || 'Gemini refinement failed')
      }
      const data: TranscriptData = await response.json()
      hydrateTranscript(data)
      setActiveTab('editor')
    } catch (err: any) {
      setGeminiError(err.message || 'Gemini refinement failed')
    } finally {
      setGeminiBusy(false)
    }
  }, [mediaKey, hydrateTranscript])

  const tabClasses = (tab: AppTab) =>
    `px-4 py-2 rounded-lg font-medium transition ${activeTab === tab
      ? 'bg-primary-900 text-white shadow-lg'
      : 'bg-primary-100 text-primary-600 hover:bg-primary-200'
    }`

  const resolvedTranscriptText = transcriptData?.transcript ?? transcriptData?.transcript_text ?? ''
  const transcriptSegments = resolvedTranscriptText.split('\n\n').filter((segment) => segment.trim()).length ?? 0

  const previewContentType = mediaContentType ?? selectedFile?.type ?? ''
  const isVideoPreview = previewContentType.startsWith('video/')
  const remoteMediaUrl = transcriptData?.media_blob_name
    ? appendAccessTokenToMediaUrl(`/api/media/${transcriptData.media_blob_name}`)
    : mediaPreviewUrl || undefined
  const clipMediaUrl = (mediaIsLocal && mediaPreviewUrl) || remoteMediaUrl
  const clipMediaType =
    (mediaIsLocal ? mediaContentType ?? selectedFile?.type : undefined) ??
    transcriptData?.media_content_type ??
    mediaContentType ??
    selectedFile?.type
  const selectedHistoryGroup = historyGroups.find((group) => group.media_key === selectedHistoryKey)

  // Track if we've already loaded from localStorage to prevent re-fetching after import
  const hasLoadedFromStorage = useRef(false)

  useEffect(() => {
    // Only load from localStorage once on initial mount
    if (hasLoadedFromStorage.current) return
    hasLoadedFromStorage.current = true

    const storedKey = typeof window !== 'undefined' ? localStorage.getItem('active_media_key') : null
    if (storedKey) {
      fetchTranscriptByKey(storedKey)
        .then(() => setActiveTab('editor'))
        .catch(() => {
          try {
            localStorage.removeItem('active_media_key')
          } catch {
            /* ignore */
          }
        })
    }
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [])

  useEffect(() => {
    const key = transcriptData?.media_key ?? mediaKey
    try {
      if (key) {
        localStorage.setItem('active_media_key', key)
      } else {
        localStorage.removeItem('active_media_key')
      }
    } catch {
      /* ignore */
    }
  }, [transcriptData?.media_key, mediaKey])

  return (
    <>
      <div className="min-h-screen bg-primary-50">
        <div className="max-w-screen-2xl mx-auto px-6 py-12">
          <div className="text-center mb-12">
            <div className="bg-gradient-to-r from-primary-900 to-primary-700 text-white rounded-2xl p-8 shadow-2xl">
              <h1 className="text-4xl font-light mb-4">TranscribeAlpha</h1>
              <p className="text-lg text-primary-100">Professional Legal Transcript Generator</p>
            </div>
          </div>

          <div className="flex justify-center mb-10 gap-4 flex-wrap items-center">
            <button className={tabClasses('transcribe')} onClick={() => setActiveTab('transcribe')}>
              Transcription
            </button>
            <button className={tabClasses('editor')} onClick={() => setActiveTab('editor')}>
              Editor
            </button>
            <button className={tabClasses('clip')} onClick={() => setActiveTab('clip')}>
              Clip Creator
            </button>
            <button
              className="btn-outline text-sm"
              onClick={() => {
                loadHistoryModal()
              }}
            >
              History
            </button>
          </div>

          {activeTab === 'transcribe' && (
            <div className="space-y-8">
              <form onSubmit={handleSubmit} className="space-y-8">
                <div className="card">
                  <div className="card-header">
                    <h2 className="text-xl font-medium">Media Upload</h2>
                  </div>
                  <div className="card-body">
                    <div
                      className="border-2 border-dashed border-primary-300 rounded-lg p-8 text-center hover:border-primary-500 hover:bg-primary-100 transition-all duration-200 cursor-pointer bg-primary-50"
                      onClick={() => fileInputRef.current?.click()}
                    >
                      <input
                        type="file"
                        ref={fileInputRef}
                        onChange={handleFileChange}
                        accept="audio/*,video/*,.mp4,.avi,.mov,.mkv,.wav,.mp3,.m4a,.flac,.ogg"
                        className="hidden"
                      />
                      {selectedFile ? (
                        <div className="space-y-2">
                          <div className="text-2xl text-green-500">âœ…</div>
                          <div className="font-medium text-primary-900">{selectedFile.name}</div>
                          <div className="text-sm text-primary-600">
                            {(selectedFile.size / (1024 * 1024)).toFixed(1)} MB
                          </div>
                          <div className="text-sm text-green-600">File selected successfully</div>
                        </div>
                      ) : (
                        <div className="space-y-2">
                          <div className="text-4xl text-primary-400">ðŸ“</div>
                          <div className="font-medium text-primary-900">Click to select audio or video file</div>
                          <div className="text-sm text-primary-600">
                            Supports MP4, AVI, MOV, WAV, MP3, FLAC and more
                          </div>
                        </div>
                      )}
                    </div>
                  </div>
                </div>

                <div className="card">
                  <div className="card-header">
                    <h2 className="text-xl font-medium">Case Information</h2>
                  </div>
                  <div className="card-body">
                    <div className="grid grid-cols-1 md:grid-cols-2 gap-6">
                      <div>
                        <label className="block text-sm font-medium text-primary-700 mb-2">
                          Case Name
                        </label>
                        <input
                          type="text"
                          name="case_name"
                          value={formData.case_name}
                          onChange={handleInputChange}
                          className="input-field"
                          placeholder="e.g., Smith vs. Johnson"
                        />
                      </div>
                      <div>
                        <label className="block text-sm font-medium text-primary-700 mb-2">
                          Case Number
                        </label>
                        <input
                          type="text"
                          name="case_number"
                          value={formData.case_number}
                          onChange={handleInputChange}
                          className="input-field"
                          placeholder="e.g., CV-2023-001234"
                        />
                      </div>
                      <div className="md:col-span-2">
                        <label className="block text-sm font-medium text-primary-700 mb-2">
                          Firm/Organization Name
                        </label>
                        <input
                          type="text"
                          name="firm_name"
                          value={formData.firm_name}
                          onChange={handleInputChange}
                          className="input-field"
                          placeholder="e.g., Legal Associates LLC"
                        />
                      </div>
                      <div>
                        <label className="block text-sm font-medium text-primary-700 mb-2">Date</label>
                        <input
                          type="date"
                          name="input_date"
                          value={formData.input_date}
                          onChange={handleInputChange}
                          className="input-field"
                        />
                      </div>
                      <div>
                        <label className="block text-sm font-medium text-primary-700 mb-2">Time</label>
                        <input
                          type="time"
                          name="input_time"
                          value={formData.input_time}
                          onChange={handleInputChange}
                          className="input-field"
                        />
                      </div>
                      <div className="md:col-span-2">
                        <label className="block text-sm font-medium text-primary-700 mb-2">Location</label>
                        <input
                          type="text"
                          name="location"
                          value={formData.location}
                          onChange={handleInputChange}
                          className="input-field"
                          placeholder="e.g., Conference Room A, 123 Main St, City, State"
                        />
                      </div>
                    </div>
                  </div>
                </div>

                <div className="card">
                  <div className="card-header">
                    <h2 className="text-xl font-medium">Transcription Settings</h2>
                  </div>
                  <div className="card-body space-y-6">
                    <div>
                      <label className="block text-sm font-medium text-primary-700 mb-2">
                        Transcription Model
                      </label>
                      <select
                        name="transcription_model"
                        value={formData.transcription_model}
                        onChange={handleInputChange}
                        className="input-field"
                      >
                        <option value="assemblyai">AssemblyAI</option>
                        <option value="gemini">Gemini 3.0 Pro</option>
                      </select>
                    </div>
                    <div>
                      <label className="block text-sm font-medium text-primary-700 mb-2">
                        Speaker Names (optional)
                      </label>
                      <input
                        type="text"
                        name="speaker_names"
                        value={formData.speaker_names}
                        onChange={handleInputChange}
                        className="input-field"
                        placeholder="e.g., John Smith, Jane Doe, Attorney Williams"
                      />
                      <p className="text-xs text-primary-600 mt-1">
                        Separate multiple speakers with commas. Leave blank for automatic detection.
                      </p>
                    </div>
                  </div>
                </div>

                {error && (
                  <div className="bg-red-50 border border-red-300 rounded-lg p-4 shadow-sm text-red-800 font-medium">
                    {error}
                  </div>
                )}

                <div className="flex justify-center">
                  <button
                    type="submit"
                    disabled={!selectedFile || isLoading}
                    className="btn-primary text-lg px-12 py-4"
                  >
                    {isLoading ? 'Processing...' : 'Generate Transcript'}
                  </button>
                </div>

                {isLoading && (
                  <div className="flex items-center justify-center gap-3 rounded-lg border border-primary-200 bg-white px-4 py-3 text-sm text-primary-700 shadow-sm">
                    <svg
                      className="h-5 w-5 animate-spin text-primary-600"
                      xmlns="http://www.w3.org/2000/svg"
                      fill="none"
                      viewBox="0 0 24 24"
                    >
                      <circle className="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" strokeWidth="4"></circle>
                      <path
                        className="opacity-75"
                        fill="currentColor"
                        d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"
                      ></path>
                    </svg>
                    <span className="font-medium">{loadingStage || 'Processing transcript...'}</span>
                  </div>
                )}
              </form>

              {transcriptData && (
                <div className="space-y-6">
                  {mediaPreviewUrl && (
                    <div className="card">
                      <div className="card-header">
                        <h2 className="text-xl font-medium">Media Preview</h2>
                      </div>
                      <div className="card-body">
                        <div className="bg-primary-900 rounded-lg p-4">
                          {isVideoPreview ? (
                            <video src={mediaPreviewUrl} controls className="w-full max-w-2xl mx-auto rounded">
                              Your browser does not support video playback.
                            </video>
                          ) : (
                            <audio src={mediaPreviewUrl} controls className="w-full max-w-2xl mx-auto">
                              Your browser does not support audio playback.
                            </audio>
                          )}
                        </div>
                        <div className="mt-4 text-center text-sm text-primary-600">
                          {selectedFile ? (
                            <>
                              <span className="font-medium">{selectedFile.name}</span> â€¢{' '}
                              {(selectedFile.size / (1024 * 1024)).toFixed(1)} MB
                            </>
                          ) : (
                            <>
                              <span className="font-medium">Session media</span>{' '}
                              {previewContentType && <>â€¢ {previewContentType}</>}
                            </>
                          )}
                        </div>
                      </div>
                    </div>
                  )}

                  <div className="card">
                    <div className="card-header">
                      <h2 className="text-xl font-medium">Generated Files</h2>
                    </div>
                    <div className="card-body space-y-4">
                      <div className="bg-green-50 border border-green-200 rounded-lg p-4">
                        <div className="text-green-800 font-medium mb-2">âœ… Transcription Complete!</div>
                        <div className="text-sm text-green-700">Generated {transcriptSegments} transcript segments</div>
                      </div>
                      <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
                        <button
                          onClick={() => {
                            if (transcriptData.docx_base64) {
                              downloadFile(
                                transcriptData.docx_base64,
                                generateFilename('transcript', '.docx'),
                                'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
                              )
                            }
                          }}
                          className="btn-primary text-center py-3"
                          disabled={!transcriptData.docx_base64}
                        >
                          ðŸ“„ Download DOCX
                        </button>
                        <button
                          onClick={() => {
                            if (transcriptData.oncue_xml_base64) {
                              downloadFile(transcriptData.oncue_xml_base64, generateFilename('transcript', '.xml'), 'application/xml')
                            }
                          }}
                          className="btn-primary text-center py-3"
                          disabled={!transcriptData.oncue_xml_base64}
                        >
                          ðŸ“‹ Download OnCue XML
                        </button>
                      </div>
                      <div className="flex justify-between items-center">
                        <p className="text-sm text-primary-600">
                          Want to tweak speaker timing or wording? Open the editor to re-sync manually.
                        </p>
                        <button
                          type="button"
                          className="btn-outline"
                          onClick={() => mediaKey && setActiveTab('editor')}
                          disabled={!mediaKey}
                        >
                          Open Editor
                        </button>
                      </div>
                      <div>
                        <h3 className="font-medium text-primary-900 mb-3">Transcript Preview:</h3>
                        <div className="bg-primary-50 rounded-lg p-4 max-h-64 overflow-y-auto">
                          <pre className="whitespace-pre-wrap text-sm text-primary-800 font-mono">
                            {resolvedTranscriptText.substring(0, 1000)}
                            {resolvedTranscriptText.length > 1000 && '...'}
                          </pre>
                        </div>
                      </div>
                    </div>
                  </div>
                </div>
              )}
            </div>
          )}

          {activeTab === 'editor' && (
            <TranscriptEditor
              mediaKey={mediaKey}
              initialData={transcriptData}
              mediaUrl={mediaPreviewUrl || undefined}
              mediaType={mediaContentType ?? selectedFile?.type}
              docxBase64={transcriptData?.docx_base64 ?? undefined}
              xmlBase64={transcriptData?.oncue_xml_base64 ?? undefined}
              onDownload={downloadFile}
              buildFilename={generateFilename}
              onSessionChange={handleSessionChange}
              onSaveComplete={handleEditorSave}
              onOpenHistory={loadHistoryModal}
              onGeminiRefine={handleGeminiRefine}
              isGeminiBusy={geminiBusy}
              geminiError={geminiError}
            />
          )}

          {activeTab === 'clip' && (
            <ClipCreator
              session={transcriptData}
              mediaKey={mediaKey}
              mediaUrl={clipMediaUrl}
              mediaType={clipMediaType}
              onSessionRefresh={handleSessionChange}
              onDownload={downloadFile}
              buildFilename={generateFilename}
              onOpenHistory={loadHistoryModal}
            />
          )}
        </div>
      </div>
      {showHistoryModal && (
        <div className="fixed inset-0 z-50 flex items-center justify-center bg-black/60 p-4">
          <div className="w-full max-w-6xl rounded-lg bg-white p-6 shadow-2xl">
            <div className="flex items-center justify-between gap-3">
              <div>
                <h3 className="text-xl font-semibold text-primary-900">Transcript History</h3>
                <p className="text-sm text-primary-600">
                  Snapshots grouped by media ID. Autosave runs every minute and keeps the latest ten per transcript.
                </p>
              </div>
              <button
                className="rounded border border-primary-300 px-3 py-1 text-sm text-primary-700 hover:bg-primary-100"
                onClick={() => setShowHistoryModal(false)}
              >
                Close
              </button>
            </div>

            {historyModalError && (
              <div className="mt-3 rounded border border-red-200 bg-red-50 px-3 py-2 text-sm text-red-700">
                {historyModalError}
              </div>
            )}

            <div className="mt-4 grid grid-cols-[260px_1fr] gap-4 max-h-[70vh]">
              <div className="rounded border border-primary-100 overflow-y-auto">
                {historyModalLoading ? (
                  <div className="p-4 text-sm text-primary-600">Loading transcripts...</div>
                ) : historyGroups.length === 0 ? (
                  <div className="p-4 text-sm text-primary-700">No saved transcripts yet.</div>
                ) : (
                  <ul>
                    {historyGroups.map((group) => (
                      <li key={group.media_key}>
                        <button
                          className={`w-full px-4 py-3 text-left transition ${selectedHistoryKey === group.media_key
                            ? 'bg-primary-100 font-semibold text-primary-900'
                            : 'hover:bg-primary-50 text-primary-800'
                            }`}
                          onClick={() => setSelectedHistoryKey(group.media_key)}
                        >
                          <div className="flex items-center justify-between gap-2">
                            <div className="text-primary-900">{group.title_label || 'Untitled transcript'}</div>
                            <div className="text-[11px] text-primary-500">
                              {group.updated_at ? new Date(group.updated_at).toLocaleString() : 'â€”'}
                            </div>
                          </div>
                          <div className="text-[11px] text-primary-500 mt-1">Key: {group.media_key}</div>
                        </button>
                      </li>
                    ))}
                  </ul>
                )}
              </div>

              <div className="rounded border border-primary-100 overflow-y-auto">
                {historyModalLoading ? (
                  <div className="p-4 text-sm text-primary-600">Loading snapshots...</div>
                ) : !selectedHistoryGroup ? (
                  <div className="p-4 text-sm text-primary-700">Select a transcript to view its snapshots.</div>
                ) : selectedHistoryGroup.snapshots.length === 0 ? (
                  <div className="p-4 text-sm text-primary-700">
                    No autosaves or manual saves yet for this media ID. Make an edit to start autosaving.
                  </div>
                ) : (
                  <ul>
                    {selectedHistoryGroup.snapshots.map((snap) => {
                      const restoreKey = `${selectedHistoryGroup.media_key}:${snap.snapshot_id}`
                      const restoring = restoringSnapshotId === restoreKey
                      return (
                        <li
                          key={`${selectedHistoryGroup.media_key}-${snap.snapshot_id}`}
                          className="flex items-center justify-between border-b border-primary-100 px-4 py-3 text-sm"
                        >
                          <div>
                            <div className="font-semibold text-primary-900">
                              {snap.title_label || selectedHistoryGroup.title_label || selectedHistoryGroup.media_key}
                            </div>
                            <div className="text-xs text-primary-600">
                              {snap.created_at ? new Date(snap.created_at).toLocaleString() : 'Unknown time'}
                            </div>
                            <div className="text-xs text-primary-500">
                              {snap.is_manual_save ? 'Manual save' : 'Autosave'} - {snap.line_count ?? 0} lines
                            </div>
                          </div>
                          <button
                            className="rounded border border-primary-300 px-3 py-1 text-xs font-semibold text-primary-800 hover:bg-primary-100 disabled:opacity-60"
                            onClick={() => handleRestoreSnapshot(selectedHistoryGroup.media_key, snap.snapshot_id)}
                            disabled={restoring}
                          >
                            {restoring ? 'Restoring...' : 'Restore'}
                          </button>
                        </li>
                      )
                    })}
                  </ul>
                )}
              </div>
            </div>
          </div>
        </div>
      )}
    </>
  )
}
===== END FILE =====

===== FILE: frontend-next/src/components/TranscriptEditor.tsx =====
'use client'

import { useCallback, useEffect, useMemo, useRef, useState } from 'react'
import { appendAccessTokenToMediaUrl, authenticatedFetch } from '@/utils/auth'

interface EditorLine {
  id: string
  speaker: string
  text: string
  start: number
  end: number
  page?: number | null
  line?: number | null
  pgln?: number | null
  is_continuation?: boolean
  timestamp_error?: boolean
}

export interface ClipSummary {
  clip_id: string
  name: string
  created_at: string
  duration: number
  start_time: number
  end_time: number
  start_pgln?: number | null
  end_pgln?: number | null
  start_page?: number | null
  start_line?: number | null
  end_page?: number | null
  end_line?: number | null
  media_blob_name?: string | null
  media_content_type?: string | null
  file_name?: string | null
}

export interface EditorSessionResponse {
  session_id?: string | null
  media_key?: string | null
  media_blob_name?: string | null
  media_content_type?: string | null
  title_data: Record<string, string>
  audio_duration: number
  lines_per_page: number
  lines: EditorLine[]
  created_at?: string
  updated_at?: string
  expires_at?: string
  docx_base64?: string | null
  oncue_xml_base64?: string | null
  transcript?: string | null
  transcript_text?: string | null
  clips?: ClipSummary[]
}

export type EditorSaveResponse = EditorSessionResponse

interface TranscriptEditorProps {
  mediaKey?: string | null
  initialData?: EditorSessionResponse | null
  mediaUrl?: string
  mediaType?: string
  docxBase64?: string | null
  xmlBase64?: string | null
  onDownload: (base64Data: string, filename: string, mimeType: string) => void
  buildFilename: (baseName: string, extension: string) => string
  onSessionChange: (session: EditorSessionResponse) => void
  onSaveComplete: (result: EditorSaveResponse) => void
  onOpenHistory?: () => void
  onGeminiRefine?: () => void
  isGeminiBusy?: boolean
  geminiError?: string | null
}

const secondsToLabel = (seconds: number) => {
  if (!Number.isFinite(seconds) || seconds < 0) {
    return '0:00.000'
  }
  const wholeSeconds = Math.floor(seconds)
  const minutes = Math.floor(wholeSeconds / 60)
  const remainingSeconds = wholeSeconds % 60
  const millis = Math.floor((seconds - wholeSeconds) * 1000)
  return `${minutes}:${remainingSeconds.toString().padStart(2, '0')}.${millis
    .toString()
    .padStart(3, '0')}`
}

// localStorage helpers for cross-page state persistence
interface LocalStorageTranscriptState {
  mediaKey: string
  lines: EditorLine[]
  titleData: Record<string, string>
  mediaBlobName?: string | null
  mediaContentType?: string | null
  audioDuration: number
  linesPerPage: number
  lastSaved: string
}

const STORAGE_KEY_PREFIX = 'transcript_state_'
const AUTO_SHIFT_STORAGE_KEY = 'editor_auto_shift_next'
const AUTO_SHIFT_PADDING_SECONDS = 0.01

function saveToLocalStorage(mediaKey: string, state: LocalStorageTranscriptState) {
  try {
    localStorage.setItem(
      `${STORAGE_KEY_PREFIX}${mediaKey}`,
      JSON.stringify(state)
    )
  } catch (err) {
    console.error('Failed to save to localStorage:', err)
  }
}

function loadFromLocalStorage(mediaKey: string): LocalStorageTranscriptState | null {
  try {
    const data = localStorage.getItem(`${STORAGE_KEY_PREFIX}${mediaKey}`)
    if (!data) return null
    return JSON.parse(data)
  } catch (err) {
    console.error('Failed to load from localStorage:', err)
    return null
  }
}

function clearLocalStorage(mediaKey: string) {
  try {
    localStorage.removeItem(`${STORAGE_KEY_PREFIX}${mediaKey}`)
  } catch (err) {
    console.error('Failed to clear localStorage:', err)
  }
}

export default function TranscriptEditor({
  mediaKey: initialMediaKey,
  initialData,
  mediaUrl,
  mediaType,
  docxBase64,
  xmlBase64,
  onDownload,
  buildFilename,
  onSessionChange,
  onSaveComplete,
  onOpenHistory,
  onGeminiRefine,
  isGeminiBusy,
  geminiError,
}: TranscriptEditorProps) {
  const [lines, setLines] = useState<EditorLine[]>(initialData?.lines ?? [])
  const [sessionMeta, setSessionMeta] = useState<EditorSessionResponse | null>(initialData ?? null)
  const [loading, setLoading] = useState(false)
  const [error, setError] = useState<string | null>(null)
  const [saving, setSaving] = useState(false)
  const [isDirty, setIsDirty] = useState(false)
  const [activeMediaKey, setActiveMediaKey] = useState<string | null>(initialData?.media_key ?? initialMediaKey ?? null)
  const [activeLineId, setActiveLineId] = useState<string | null>(null)
  const [selectedLineId, setSelectedLineId] = useState<string | null>(null)
  const [autoScroll, setAutoScroll] = useState(true)
  const [editingField, setEditingField] = useState<{ lineId: string; field: 'speaker' | 'text'; value: string } | null>(null)
  const [autoShiftNextLine, setAutoShiftNextLine] = useState(true)

  const videoRef = useRef<HTMLVideoElement>(null)
  const audioRef = useRef<HTMLAudioElement>(null)
  const editInputRef = useRef<HTMLInputElement | HTMLTextAreaElement | null>(null)
  const lineRefs = useRef<Record<string, HTMLDivElement | null>>({})
  const activeLineMarker = useRef<string | null>(null)
  // Skip resetting isDirty/history in SYNC EFFECT when we've just done a local update (e.g., resync)
  const skipSyncEffectReset = useRef(false)

  const [importTranscriptFile, setImportTranscriptFile] = useState<File | null>(null)
  const [importMediaFile, setImportMediaFile] = useState<File | null>(null)
  const [importing, setImporting] = useState(false)
  const [importError, setImportError] = useState<string | null>(null)
  const [isDraggingOver, setIsDraggingOver] = useState(false)
  const [localMediaPreviewUrl, setLocalMediaPreviewUrl] = useState<string | null>(null)
  const [localMediaType, setLocalMediaType] = useState<string | undefined>(undefined)
  const [renameFrom, setRenameFrom] = useState('')
  const [renameTo, setRenameTo] = useState('')
  const [renameFeedback, setRenameFeedback] = useState<string | null>(null)
  const [addError, setAddError] = useState<string | null>(null)
  const [deleteError, setDeleteError] = useState<string | null>(null)
  const [history, setHistory] = useState<EditorLine[][]>([])
  const [future, setFuture] = useState<EditorLine[][]>([])
  const [snapshotError, setSnapshotError] = useState<string | null>(null)
  const lastSnapshotRef = useRef<number>(0)

  // Refs for auto-save to avoid resetting timer on every edit
  const linesRef = useRef<EditorLine[]>(initialData?.lines ?? [])
  const isDirtyRef = useRef(false)
  const sessionMetaRef = useRef<EditorSessionResponse | null>(initialData ?? null)

  // Rev AI Re-sync State
  const [isResyncing, setIsResyncing] = useState(false)
  const [resyncError, setResyncError] = useState<string | null>(null)

  const effectiveMediaUrl = useMemo(() => {
    if (localMediaPreviewUrl) return localMediaPreviewUrl
    if (mediaUrl) return appendAccessTokenToMediaUrl(mediaUrl)
    if (sessionMeta?.media_blob_name) {
      return appendAccessTokenToMediaUrl(`/api/media/${sessionMeta.media_blob_name}`)
    }
    return undefined
  }, [localMediaPreviewUrl, mediaUrl, sessionMeta])

  const effectiveMediaType = useMemo(
    () => localMediaType ?? mediaType ?? sessionMeta?.media_content_type ?? undefined,
    [localMediaType, mediaType, sessionMeta],
  )

  const isVideo = useMemo(
    () => (effectiveMediaType ?? '').startsWith('video/'),
    [effectiveMediaType],
  )

  // Keep refs in sync with state for auto-save interval
  useEffect(() => { linesRef.current = lines }, [lines])
  useEffect(() => { isDirtyRef.current = isDirty }, [isDirty])
  useEffect(() => { sessionMetaRef.current = sessionMeta }, [sessionMeta])

  const lineBoundaries = useMemo(
    () =>
      lines.map((line) => {
        const start = Number.isFinite(line.start) ? line.start : 0
        const end = Number.isFinite(line.end) ? line.end : start
        return {
          id: line.id,
          start,
          end: end > start ? end : start + 0.05,
        }
      }),
    [lines],
  )

  const fetchTranscript = useCallback(
    async (key?: string | null) => {
      const targetKey = key || activeMediaKey || initialMediaKey
      if (!targetKey) {
        setError('No media key provided')
        return
      }

      setLoading(true)
      setError(null)

      try {
        // Try loading from server first
        const response = await authenticatedFetch(`/api/transcripts/by-key/${encodeURIComponent(targetKey)}`)

        if (!response.ok) {
          if (response.status === 404) {
            // Try localStorage fallback
            const cached = loadFromLocalStorage(targetKey)
            if (cached) {
              setLines(cached.lines)
              setSessionMeta({
                title_data: cached.titleData,
                audio_duration: cached.audioDuration,
                lines_per_page: cached.linesPerPage,
                lines: cached.lines,
                media_blob_name: cached.mediaBlobName,
                media_content_type: cached.mediaContentType,
              } as EditorSessionResponse)
              setActiveMediaKey(targetKey)
              setError('Loaded from local cache. Save to sync with server.')
              setLoading(false)
              return
            }
          }

          const detail = await response.json().catch(() => ({}))
          throw new Error(detail?.detail || 'Failed to load transcript')
        }

        const data: EditorSessionResponse = await response.json()
        setSessionMeta(data)
        setLines(data.lines || [])
        setActiveMediaKey(targetKey)
        setHistory([])
        setFuture([])
        setIsDirty(false)
        setActiveLineId(null)
        setSelectedLineId(null)
        setEditingField(null)
        activeLineMarker.current = null
        onSessionChange(data)

        // Save to localStorage for offline access
        saveToLocalStorage(targetKey, {
          mediaKey: targetKey,
          lines: data.lines || [],
          titleData: data.title_data ?? {},
          mediaBlobName: data.media_blob_name,
          mediaContentType: data.media_content_type,
          audioDuration: data.audio_duration,
          linesPerPage: data.lines_per_page,
          lastSaved: new Date().toISOString(),
        })

      } catch (err: any) {
        setError(err.message || 'Failed to load transcript')
      } finally {
        setLoading(false)
      }
    },
    [activeMediaKey, initialMediaKey, onSessionChange],
  )

  useEffect(() => {
    if (!initialData) return
    setSessionMeta(initialData)
    setLines(initialData.lines ?? [])
    // Only update activeMediaKey from props, not from internal state (to avoid circular updates)
    const resolvedKey = initialData.media_key ?? initialMediaKey ?? null
    if (resolvedKey) {
      setActiveMediaKey(resolvedKey)
    }

    // Skip resetting edit state if we just did a local update (e.g., resync)
    if (skipSyncEffectReset.current) {
      skipSyncEffectReset.current = false
    } else {
      setHistory([])
      setFuture([])
      setIsDirty(false)
    }

    setActiveLineId(null)
    setSelectedLineId(null)
    setEditingField(null)
    setSnapshotError(null)
    activeLineMarker.current = null
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [initialData, initialMediaKey])

  useEffect(() => {
    if (initialData || sessionMeta) return
    if (initialMediaKey || activeMediaKey) {
      fetchTranscript(initialMediaKey || activeMediaKey)
    }
  }, [initialData, sessionMeta, initialMediaKey, activeMediaKey, fetchTranscript])

  // Track the current editing session to avoid re-selecting text on every keystroke
  const editingLineId = editingField?.lineId
  const editingFieldName = editingField?.field

  useEffect(() => {
    if (!editingLineId || !editingFieldName) return
    if (editInputRef.current) {
      editInputRef.current.focus()
      if (editingFieldName === 'speaker' && 'select' in editInputRef.current) {
        ;(editInputRef.current as HTMLInputElement).select()
      }
    }
  }, [editingLineId, editingFieldName]) // Only run when lineId or field changes, not when value changes

  useEffect(() => {
    const player = effectiveMediaUrl ? (isVideo ? videoRef.current : audioRef.current) : null
    if (!player) return

    const handleTimeUpdate = () => {
      const currentTime = player.currentTime
      let currentLineId: string | null = null
      for (let i = 0; i < lineBoundaries.length; i += 1) {
        const boundary = lineBoundaries[i]
        if (currentTime >= boundary.start && currentTime < boundary.end + 0.01) {
          currentLineId = boundary.id
          break
        }
      }
      if (!currentLineId && lineBoundaries.length) {
        const lastBoundary = lineBoundaries[lineBoundaries.length - 1]
        if (currentTime >= lastBoundary.end) {
          currentLineId = lastBoundary.id
        }
      }
      if (currentLineId && currentLineId !== activeLineMarker.current) {
        activeLineMarker.current = currentLineId
        setActiveLineId(currentLineId)
        if (autoScroll) {
          const target = lineRefs.current[currentLineId]
          if (target) {
            target.scrollIntoView({ block: 'center', behavior: 'smooth' })
          }
        }
      }
    }

    player.addEventListener('timeupdate', handleTimeUpdate)
    return () => {
      player.removeEventListener('timeupdate', handleTimeUpdate)
    }
  }, [effectiveMediaUrl, isVideo, lineBoundaries, autoScroll])

  const handleLineFieldChange = useCallback(
    (lineId: string, field: keyof EditorLine, value: string | number) => {
      setLines((prev) => {
        const normalizedValue =
          field === 'speaker' || field === 'text'
            ? typeof value === 'string'
              ? value
              : value.toString()
            : typeof value === 'number'
              ? value
              : parseFloat(value as string) || 0

        const nextLines = prev.map((line) =>
          line.id === lineId
            ? {
              ...line,
              [field]: normalizedValue,
              ...(field === 'start' || field === 'end' ? { timestamp_error: false } : null),
            }
            : line,
        )

        if (field === 'end' && autoShiftNextLine) {
          const targetIndex = nextLines.findIndex((line) => line.id === lineId)
          if (targetIndex >= 0 && nextLines[targetIndex + 1]) {
            const targetLine = nextLines[targetIndex]
            const followingLine = nextLines[targetIndex + 1]
            const numericEnd =
              typeof normalizedValue === 'number'
                ? normalizedValue
                : parseFloat(normalizedValue as string) || targetLine.end
            const adjustedStart = Math.max(0, parseFloat((numericEnd + AUTO_SHIFT_PADDING_SECONDS).toFixed(3)))
            nextLines[targetIndex + 1] = { ...followingLine, start: adjustedStart }
          }
        }

        return nextLines
      })
      setIsDirty(true)
    },
    [autoShiftNextLine],
  )

  const playLine = useCallback(
    (line: EditorLine) => {
      if (!effectiveMediaUrl) return
      setSelectedLineId(line.id)
      const player = isVideo ? videoRef.current : audioRef.current
      if (!player) return

      const seekAndPlay = () => {
        player.currentTime = line.start
        player.play().catch(() => {})
      }

      // Check if media metadata is loaded (readyState >= 1 means HAVE_METADATA)
      if (player.readyState >= 1) {
        seekAndPlay()
      } else {
        // Wait for metadata to load before seeking
        const handleLoadedMetadata = () => {
          player.removeEventListener('loadedmetadata', handleLoadedMetadata)
          seekAndPlay()
        }
        player.addEventListener('loadedmetadata', handleLoadedMetadata)
        // Also trigger a load if the player hasn't started loading
        if (player.readyState === 0) {
          player.load()
        }
      }
    },
    [effectiveMediaUrl, isVideo],
  )

  useEffect(() => {
    return () => {
      if (localMediaPreviewUrl) {
        URL.revokeObjectURL(localMediaPreviewUrl)
      }
    }
  }, [localMediaPreviewUrl])

  // beforeunload handler for cross-page persistence
  useEffect(() => {
    const handleBeforeUnload = () => {
      if (activeMediaKey && sessionMeta) {
        saveToLocalStorage(activeMediaKey, {
          mediaKey: activeMediaKey,
          lines,
          titleData: sessionMeta.title_data ?? {},
          mediaBlobName: sessionMeta.media_blob_name,
          mediaContentType: sessionMeta.media_content_type,
          audioDuration: sessionMeta.audio_duration,
          linesPerPage: sessionMeta.lines_per_page,
          lastSaved: new Date().toISOString(),
        })
      }
    }

    window.addEventListener('beforeunload', handleBeforeUnload)
    return () => window.removeEventListener('beforeunload', handleBeforeUnload)
  }, [activeMediaKey, lines, sessionMeta])

  useEffect(() => {
    if (!activeMediaKey) return

    const interval = setInterval(async () => {
      // Read from refs to get latest values without resetting the timer
      if (!isDirtyRef.current) return
      const currentSessionMeta = sessionMetaRef.current
      if (!currentSessionMeta) return

      try {
        const now = Date.now()
        if (now - lastSnapshotRef.current < 5000) return  // Debounce

        // Auto-save creates both current state AND snapshot
        await authenticatedFetch(`/api/transcripts/by-key/${encodeURIComponent(activeMediaKey)}`, {
          method: 'PUT',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            lines: linesRef.current,
            title_data: currentSessionMeta.title_data ?? {},
            is_manual_save: false,  // Auto-save flag
            audio_duration: currentSessionMeta.audio_duration,
            lines_per_page: currentSessionMeta.lines_per_page,
            media_blob_name: currentSessionMeta.media_blob_name,
            media_content_type: currentSessionMeta.media_content_type,
          }),
        })

        lastSnapshotRef.current = now
        setSnapshotError(null)

        // Also save to localStorage
        saveToLocalStorage(activeMediaKey, {
          mediaKey: activeMediaKey,
          lines: linesRef.current,
          titleData: currentSessionMeta.title_data ?? {},
          mediaBlobName: currentSessionMeta.media_blob_name,
          mediaContentType: currentSessionMeta.media_content_type,
          audioDuration: currentSessionMeta.audio_duration,
          linesPerPage: currentSessionMeta.lines_per_page,
          lastSaved: new Date().toISOString(),
        })

      } catch (err: any) {
        setSnapshotError(err.message || 'Auto-save failed')
      }
    }, 60000)  // 60 seconds

    return () => clearInterval(interval)
  }, [activeMediaKey])  // Only reset interval when media key changes

  const cloneLines = useCallback((source: EditorLine[]) => source.map((line) => ({ ...line })), [])

  const pushHistory = useCallback(
    (snapshot: EditorLine[]) => {
      setHistory((prev) => [...prev.slice(-49), cloneLines(snapshot)])
      setFuture([])
    },
    [cloneLines],
  )

  const beginEdit = useCallback((line: EditorLine, field: 'speaker' | 'text') => {
    setEditingField({
      lineId: line.id,
      field,
      value: field === 'speaker' ? line.speaker : line.text,
    })
  }, [])

  const commitEdit = useCallback(() => {
    if (!editingField) return
    pushHistory(lines)
    handleLineFieldChange(editingField.lineId, editingField.field, editingField.value)
    setEditingField(null)
  }, [editingField, handleLineFieldChange, lines, pushHistory])

  const cancelEdit = useCallback(() => {
    setEditingField(null)
  }, [])

  useEffect(() => {
    try {
      const stored = localStorage.getItem(AUTO_SHIFT_STORAGE_KEY)
      if (stored === 'true') {
        setAutoShiftNextLine(true)
      } else if (stored === 'false') {
        setAutoShiftNextLine(false)
      }
    } catch (err) {
      console.error('Failed to load auto-shift preference:', err)
    }
  }, [])

  useEffect(() => {
    try {
      localStorage.setItem(AUTO_SHIFT_STORAGE_KEY, autoShiftNextLine ? 'true' : 'false')
    } catch (err) {
      console.error('Failed to save auto-shift preference:', err)
    }
  }, [autoShiftNextLine])

  const handleAddUtterance = useCallback(() => {
    setAddError(null)
    setDeleteError(null)
    if (!lines.length) {
      setAddError('No lines available to insert after.')
      return
    }

    pushHistory(lines)

    const minDuration = 0.2
    const targetId = selectedLineId ?? activeLineId ?? lines[lines.length - 1]?.id
    const targetIndex = lines.findIndex((line) => line.id === targetId)
    if (targetIndex < 0) {
      setAddError('Select a line to insert after.')
      return
    }

    const currentLine = lines[targetIndex]
    const nextLine = lines[targetIndex + 1]
    const nextStart = nextLine ? Number(nextLine.start) : null
    const currentStart = Number(currentLine.start) || 0
    const currentEnd = Number(currentLine.end) || currentStart

    let newStart = currentEnd
    let newEnd: number
    let updatedCurrentEnd = currentEnd

    if (nextLine && nextStart !== null && !Number.isNaN(nextStart)) {
      const gap = nextStart - currentEnd
      if (gap >= 2) {
        newStart = currentEnd
        newEnd = nextStart
        if (newEnd - newStart < minDuration) {
          newEnd = newStart + minDuration
        }
      } else {
        const duration = Math.max(currentEnd - currentStart, minDuration * 2)
        updatedCurrentEnd = currentStart + duration / 2
        newStart = updatedCurrentEnd
        newEnd = Math.min(currentStart + duration, nextStart)
        if (newEnd - newStart < minDuration) {
          newEnd = newStart + minDuration
        }
      }
    } else {
      const fallbackDuration = Math.max((sessionMeta?.audio_duration ?? 0) - currentEnd, minDuration)
      newStart = currentEnd
      newEnd = newStart + fallbackDuration
    }

    const newLineId = `new-${Date.now()}`
    const updatedLines = [...lines]
    updatedLines[targetIndex] = {
      ...currentLine,
      end: updatedCurrentEnd,
    }
    updatedLines.splice(targetIndex + 1, 0, {
      id: newLineId,
      speaker: currentLine.speaker,
      text: '',
      start: newStart,
      end: newEnd,
      is_continuation: false,
    })

    setLines(updatedLines)
    setSelectedLineId(newLineId)
    setEditingField({ lineId: newLineId, field: 'text', value: '' })
    setIsDirty(true)
  }, [lines, selectedLineId, activeLineId, sessionMeta, pushHistory])

  const handleDeleteUtterance = useCallback(() => {
    setDeleteError(null)
    setAddError(null)
    if (!lines.length) {
      setDeleteError('No lines to delete.')
      return
    }
    const targetId = selectedLineId ?? activeLineId
    if (!targetId) {
      setDeleteError('Select a line to delete.')
      return
    }
    const targetIndex = lines.findIndex((line) => line.id === targetId)
    if (targetIndex < 0) {
      setDeleteError('Select a line to delete.')
      return
    }
    if (lines.length === 1) {
      setDeleteError('At least one utterance must remain.')
      return
    }

    pushHistory(lines)

    const nextSelection = lines[targetIndex + 1]?.id || lines[targetIndex - 1]?.id || null
    const updated = lines.filter((line) => line.id !== targetId)
    setLines(updated)
    setSelectedLineId(nextSelection)
    setIsDirty(true)
  }, [lines, selectedLineId, activeLineId, pushHistory])

  const handleRenameSpeaker = useCallback(
    (event?: React.FormEvent) => {
      if (event) {
        event.preventDefault()
      }
      const source = renameFrom.trim()
      const target = renameTo.trim()
      if (!source || !target) {
        setRenameFeedback('Enter both the current and new speaker names.')
        return
      }
      pushHistory(lines)
      const normalizedSource = source.toUpperCase()
      const normalizedTarget = target.toUpperCase()
      let changes = 0
      setLines((prev) =>
        prev.map((line) => {
          if (line.speaker.trim().toUpperCase() === normalizedSource) {
            changes += 1
            return { ...line, speaker: normalizedTarget }
          }
          return line
        }),
      )
      if (changes === 0) {
        setRenameFeedback('No matching speaker labels were found.')
        return
      }
      setIsDirty(true)
      setRenameFeedback(`Renamed ${changes} line${changes === 1 ? '' : 's'}. Save to update exports.`)
    },
    [renameFrom, renameTo, lines, pushHistory],
  )

  const handleUndo = useCallback(() => {
    if (!history.length) return
    const previous = history[history.length - 1]
    setHistory((prev) => prev.slice(0, prev.length - 1))
    setFuture((prev) => [cloneLines(lines), ...prev])
    setLines(previous)
    setSelectedLineId(null)
    setIsDirty(true)
  }, [history, cloneLines, lines])

  const handleRedo = useCallback(() => {
    if (!future.length) return
    const [next, ...rest] = future
    setFuture(rest)
    setHistory((prev) => [...prev.slice(-49), cloneLines(lines)])
    setLines(next)
    setSelectedLineId(null)
    setIsDirty(true)
  }, [future, cloneLines, lines])

  const handleSave = useCallback(async () => {
    if (!activeMediaKey) {
      setError('No media key available to save.')
      return
    }
    if (!sessionMeta) {
      setError('No transcript available to save.')
      return
    }

    setSaving(true)
    setError(null)

    try {
      const response = await authenticatedFetch(`/api/transcripts/by-key/${encodeURIComponent(activeMediaKey)}`, {
        method: 'PUT',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          lines,
          title_data: sessionMeta?.title_data ?? {},
          is_manual_save: true,  // Manual save flag
          audio_duration: sessionMeta?.audio_duration ?? 0,
          lines_per_page: sessionMeta?.lines_per_page ?? 25,
          media_blob_name: sessionMeta?.media_blob_name,
          media_content_type: sessionMeta?.media_content_type,
        }),
      })

      if (!response.ok) {
        const detail = await response.json().catch(() => ({}))
        throw new Error(detail?.detail || 'Failed to save')
      }

      const data: EditorSaveResponse = await response.json()
      setSessionMeta(data)
      setLines(data.lines || [])
      setActiveMediaKey(data.media_key ?? activeMediaKey)
      setIsDirty(false)
      setActiveLineId(null)
      setSelectedLineId(null)
      setEditingField(null)
      activeLineMarker.current = null
      setHistory([])
      setFuture([])

      // Save to localStorage
      saveToLocalStorage(data.media_key ?? activeMediaKey, {
        mediaKey: data.media_key ?? activeMediaKey!,
        lines: data.lines || [],
        titleData: data.title_data ?? {},
        mediaBlobName: data.media_blob_name,
        mediaContentType: data.media_content_type,
        audioDuration: data.audio_duration,
        linesPerPage: data.lines_per_page,
        lastSaved: new Date().toISOString(),
      })

      onSaveComplete(data)
      onSessionChange(data)

    } catch (err: any) {
      setError(err.message || 'Failed to save')
    } finally {
      setSaving(false)
    }
  }, [activeMediaKey, lines, sessionMeta, onSaveComplete, onSessionChange])

  const handleImport = useCallback(
    async (event: React.FormEvent) => {
      event.preventDefault()
      if (!importTranscriptFile) {
        setImportError('Select a transcript file (XML or DOCX) to import.')
        return
      }
      if (!importMediaFile) {
        setImportError('Media file is required for import.')
        return
      }
      setImporting(true)
      setImportError(null)
      try {
        const formData = new FormData()
        formData.append('transcript_file', importTranscriptFile)
        formData.append('media_file', importMediaFile)

        const response = await authenticatedFetch('/api/transcripts/import', {
          method: 'POST',
          body: formData,
        })
        if (!response.ok) {
          const detail = await response.json().catch(() => ({}))
          throw new Error(detail?.detail || 'Failed to import transcript')
        }
        const data: EditorSessionResponse = await response.json()
        setSessionMeta(data)
        setLines(data.lines || [])
        setHistory([])
        setFuture([])
        setIsDirty(false)
        setActiveLineId(null)
        setSelectedLineId(null)
        setEditingField(null)
        activeLineMarker.current = null
        const importedMediaKey = data.media_key ?? data.title_data?.MEDIA_ID ?? data.media_blob_name ?? null
        if (importedMediaKey) {
          setActiveMediaKey(importedMediaKey)
        }
        onSessionChange(data)
        setImportTranscriptFile(null)
        setImportMediaFile(null)
        // Also reset local media preview since we now use the imported session's media
        if (localMediaPreviewUrl) {
          URL.revokeObjectURL(localMediaPreviewUrl)
        }
        setLocalMediaPreviewUrl(null)
        setLocalMediaType(undefined)
      } catch (err: any) {
        setImportError(err.message || 'Failed to import transcript')
      } finally {
        setImporting(false)
      }
    },
    [importTranscriptFile, importMediaFile, localMediaPreviewUrl, onSessionChange],
  )

  const handleResync = useCallback(async () => {
    if (!activeMediaKey) {
      setResyncError('No active transcript to re-sync.')
      return
    }

    if (!confirm('This will update all timestamps based on audio alignment. Text changes will be preserved. Continue?')) {
      return
    }

    setIsResyncing(true)
    setResyncError(null)

    try {
      const response = await authenticatedFetch('/api/resync', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          media_key: activeMediaKey,
        }),
      })

      if (!response.ok) {
        const detail = await response.json().catch(() => ({}))
        throw new Error(detail?.detail || 'Re-sync failed')
      }

      const data = await response.json()

      // Use the response data directly instead of refetching
      // (GCS write propagation can cause fetchTranscript to get stale data)
      if (data.lines) {
        // Save current state to history so user can undo the resync
        pushHistory(lines)
        setLines(data.lines)
        setIsDirty(true)
      }

      // Update session meta with new artifacts
      setSessionMeta((prev) => prev ? {
        ...prev,
        lines: data.lines ?? prev.lines,
        docx_base64: data.docx_base64 ?? prev.docx_base64,
        oncue_xml_base64: data.oncue_xml_base64 ?? prev.oncue_xml_base64,
      } : prev)

      // Notify parent of the update (skip SYNC EFFECT reset since we already set isDirty/history)
      if (sessionMeta) {
        skipSyncEffectReset.current = true
        onSessionChange({
          ...sessionMeta,
          lines: data.lines ?? sessionMeta.lines,
          docx_base64: data.docx_base64 ?? sessionMeta.docx_base64,
          oncue_xml_base64: data.oncue_xml_base64 ?? sessionMeta.oncue_xml_base64,
        })
      }

    } catch (err: any) {
      setResyncError(err.message || 'Re-sync failed')
    } finally {
      setIsResyncing(false)
    }
  }, [activeMediaKey, sessionMeta, onSessionChange, pushHistory, lines])

  const docxData = docxBase64 ?? sessionMeta?.docx_base64 ?? ''
  const xmlData = xmlBase64 ?? sessionMeta?.oncue_xml_base64 ?? ''
  const transcriptText = sessionMeta?.transcript ?? sessionMeta?.transcript_text ?? ''

  const sessionInfo = sessionMeta?.title_data ?? {}
  const expiresLabel = sessionMeta?.expires_at ? new Date(sessionMeta.expires_at).toLocaleString() : 'â€”'
  const updatedLabel = sessionMeta?.updated_at ? new Date(sessionMeta.updated_at).toLocaleString() : 'â€”'

  // Handle page-level drag and drop for transcript/media import
  const handlePageDragOver = useCallback((e: React.DragEvent) => {
    e.preventDefault()
    e.stopPropagation()
    setIsDraggingOver(true)
  }, [])

  const handlePageDragLeave = useCallback((e: React.DragEvent) => {
    e.preventDefault()
    e.stopPropagation()
    // Only set to false if we're leaving the main container
    if (e.currentTarget === e.target) {
      setIsDraggingOver(false)
    }
  }, [])

  const handlePageDrop = useCallback((e: React.DragEvent) => {
    e.preventDefault()
    e.stopPropagation()
    setIsDraggingOver(false)
    const files = Array.from(e.dataTransfer.files)
    for (const file of files) {
      const ext = file.name.toLowerCase().split('.').pop()
      if (ext === 'xml' || ext === 'docx') {
        setImportTranscriptFile(file)
      } else if (file.type.startsWith('audio/') || file.type.startsWith('video/')) {
        setImportMediaFile(file)
        if (localMediaPreviewUrl) {
          URL.revokeObjectURL(localMediaPreviewUrl)
        }
        const url = URL.createObjectURL(file)
        setLocalMediaPreviewUrl(url)
        setLocalMediaType(file.type)
      }
    }
  }, [localMediaPreviewUrl])

  return (
    <div
      className="space-y-6 relative"
      onDragOver={handlePageDragOver}
      onDragLeave={handlePageDragLeave}
      onDrop={handlePageDrop}
    >
      {/* Page-level drop overlay */}
      {isDraggingOver && (
        <div className="fixed inset-0 z-[9998] flex items-center justify-center bg-primary-900/60 backdrop-blur-sm pointer-events-none">
          <div className="rounded-2xl border-4 border-dashed border-white bg-primary-800/80 px-12 py-10 text-center shadow-2xl">
            <p className="text-2xl font-bold text-white">Drop files to import</p>
            <p className="mt-2 text-sm text-primary-200">
              Transcript (XML or DOCX) + Media file
            </p>
          </div>
        </div>
      )}
      <div className="card">
        <div className="card-header flex flex-col gap-3 md:flex-row md:items-center md:justify-between">
          <div>
            <h2 className="text-xl font-medium">Manual Sync Editor</h2>
          </div>
          <div className="flex flex-wrap items-center gap-3">
            <label className="flex items-center gap-2 text-sm text-white">
              <input
                type="checkbox"
                className="h-4 w-4"
                checked={autoScroll}
                onChange={(event) => setAutoScroll(event.target.checked)}
              />
              Auto-scroll
            </label>
            <label
              className="flex items-center gap-2 text-sm text-white"
              title="When enabled, changing a line's end time snaps the next line's start time so it begins immediately after the edit."
            >
              <input
                type="checkbox"
                className="h-4 w-4"
                checked={autoShiftNextLine}
                onChange={(event) => setAutoShiftNextLine(event.target.checked)}
              />
              Auto-Shift Next Line
            </label>
            <div className="flex items-center gap-2">
              <button
                className="rounded-lg border-2 border-primary-200 bg-white px-3 py-2 text-sm font-semibold text-primary-800 shadow-sm hover:border-primary-400 hover:bg-primary-50"
                onClick={onOpenHistory}
                title="View transcript history and snapshots"
              >
                History
              </button>
              <button
                className="rounded-lg border-2 border-primary-200 bg-white px-3 py-2 text-sm font-semibold text-primary-800 shadow-sm hover:border-primary-400 hover:bg-primary-50 disabled:opacity-60"
                onClick={handleUndo}
                disabled={!history.length}
                title="Undo last edit"
              >
                Undo
              </button>
              <button
                className="rounded-lg border-2 border-primary-200 bg-white px-3 py-2 text-sm font-semibold text-primary-800 shadow-sm hover:border-primary-400 hover:bg-primary-50 disabled:opacity-60"
                onClick={handleRedo}
                disabled={!future.length}
                title="Redo"
              >
                Redo
              </button>
              <button
                className="rounded-lg border-2 border-primary-300 bg-primary-50 px-4 py-2 text-sm font-semibold text-primary-900 shadow-sm hover:border-primary-500 hover:bg-primary-100"
                onClick={handleAddUtterance}
                title="Insert a new utterance after the selected line. If there's a 2s gap before the next line, the new entry fills it; otherwise it takes the second half of the selected line's timing."
              >
                Add Utterance
              </button>
              <span
                className="cursor-help rounded-full border border-primary-300 px-2 py-0.5 text-xs font-bold text-primary-800"
                title="Adds a line after the highlighted row. If a 2+ second gap exists before the next line, it fills the gap. Otherwise, it splits the selected line and gives the second half to the new speaker."
              >
                ?
              </span>
              <button
                className="rounded-lg border-2 border-red-200 bg-red-50 px-3 py-2 text-sm font-semibold text-red-700 shadow-sm hover:border-red-300 hover:bg-red-100"
                onClick={handleDeleteUtterance}
                title="Delete the selected utterance. At least one line must remain."
              >
                Delete Utterance
              </button>
            </div>
            {onGeminiRefine && (
              <button
                className="rounded-lg border-2 border-amber-400 bg-amber-100 px-4 py-2 text-sm font-semibold text-amber-900 shadow-sm hover:bg-amber-200 disabled:opacity-60"
                onClick={onGeminiRefine}
                disabled={isGeminiBusy}
                title="Refine the current transcript using Gemini corrections."
              >
                {isGeminiBusy ? 'Running Gemini...' : 'Polish with Gemini 3.0'}
              </button>
            )}
            <button
              className="rounded-lg border-2 border-indigo-400 bg-indigo-100 px-4 py-2 text-sm font-semibold text-indigo-900 shadow-sm hover:bg-indigo-200 disabled:opacity-60"
              onClick={handleResync}
              disabled={isResyncing || !effectiveMediaUrl}
              title="Automatically re-align timestamps to the media file."
            >
              {isResyncing ? 'Re-syncing...' : 'Auto Re-sync'}
            </button>
            <button className="btn-primary px-4 py-2" onClick={handleSave} disabled={saving || !sessionMeta || !isDirty}>
              {saving ? 'Saving...' : 'Save Changes'}
            </button>
          </div>
        </div>
        <div className="card-body space-y-6">
          {error && (
            <div className="rounded-lg border border-red-200 bg-red-50 p-3 text-sm text-red-700">
              {error}
            </div>
          )}
          {geminiError && (
            <div className="rounded-lg border border-red-200 bg-red-50 p-3 text-sm text-red-700">
              Gemini Error: {geminiError}
            </div>
          )}
          {snapshotError && (
            <div className="rounded-lg border border-amber-200 bg-amber-50 p-3 text-sm text-amber-800">
              {snapshotError}
            </div>
          )}
          {(addError || deleteError) && (
            <div className="rounded-lg border border-amber-200 bg-amber-50 p-3 text-sm text-amber-800">
              {addError || deleteError}
            </div>
          )}
          {resyncError && (
            <div className="rounded-lg border border-red-200 bg-red-50 p-3 text-sm text-red-700">
              Re-sync Error: {resyncError}
            </div>
          )}

          <div className="grid grid-cols-1 gap-6 xl:grid-cols-[280px_minmax(0,1fr)]">
            <div className="space-y-4">
              {effectiveMediaUrl ? (
                <div className="rounded-lg border border-primary-200 bg-white p-4 space-y-2">
                  <p className="text-sm font-medium text-primary-900">Media Preview</p>
                  {isVideo ? (
                    <video
                      key={effectiveMediaUrl}
                      ref={videoRef}
                      controls
                      preload="metadata"
                      className="w-full rounded-lg border border-primary-200 shadow"
                      src={effectiveMediaUrl}
                    />
                  ) : (
                    <audio
                      key={effectiveMediaUrl}
                      ref={audioRef}
                      controls
                      preload="metadata"
                      className="w-full"
                      src={effectiveMediaUrl}
                    />
                  )}
                </div>
              ) : (
                <div className="rounded-lg border border-dashed border-primary-300 p-4 text-sm text-primary-500">
                  Upload media to enable playback controls.
                </div>
              )}

              <div className="rounded-lg border border-primary-200 bg-primary-50 p-4 text-sm text-primary-700 space-y-2">
                <div className="flex justify-between">
                  <span className="font-medium text-primary-900">Updated</span>
                  <span>{updatedLabel}</span>
                </div>
                <div className="flex justify-between">
                  <span className="font-medium text-primary-900">Expires</span>
                  <span>{expiresLabel}</span>
                </div>
                <div className="flex justify-between">
                  <span className="font-medium text-primary-900">Lines</span>
                  <span>{lines.length}</span>
                </div>
                <div className="flex justify-between">
                  <span className="font-medium text-primary-900">Duration</span>
                  <span>{secondsToLabel(sessionMeta?.audio_duration ?? 0)}</span>
                </div>
              </div>

              <div className="rounded-lg border border-primary-200 bg-white p-4 space-y-3 text-sm text-primary-700">
                <h3 className="font-medium text-primary-900">Case Details</h3>
                <p>
                  <span className="font-semibold">Case:</span> {sessionInfo.CASE_NAME || 'â€”'}
                </p>
                <p>
                  <span className="font-semibold">Number:</span> {sessionInfo.CASE_NUMBER || 'â€”'}
                </p>
                <p>
                  <span className="font-semibold">Firm:</span> {sessionInfo.FIRM_OR_ORGANIZATION_NAME || 'â€”'}
                </p>
                <p>
                  <span className="font-semibold">Date:</span> {sessionInfo.DATE || 'â€”'}
                </p>
              </div>

              <div className="rounded-lg border border-primary-200 bg-white p-4 space-y-3 text-sm text-primary-700">
                <div className="flex items-center justify-between gap-2">
                  <h3 className="font-medium text-primary-900">Rename Speaker</h3>
                  <span className="text-[10px] uppercase tracking-wide text-primary-400">Find & Replace</span>
                </div>
                <p className="text-xs text-primary-600">Replace every instance of a speaker label across the transcript.</p>
                {renameFeedback && (
                  <div className="rounded border border-primary-200 bg-primary-50 px-3 py-2 text-xs text-primary-800">
                    {renameFeedback}
                  </div>
                )}
                <form className="space-y-3" onSubmit={handleRenameSpeaker}>
                  <div className="grid grid-cols-1 gap-3">
                    <div>
                      <label className="text-xs font-medium text-primary-700">Current name</label>
                      <input
                        type="text"
                        value={renameFrom}
                        onChange={(event) => {
                          setRenameFrom(event.target.value.toUpperCase())
                          if (renameFeedback) setRenameFeedback(null)
                        }}
                        className="mt-1 w-full rounded border border-primary-200 px-3 py-2 text-xs uppercase text-primary-800 focus:border-primary-500 focus:outline-none focus:ring-1 focus:ring-primary-400"
                        placeholder="e.g., SPKR 01"
                      />
                    </div>
                    <div>
                      <label className="text-xs font-medium text-primary-700">New name</label>
                      <input
                        type="text"
                        value={renameTo}
                        onChange={(event) => {
                          setRenameTo(event.target.value.toUpperCase())
                          if (renameFeedback) setRenameFeedback(null)
                        }}
                        className="mt-1 w-full rounded border border-primary-200 px-3 py-2 text-xs uppercase text-primary-800 focus:border-primary-500 focus:outline-none focus:ring-1 focus:ring-primary-400"
                        placeholder="e.g., WITNESS"
                      />
                    </div>
                  </div>
                  <button type="submit" className="btn-primary w-full text-sm" disabled={!lines.length}>
                    Rename Speaker
                  </button>
                </form>
              </div>

              <div className="rounded-lg border-2 border-primary-200 bg-white p-4 space-y-3">
                <h3 className="text-sm font-medium text-primary-900">Import Transcript</h3>
                <p className="text-xs text-primary-600">
                  Drag & drop files anywhere on the page, or use the inputs below.
                </p>
                {importError && (
                  <p className="text-xs text-red-600">{importError}</p>
                )}
                <form className="space-y-3" onSubmit={handleImport}>
                  <div>
                    <label className="text-xs font-medium text-primary-700">Transcript (XML or DOCX) *</label>
                    <input
                      type="file"
                      accept=".xml,.docx"
                      onChange={(event) => setImportTranscriptFile(event.target.files?.[0] ?? null)}
                      className="mt-1 w-full text-xs text-primary-700 file:mr-3 file:rounded file:border-0 file:bg-primary-100 file:px-3 file:py-1 file:text-primary-800"
                    />
                    {importTranscriptFile && (
                      <p className="mt-1 text-xs text-primary-600">
                        Selected: {importTranscriptFile.name}
                      </p>
                    )}
                  </div>
                  <div>
                    <label className="text-xs font-medium text-primary-700">Media File *</label>
                    <input
                      type="file"
                      accept="audio/*,video/*"
                      onChange={(event) => {
                        const file = event.target.files?.[0] ?? null
                        setImportMediaFile(file)
                        if (localMediaPreviewUrl) {
                          URL.revokeObjectURL(localMediaPreviewUrl)
                        }
                        if (file) {
                          const url = URL.createObjectURL(file)
                          setLocalMediaPreviewUrl(url)
                          setLocalMediaType(file.type)
                        } else {
                          setLocalMediaPreviewUrl(null)
                          setLocalMediaType(undefined)
                        }
                      }}
                      className="mt-1 w-full text-xs text-primary-700 file:mr-3 file:rounded file:border-0 file:bg-primary-100 file:px-3 file:py-1 file:text-primary-800"
                    />
                    {importMediaFile && (
                      <p className="mt-1 text-xs text-primary-600">
                        Selected: {importMediaFile.name}
                      </p>
                    )}
                  </div>
                  <p className="text-[10px] text-primary-500">
                    DOCX imports run automatic timestamp alignment via Rev AI.
                  </p>
                  <button type="submit" className="btn-outline w-full text-sm" disabled={importing || !importTranscriptFile || !importMediaFile}>
                    {importing ? 'Importingâ€¦' : 'Import Transcript'}
                  </button>
                </form>
              </div>

              <div className="rounded-lg border border-primary-200 bg-white p-4 space-y-2 text-sm text-primary-700">
                <h3 className="font-medium text-primary-900">Downloads</h3>
                <button
                  className="btn-outline w-full"
                  onClick={() =>
                    docxData &&
                    onDownload(
                      docxData,
                      buildFilename('Transcript-Edited', '.docx'),
                      'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
                    )
                  }
                  disabled={!docxData}
                >
                  Download DOCX
                </button>
                <button
                  className="btn-outline w-full"
                  onClick={() =>
                    xmlData && onDownload(xmlData, buildFilename('Transcript-Edited', '.xml'), 'application/xml')
                  }
                  disabled={!xmlData}
                >
                  Download OnCue XML
                </button>
                {transcriptText && (
                  <button
                    className="btn-outline w-full"
                    onClick={() =>
                      onDownload(
                        btoa(unescape(encodeURIComponent(transcriptText))),
                        buildFilename('Transcript-Preview', '.txt'),
                        'text/plain',
                      )
                    }
                  >
                    Download Transcript Text
                  </button>
                )}
              </div>
            </div>

            <div>
              <div className="rounded-lg border border-primary-200 bg-white shadow-inner">
                <div className="grid grid-cols-[70px_170px_minmax(0,1fr)_220px] border-b border-primary-200 bg-primary-100 px-5 py-3 text-[11px] font-semibold uppercase tracking-wide text-primary-600">
                  <div>Pg:Ln</div>
                  <div>Speaker</div>
                  <div>Utterance</div>
                  <div className="text-right">Timing</div>
                </div>
                <div className="max-h-[72vh] overflow-y-auto">
                  {loading ? (
                    <div className="p-6 text-center text-primary-500">Loading editorâ€¦</div>
                  ) : lines.length === 0 ? (
                    <div className="p-6 text-center text-primary-500">No lines available. Import or transcribe to begin editing.</div>
                  ) : (
                    lines.map((line) => {
                      const isActive = activeLineId === line.id
                      const isSelected = selectedLineId === line.id
                      const rowClasses = [
                        'grid grid-cols-[70px_170px_minmax(0,1fr)_220px] items-start gap-5 border-b border-primary-100 px-5 py-3 text-sm',
                        isActive ? 'bg-yellow-200' : 'bg-white hover:bg-primary-200',
                        isSelected ? 'ring-2 ring-primary-300' : '',
                      ]
                      const timingInputClass = line.timestamp_error
                        ? 'w-24 rounded border border-red-400 bg-red-50 px-2 py-1 text-xs text-red-700 focus:border-red-500 focus:outline-none focus:ring-1 focus:ring-red-400'
                        : 'w-24 rounded border border-primary-200 px-2 py-1 text-xs text-primary-800 focus:border-primary-500 focus:outline-none focus:ring-1 focus:ring-primary-400'
                      return (
                        <div
                          key={line.id}
                          ref={(el) => {
                            lineRefs.current[line.id] = el
                          }}
                          onClick={() => setSelectedLineId(line.id)}
                          className={rowClasses.join(' ')}
                        >
                          <div className="text-xs font-mono text-primary-500">
                            {line.page ?? 'â€”'}:{line.line ?? 'â€”'}
                          </div>
                          <div
                            className="min-w-0 cursor-pointer truncate text-primary-900 pr-4"
                            onDoubleClick={() => beginEdit(line, 'speaker')}
                          >
                            {editingField && editingField.lineId === line.id && editingField.field === 'speaker' ? (
                              <input
                                ref={editInputRef as React.MutableRefObject<HTMLInputElement | null>}
                                className="input text-xs uppercase"
                                value={editingField.value}
                                onChange={(event) =>
                                  setEditingField((prev) =>
                                    prev ? { ...prev, value: event.target.value.toUpperCase() } : prev,
                                  )
                                }
                                onBlur={commitEdit}
                                onKeyDown={(event) => {
                                  if (event.key === 'Enter') {
                                    event.preventDefault()
                                    commitEdit()
                                  } else if (event.key === 'Escape') {
                                    event.preventDefault()
                                    cancelEdit()
                                  }
                                }}
                              />
                            ) : (
                              <span className="uppercase">{line.speaker || 'â€”'}</span>
                            )}
                          </div>
                          <div
                            className="min-w-0 cursor-text whitespace-pre-wrap text-primary-800 pr-6"
                            onDoubleClick={() => beginEdit(line, 'text')}
                          >
                            {editingField && editingField.lineId === line.id && editingField.field === 'text' ? (
                              <textarea
                                ref={editInputRef as React.MutableRefObject<HTMLTextAreaElement | null>}
                                className="textarea text-sm"
                                rows={3}
                                value={editingField.value}
                                onChange={(event) =>
                                  setEditingField((prev) => (prev ? { ...prev, value: event.target.value } : prev))
                                }
                                onBlur={commitEdit}
                                onKeyDown={(event) => {
                                  if (event.key === 'Enter' && !event.shiftKey) {
                                    event.preventDefault()
                                    commitEdit()
                                  } else if (event.key === 'Escape') {
                                    event.preventDefault()
                                    cancelEdit()
                                  }
                                }}
                              />
                            ) : (
                              <span>{line.text || 'â€”'}</span>
                            )}
                          </div>
                          <div className="flex items-center justify-end gap-5 text-xs text-primary-600">
                            <div className="flex flex-col items-end gap-1 text-[11px] text-primary-500">
                              <span className="uppercase tracking-wide text-[10px] text-primary-400">Start</span>
                              <input
                                type="number"
                                step="0.01"
                                min={0}
                                value={line.start}
                                onChange={(event) =>
                                  handleLineFieldChange(line.id, 'start', parseFloat(event.target.value))
                                }
                                className={timingInputClass}
                                title={line.timestamp_error ? 'Missing timestamp â€” adjust start/end to fix.' : undefined}
                              />
                            </div>
                            <div className="flex flex-col items-end gap-1 text-[11px] text-primary-500">
                              <span className="uppercase tracking-wide text-[10px] text-primary-400">End</span>
                              <input
                                type="number"
                                step="0.01"
                                min={0}
                                value={line.end}
                                onChange={(event) =>
                                  handleLineFieldChange(line.id, 'end', parseFloat(event.target.value))
                                }
                                className={timingInputClass}
                                title={line.timestamp_error ? 'Missing timestamp â€” adjust start/end to fix.' : undefined}
                              />
                              {line.timestamp_error && (
                                <span className="text-[10px] font-semibold uppercase tracking-wide text-red-600">
                                  Fix timing
                                </span>
                              )}
                            </div>
                            <button
                              type="button"
                              className="rounded border border-primary-300 px-3 py-1 text-xs font-medium text-primary-700 hover:border-primary-500 hover:bg-primary-100"
                              onClick={() => playLine(line)}
                              disabled={!effectiveMediaUrl}
                            >
                              Play
                            </button>
                          </div>
                        </div>
                      )
                    })
                  )}
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>

      {/* Re-sync Loading Overlay - uses z-[9999] to ensure it's above everything */}
      {isResyncing && (
        <div className="fixed top-0 left-0 right-0 bottom-0 z-[9999] flex items-center justify-center bg-black/50 backdrop-blur-sm">
          <div className="w-full max-w-sm rounded-xl bg-white p-8 shadow-2xl text-center">
            <div className="mb-4 flex justify-center">
              {/* Simple Spinner */}
              <svg className="h-10 w-10 animate-spin text-indigo-600" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
                <circle className="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" strokeWidth="4"></circle>
                <path className="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
              </svg>
            </div>
            <h3 className="text-lg font-bold text-gray-900">Re-syncing Transcript</h3>
            <p className="mt-2 text-sm text-gray-600">
              Automatically re-syncing the transcript to the media file. <br />
              This could take a few minutes for longer files.
            </p>
          </div>
        </div>
      )}
    </div>
  )
}
===== END FILE =====

===== FILE: frontend-next/src/utils/auth.ts =====
/**
 * Authentication utility for TranscribeAlpha
 * Handles token storage, refresh, and API authentication
 */

export interface User {
  username: string;
  role: string;
}

export interface AuthTokens {
  access_token: string;
  refresh_token: string;
}

/**
 * Get the current access token from localStorage
 */
export function getAccessToken(): string | null {
  if (typeof window === 'undefined') return null;
  return localStorage.getItem('access_token');
}

/**
 * Get the current refresh token from localStorage
 */
export function getRefreshToken(): string | null {
  if (typeof window === 'undefined') return null;
  return localStorage.getItem('refresh_token');
}

/**
 * Get the current user from localStorage
 */
export function getCurrentUser(): User | null {
  if (typeof window === 'undefined') return null;
  const userStr = localStorage.getItem('user');
  if (!userStr) return null;
  try {
    return JSON.parse(userStr);
  } catch {
    return null;
  }
}

/**
 * Check if user is authenticated
 */
export function isAuthenticated(): boolean {
  return !!getAccessToken();
}

/**
 * Clear all authentication data
 */
export function clearAuth(): void {
  if (typeof window === 'undefined') return;
  localStorage.removeItem('access_token');
  localStorage.removeItem('refresh_token');
  localStorage.removeItem('user');
}

/**
 * Logout the current user
 */
export async function logout(): Promise<void> {
  try {
    const token = getAccessToken();
    if (token) {
      await fetch('/api/auth/logout', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${token}`,
          'Content-Type': 'application/json',
        },
      });
    }
  } catch (error) {
    console.error('Logout error:', error);
  } finally {
    clearAuth();
    // Reload the page to show login screen
    window.location.reload();
  }
}

/**
 * Refresh the access token using the refresh token
 */
export async function refreshAccessToken(): Promise<string | null> {
  const refreshToken = getRefreshToken();
  if (!refreshToken) {
    return null;
  }

  try {
    const response = await fetch('/api/auth/refresh', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({ refresh_token: refreshToken }),
    });

    if (!response.ok) {
      clearAuth();
      return null;
    }

    const data = await response.json();
    localStorage.setItem('access_token', data.access_token);
    return data.access_token;
  } catch (error) {
    console.error('Token refresh error:', error);
    clearAuth();
    return null;
  }
}

/**
 * Make an authenticated API request with automatic token refresh
 */
export async function authenticatedFetch(
  url: string,
  options: RequestInit = {}
): Promise<Response> {
  let token = getAccessToken();

  if (!token) {
    throw new Error('No access token available');
  }

  // Add Authorization header
  const headers = new Headers(options.headers);
  headers.set('Authorization', `Bearer ${token}`);

  const requestOptions: RequestInit = {
    ...options,
    headers,
  };

  // Make the request
  let response = await fetch(url, requestOptions);

  // If unauthorized, try to refresh the token and retry once
  if (response.status === 401) {
    console.log('Access token expired, refreshing...');
    token = await refreshAccessToken();

    if (token) {
      // Retry with new token
      headers.set('Authorization', `Bearer ${token}`);
      response = await fetch(url, requestOptions);
    } else {
      // Refresh failed, redirect to login
      clearAuth();
      window.location.reload();
      throw new Error('Authentication failed');
    }
  }

  return response;
}

/**
 * Add Authorization header to fetch options
 * This is a simpler helper for when you want to handle the response yourself
 */
export function getAuthHeaders(): HeadersInit {
  const token = getAccessToken();
  if (!token) {
    return {};
  }
  return {
    'Authorization': `Bearer ${token}`,
  };
}

/**
 * Append the current access token to media URLs that can't send headers.
 */
export function appendAccessTokenToMediaUrl(url: string): string {
  if (!url || !url.includes('/api/media/')) {
    return url;
  }
  if (url.includes('token=')) {
    return url;
  }
  const token = getAccessToken();
  if (!token) {
    return url;
  }
  const separator = url.includes('?') ? '&' : '?';
  return `${url}${separator}token=${encodeURIComponent(token)}`;
}

/**
 * Check if the access token is expired
 */
export function isTokenExpired(): boolean {
  const token = getAccessToken();
  if (!token) return true;

  try {
    // Decode JWT payload (simple base64 decode, not cryptographic verification)
    const payload = JSON.parse(atob(token.split('.')[1]));
    const exp = payload.exp;

    if (!exp) return true;

    // Check if token is expired
    const now = Math.floor(Date.now() / 1000);
    return now >= exp;
  } catch {
    return true;
  }
}

/**
 * Initialize authentication (no automatic refresh needed - tokens last 1 year)
 * Users stay logged in until they explicitly log out
 */
export function initializeTokenRefresh(): void {
  // Tokens now last 1 year, so no automatic refresh is needed
  // Users will stay logged in until they explicitly log out
  // This function is kept for API compatibility
}
===== END FILE =====

===== FILE: frontend-next/tailwind.config.js =====
/** @type {import('tailwindcss').Config} */
module.exports = {
  content: [
    './src/pages/**/*.{js,ts,jsx,tsx,mdx}',
    './src/components/**/*.{js,ts,jsx,tsx,mdx}',
    './src/app/**/*.{js,ts,jsx,tsx,mdx}',
  ],
  theme: {
    extend: {
      colors: {
        primary: {
          50: '#f8fafc',
          100: '#f1f5f9',
          200: '#e2e8f0',
          300: '#cbd5e1',
          400: '#94a3b8',
          500: '#64748b',
          600: '#475569',
          700: '#334155',
          800: '#1e293b',
          900: '#0f172a',
        },
      },
      fontFamily: {
        sans: ['Inter', 'system-ui', 'sans-serif'],
      },
    },
  },
  plugins: [],
}
===== END FILE =====

===== FILE: frontend-next/tsconfig.json =====
{
  "compilerOptions": {
    "target": "es5",
    "lib": ["dom", "dom.iterable", "es6"],
    "allowJs": true,
    "skipLibCheck": true,
    "strict": true,
    "noEmit": true,
    "esModuleInterop": true,
    "module": "esnext",
    "moduleResolution": "bundler",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "jsx": "preserve",
    "incremental": true,
    "plugins": [
      {
        "name": "next"
      }
    ],
    "paths": {
      "@/*": ["./src/*"]
    }
  },
  "include": ["next-env.d.ts", "**/*.ts", "**/*.tsx", ".next/types/**/*.ts"],
  "exclude": ["node_modules"]
}
===== END FILE =====

===== FILE: frontend-next/tsconfig.tsbuildinfo =====
{"fileNames":["./node_modules/typescript/lib/lib.es5.d.ts","./node_modules/typescript/lib/lib.es2015.d.ts","./node_modules/typescript/lib/lib.es2016.d.ts","./node_modules/typescript/lib/lib.es2017.d.ts","./node_modules/typescript/lib/lib.es2018.d.ts","./node_modules/typescript/lib/lib.es2019.d.ts","./node_modules/typescript/lib/lib.es2020.d.ts","./node_modules/typescript/lib/lib.dom.d.ts","./node_modules/typescript/lib/lib.dom.iterable.d.ts","./node_modules/typescript/lib/lib.es2015.core.d.ts","./node_modules/typescript/lib/lib.es2015.collection.d.ts","./node_modules/typescript/lib/lib.es2015.generator.d.ts","./node_modules/typescript/lib/lib.es2015.iterable.d.ts","./node_modules/typescript/lib/lib.es2015.promise.d.ts","./node_modules/typescript/lib/lib.es2015.proxy.d.ts","./node_modules/typescript/lib/lib.es2015.reflect.d.ts","./node_modules/typescript/lib/lib.es2015.symbol.d.ts","./node_modules/typescript/lib/lib.es2015.symbol.wellknown.d.ts","./node_modules/typescript/lib/lib.es2016.array.include.d.ts","./node_modules/typescript/lib/lib.es2016.intl.d.ts","./node_modules/typescript/lib/lib.es2017.arraybuffer.d.ts","./node_modules/typescript/lib/lib.es2017.date.d.ts","./node_modules/typescript/lib/lib.es2017.object.d.ts","./node_modules/typescript/lib/lib.es2017.sharedmemory.d.ts","./node_modules/typescript/lib/lib.es2017.string.d.ts","./node_modules/typescript/lib/lib.es2017.intl.d.ts","./node_modules/typescript/lib/lib.es2017.typedarrays.d.ts","./node_modules/typescript/lib/lib.es2018.asyncgenerator.d.ts","./node_modules/typescript/lib/lib.es2018.asynciterable.d.ts","./node_modules/typescript/lib/lib.es2018.intl.d.ts","./node_modules/typescript/lib/lib.es2018.promise.d.ts","./node_modules/typescript/lib/lib.es2018.regexp.d.ts","./node_modules/typescript/lib/lib.es2019.array.d.ts","./node_modules/typescript/lib/lib.es2019.object.d.ts","./node_modules/typescript/lib/lib.es2019.string.d.ts","./node_modules/typescript/lib/lib.es2019.symbol.d.ts","./node_modules/typescript/lib/lib.es2019.intl.d.ts","./node_modules/typescript/lib/lib.es2020.bigint.d.ts","./node_modules/typescript/lib/lib.es2020.date.d.ts","./node_modules/typescript/lib/lib.es2020.promise.d.ts","./node_modules/typescript/lib/lib.es2020.sharedmemory.d.ts","./node_modules/typescript/lib/lib.es2020.string.d.ts","./node_modules/typescript/lib/lib.es2020.symbol.wellknown.d.ts","./node_modules/typescript/lib/lib.es2020.intl.d.ts","./node_modules/typescript/lib/lib.es2020.number.d.ts","./node_modules/typescript/lib/lib.decorators.d.ts","./node_modules/typescript/lib/lib.decorators.legacy.d.ts","./node_modules/next/dist/styled-jsx/types/css.d.ts","./node_modules/@types/react/global.d.ts","./node_modules/csstype/index.d.ts","./node_modules/@types/prop-types/index.d.ts","./node_modules/@types/react/index.d.ts","./node_modules/next/dist/styled-jsx/types/index.d.ts","./node_modules/next/dist/styled-jsx/types/macro.d.ts","./node_modules/next/dist/styled-jsx/types/style.d.ts","./node_modules/next/dist/styled-jsx/types/global.d.ts","./node_modules/next/dist/shared/lib/amp.d.ts","./node_modules/next/amp.d.ts","./node_modules/@types/node/compatibility/disposable.d.ts","./node_modules/@types/node/compatibility/indexable.d.ts","./node_modules/@types/node/compatibility/iterators.d.ts","./node_modules/@types/node/compatibility/index.d.ts","./node_modules/@types/node/globals.typedarray.d.ts","./node_modules/@types/node/buffer.buffer.d.ts","../../../node_modules/buffer/index.d.ts","./node_modules/undici-types/header.d.ts","./node_modules/undici-types/readable.d.ts","./node_modules/undici-types/file.d.ts","./node_modules/undici-types/fetch.d.ts","./node_modules/undici-types/formdata.d.ts","./node_modules/undici-types/connector.d.ts","./node_modules/undici-types/client.d.ts","./node_modules/undici-types/errors.d.ts","./node_modules/undici-types/dispatcher.d.ts","./node_modules/undici-types/global-dispatcher.d.ts","./node_modules/undici-types/global-origin.d.ts","./node_modules/undici-types/pool-stats.d.ts","./node_modules/undici-types/pool.d.ts","./node_modules/undici-types/handlers.d.ts","./node_modules/undici-types/balanced-pool.d.ts","./node_modules/undici-types/agent.d.ts","./node_modules/undici-types/mock-interceptor.d.ts","./node_modules/undici-types/mock-agent.d.ts","./node_modules/undici-types/mock-client.d.ts","./node_modules/undici-types/mock-pool.d.ts","./node_modules/undici-types/mock-errors.d.ts","./node_modules/undici-types/proxy-agent.d.ts","./node_modules/undici-types/env-http-proxy-agent.d.ts","./node_modules/undici-types/retry-handler.d.ts","./node_modules/undici-types/retry-agent.d.ts","./node_modules/undici-types/api.d.ts","./node_modules/undici-types/interceptors.d.ts","./node_modules/undici-types/util.d.ts","./node_modules/undici-types/cookies.d.ts","./node_modules/undici-types/patch.d.ts","./node_modules/undici-types/websocket.d.ts","./node_modules/undici-types/eventsource.d.ts","./node_modules/undici-types/filereader.d.ts","./node_modules/undici-types/diagnostics-channel.d.ts","./node_modules/undici-types/content-type.d.ts","./node_modules/undici-types/cache.d.ts","./node_modules/undici-types/index.d.ts","./node_modules/@types/node/globals.d.ts","./node_modules/@types/node/assert.d.ts","./node_modules/@types/node/assert/strict.d.ts","./node_modules/@types/node/async_hooks.d.ts","./node_modules/@types/node/buffer.d.ts","./node_modules/@types/node/child_process.d.ts","./node_modules/@types/node/cluster.d.ts","./node_modules/@types/node/console.d.ts","./node_modules/@types/node/constants.d.ts","./node_modules/@types/node/crypto.d.ts","./node_modules/@types/node/dgram.d.ts","./node_modules/@types/node/diagnostics_channel.d.ts","./node_modules/@types/node/dns.d.ts","./node_modules/@types/node/dns/promises.d.ts","./node_modules/@types/node/domain.d.ts","./node_modules/@types/node/dom-events.d.ts","./node_modules/@types/node/events.d.ts","./node_modules/@types/node/fs.d.ts","./node_modules/@types/node/fs/promises.d.ts","./node_modules/@types/node/http.d.ts","./node_modules/@types/node/http2.d.ts","./node_modules/@types/node/https.d.ts","./node_modules/@types/node/inspector.d.ts","./node_modules/@types/node/module.d.ts","./node_modules/@types/node/net.d.ts","./node_modules/@types/node/os.d.ts","./node_modules/@types/node/path.d.ts","./node_modules/@types/node/perf_hooks.d.ts","./node_modules/@types/node/process.d.ts","./node_modules/@types/node/punycode.d.ts","./node_modules/@types/node/querystring.d.ts","./node_modules/@types/node/readline.d.ts","./node_modules/@types/node/readline/promises.d.ts","./node_modules/@types/node/repl.d.ts","./node_modules/@types/node/sea.d.ts","./node_modules/@types/node/stream.d.ts","./node_modules/@types/node/stream/promises.d.ts","./node_modules/@types/node/stream/consumers.d.ts","./node_modules/@types/node/stream/web.d.ts","./node_modules/@types/node/string_decoder.d.ts","./node_modules/@types/node/test.d.ts","./node_modules/@types/node/timers.d.ts","./node_modules/@types/node/timers/promises.d.ts","./node_modules/@types/node/tls.d.ts","./node_modules/@types/node/trace_events.d.ts","./node_modules/@types/node/tty.d.ts","./node_modules/@types/node/url.d.ts","./node_modules/@types/node/util.d.ts","./node_modules/@types/node/v8.d.ts","./node_modules/@types/node/vm.d.ts","./node_modules/@types/node/wasi.d.ts","./node_modules/@types/node/worker_threads.d.ts","./node_modules/@types/node/zlib.d.ts","./node_modules/@types/node/index.d.ts","./node_modules/next/dist/server/get-page-files.d.ts","./node_modules/@types/react/canary.d.ts","./node_modules/@types/react/experimental.d.ts","./node_modules/@types/react-dom/index.d.ts","./node_modules/@types/react-dom/canary.d.ts","./node_modules/@types/react-dom/experimental.d.ts","./node_modules/next/dist/compiled/webpack/webpack.d.ts","./node_modules/next/dist/server/config.d.ts","./node_modules/next/dist/lib/load-custom-routes.d.ts","./node_modules/next/dist/shared/lib/image-config.d.ts","./node_modules/next/dist/build/webpack/plugins/subresource-integrity-plugin.d.ts","./node_modules/next/dist/server/body-streams.d.ts","./node_modules/next/dist/server/future/route-kind.d.ts","./node_modules/next/dist/server/future/route-definitions/route-definition.d.ts","./node_modules/next/dist/server/future/route-matches/route-match.d.ts","./node_modules/next/dist/client/components/app-router-headers.d.ts","./node_modules/next/dist/server/request-meta.d.ts","./node_modules/next/dist/server/config-shared.d.ts","./node_modules/next/dist/server/base-http/index.d.ts","./node_modules/next/dist/server/api-utils/index.d.ts","./node_modules/next/dist/server/node-environment.d.ts","./node_modules/next/dist/server/require-hook.d.ts","./node_modules/next/dist/server/node-polyfill-crypto.d.ts","./node_modules/next/dist/build/analysis/get-page-static-info.d.ts","./node_modules/next/dist/build/webpack/loaders/get-module-build-info.d.ts","./node_modules/next/dist/build/webpack/plugins/middleware-plugin.d.ts","./node_modules/next/dist/server/lib/revalidate.d.ts","./node_modules/next/dist/lib/setup-exception-listeners.d.ts","./node_modules/next/dist/build/index.d.ts","./node_modules/next/dist/server/response-cache/types.d.ts","./node_modules/next/dist/server/response-cache/index.d.ts","./node_modules/next/dist/server/lib/incremental-cache/index.d.ts","./node_modules/next/dist/client/components/hooks-server-context.d.ts","./node_modules/next/dist/client/components/static-generation-async-storage.external.d.ts","./node_modules/next/dist/server/render-result.d.ts","./node_modules/next/dist/server/future/helpers/i18n-provider.d.ts","./node_modules/next/dist/server/web/next-url.d.ts","./node_modules/next/dist/compiled/@edge-runtime/cookies/index.d.ts","./node_modules/next/dist/server/web/spec-extension/cookies.d.ts","./node_modules/next/dist/server/web/spec-extension/request.d.ts","./node_modules/next/dist/server/web/spec-extension/fetch-event.d.ts","./node_modules/next/dist/server/web/spec-extension/response.d.ts","./node_modules/next/dist/server/web/types.d.ts","./node_modules/next/dist/build/webpack/plugins/pages-manifest-plugin.d.ts","./node_modules/next/dist/shared/lib/router/utils/route-regex.d.ts","./node_modules/next/dist/shared/lib/router/utils/route-matcher.d.ts","./node_modules/next/dist/shared/lib/router/utils/parse-url.d.ts","./node_modules/next/dist/server/base-http/node.d.ts","./node_modules/next/dist/server/font-utils.d.ts","./node_modules/next/dist/build/webpack/plugins/flight-manifest-plugin.d.ts","./node_modules/next/dist/server/future/route-modules/route-module.d.ts","./node_modules/next/dist/server/load-components.d.ts","./node_modules/next/dist/shared/lib/router/utils/middleware-route-matcher.d.ts","./node_modules/next/dist/build/webpack/plugins/next-font-manifest-plugin.d.ts","./node_modules/next/dist/server/future/route-definitions/locale-route-definition.d.ts","./node_modules/next/dist/server/future/route-definitions/pages-route-definition.d.ts","./node_modules/next/dist/shared/lib/mitt.d.ts","./node_modules/next/dist/client/with-router.d.ts","./node_modules/next/dist/client/router.d.ts","./node_modules/next/dist/client/route-loader.d.ts","./node_modules/next/dist/client/page-loader.d.ts","./node_modules/next/dist/shared/lib/bloom-filter.d.ts","./node_modules/next/dist/shared/lib/router/router.d.ts","./node_modules/next/dist/shared/lib/router-context.shared-runtime.d.ts","./node_modules/next/dist/shared/lib/loadable-context.shared-runtime.d.ts","./node_modules/next/dist/shared/lib/loadable.shared-runtime.d.ts","./node_modules/next/dist/shared/lib/image-config-context.shared-runtime.d.ts","./node_modules/next/dist/shared/lib/hooks-client-context.shared-runtime.d.ts","./node_modules/next/dist/shared/lib/head-manager-context.shared-runtime.d.ts","./node_modules/next/dist/server/future/route-definitions/app-page-route-definition.d.ts","./node_modules/next/dist/shared/lib/modern-browserslist-target.d.ts","./node_modules/next/dist/shared/lib/constants.d.ts","./node_modules/next/dist/build/webpack/loaders/metadata/types.d.ts","./node_modules/next/dist/build/webpack/loaders/next-app-loader.d.ts","./node_modules/next/dist/server/lib/app-dir-module.d.ts","./node_modules/next/dist/server/web/spec-extension/adapters/request-cookies.d.ts","./node_modules/next/dist/server/async-storage/draft-mode-provider.d.ts","./node_modules/next/dist/server/web/spec-extension/adapters/headers.d.ts","./node_modules/next/dist/client/components/request-async-storage.external.d.ts","./node_modules/next/dist/server/app-render/create-error-handler.d.ts","./node_modules/next/dist/server/app-render/app-render.d.ts","./node_modules/next/dist/shared/lib/server-inserted-html.shared-runtime.d.ts","./node_modules/next/dist/shared/lib/amp-context.shared-runtime.d.ts","./node_modules/next/dist/server/future/route-modules/app-page/vendored/contexts/entrypoints.d.ts","./node_modules/next/dist/server/future/route-modules/app-page/module.compiled.d.ts","./node_modules/next/dist/client/components/error-boundary.d.ts","./node_modules/next/dist/client/components/router-reducer/create-initial-router-state.d.ts","./node_modules/next/dist/client/components/app-router.d.ts","./node_modules/next/dist/client/components/layout-router.d.ts","./node_modules/next/dist/client/components/render-from-template-context.d.ts","./node_modules/next/dist/client/components/action-async-storage.external.d.ts","./node_modules/next/dist/client/components/static-generation-bailout.d.ts","./node_modules/next/dist/client/components/static-generation-searchparams-bailout-provider.d.ts","./node_modules/next/dist/client/components/searchparams-bailout-proxy.d.ts","./node_modules/next/dist/server/app-render/rsc/preloads.d.ts","./node_modules/next/dist/server/app-render/rsc/taint.d.ts","./node_modules/next/dist/client/components/not-found-boundary.d.ts","./node_modules/next/dist/server/app-render/entry-base.d.ts","./node_modules/next/dist/build/templates/app-page.d.ts","./node_modules/next/dist/server/future/route-modules/app-page/module.d.ts","./node_modules/next/dist/server/app-render/types.d.ts","./node_modules/next/dist/client/components/router-reducer/fetch-server-response.d.ts","./node_modules/next/dist/client/components/router-reducer/router-reducer-types.d.ts","./node_modules/next/dist/shared/lib/app-router-context.shared-runtime.d.ts","./node_modules/next/dist/server/future/route-modules/pages/vendored/contexts/entrypoints.d.ts","./node_modules/next/dist/server/future/route-modules/pages/module.compiled.d.ts","./node_modules/next/dist/build/templates/pages.d.ts","./node_modules/next/dist/server/future/route-modules/pages/module.d.ts","./node_modules/next/dist/server/render.d.ts","./node_modules/next/dist/server/future/route-definitions/pages-api-route-definition.d.ts","./node_modules/next/dist/server/future/route-matches/pages-api-route-match.d.ts","./node_modules/next/dist/server/future/route-matchers/route-matcher.d.ts","./node_modules/next/dist/server/future/route-matcher-providers/route-matcher-provider.d.ts","./node_modules/next/dist/server/future/route-matcher-managers/route-matcher-manager.d.ts","./node_modules/next/dist/server/future/normalizers/normalizer.d.ts","./node_modules/next/dist/server/future/normalizers/locale-route-normalizer.d.ts","./node_modules/next/dist/server/future/normalizers/request/rsc.d.ts","./node_modules/next/dist/server/future/normalizers/request/postponed.d.ts","./node_modules/next/dist/server/base-server.d.ts","./node_modules/next/dist/server/image-optimizer.d.ts","./node_modules/next/dist/server/next-server.d.ts","./node_modules/next/dist/lib/coalesced-function.d.ts","./node_modules/next/dist/trace/shared.d.ts","./node_modules/next/dist/trace/trace.d.ts","./node_modules/next/dist/trace/index.d.ts","./node_modules/next/dist/build/webpack-config.d.ts","./node_modules/next/dist/build/webpack/plugins/define-env-plugin.d.ts","./node_modules/next/dist/build/swc/index.d.ts","./node_modules/next/dist/server/dev/parse-version-info.d.ts","./node_modules/next/dist/server/dev/hot-reloader-types.d.ts","./node_modules/next/dist/telemetry/storage.d.ts","./node_modules/next/dist/server/lib/types.d.ts","./node_modules/next/dist/server/lib/router-utils/types.d.ts","./node_modules/next/dist/server/lib/render-server.d.ts","./node_modules/next/dist/server/lib/router-server.d.ts","./node_modules/next/dist/shared/lib/router/utils/path-match.d.ts","./node_modules/next/dist/server/lib/router-utils/filesystem.d.ts","./node_modules/next/dist/server/lib/router-utils/setup-dev-bundler.d.ts","./node_modules/next/dist/server/lib/dev-bundler-service.d.ts","./node_modules/next/dist/server/dev/static-paths-worker.d.ts","./node_modules/next/dist/server/dev/next-dev-server.d.ts","./node_modules/next/dist/server/next.d.ts","./node_modules/next/dist/lib/metadata/types/alternative-urls-types.d.ts","./node_modules/next/dist/lib/metadata/types/extra-types.d.ts","./node_modules/next/dist/lib/metadata/types/metadata-types.d.ts","./node_modules/next/dist/lib/metadata/types/manifest-types.d.ts","./node_modules/next/dist/lib/metadata/types/opengraph-types.d.ts","./node_modules/next/dist/lib/metadata/types/twitter-types.d.ts","./node_modules/next/dist/lib/metadata/types/metadata-interface.d.ts","./node_modules/next/types/index.d.ts","./node_modules/next/dist/shared/lib/html-context.shared-runtime.d.ts","./node_modules/@next/env/dist/index.d.ts","./node_modules/next/dist/shared/lib/utils.d.ts","./node_modules/next/dist/pages/_app.d.ts","./node_modules/next/app.d.ts","./node_modules/next/dist/server/web/spec-extension/unstable-cache.d.ts","./node_modules/next/dist/server/web/spec-extension/revalidate-path.d.ts","./node_modules/next/dist/server/web/spec-extension/revalidate-tag.d.ts","./node_modules/next/dist/server/web/spec-extension/unstable-no-store.d.ts","./node_modules/next/cache.d.ts","./node_modules/next/dist/shared/lib/runtime-config.external.d.ts","./node_modules/next/config.d.ts","./node_modules/next/dist/pages/_document.d.ts","./node_modules/next/document.d.ts","./node_modules/next/dist/shared/lib/dynamic.d.ts","./node_modules/next/dynamic.d.ts","./node_modules/next/dist/pages/_error.d.ts","./node_modules/next/error.d.ts","./node_modules/next/dist/shared/lib/head.d.ts","./node_modules/next/head.d.ts","./node_modules/next/dist/shared/lib/get-img-props.d.ts","./node_modules/next/dist/client/image-component.d.ts","./node_modules/next/dist/shared/lib/image-external.d.ts","./node_modules/next/image.d.ts","./node_modules/next/dist/client/link.d.ts","./node_modules/next/link.d.ts","./node_modules/next/dist/client/components/redirect.d.ts","./node_modules/next/dist/client/components/not-found.d.ts","./node_modules/next/dist/client/components/navigation.d.ts","./node_modules/next/navigation.d.ts","./node_modules/next/router.d.ts","./node_modules/next/dist/client/script.d.ts","./node_modules/next/script.d.ts","./node_modules/next/dist/server/web/spec-extension/user-agent.d.ts","./node_modules/next/dist/compiled/@edge-runtime/primitives/url.d.ts","./node_modules/next/dist/server/web/spec-extension/image-response.d.ts","./node_modules/next/dist/compiled/@vercel/og/satori/index.d.ts","./node_modules/next/dist/compiled/@vercel/og/emoji/index.d.ts","./node_modules/next/dist/compiled/@vercel/og/types.d.ts","./node_modules/next/server.d.ts","./node_modules/next/types/global.d.ts","./node_modules/next/types/compiled.d.ts","./node_modules/next/index.d.ts","./src/app/layout.tsx","./src/components/transcribeform.tsx","./src/app/page.tsx","./node_modules/@types/json5/index.d.ts","../../../node_modules/@types/connect/index.d.ts","../../../node_modules/@types/body-parser/index.d.ts","../../../node_modules/@types/mime/index.d.ts","../../../node_modules/@types/send/index.d.ts","../../../node_modules/@types/qs/index.d.ts","../../../node_modules/@types/range-parser/index.d.ts","../../../node_modules/@types/express-serve-static-core/index.d.ts","../../../node_modules/@types/http-errors/index.d.ts","../../../node_modules/@types/serve-static/index.d.ts","../../../node_modules/@types/express/index.d.ts","../../../node_modules/form-data/index.d.ts","../../../node_modules/@types/node-fetch/externals.d.ts","../../../node_modules/@types/node-fetch/index.d.ts","../../../node_modules/@types/nodemailer/lib/dkim/index.d.ts","../../../node_modules/@types/nodemailer/lib/mailer/mail-message.d.ts","../../../node_modules/@types/nodemailer/lib/xoauth2/index.d.ts","../../../node_modules/@types/nodemailer/lib/mailer/index.d.ts","../../../node_modules/@types/nodemailer/lib/mime-node/index.d.ts","../../../node_modules/@types/nodemailer/lib/smtp-connection/index.d.ts","../../../node_modules/@types/nodemailer/lib/shared/index.d.ts","../../../node_modules/@types/nodemailer/lib/json-transport/index.d.ts","../../../node_modules/@types/nodemailer/lib/sendmail-transport/index.d.ts","../../../node_modules/@types/nodemailer/lib/ses-transport/index.d.ts","../../../node_modules/@types/nodemailer/lib/smtp-pool/index.d.ts","../../../node_modules/@types/nodemailer/lib/smtp-transport/index.d.ts","../../../node_modules/@types/nodemailer/lib/stream-transport/index.d.ts","../../../node_modules/@types/nodemailer/index.d.ts","../../../node_modules/@types/office-js/index.d.ts","../../../node_modules/typed-query-selector/parser.d.ts","../../../node_modules/devtools-protocol/types/protocol.d.ts","../../../node_modules/devtools-protocol/types/protocol-mapping.d.ts","../../../node_modules/chromium-bidi/lib/cjs/protocol/generated/webdriver-bidi.d.ts","../../../node_modules/chromium-bidi/lib/cjs/protocol/cdp.d.ts","../../../node_modules/chromium-bidi/lib/cjs/protocol/generated/webdriver-bidi-bluetooth.d.ts","../../../node_modules/chromium-bidi/lib/cjs/protocol/generated/webdriver-bidi-permissions.d.ts","../../../node_modules/chromium-bidi/lib/cjs/protocol/chromium-bidi.d.ts","../../../node_modules/chromium-bidi/lib/cjs/protocol/errorresponse.d.ts","../../../node_modules/chromium-bidi/lib/cjs/protocol/protocol.d.ts","../../../node_modules/puppeteer/lib/types.d.ts","../../../node_modules/@types/yauzl/index.d.ts"],"fileIdsList":[[64,107,122,156,354],[64,107,122,156],[64,107,119,122,156,357,358,359],[64,107,355,358,360,362],[64,107],[64,107,122,149,156,364,365],[64,107,156,368,370,374,375,376,377,378,379],[64,107,138,156],[64,107,119,156,368,370,371,373,380],[64,107,119,127,138,149,156,367,368,369,371,372,373,380],[64,107,138,156,370,371],[64,107,138,156,370],[64,107,156,368,370,371,373,380],[64,107,138,156,372],[64,107,119,127,138,146,156,369,371,373],[64,107,119,156,368,370,371,372,373,380],[64,107,119,138,156,368,369,370,371,372,373,380],[64,107,119,138,156,368,370,371,373,380],[64,107,122,138,156,373],[64,107,120,138,156,356],[64,107,122,156,357,361],[64,107,119,138,156],[64,107,383,384,385],[64,107,385,386,387,388],[64,107,385],[64,107,385,386,387,388,389,390],[64,107,383],[64,107,122,138,156],[64,107,108,138,156,382,383,384,391],[64,104,107],[64,106,107],[107],[64,107,112,141],[64,107,108,113,119,120,127,138,149],[64,107,108,109,119,127],[59,60,61,64,107],[64,107,110,150],[64,107,111,112,120,128],[64,107,112,138,146],[64,107,113,115,119,127],[64,106,107,114],[64,107,115,116],[64,107,117,119],[64,106,107,119],[64,107,119,120,121,138,149],[64,107,119,120,121,134,138,141],[64,102,107],[64,107,115,119,122,127,138,149],[64,107,119,120,122,123,127,138,146,149],[64,107,122,124,138,146,149],[62,63,64,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155],[64,107,119,125],[64,107,126,149,154],[64,107,115,119,127,138],[64,107,128],[64,107,129],[64,106,107,130],[64,104,105,106,107,108,109,110,111,112,113,114,115,116,117,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155],[64,107,132],[64,107,133],[64,107,119,134,135],[64,107,134,136,150,152],[64,107,119,138,139,141],[64,107,140,141],[64,107,138,139],[64,107,141],[64,107,142],[64,104,107,138,143],[64,107,119,144,145],[64,107,144,145],[64,107,112,127,138,146],[64,107,147],[64,107,127,148],[64,107,122,133,149],[64,107,112,150],[64,107,138,151],[64,107,126,152],[64,107,153],[64,107,119,121,130,138,141,149,152,154],[64,107,138,155],[52,64,107,160,161,162],[52,64,107,160,161],[52,64,107],[52,56,64,107,159,306,345],[52,56,64,107,158,306,345],[49,50,51,64,107],[57,64,107],[64,107,310],[64,107,312,313,314,315],[64,107,317],[64,107,165,174,181,306],[64,107,165,172,176,183],[64,107,174,283],[64,107,231,241,254,348],[64,107,262],[64,107,165,174,180,218,228,281,348],[64,107,180,348],[64,107,174,228,229,348],[64,107,174,180,218,348],[64,107,348],[64,107,180,181,348],[64,106,107,156],[52,64,107,242,243,259],[52,64,107,159],[52,64,107,242,257],[64,107,238,260,333,334],[64,107,195],[64,106,107,156,195,232,233,234],[52,64,107,257,260],[64,107,257,259],[52,64,107,257,258,260],[64,106,107,156,175,188,189],[52,64,107,166,327],[52,64,107,149,156],[52,64,107,180,216],[52,64,107,180],[64,107,214,219],[52,64,107,215,309],[52,56,64,107,122,156,158,159,306,343,344],[64,107,164],[64,107,299,300,301,302,303,304],[64,107,301],[52,64,107,307,309],[52,64,107,309],[64,107,122,156,175,309],[64,107,122,156,173,190,191,206,235,236,256,257],[64,107,189,190,235,244,245,246,247,248,249,250,251,252,253,348],[52,64,107,133,156,174,188,206,208,210,256,306,348],[64,107,122,156,175,176,195,196,232],[64,107,122,156,174,176],[64,107,122,138,156,173,175,176],[64,107,122,133,149,156,164,166,173,174,175,176,180,183,185,187,188,191,192,200,202,205,206,208,209,210,257,265,267,270,272,273,274,306],[64,107,165,166,167,173,306,309,348],[64,107,174],[64,107,122,138,149,156,170,282,284,285,348],[64,107,133,149,156,170,173,175,188,199,200,202,203,204,208,270,275,277,295,296],[64,107,174,178,188],[64,107,173,174],[64,107,192,271],[64,107,271],[64,107,169,170],[64,107,169,211],[64,107,169],[64,107,171,192,269],[64,107,268],[64,107,170,171],[64,107,171,266],[64,107,170],[64,107,256],[64,107,122,156,173,191,207,226,231,237,240,255,257],[64,107,220,221,222,223,224,225,238,239,260,307],[64,107,264],[64,107,122,156,173,191,207,212,261,263,265,306,309],[64,107,122,149,156,166,173,174,187],[64,107,230],[64,107,122,156,288,294],[64,107,185,187,309],[64,107,289,295,298],[64,107,122,178,288,290],[64,107,165,174,185,209,292],[64,107,122,156,174,180,209,278,286,287,291,292,293],[64,107,157,206,207,306,309],[64,107,122,133,149,156,171,173,175,178,182,183,185,187,188,191,199,200,202,203,204,205,208,267,275,276,309],[64,107,122,156,173,174,178,277,297],[64,107,122,156,183,190],[52,64,107,122,133,156,164,166,173,176,191,205,206,208,210,264,306,309],[64,107,122,133,149,156,168,171,172,175],[64,107,186],[64,107,122,156,183,191],[64,107,122,156,174,192],[64,107,194],[64,107,196],[64,107,174,193,195,199],[64,107,174,193,195],[64,107,122,156,168,174,175,196,197,198],[52,64,107,257,258,259],[64,107,227],[52,64,107,166],[52,64,107,202],[52,64,107,157,205,210,306,309],[64,107,166,327,328],[52,64,107,219],[52,64,107,133,149,156,164,213,215,217,218,309],[64,107,175,180,202],[64,107,133,156],[64,107,201],[52,64,107,120,122,133,156,164,219,228,306,307,308],[48,52,53,54,55,64,107,158,159,306,345],[64,107,112],[64,107,279,280],[64,107,279],[64,107,319],[64,107,321],[64,107,323],[64,107,325],[64,107,329],[56,58,64,107,306,311,316,318,320,322,324,326,330,332,336,337,339,346,347,348],[64,107,331],[64,107,335],[64,107,215],[64,107,338],[64,106,107,196,197,198,199,340,341,342,345],[64,107,156],[52,56,64,107,122,124,133,156,158,159,160,162,164,176,298,305,309,345],[64,74,78,107,149],[64,74,107,138,149],[64,69,107],[64,71,74,107,146,149],[64,107,127,146],[64,69,107,156],[64,71,74,107,127,149],[64,66,67,70,73,107,119,138,149],[64,74,81,107],[64,66,72,107],[64,74,95,96,107],[64,70,74,107,141,149,156],[64,95,107,156],[64,68,69,107,156],[64,74,107],[64,68,69,70,71,72,73,74,75,76,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,96,97,98,99,100,101,107],[64,74,89,107],[64,74,81,82,107],[64,72,74,82,83,107],[64,73,107],[64,66,69,74,107],[64,74,78,82,83,107],[64,78,107],[64,72,74,77,107,149],[64,66,71,74,81,107],[64,107,138],[64,69,74,95,107,154,156],[64,107,349],[64,107,351]],"fileInfos":[{"version":"c430d44666289dae81f30fa7b2edebf186ecc91a2d4c71266ea6ae76388792e1","affectsGlobalScope":true,"impliedFormat":1},{"version":"45b7ab580deca34ae9729e97c13cfd999df04416a79116c3bfb483804f85ded4","impliedFormat":1},{"version":"3facaf05f0c5fc569c5649dd359892c98a85557e3e0c847964caeb67076f4d75","impliedFormat":1},{"version":"e44bb8bbac7f10ecc786703fe0a6a4b952189f908707980ba8f3c8975a760962","impliedFormat":1},{"version":"5e1c4c362065a6b95ff952c0eab010f04dcd2c3494e813b493ecfd4fcb9fc0d8","impliedFormat":1},{"version":"68d73b4a11549f9c0b7d352d10e91e5dca8faa3322bfb77b661839c42b1ddec7","impliedFormat":1},{"version":"5efce4fc3c29ea84e8928f97adec086e3dc876365e0982cc8479a07954a3efd4","impliedFormat":1},{"version":"080941d9f9ff9307f7e27a83bcd888b7c8270716c39af943532438932ec1d0b9","affectsGlobalScope":true,"impliedFormat":1},{"version":"2e80ee7a49e8ac312cc11b77f1475804bee36b3b2bc896bead8b6e1266befb43","affectsGlobalScope":true,"impliedFormat":1},{"version":"c57796738e7f83dbc4b8e65132f11a377649c00dd3eee333f672b8f0a6bea671","affectsGlobalScope":true,"impliedFormat":1},{"version":"dc2df20b1bcdc8c2d34af4926e2c3ab15ffe1160a63e58b7e09833f616efff44","affectsGlobalScope":true,"impliedFormat":1},{"version":"515d0b7b9bea2e31ea4ec968e9edd2c39d3eebf4a2d5cbd04e88639819ae3b71","affectsGlobalScope":true,"impliedFormat":1},{"version":"0559b1f683ac7505ae451f9a96ce4c3c92bdc71411651ca6ddb0e88baaaad6a3","affectsGlobalScope":true,"impliedFormat":1},{"version":"0dc1e7ceda9b8b9b455c3a2d67b0412feab00bd2f66656cd8850e8831b08b537","affectsGlobalScope":true,"impliedFormat":1},{"version":"ce691fb9e5c64efb9547083e4a34091bcbe5bdb41027e310ebba8f7d96a98671","affectsGlobalScope":true,"impliedFormat":1},{"version":"8d697a2a929a5fcb38b7a65594020fcef05ec1630804a33748829c5ff53640d0","affectsGlobalScope":true,"impliedFormat":1},{"version":"4ff2a353abf8a80ee399af572debb8faab2d33ad38c4b4474cff7f26e7653b8d","affectsGlobalScope":true,"impliedFormat":1},{"version":"fb0f136d372979348d59b3f5020b4cdb81b5504192b1cacff5d1fbba29378aa1","affectsGlobalScope":true,"impliedFormat":1},{"version":"d15bea3d62cbbdb9797079416b8ac375ae99162a7fba5de2c6c505446486ac0a","affectsGlobalScope":true,"impliedFormat":1},{"version":"68d18b664c9d32a7336a70235958b8997ebc1c3b8505f4f1ae2b7e7753b87618","affectsGlobalScope":true,"impliedFormat":1},{"version":"eb3d66c8327153d8fa7dd03f9c58d351107fe824c79e9b56b462935176cdf12a","affectsGlobalScope":true,"impliedFormat":1},{"version":"38f0219c9e23c915ef9790ab1d680440d95419ad264816fa15009a8851e79119","affectsGlobalScope":true,"impliedFormat":1},{"version":"69ab18c3b76cd9b1be3d188eaf8bba06112ebbe2f47f6c322b5105a6fbc45a2e","affectsGlobalScope":true,"impliedFormat":1},{"version":"a680117f487a4d2f30ea46f1b4b7f58bef1480456e18ba53ee85c2746eeca012","affectsGlobalScope":true,"impliedFormat":1},{"version":"2f11ff796926e0832f9ae148008138ad583bd181899ab7dd768a2666700b1893","affectsGlobalScope":true,"impliedFormat":1},{"version":"4de680d5bb41c17f7f68e0419412ca23c98d5749dcaaea1896172f06435891fc","affectsGlobalScope":true,"impliedFormat":1},{"version":"954296b30da6d508a104a3a0b5d96b76495c709785c1d11610908e63481ee667","affectsGlobalScope":true,"impliedFormat":1},{"version":"ac9538681b19688c8eae65811b329d3744af679e0bdfa5d842d0e32524c73e1c","affectsGlobalScope":true,"impliedFormat":1},{"version":"0a969edff4bd52585473d24995c5ef223f6652d6ef46193309b3921d65dd4376","affectsGlobalScope":true,"impliedFormat":1},{"version":"9e9fbd7030c440b33d021da145d3232984c8bb7916f277e8ffd3dc2e3eae2bdb","affectsGlobalScope":true,"impliedFormat":1},{"version":"811ec78f7fefcabbda4bfa93b3eb67d9ae166ef95f9bff989d964061cbf81a0c","affectsGlobalScope":true,"impliedFormat":1},{"version":"717937616a17072082152a2ef351cb51f98802fb4b2fdabd32399843875974ca","affectsGlobalScope":true,"impliedFormat":1},{"version":"d7e7d9b7b50e5f22c915b525acc5a49a7a6584cf8f62d0569e557c5cfc4b2ac2","affectsGlobalScope":true,"impliedFormat":1},{"version":"71c37f4c9543f31dfced6c7840e068c5a5aacb7b89111a4364b1d5276b852557","affectsGlobalScope":true,"impliedFormat":1},{"version":"576711e016cf4f1804676043e6a0a5414252560eb57de9faceee34d79798c850","affectsGlobalScope":true,"impliedFormat":1},{"version":"89c1b1281ba7b8a96efc676b11b264de7a8374c5ea1e6617f11880a13fc56dc6","affectsGlobalScope":true,"impliedFormat":1},{"version":"74f7fa2d027d5b33eb0471c8e82a6c87216223181ec31247c357a3e8e2fddc5b","affectsGlobalScope":true,"impliedFormat":1},{"version":"d6d7ae4d1f1f3772e2a3cde568ed08991a8ae34a080ff1151af28b7f798e22ca","affectsGlobalScope":true,"impliedFormat":1},{"version":"063600664504610fe3e99b717a1223f8b1900087fab0b4cad1496a114744f8df","affectsGlobalScope":true,"impliedFormat":1},{"version":"934019d7e3c81950f9a8426d093458b65d5aff2c7c1511233c0fd5b941e608ab","affectsGlobalScope":true,"impliedFormat":1},{"version":"52ada8e0b6e0482b728070b7639ee42e83a9b1c22d205992756fe020fd9f4a47","affectsGlobalScope":true,"impliedFormat":1},{"version":"3bdefe1bfd4d6dee0e26f928f93ccc128f1b64d5d501ff4a8cf3c6371200e5e6","affectsGlobalScope":true,"impliedFormat":1},{"version":"59fb2c069260b4ba00b5643b907ef5d5341b167e7d1dbf58dfd895658bda2867","affectsGlobalScope":true,"impliedFormat":1},{"version":"639e512c0dfc3fad96a84caad71b8834d66329a1f28dc95e3946c9b58176c73a","affectsGlobalScope":true,"impliedFormat":1},{"version":"368af93f74c9c932edd84c58883e736c9e3d53cec1fe24c0b0ff451f529ceab1","affectsGlobalScope":true,"impliedFormat":1},{"version":"8e7f8264d0fb4c5339605a15daadb037bf238c10b654bb3eee14208f860a32ea","affectsGlobalScope":true,"impliedFormat":1},{"version":"782dec38049b92d4e85c1585fbea5474a219c6984a35b004963b00beb1aab538","affectsGlobalScope":true,"impliedFormat":1},{"version":"0990a7576222f248f0a3b888adcb7389f957928ce2afb1cd5128169086ff4d29","impliedFormat":1},{"version":"eb5b19b86227ace1d29ea4cf81387279d04bb34051e944bc53df69f58914b788","affectsGlobalScope":true,"impliedFormat":1},{"version":"8a8eb4ebffd85e589a1cc7c178e291626c359543403d58c9cd22b81fab5b1fb9","impliedFormat":1},{"version":"87d9d29dbc745f182683f63187bf3d53fd8673e5fca38ad5eaab69798ed29fbc","impliedFormat":1},{"version":"472f5aab7edc498a0a761096e8e254c5bc3323d07a1e7f5f8b8ec0d6395b60a0","affectsGlobalScope":true,"impliedFormat":1},{"version":"cc69795d9954ee4ad57545b10c7bf1a7260d990231b1685c147ea71a6faa265c","impliedFormat":1},{"version":"8bc6c94ff4f2af1f4023b7bb2379b08d3d7dd80c698c9f0b07431ea16101f05f","impliedFormat":1},{"version":"1b61d259de5350f8b1e5db06290d31eaebebc6baafd5f79d314b5af9256d7153","impliedFormat":1},{"version":"57194e1f007f3f2cbef26fa299d4c6b21f4623a2eddc63dfeef79e38e187a36e","impliedFormat":1},{"version":"0f6666b58e9276ac3a38fdc80993d19208442d6027ab885580d93aec76b4ef00","impliedFormat":1},{"version":"05fd364b8ef02fb1e174fbac8b825bdb1e5a36a016997c8e421f5fab0a6da0a0","impliedFormat":1},{"version":"70521b6ab0dcba37539e5303104f29b721bfb2940b2776da4cc818c07e1fefc1","affectsGlobalScope":true,"impliedFormat":1},{"version":"ab41ef1f2cdafb8df48be20cd969d875602483859dc194e9c97c8a576892c052","affectsGlobalScope":true,"impliedFormat":1},{"version":"d153a11543fd884b596587ccd97aebbeed950b26933ee000f94009f1ab142848","affectsGlobalScope":true,"impliedFormat":1},{"version":"21d819c173c0cf7cc3ce57c3276e77fd9a8a01d35a06ad87158781515c9a438a","impliedFormat":1},{"version":"a79e62f1e20467e11a904399b8b18b18c0c6eea6b50c1168bf215356d5bebfaf","affectsGlobalScope":true,"impliedFormat":1},{"version":"49a5a44f2e68241a1d2bd9ec894535797998841c09729e506a7cbfcaa40f2180","affectsGlobalScope":true,"impliedFormat":1},{"version":"8e9c23ba78aabc2e0a27033f18737a6df754067731e69dc5f52823957d60a4b6","impliedFormat":1},{"version":"5929864ce17fba74232584d90cb721a89b7ad277220627cc97054ba15a98ea8f","impliedFormat":1},{"version":"763fe0f42b3d79b440a9b6e51e9ba3f3f91352469c1e4b3b67bfa4ff6352f3f4","impliedFormat":1},{"version":"25c8056edf4314820382a5fdb4bb7816999acdcb929c8f75e3f39473b87e85bc","impliedFormat":1},{"version":"c464d66b20788266e5353b48dc4aa6bc0dc4a707276df1e7152ab0c9ae21fad8","impliedFormat":1},{"version":"78d0d27c130d35c60b5e5566c9f1e5be77caf39804636bc1a40133919a949f21","impliedFormat":1},{"version":"c6fd2c5a395f2432786c9cb8deb870b9b0e8ff7e22c029954fabdd692bff6195","impliedFormat":1},{"version":"1d6e127068ea8e104a912e42fc0a110e2aa5a66a356a917a163e8cf9a65e4a75","impliedFormat":1},{"version":"5ded6427296cdf3b9542de4471d2aa8d3983671d4cac0f4bf9c637208d1ced43","impliedFormat":1},{"version":"7f182617db458e98fc18dfb272d40aa2fff3a353c44a89b2c0ccb3937709bfb5","impliedFormat":1},{"version":"cadc8aced301244057c4e7e73fbcae534b0f5b12a37b150d80e5a45aa4bebcbd","impliedFormat":1},{"version":"385aab901643aa54e1c36f5ef3107913b10d1b5bb8cbcd933d4263b80a0d7f20","impliedFormat":1},{"version":"9670d44354bab9d9982eca21945686b5c24a3f893db73c0dae0fd74217a4c219","impliedFormat":1},{"version":"0b8a9268adaf4da35e7fa830c8981cfa22adbbe5b3f6f5ab91f6658899e657a7","impliedFormat":1},{"version":"11396ed8a44c02ab9798b7dca436009f866e8dae3c9c25e8c1fbc396880bf1bb","impliedFormat":1},{"version":"ba7bc87d01492633cb5a0e5da8a4a42a1c86270e7b3d2dea5d156828a84e4882","impliedFormat":1},{"version":"4893a895ea92c85345017a04ed427cbd6a1710453338df26881a6019432febdd","impliedFormat":1},{"version":"c21dc52e277bcfc75fac0436ccb75c204f9e1b3fa5e12729670910639f27343e","impliedFormat":1},{"version":"13f6f39e12b1518c6650bbb220c8985999020fe0f21d818e28f512b7771d00f9","impliedFormat":1},{"version":"9b5369969f6e7175740bf51223112ff209f94ba43ecd3bb09eefff9fd675624a","impliedFormat":1},{"version":"4fe9e626e7164748e8769bbf74b538e09607f07ed17c2f20af8d680ee49fc1da","impliedFormat":1},{"version":"24515859bc0b836719105bb6cc3d68255042a9f02a6022b3187948b204946bd2","impliedFormat":1},{"version":"ea0148f897b45a76544ae179784c95af1bd6721b8610af9ffa467a518a086a43","impliedFormat":1},{"version":"24c6a117721e606c9984335f71711877293a9651e44f59f3d21c1ea0856f9cc9","impliedFormat":1},{"version":"dd3273ead9fbde62a72949c97dbec2247ea08e0c6952e701a483d74ef92d6a17","impliedFormat":1},{"version":"405822be75ad3e4d162e07439bac80c6bcc6dbae1929e179cf467ec0b9ee4e2e","impliedFormat":1},{"version":"0db18c6e78ea846316c012478888f33c11ffadab9efd1cc8bcc12daded7a60b6","impliedFormat":1},{"version":"e61be3f894b41b7baa1fbd6a66893f2579bfad01d208b4ff61daef21493ef0a8","impliedFormat":1},{"version":"bd0532fd6556073727d28da0edfd1736417a3f9f394877b6d5ef6ad88fba1d1a","impliedFormat":1},{"version":"89167d696a849fce5ca508032aabfe901c0868f833a8625d5a9c6e861ef935d2","impliedFormat":1},{"version":"615ba88d0128ed16bf83ef8ccbb6aff05c3ee2db1cc0f89ab50a4939bfc1943f","impliedFormat":1},{"version":"a4d551dbf8746780194d550c88f26cf937caf8d56f102969a110cfaed4b06656","impliedFormat":1},{"version":"8bd86b8e8f6a6aa6c49b71e14c4ffe1211a0e97c80f08d2c8cc98838006e4b88","impliedFormat":1},{"version":"317e63deeb21ac07f3992f5b50cdca8338f10acd4fbb7257ebf56735bf52ab00","impliedFormat":1},{"version":"4732aec92b20fb28c5fe9ad99521fb59974289ed1e45aecb282616202184064f","impliedFormat":1},{"version":"2e85db9e6fd73cfa3d7f28e0ab6b55417ea18931423bd47b409a96e4a169e8e6","impliedFormat":1},{"version":"c46e079fe54c76f95c67fb89081b3e399da2c7d109e7dca8e4b58d83e332e605","impliedFormat":1},{"version":"bf67d53d168abc1298888693338cb82854bdb2e69ef83f8a0092093c2d562107","impliedFormat":1},{"version":"1ca84b44ad1d8e4576f24904d8b95dd23b94ea67e1575f89614ac90062fc67f4","affectsGlobalScope":true,"impliedFormat":1},{"version":"6d586db0a09a9495ebb5dece28f54df9684bfbd6e1f568426ca153126dac4a40","impliedFormat":1},{"version":"7394959e5a741b185456e1ef5d64599c36c60a323207450991e7a42e08911419","impliedFormat":1},{"version":"8c0bcd6c6b67b4b503c11e91a1fb91522ed585900eab2ab1f61bba7d7caa9d6f","impliedFormat":1},{"version":"567b7f607f400873151d7bc63a049514b53c3c00f5f56e9e95695d93b66a138e","affectsGlobalScope":true,"impliedFormat":1},{"version":"f3e58c4c18a031cbb17abec7a4ad0bd5ae9fc70c1f4ba1e7fb921ad87c504aca","impliedFormat":1},{"version":"84c1930e33d1bb12ad01bcbe11d656f9646bd21b2fb2afd96e8e10615a021aef","impliedFormat":1},{"version":"35ec8b6760fd7138bbf5809b84551e31028fb2ba7b6dc91d95d098bf212ca8b4","affectsGlobalScope":true,"impliedFormat":1},{"version":"5524481e56c48ff486f42926778c0a3cce1cc85dc46683b92b1271865bcf015a","impliedFormat":1},{"version":"4b87f767c7bc841511113c876a6b8bf1fd0cb0b718c888ad84478b372ec486b1","affectsGlobalScope":true,"impliedFormat":1},{"version":"8d04e3640dd9eb67f7f1e5bd3d0bf96c784666f7aefc8ac1537af6f2d38d4c29","impliedFormat":1},{"version":"9d19808c8c291a9010a6c788e8532a2da70f811adb431c97520803e0ec649991","impliedFormat":1},{"version":"2bf469abae4cc9c0f340d4e05d9d26e37f936f9c8ca8f007a6534f109dcc77e4","impliedFormat":1},{"version":"4aacb0dd020eeaef65426153686cc639a78ec2885dc72ad220be1d25f1a439df","impliedFormat":1},{"version":"f0bd7e6d931657b59605c44112eaf8b980ba7f957a5051ed21cb93d978cf2f45","impliedFormat":1},{"version":"71450bbc2d82821d24ca05699a533e72758964e9852062c53b30f31c36978ab8","affectsGlobalScope":true,"impliedFormat":1},{"version":"0ada07543808f3b967624645a8e1ccd446f8b01ade47842acf1328aec899fed0","affectsGlobalScope":true,"impliedFormat":1},{"version":"4c21aaa8257d7950a5b75a251d9075b6a371208fc948c9c8402f6690ef3b5b55","impliedFormat":1},{"version":"b5895e6353a5d708f55d8685c38a235c3a6d8138e374dee8ceb8ffde5aa8002a","impliedFormat":1},{"version":"54c4f21f578864961efc94e8f42bc893a53509e886370ec7dd602e0151b9266c","impliedFormat":1},{"version":"de735eca2c51dd8b860254e9fdb6d9ec19fe402dfe597c23090841ce3937cfc5","impliedFormat":1},{"version":"4ff41188773cbf465807dd2f7059c7494cbee5115608efc297383832a1150c43","impliedFormat":1},{"version":"5650cf3dace09e7c25d384e3e6b818b938f68f4e8de96f52d9c5a1b3db068e86","impliedFormat":1},{"version":"1354ca5c38bd3fd3836a68e0f7c9f91f172582ba30ab15bb8c075891b91502b7","affectsGlobalScope":true,"impliedFormat":1},{"version":"5155da3047ef977944d791a2188ff6e6c225f6975cc1910ab7bb6838ab84cede","impliedFormat":1},{"version":"93f437e1398a4f06a984f441f7fa7a9f0535c04399619b5c22e0b87bdee182cb","impliedFormat":1},{"version":"afbe24ab0d74694372baa632ecb28bb375be53f3be53f9b07ecd7fc994907de5","impliedFormat":1},{"version":"e16d218a30f6a6810b57f7e968124eaa08c7bb366133ea34bbf01e7cd6b8c0ad","affectsGlobalScope":true,"impliedFormat":1},{"version":"eb8692dea24c27821f77e397272d9ed2eda0b95e4a75beb0fdda31081d15a8ae","affectsGlobalScope":true,"impliedFormat":1},{"version":"9e043a1bc8fbf2a255bccf9bf27e0f1caf916c3b0518ea34aa72357c0afd42ec","impliedFormat":1},{"version":"b4f70ec656a11d570e1a9edce07d118cd58d9760239e2ece99306ee9dfe61d02","impliedFormat":1},{"version":"3bc2f1e2c95c04048212c569ed38e338873f6a8593930cf5a7ef24ffb38fc3b6","impliedFormat":1},{"version":"8145e07aad6da5f23f2fcd8c8e4c5c13fb26ee986a79d03b0829b8fce152d8b2","impliedFormat":1},{"version":"f9d9d753d430ed050dc1bf2667a1bab711ccbb1c1507183d794cc195a5b085cc","impliedFormat":1},{"version":"9eece5e586312581ccd106d4853e861aaaa1a39f8e3ea672b8c3847eedd12f6e","impliedFormat":1},{"version":"5b6844ad931dcc1d3aca53268f4bd671428421464b1286746027aede398094f2","impliedFormat":1},{"version":"37ba7b45141a45ce6e80e66f2a96c8a5ab1bcef0fc2d0f56bb58df96ec67e972","impliedFormat":1},{"version":"125d792ec6c0c0f657d758055c494301cc5fdb327d9d9d5960b3f129aff76093","impliedFormat":1},{"version":"0225ecb9ed86bdb7a2c7fd01f1556906902929377b44483dc4b83e03b3ef227d","affectsGlobalScope":true,"impliedFormat":1},{"version":"1851a3b4db78664f83901bb9cac9e45e03a37bb5933cc5bf37e10bb7e91ab4eb","impliedFormat":1},{"version":"461e54289e6287e8494a0178ba18182acce51a02bca8dea219149bf2cf96f105","impliedFormat":1},{"version":"12ed4559eba17cd977aa0db658d25c4047067444b51acfdcbf38470630642b23","affectsGlobalScope":true,"impliedFormat":1},{"version":"f3ffabc95802521e1e4bcba4c88d8615176dc6e09111d920c7a213bdda6e1d65","impliedFormat":1},{"version":"e31e51c55800014d926e3f74208af49cb7352803619855c89296074d1ecbb524","impliedFormat":1},{"version":"ae56f65caf3be91108707bd8dfbccc2a57a91feb5daabf7165a06a945545ed26","impliedFormat":1},{"version":"a136d5de521da20f31631a0a96bf712370779d1c05b7015d7019a9b2a0446ca9","impliedFormat":1},{"version":"dfb96ba5177b68003deec9e773c47257da5c4c8a74053d8956389d832df72002","affectsGlobalScope":true,"impliedFormat":1},{"version":"92d3070580cf72b4bb80959b7f16ede9a3f39e6f4ef2ac87cfa4561844fdc69f","affectsGlobalScope":true,"impliedFormat":1},{"version":"d3dffd70e6375b872f0b4e152de4ae682d762c61a24881ecc5eb9f04c5caf76f","impliedFormat":1},{"version":"613deebaec53731ff6b74fe1a89f094b708033db6396b601df3e6d5ab0ec0a47","impliedFormat":1},{"version":"d91a7d8b5655c42986f1bdfe2105c4408f472831c8f20cf11a8c3345b6b56c8c","impliedFormat":1},{"version":"e56eb632f0281c9f8210eb8c86cc4839a427a4ffffcfd2a5e40b956050b3e042","affectsGlobalScope":true,"impliedFormat":1},{"version":"e8a979b8af001c9fc2e774e7809d233c8ca955a28756f52ee5dee88ccb0611d2","impliedFormat":1},{"version":"cac793cc47c29e26e4ac3601dcb00b4435ebed26203485790e44f2ad8b6ad847","impliedFormat":1},{"version":"8caa5c86be1b793cd5f599e27ecb34252c41e011980f7d61ae4989a149ff6ccc","impliedFormat":1},{"version":"3609e455ffcba8176c8ce0aa57f8258fe10cf03987e27f1fab68f702b4426521","impliedFormat":1},{"version":"d1bd4e51810d159899aad1660ccb859da54e27e08b8c9862b40cd36c1d9ff00f","impliedFormat":1},{"version":"17ed71200119e86ccef2d96b73b02ce8854b76ad6bd21b5021d4269bec527b5f","impliedFormat":1},{"version":"1cfa8647d7d71cb03847d616bd79320abfc01ddea082a49569fda71ac5ece66b","impliedFormat":1},{"version":"bb7a61dd55dc4b9422d13da3a6bb9cc5e89be888ef23bbcf6558aa9726b89a1c","impliedFormat":1},{"version":"db6d2d9daad8a6d83f281af12ce4355a20b9a3e71b82b9f57cddcca0a8964a96","impliedFormat":1},{"version":"cfe4ef4710c3786b6e23dae7c086c70b4f4835a2e4d77b75d39f9046106e83d3","impliedFormat":1},{"version":"cbea99888785d49bb630dcbb1613c73727f2b5a2cf02e1abcaab7bcf8d6bf3c5","impliedFormat":1},{"version":"3b8f725c3d5ffb64bf876c87409686875102c6f7450b268d8f5188b6920f7c25","impliedFormat":1},{"version":"a86f82d646a739041d6702101afa82dcb935c416dd93cbca7fd754fd0282ce1f","impliedFormat":1},{"version":"2dad084c67e649f0f354739ec7df7c7df0779a28a4f55c97c6b6883ae850d1ce","impliedFormat":1},{"version":"fa5bbc7ab4130dd8cdc55ea294ec39f76f2bc507a0f75f4f873e38631a836ca7","impliedFormat":1},{"version":"df45ca1176e6ac211eae7ddf51336dc075c5314bc5c253651bae639defd5eec5","impliedFormat":1},{"version":"cf86de1054b843e484a3c9300d62fbc8c97e77f168bbffb131d560ca0474d4a8","impliedFormat":1},{"version":"37f7b8e560025858aae5195ca74a3e95ecd55591e2babc0acd57bc1dab4ea8ea","impliedFormat":1},{"version":"e2d5483c9a79900ba9d6012135f18b662b3ca1d33fde4f5e39b71f74e47d6331","impliedFormat":1},{"version":"22b9fab85e85b95f6378b5a2bd43c9d2e15106d760e0e58111c416fe224cc76f","impliedFormat":1},{"version":"fc46f093d1b754a8e3e34a071a1dd402f42003927676757a9a10c6f1d195a35b","impliedFormat":1},{"version":"b7b3258e8d47333721f9d4c287361d773f8fa88e52d1148812485d9fc06d2577","impliedFormat":1},{"version":"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855","impliedFormat":1},{"version":"49e567e0aa388ab416eeb7a7de9bce5045a7b628bad18d1f6fa9d3eacee7bc3f","impliedFormat":1},{"version":"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855","impliedFormat":1},{"version":"87eaecac33864ecec8972b1773c5d897f0f589deb7ac8fe0dcdf4b721b06e28d","impliedFormat":1},{"version":"47e5af2a841356a961f815e7c55d72554db0c11b4cba4d0caab91f8717846a94","impliedFormat":1},{"version":"4c91cc1ab59b55d880877ccf1999ded0bb2ebc8e3a597c622962d65bf0e76be8","impliedFormat":1},{"version":"fa1ea09d3e073252eccff2f6630a4ce5633cc2ff963ba672dd8fd6783108ea83","impliedFormat":1},{"version":"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855","impliedFormat":1},{"version":"309816cd6e597f4d4b080bc5e36215c6b78196f744d578adf61589bee5fd7eea","impliedFormat":1},{"version":"bdb44eca306ff5b62bcf2b4e70e96a40987e018029d95565e2f234aad80830cf","impliedFormat":1},{"version":"edaa0bbf2891b17f904a67aef7f9d53371c993fe3ff6dec708c2aff6083b01af","impliedFormat":1},{"version":"89aece12f9cd6d736ae7c350800f257a2363f6322ae8f998da73153fb405d8af","impliedFormat":1},{"version":"d23518a5f155f1a3e07214baf0295687507122ae2e6e9bd5e772551ebd4b3157","impliedFormat":1},{"version":"aa9a92be255ec97f669ea89678fafcbd35d165f65b68ff22685263f6eaeb3c9c","impliedFormat":1},{"version":"fa8b514302736759e491d3df074a61f54ed1a6a69b4aadee05dbcdda53f881c3","impliedFormat":1},{"version":"e8da637cbd6ed1cf6c36e9424f6bcee4515ca2c677534d4006cbd9a05f930f0c","impliedFormat":1},{"version":"ca1b882a105a1972f82cc58e3be491e7d750a1eb074ffd13b198269f57ed9e1b","impliedFormat":1},{"version":"c9d71f340f1a4576cd2a572f73a54dc7212161fa172dfe3dea64ac627c8fcb50","impliedFormat":1},{"version":"3867ca0e9757cc41e04248574f4f07b8f9e3c0c2a796a5eb091c65bfd2fc8bdb","impliedFormat":1},{"version":"6c66f6f7d9ff019a644ff50dd013e6bf59be4bf389092948437efa6b77dc8f9a","impliedFormat":1},{"version":"4e10622f89fea7b05dd9b52fb65e1e2b5cbd96d4cca3d9e1a60bb7f8a9cb86a1","impliedFormat":1},{"version":"ef2d1bd01d144d426b72db3744e7a6b6bb518a639d5c9c8d86438fb75a3b1934","impliedFormat":1},{"version":"b9750fe7235da7d8bf75cb171bf067b7350380c74271d3f80f49aea7466b55b5","impliedFormat":1},{"version":"ac60bbee0d4235643cc52b57768b22de8c257c12bd8c2039860540cab1fa1d82","impliedFormat":1},{"version":"973b59a17aaa817eb205baf6c132b83475a5c0a44e8294a472af7793b1817e89","impliedFormat":1},{"version":"ada39cbb2748ab2873b7835c90c8d4620723aedf323550e8489f08220e477c7f","impliedFormat":1},{"version":"6e5f5cee603d67ee1ba6120815497909b73399842254fc1e77a0d5cdc51d8c9c","impliedFormat":1},{"version":"f79e0681538ef94c273a46bb1a073b4fe9fdc93ef7f40cc2c3abd683b85f51fc","impliedFormat":1},{"version":"70f3814c457f54a7efe2d9ce9d2686de9250bb42eb7f4c539bd2280a42e52d33","impliedFormat":1},{"version":"17ace83a5bea3f1da7e0aef7aab0f52bca22619e243537a83a89352a611b837d","impliedFormat":1},{"version":"ef61792acbfa8c27c9bd113f02731e66229f7d3a169e3c1993b508134f1a58e0","impliedFormat":1},{"version":"6cf2d240d4e449ccfee82aff7ce0fd1890c1b6d4f144ec003aa51f7f70f68935","impliedFormat":1},{"version":"f6404e7837b96da3ea4d38c4f1a3812c96c9dcdf264e93d5bdb199f983a3ef4b","impliedFormat":1},{"version":"c5426dbfc1cf90532f66965a7aa8c1136a78d4d0f96d8180ecbfc11d7722f1a5","impliedFormat":1},{"version":"65a15fc47900787c0bd18b603afb98d33ede930bed1798fc984d5ebb78b26cf9","impliedFormat":1},{"version":"9d202701f6e0744adb6314d03d2eb8fc994798fc83d91b691b75b07626a69801","impliedFormat":1},{"version":"de9d2df7663e64e3a91bf495f315a7577e23ba088f2949d5ce9ec96f44fba37d","impliedFormat":1},{"version":"c7af78a2ea7cb1cd009cfb5bdb48cd0b03dad3b54f6da7aab615c2e9e9d570c5","impliedFormat":1},{"version":"1dc574e42493e8bf9bb37be44d9e38c5bd7bbc04f884e5e58b4d69636cb192b3","impliedFormat":1},{"version":"9deab571c42ed535c17054f35da5b735d93dc454d83c9a5330ecc7a4fb184e9e","affectsGlobalScope":true,"impliedFormat":1},{"version":"db01d18853469bcb5601b9fc9826931cc84cc1a1944b33cad76fd6f1e3d8c544","affectsGlobalScope":true,"impliedFormat":1},{"version":"6b8e8c0331a0c2e9fb53b8b0d346e44a8db8c788dae727a2c52f4cf3bd857f0d","impliedFormat":1},{"version":"903e299a28282fa7b714586e28409ed73c3b63f5365519776bf78e8cf173db36","affectsGlobalScope":true,"impliedFormat":1},{"version":"fa6c12a7c0f6b84d512f200690bfc74819e99efae69e4c95c4cd30f6884c526e","impliedFormat":1},{"version":"f1c32f9ce9c497da4dc215c3bc84b722ea02497d35f9134db3bb40a8d918b92b","impliedFormat":1},{"version":"b73c319af2cc3ef8f6421308a250f328836531ea3761823b4cabbd133047aefa","affectsGlobalScope":true,"impliedFormat":1},{"version":"e433b0337b8106909e7953015e8fa3f2d30797cea27141d1c5b135365bb975a6","impliedFormat":1},{"version":"dd3900b24a6a8745efeb7ad27629c0f8a626470ac229c1d73f1fe29d67e44dca","impliedFormat":1},{"version":"ddff7fc6edbdc5163a09e22bf8df7bef75f75369ebd7ecea95ba55c4386e2441","impliedFormat":1},{"version":"106c6025f1d99fd468fd8bf6e5bda724e11e5905a4076c5d29790b6c3745e50c","impliedFormat":1},{"version":"ec29be0737d39268696edcec4f5e97ce26f449fa9b7afc2f0f99a86def34a418","impliedFormat":1},{"version":"8945919709e0c6069c32ca26a675a0de90fd2ad70d5bc3ba281c628729a0c39d","impliedFormat":1},{"version":"ec6cba1c02c675e4dd173251b156792e8d3b0c816af6d6ad93f1a55d674591aa","impliedFormat":1},{"version":"763ee3998716d599321e34b7f7e93a8e57bef751206325226ebf088bf75ea460","impliedFormat":1},{"version":"e15d3c84d5077bb4a3adee4c791022967b764dc41cb8fa3cfa44d4379b2c95f5","impliedFormat":1},{"version":"3556cfbab7b43da96d15a442ddbb970e1f2fc97876d055b6555d86d7ac57dae5","impliedFormat":1},{"version":"437751e0352c6e924ddf30e90849f1d9eb00ca78c94d58d6a37202ec84eb8393","impliedFormat":1},{"version":"48e8af7fdb2677a44522fd185d8c87deff4d36ee701ea003c6c780b1407a1397","impliedFormat":1},{"version":"606e6f841ba9667de5d83ca458449f0ed8c511ba635f753eaa731e532dea98c7","impliedFormat":1},{"version":"7c0d4fc71fe32cedb758c7e3c08715235a51e5a22d184306a59dae10a9c7ffaa","impliedFormat":1},{"version":"ce8a0b21e80cf5f10adc9336b46ffc666696d1373a763b170baf69a722f85d67","impliedFormat":1},{"version":"2e4f37ffe8862b14d8e24ae8763daaa8340c0df0b859d9a9733def0eee7562d9","impliedFormat":1},{"version":"13283350547389802aa35d9f2188effaeac805499169a06ef5cd77ce2a0bd63f","impliedFormat":1},{"version":"680793958f6a70a44c8d9ae7d46b7a385361c69ac29dcab3ed761edce1c14ab8","impliedFormat":1},{"version":"6ac6715916fa75a1f7ebdfeacac09513b4d904b667d827b7535e84ff59679aff","impliedFormat":1},{"version":"baeffe1b7d836196d497eb755699718deb729a2033078a018f037a14ecaeb9a7","impliedFormat":1},{"version":"39da0a8478aede3a55308089e231c5966b2196e7201494280b1e19f8ec8e24d4","impliedFormat":1},{"version":"90be1a7f573bad71331ff10deeadce25b09034d3d27011c2155bcb9cb9800b7f","impliedFormat":1},{"version":"bc7221c9a8dc71587ff784120f7707985627282dad0a99439e893a1588651ef0","impliedFormat":1},{"version":"438c7513b1df91dcef49b13cd7a1c4720f91a36e88c1df731661608b7c055f10","impliedFormat":1},{"version":"ad444a874f011d3a797f1a41579dbfcc6b246623f49c20009f60e211dbd5315e","impliedFormat":1},{"version":"1124613ba0669e7ea5fb785ede1c3f254ed1968335468b048b8fc35c172393de","impliedFormat":1},{"version":"5fa139523e35fd907f3dd6c2e38ef2066687b27ed88e2680783e05662355ac04","impliedFormat":1},{"version":"9c250db4bab4f78fad08be7f4e43e962cc143e0f78763831653549ceb477344a","impliedFormat":1},{"version":"9385cdc09850950bc9b59cca445a3ceb6fcca32b54e7b626e746912e489e535e","impliedFormat":1},{"version":"0a72186f94215d020cb386f7dca81d7495ab6c17066eb07d0f44a5bf33c1b21a","impliedFormat":1},{"version":"db7c948e2e69559324be7628cb63296ec8986d60f26173f9e324aeb8a2fe23d8","impliedFormat":1},{"version":"9c2353ef1fb353a1c8f30af2cf104f0bc64ebc2fcdb98c2834d451bd654664ab","impliedFormat":1},{"version":"63a8e96f65a22604eae82737e409d1536e69a467bb738bec505f4f97cce9d878","impliedFormat":1},{"version":"3fd78152a7031315478f159c6a5872c712ece6f01212c78ea82aef21cb0726e2","impliedFormat":1},{"version":"7fda4c0e3f50513286029633c458ee82cee563cd6af20b92e43b4425c969c146","impliedFormat":1},{"version":"cda4052f66b1e6cb7cf1fdfd96335d1627aa24a3b8b82ba4a9f873ec3a7bcde8","impliedFormat":1},{"version":"703733dde084b7e856f5940f9c3c12007ca62858accb9482c2b65e030877702d","impliedFormat":1},{"version":"413cb597cc5933562ec064bfb1c3a9164ef5d2f09e5f6b7bd19f483d5352449e","impliedFormat":1},{"version":"fd933f824347f9edd919618a76cdb6a0c0085c538115d9a287fa0c7f59957ab3","impliedFormat":1},{"version":"6ac6715916fa75a1f7ebdfeacac09513b4d904b667d827b7535e84ff59679aff","impliedFormat":1},{"version":"6a1aa3e55bdc50503956c5cd09ae4cd72e3072692d742816f65c66ca14f4dfdd","impliedFormat":1},{"version":"ab75cfd9c4f93ffd601f7ca1753d6a9d953bbedfbd7a5b3f0436ac8a1de60dfa","impliedFormat":1},{"version":"6cc79183c88040697e1552ba81c5245b0c701b965623774587c4b9d1e7497278","impliedFormat":1},{"version":"b73cbf0a72c8800cf8f96a9acfe94f3ad32ca71342a8908b8ae484d61113f647","impliedFormat":1},{"version":"bae6dd176832f6423966647382c0d7ba9e63f8c167522f09a982f086cd4e8b23","impliedFormat":1},{"version":"1364f64d2fb03bbb514edc42224abd576c064f89be6a990136774ecdd881a1da","impliedFormat":1},{"version":"c9958eb32126a3843deedda8c22fb97024aa5d6dd588b90af2d7f2bfac540f23","impliedFormat":1},{"version":"950fb67a59be4c2dbe69a5786292e60a5cb0e8612e0e223537784c731af55db1","impliedFormat":1},{"version":"e927c2c13c4eaf0a7f17e6022eee8519eb29ef42c4c13a31e81a611ab8c95577","impliedFormat":1},{"version":"07ca44e8d8288e69afdec7a31fa408ce6ab90d4f3d620006701d5544646da6aa","impliedFormat":1},{"version":"82c27d4cf380b0e6cd62628f069b850298d20051f0b7b0a1904fdb38c53fa7a6","impliedFormat":1},{"version":"c97b9278c8ce212c1bdf4fae9c77d58c15565d4ebf663d761a9deb924b6ca8b3","impliedFormat":1},{"version":"8bb6e7ce91ec84336203e87010b1198514548c2e44789752c1741eaac02f2431","impliedFormat":1},{"version":"b33ac7d8d7d1bfc8cc06c75d1ee186d21577ab2026f482e29babe32b10b26512","impliedFormat":1},{"version":"24f8f342c14c911eedfee43074c6a0d0a5ebb5ec984353bffaeadddb3f6a6b1c","impliedFormat":1},{"version":"6459054aabb306821a043e02b89d54da508e3a6966601a41e71c166e4ea1474f","impliedFormat":1},{"version":"03d4a10c21ac451b682246f3261b769247baf774c4878551c02256ae98299b1c","impliedFormat":1},{"version":"2d9b710fee8c3d7eabee626af8fd6ec2cf6f71e6b7429b307b8f67d70b1707c5","impliedFormat":1},{"version":"652a4bbefba6aa309bfc3063f59ed1a2e739c1d802273b0e6e0aa7082659f3b3","impliedFormat":1},{"version":"d7ca19bfb1ba4c3ef59d43bd7cd3719d8c5ffb60a9b6f402dee4e229f4d921aa","impliedFormat":1},{"version":"0c0a85a19b60f2ec18a32ff051bb1423860977a16b645dbf159baa7202bc633b","impliedFormat":1},{"version":"fc5bdc1d13667041055811568043956c75150923d8b9a32b989ac7588418ce47","impliedFormat":1},{"version":"f974e4a06953682a2c15d5bd5114c0284d5abf8bc0fe4da25cb9159427b70072","impliedFormat":1},{"version":"d3b290cc3c08cbde2b463df2616b948fb32733dafe3ac29b9e6ded26baee5489","impliedFormat":1},{"version":"94404c4a878fe291e7578a2a80264c6f18e9f1933fbb57e48f0eb368672e389c","impliedFormat":1},{"version":"5c1b7f03aa88be854bc15810bfd5bd5a1943c5a7620e1c53eddd2a013996343e","impliedFormat":1},{"version":"f416c9c3eee9d47ff49132c34f96b9180e50485d435d5748f0e8b72521d28d2e","impliedFormat":1},{"version":"9558d365d0e72b6d9bd8c1742fe1185f983965c6d2eff88a117a59b9f51d3c5f","impliedFormat":1},{"version":"6cc2961fbe8d32e34fd4c7f1b7045353016fff50df98bc31af7c7d1b4b6eb552","impliedFormat":1},{"version":"01aa917531e116485beca44a14970834687b857757159769c16b228eb1e49c5f","impliedFormat":1},{"version":"a2e1f7010ae5f746b937621840cb87dee9eeb69188d32880bd9752029084212c","impliedFormat":1},{"version":"dd30eb34b5c4597a568de0efb8b34e328c224648c258759ac541beb16256ffb6","impliedFormat":1},{"version":"6129bd7098131a0e346352901bc8d461a76d0568686bb0e1f8499df91fde8a1f","impliedFormat":1},{"version":"7cd7923a36835c1194a92b808068a524c4e7c0ff7bdc8712865800e6963d75da","impliedFormat":1},{"version":"82200d39d66c91f502f74c85db8c7a8d56cfc361c20d7da6d7b68a4eeaaefbf4","impliedFormat":1},{"version":"741067675daa6d4334a2dc80a4452ca3850e89d5852e330db7cb2b5f867173b1","impliedFormat":1},{"version":"a1c8542ed1189091dd39e732e4390882a9bcd15c0ca093f6e9483eba4e37573f","impliedFormat":1},{"version":"131b1475d2045f20fb9f43b7aa6b7cb51f25250b5e4c6a1d4aa3cf4dd1a68793","impliedFormat":1},{"version":"3a17f09634c50cce884721f54fd9e7b98e03ac505889c560876291fcf8a09e90","impliedFormat":1},{"version":"32531dfbb0cdc4525296648f53b2b5c39b64282791e2a8c765712e49e6461046","impliedFormat":1},{"version":"0ce1b2237c1c3df49748d61568160d780d7b26693bd9feb3acb0744a152cd86d","impliedFormat":1},{"version":"e489985388e2c71d3542612685b4a7db326922b57ac880f299da7026a4e8a117","impliedFormat":1},{"version":"76264a4df0b7c78b7b12dfaedc05d9f1016f27be1f3d0836417686ff6757f659","impliedFormat":1},{"version":"c0fabd699e6e0b6bfc1728c048e52737b73fb6609eeeae0f7f4775ff14ff2df6","affectsGlobalScope":true,"impliedFormat":1},{"version":"fd1b9d883b9446f1e1da1e1033a6a98995c25fbf3c10818a78960e2f2917d10c","impliedFormat":1},{"version":"19252079538942a69be1645e153f7dbbc1ef56b4f983c633bf31fe26aeac32cd","impliedFormat":1},{"version":"4dd4f6e28afc1ee30ce76ffc659d19e14dff29cb19b7747610ada3535b7409af","impliedFormat":1},{"version":"1640728521f6ab040fc4a85edd2557193839d0cd0e41c02004fc8d415363d4e2","impliedFormat":1},{"version":"65c24a8baa2cca1de069a0ba9fba82a173690f52d7e2d0f1f7542d59d5eb4db0","impliedFormat":1},{"version":"ec9fd890d681789cb0aa9efbc50b1e0afe76fbf3c49c3ac50ff80e90e29c6bcb","impliedFormat":1},{"version":"5fbd292aa08208ae99bf06d5da63321fdc768ee43a7a104980963100a3841752","impliedFormat":1},{"version":"9eac5a6beea91cfb119688bf44a5688b129b804ede186e5e2413572a534c21bb","impliedFormat":1},{"version":"e81bf06c0600517d8f04cc5de398c28738bfdf04c91fb42ad835bfe6b0d63a23","impliedFormat":1},{"version":"363996fe13c513a7793aa28ffb05b5d0230db2b3d21b7bfaf21f79e4cde54b4e","impliedFormat":1},{"version":"b7fff2d004c5879cae335db8f954eb1d61242d9f2d28515e67902032723caeab","impliedFormat":1},{"version":"5f3dc10ae646f375776b4e028d2bed039a93eebbba105694d8b910feebbe8b9c","impliedFormat":1},{"version":"7f6c48cacd08c1b1e29737b8221b7661e6b855767f8778f9a181fa2f74c09d21","impliedFormat":1},{"version":"4545c1a1ceca170d5d83452dd7c4994644c35cf676a671412601689d9a62da35","impliedFormat":1},{"version":"15959543f93f27e8e2b1a012fe28e14b682034757e2d7a6c1f02f87107fc731e","impliedFormat":1},{"version":"a2d648d333cf67b9aeac5d81a1a379d563a8ffa91ddd61c6179f68de724260ff","impliedFormat":1},{"version":"4e828bf688597c32905215785730cbdb603b54e284d472a23fc0195c6d4aeee8","impliedFormat":1},{"version":"a3f41ed1b4f2fc3049394b945a68ae4fdefd49fa1739c32f149d32c0545d67f5","impliedFormat":1},{"version":"4da80db9ed5a1a20fd5bfce863dd178b8928bcaf4a3d75e8657bcae32e572ede","impliedFormat":1},{"version":"47699512e6d8bebf7be488182427189f999affe3addc1c87c882d36b7f2d0b0e","impliedFormat":1},{"version":"f72ee46ae3f73e6c5ff0da682177251d80500dd423bfd50286124cd0ca11e160","impliedFormat":1},{"version":"898b714aad9cfd0e546d1ad2c031571de7622bd0f9606a499bee193cf5e7cf0c","impliedFormat":1},{"version":"d707fb7ca32930495019a4c85500385f6850c785ee0987a1b6bcad6ade95235e","impliedFormat":1},{"version":"fedebeae32c5cdd1a85b4e0504a01996e4a8adf3dfa72876920d3dd6e42978e7","impliedFormat":1},{"version":"5d26aae738fa3efc87c24f6e5ec07c54694e6bcf431cc38d3da7576d6bb35bd6","impliedFormat":1},{"version":"cdf21eee8007e339b1b9945abf4a7b44930b1d695cc528459e68a3adc39a622e","impliedFormat":1},{"version":"e0aa1079d58134e55ad2f73508ad1be565a975f2247245d76c64c1ca9e5e5b26","impliedFormat":1},{"version":"cd0c5af42811a4a56a0f77856cfa6c170278e9522888db715b11f176df3ff1f2","impliedFormat":1},{"version":"68f81dad9e8d7b7aa15f35607a70c8b68798cf579ac44bd85325b8e2f1fb3600","impliedFormat":1},{"version":"1de80059b8078ea5749941c9f863aa970b4735bdbb003be4925c853a8b6b4450","impliedFormat":1},{"version":"1d079c37fa53e3c21ed3fa214a27507bda9991f2a41458705b19ed8c2b61173d","impliedFormat":1},{"version":"94fd3ce628bd94a2caf431e8d85901dbe3a64ab52c0bd1dbe498f63ca18789f7","impliedFormat":1},{"version":"5835a6e0d7cd2738e56b671af0e561e7c1b4fb77751383672f4b009f4e161d70","impliedFormat":1},{"version":"c0eeaaa67c85c3bb6c52b629ebbfd3b2292dc67e8c0ffda2fc6cd2f78dc471e6","impliedFormat":1},{"version":"4b7f74b772140395e7af67c4841be1ab867c11b3b82a51b1aeb692822b76c872","impliedFormat":1},{"version":"27be6622e2922a1b412eb057faa854831b95db9db5035c3f6d4b677b902ab3b7","impliedFormat":1},{"version":"2470a2412a59c6177cd4408dd7edb099ca7ace68c0187f54187dfee56dc9c5aa","impliedFormat":99},{"version":"c2008605e78208cfa9cd70bd29856b72dda7ad89df5dc895920f8e10bcb9cd0a","impliedFormat":99},{"version":"ec61ebac4d71c4698318673efbb5c481a6c4d374da8d285f6557541a5bd318d0","impliedFormat":99},{"version":"16fd66ae997b2f01c972531239da90fbf8ab4022bb145b9587ef746f6cecde5a","affectsGlobalScope":true,"impliedFormat":1},{"version":"fc8fbee8f73bf5ffd6ba08ba1c554d6f714c49cae5b5e984afd545ab1b7abe06","affectsGlobalScope":true,"impliedFormat":1},{"version":"3586f5ea3cc27083a17bd5c9059ede9421d587286d5a47f4341a4c2d00e4fa91","impliedFormat":1},{"version":"521fc35a732f1a19f5d52024c2c22e257aa63258554968f7806a823be2f82b03","impliedFormat":1},{"version":"9b979039facccd0d5af78cfc9b5c3b15345999f53ceca6c5b3cb504992a14912","signature":"b0bcc3c474cf34eabaa3c6a23f95734d9999345db37b96201ac285771310b8ff"},{"version":"f452227174ee4ab9b9b434e8ce867ea1cae49e3c45e42b4034bf5abfb8ab4790","signature":"815bece783e31769424539ac40774895075d23c1d379b4ddbafa952a4a7cfa2a"},{"version":"9043966b8b5a32497b04bcc9a34502dbae8e34c59eb2005cb8c92729dd848569","signature":"3eb972ae325aa293fdb6077cdf956f209ee6ea34b4e874ff7ec8686b3079972f"},{"version":"96d14f21b7652903852eef49379d04dbda28c16ed36468f8c9fa08f7c14c9538","impliedFormat":1},{"version":"104c67f0da1bdf0d94865419247e20eded83ce7f9911a1aa75fc675c077ca66e","impliedFormat":1},{"version":"cc0d0b339f31ce0ab3b7a5b714d8e578ce698f1e13d7f8c60bfb766baeb1d35c","impliedFormat":1},{"version":"d3f2d715f57df3f04bf7b16dde01dec10366f64fce44503c92b8f78f614c1769","impliedFormat":1},{"version":"b78cd10245a90e27e62d0558564f5d9a16576294eee724a59ae21b91f9269e4a","impliedFormat":1},{"version":"936eb43a381712a8ec1249f2afc819f6fc7ca68f10dfec71762b428dfdc53bf1","impliedFormat":1},{"version":"2f5747b1508ccf83fad0c251ba1e5da2f5a30b78b09ffa1cfaf633045160afed","impliedFormat":1},{"version":"86ea91bfa7fef1eeb958056f30f1db4e0680bc9b5132e5e9d6e9cfd773c0c4fd","affectsGlobalScope":true,"impliedFormat":1},{"version":"b71c603a539078a5e3a039b20f2b0a0d1708967530cf97dec8850a9ca45baa2b","impliedFormat":1},{"version":"0e13570a7e86c6d83dd92e81758a930f63747483e2cd34ef36fcdb47d1f9726a","impliedFormat":1},{"version":"5c45abf1e13e4463eacfd5dedda06855da8748a6a6cb3334f582b52e219acc04","impliedFormat":1},{"version":"736097ddbb2903bef918bb3b5811ef1c9c5656f2a73bd39b22a91b9cc2525e50","impliedFormat":1},{"version":"4340936f4e937c452ae783514e7c7bbb7fc06d0c97993ff4865370d0962bb9cf","impliedFormat":1},{"version":"5fc6e6b8232254d80ed6b802372dba7f426f0a596f5fe26b7773acfdc8232926","impliedFormat":1},{"version":"6825eb4d1c8beb77e9ed6681c830326a15ebf52b171f83ffbca1b1574c90a3b0","impliedFormat":1},{"version":"1741975791f9be7f803a826457273094096e8bba7a50f8fa960d5ed2328cdbcc","impliedFormat":1},{"version":"6ec0d1c15d14d63d08ccb10d09d839bf8a724f6b4b9ed134a3ab5042c54a7721","impliedFormat":1},{"version":"043a3b03dcb40d6b87d36ad26378c80086905232ee5602f067eaaed21baa42ef","impliedFormat":1},{"version":"b61028c5e29a0691e91a03fa2c4501ea7ed27f8fa536286dc2887a39a38b6c44","impliedFormat":1},{"version":"2c3bcb8a4ea2fcb4208a06672af7540dd65bf08298d742f041ffa6cbe487cf80","impliedFormat":1},{"version":"1cce0460d75645fc40044c729da9a16c2e0dabe11a58b5e4bfd62ac840a1835d","impliedFormat":1},{"version":"c784a9f75a6f27cf8c43cc9a12c66d68d3beb2e7376e1babfae5ae4998ffbc4a","impliedFormat":1},{"version":"feb4c51948d875fdbbaa402dad77ee40cf1752b179574094b613d8ad98921ce1","impliedFormat":1},{"version":"a6d3984b706cefe5f4a83c1d3f0918ff603475a2a3afa9d247e4114f18b1f1ef","impliedFormat":1},{"version":"b457d606cabde6ea3b0bc32c23dc0de1c84bb5cb06d9e101f7076440fc244727","impliedFormat":1},{"version":"9d59919309a2d462b249abdefba8ca36b06e8e480a77b36c0d657f83a63af465","impliedFormat":1},{"version":"9faa2661daa32d2369ec31e583df91fd556f74bcbd036dab54184303dee4f311","impliedFormat":1},{"version":"ba2e5b6da441b8cf9baddc30520c59dc3ab47ad3674f6cb51f64e7e1f662df12","impliedFormat":1},{"version":"9e8020e898d31ac0e771d197ce7391ce13065cd5e63c8cd26cdaf66b4f18a2a6","affectsGlobalScope":true,"impliedFormat":1},{"version":"f21ce049835dad382b22691fb6b34076d0717307d46d92320893765be010cd56","impliedFormat":1},{"version":"d14487891bf108abe8cd453e524c43adcc6ab460076de130fdceeae056716f5c","impliedFormat":1},{"version":"668ad7a30d682016ad429b19348e787c0b44ba48488f398fca2623f9be9bd2c9","impliedFormat":1},{"version":"a716e3f374ec689caa659bd11ea1c4bc710ecceb295baf224f93ece3344707ed","impliedFormat":1},{"version":"b20550496b496031dadad8f80eec01d115b299cb285ffc2bd64873e123efc0cf","impliedFormat":1},{"version":"c46813bfd156c5357506d49c461131c7f75367bf52052274c9889315fd12af29","impliedFormat":1},{"version":"665f83fc3e9992c7a5e15a470e4b9e10e8b588c35593b0058c8d1a9eca487c56","impliedFormat":1},{"version":"1d85c932bcb40ec1daa5fc23f7924e63d6537f6fda79a96cedeb6506c0ee6fa2","impliedFormat":1},{"version":"dd36b144e0e70b4e38f588913af663ed959b10b5cf80952a4beb22a10255bf08","impliedFormat":1},{"version":"d064b43717b5b5dfca0d6cd738022ab377c90e45f05edbcd5a0c8753e6627d88","impliedFormat":1},{"version":"d9f740654bb5703265eade0fb65edce48a32726e3b56041d23158121948c9a9f","impliedFormat":1},{"version":"74d5a87c3616cd5d8691059d531504403aa857e09cbaecb1c64dfb9ace0db185","impliedFormat":1}],"root":[[350,352]],"options":{"allowJs":true,"esModuleInterop":true,"jsx":1,"module":99,"skipLibCheck":true,"strict":true,"target":1},"referencedMap":[[355,1],[354,2],[360,3],[363,4],[361,5],[356,5],[365,5],[366,6],[380,7],[367,8],[374,9],[370,10],[368,11],[371,12],[375,13],[376,9],[373,14],[372,15],[377,16],[378,17],[379,18],[369,19],[381,5],[358,5],[359,5],[357,20],[362,21],[393,22],[65,5],[386,23],[389,24],[390,25],[387,5],[388,5],[385,5],[391,26],[384,27],[383,5],[364,28],[392,29],[382,5],[308,5],[353,5],[104,30],[105,30],[106,31],[64,32],[107,33],[108,34],[109,35],[59,5],[62,36],[60,5],[61,5],[110,37],[111,38],[112,39],[113,40],[114,41],[115,42],[116,42],[118,5],[117,43],[119,44],[120,45],[121,46],[103,47],[63,5],[122,48],[123,49],[124,50],[156,51],[125,52],[126,53],[127,54],[128,55],[129,56],[130,57],[131,58],[132,59],[133,60],[134,61],[135,61],[136,62],[137,5],[138,63],[140,64],[139,65],[141,66],[142,67],[143,68],[144,69],[145,70],[146,71],[147,72],[148,73],[149,74],[150,75],[151,76],[152,77],[153,78],[154,79],[155,80],[51,5],[161,81],[162,82],[160,83],[158,84],[159,85],[49,5],[52,86],[50,5],[58,87],[311,88],[316,89],[318,90],[180,91],[185,92],[284,93],[255,94],[263,95],[282,96],[181,97],[229,5],[230,98],[283,99],[206,100],[182,101],[210,100],[200,100],[167,100],[247,102],[172,5],[244,103],[242,104],[189,5],[245,105],[335,106],[253,83],[334,5],[333,107],[246,83],[235,108],[243,109],[258,110],[259,111],[250,5],[190,112],[248,5],[249,83],[328,113],[331,114],[217,115],[216,116],[215,117],[338,83],[214,118],[194,5],[341,5],[344,5],[343,83],[345,119],[163,5],[278,5],[165,120],[299,5],[300,5],[302,5],[305,121],[301,5],[303,122],[304,122],[184,5],[310,118],[319,123],[323,124],[176,125],[237,126],[236,5],[254,127],[251,5],[252,5],[257,128],[233,129],[175,130],[204,131],[275,132],[168,28],[174,133],[164,134],[286,135],[297,136],[285,5],[296,137],[205,5],[192,138],[272,139],[271,5],[274,140],[273,140],[226,141],[211,141],[266,142],[212,142],[170,143],[169,5],[270,144],[269,145],[268,146],[267,147],[171,148],[241,149],[256,150],[240,151],[262,152],[264,153],[261,151],[207,148],[157,5],[276,154],[231,155],[295,156],[188,157],[290,158],[183,5],[291,159],[293,160],[294,161],[289,5],[288,28],[208,162],[277,163],[298,164],[177,5],[179,5],[191,165],[265,166],[173,167],[178,5],[187,168],[186,169],[193,170],[234,2],[232,107],[195,171],[197,172],[342,5],[196,173],[198,174],[313,5],[314,5],[312,5],[315,5],[340,5],[199,175],[239,83],[57,5],[260,176],[218,5],[228,177],[321,83],[327,178],[225,83],[325,83],[224,179],[307,180],[223,178],[166,5],[329,181],[221,83],[222,83],[213,5],[227,5],[220,182],[219,183],[209,184],[203,185],[292,5],[202,186],[201,5],[317,5],[238,83],[309,187],[48,5],[56,188],[53,83],[54,5],[55,5],[287,189],[281,190],[279,5],[280,191],[320,192],[322,193],[324,194],[326,195],[330,196],[349,197],[332,198],[336,199],[337,200],[339,201],[346,202],[348,5],[347,203],[306,204],[46,5],[47,5],[8,5],[9,5],[11,5],[10,5],[2,5],[12,5],[13,5],[14,5],[15,5],[16,5],[17,5],[18,5],[19,5],[3,5],[20,5],[21,5],[4,5],[22,5],[26,5],[23,5],[24,5],[25,5],[27,5],[28,5],[29,5],[5,5],[30,5],[31,5],[32,5],[33,5],[6,5],[37,5],[34,5],[35,5],[36,5],[38,5],[7,5],[39,5],[44,5],[45,5],[40,5],[41,5],[42,5],[43,5],[1,5],[81,205],[91,206],[80,205],[101,207],[72,208],[71,209],[100,203],[94,210],[99,211],[74,212],[88,213],[73,214],[97,215],[69,216],[68,203],[98,217],[70,218],[75,219],[76,5],[79,219],[66,5],[102,220],[92,221],[83,222],[84,223],[86,224],[82,225],[85,226],[95,203],[77,227],[78,228],[87,229],[67,230],[90,221],[89,219],[93,5],[96,231],[350,232],[352,233],[351,83]],"affectedFilesPendingEmit":[350,352,351],"version":"5.9.2"}
===== END FILE =====

===== FILE: main.py =====
#!/usr/bin/env python3
"""
Main entry point for TranscribeAlpha application.
This file provides a direct import path for deployment platforms.
"""

import sys
import os
import logging

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

logger.info("TranscribeAlpha starting up")

# Ensure we can import from current directory and backend
current_dir = os.path.dirname(os.path.abspath(__file__))
backend_dir = os.path.join(current_dir, 'backend')

sys.path.insert(0, current_dir)
sys.path.insert(0, backend_dir)

# Import the app
try:
    from backend.server import app
    logger.info("Imported app from backend.server")
except ImportError as e:
    logger.warning("Failed to import from backend.server: %s", e)
    try:
        os.chdir(backend_dir)
        sys.path.insert(0, backend_dir)
        from server import app
        logger.info("Imported app from server")
    except ImportError as e2:
        logger.error("Failed to import app: %s, %s", e, e2)
        raise ImportError(f"Could not import app: {e}, {e2}")

if __name__ == "__main__":
    port = int(os.getenv("PORT", 8080))
    host = os.getenv("HOST", "0.0.0.0")
    logger.info("Starting server on %s:%d", host, port)

    import hypercorn.asyncio
    import hypercorn.config
    import asyncio

    config = hypercorn.config.Config()
    config.bind = [f"{host}:{port}"]
    config.h2 = True

    asyncio.run(hypercorn.asyncio.serve(app, config))
===== END FILE =====

===== FILE: requirements.txt =====
fastapi>=0.110.0
uvicorn[standard]>=0.27.0
hypercorn>=0.16.0
python-multipart>=0.0.6
google-cloud-storage>=2.10.0
python-docx>=1.1.0
ffmpeg-python>=0.2.0
pydub>=0.25.1
pydantic>=2.5.0
assemblyai>=0.30.0
packaging>=23.0
google-genai>=1.52.0
python-jose[cryptography]>=3.3.0
bcrypt>=4.0.0
google-cloud-secret-manager>=2.16.0
requests>=2.31.0
===== END FILE =====

===== FILE: scripts/add_user.sh =====
#!/bin/bash
#
# Add a new user to TranscribeAlpha
# Usage: ./scripts/add_user.sh <username> <password> [role]
#
# Example:
#   ./scripts/add_user.sh JohnDoe mypassword123
#   ./scripts/add_user.sh AdminUser adminpass admin
#

set -e

SECRET_NAME="transcribealpha-users"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# Check arguments
if [ $# -lt 2 ]; then
    echo -e "${RED}Usage: $0 <username> <password> [role]${NC}"
    echo ""
    echo "Arguments:"
    echo "  username  - The username for the new account"
    echo "  password  - The password for the new account"
    echo "  role      - Optional: 'admin' or 'user' (default: user)"
    echo ""
    echo "Example:"
    echo "  $0 JohnDoe mypassword123"
    echo "  $0 AdminUser adminpass admin"
    exit 1
fi

USERNAME="$1"
PASSWORD="$2"
ROLE="${3:-user}"

echo -e "${YELLOW}Adding user: ${USERNAME} (role: ${ROLE})${NC}"

# Check if gcloud is installed
if ! command -v gcloud &> /dev/null; then
    echo -e "${RED}Error: gcloud CLI is not installed${NC}"
    echo "Install it from: https://cloud.google.com/sdk/docs/install"
    exit 1
fi

# Check if logged in to gcloud
if ! gcloud auth print-identity-token &> /dev/null; then
    echo -e "${RED}Error: Not logged in to gcloud${NC}"
    echo "Run: gcloud auth login"
    exit 1
fi

# Check if Python is available
if ! command -v python3 &> /dev/null; then
    echo -e "${RED}Error: python3 is not installed${NC}"
    exit 1
fi

# Check if bcrypt is installed
if ! python3 -c "import bcrypt" 2>/dev/null; then
    echo -e "${YELLOW}Installing bcrypt...${NC}"
    pip3 install bcrypt --quiet
fi

# Generate password hash
echo "Generating password hash..."
PASSWORD_HASH=$(python3 -c "import bcrypt; print(bcrypt.hashpw('$PASSWORD'.encode(), bcrypt.gensalt()).decode())")

if [ -z "$PASSWORD_HASH" ]; then
    echo -e "${RED}Error: Failed to generate password hash${NC}"
    exit 1
fi

# Get current users from Secret Manager
echo "Fetching current users from Secret Manager..."
CURRENT_USERS=$(gcloud secrets versions access latest --secret="$SECRET_NAME" 2>/dev/null || echo '{"users":[]}')

# Check if user already exists
if echo "$CURRENT_USERS" | python3 -c "import sys, json; users = json.load(sys.stdin); exit(0 if any(u['username'] == '$USERNAME' for u in users.get('users', [])) else 1)" 2>/dev/null; then
    echo -e "${RED}Error: User '$USERNAME' already exists${NC}"
    exit 1
fi

# Add new user to JSON
echo "Adding user to configuration..."
TIMESTAMP=$(date -u +"%Y-%m-%dT%H:%M:%SZ")

NEW_USERS=$(echo "$CURRENT_USERS" | python3 -c "
import sys, json
data = json.load(sys.stdin)
data['users'].append({
    'username': '$USERNAME',
    'password_hash': '$PASSWORD_HASH',
    'role': '$ROLE',
    'created_at': '$TIMESTAMP'
})
print(json.dumps(data, indent=2))
")

# Save to temp file and upload
TEMP_FILE=$(mktemp)
echo "$NEW_USERS" > "$TEMP_FILE"

echo "Uploading to Secret Manager..."
gcloud secrets versions add "$SECRET_NAME" --data-file="$TEMP_FILE" --quiet

# Cleanup
rm -f "$TEMP_FILE"

echo ""
echo -e "${GREEN}User '$USERNAME' added successfully!${NC}"
echo ""
echo "Note: Changes take effect within 5 minutes (cache refresh)."
echo "To apply immediately, redeploy the Cloud Run service."
===== END FILE =====

===== FILE: scripts/export_codebase.py =====
#!/usr/bin/env python3
import argparse
import os
import sys
from pathlib import Path
from typing import Iterable, List, Set, Tuple


REPO_ROOT = Path(__file__).resolve().parents[1]

EXCLUDE_DIR_NAMES = {
    ".git",
    ".idea",
    ".next",
    ".pytest_cache",
    ".venv",
    ".vscode",
    "__pycache__",
    "node_modules",
    "out",
}
EXCLUDE_FILE_NAMES = {
    ".DS_Store",
    "Nielsen, Martin 2019-07-23.xml",
}


PART_SPECS = {
    "transcriber": [
        "backend/api/transcripts.py",
        "backend/transcriber.py",
        "backend/gemini.py",
        "backend/transcript_formatting.py",
        "backend/transcript_utils.py",
        "backend/models.py",
        "backend/media_processing.py",
        "backend/rev_ai_sync.py",
        "frontend-next/src/components/TranscribeForm.tsx",
        "frontend-next/src/utils/auth.ts",
    ],
    "editor": [
        "backend/api/transcripts.py",
        "backend/rev_ai_sync.py",
        "backend/transcript_formatting.py",
        "backend/transcript_utils.py",
        "backend/storage.py",
        "backend/models.py",
        "frontend-next/src/components/TranscriptEditor.tsx",
        "frontend-next/src/components/TranscribeForm.tsx",
        "frontend-next/src/utils/auth.ts",
    ],
    "clip_creator": [
        "backend/api/clips.py",
        "backend/api/media.py",
        "backend/media_processing.py",
        "backend/transcript_formatting.py",
        "backend/transcript_utils.py",
        "backend/storage.py",
        "backend/models.py",
        "frontend-next/src/components/ClipCreator.tsx",
        "frontend-next/src/components/TranscribeForm.tsx",
        "frontend-next/src/utils/auth.ts",
    ],
}


def is_binary_bytes(data: bytes) -> bool:
    if b"\x00" in data:
        return True
    sample = data[:4096]
    if not sample:
        return False
    text_chars = set(b"\n\r\t\f\b")
    text_chars.update(range(0x20, 0x7F))
    non_text = sum(1 for b in sample if b not in text_chars)
    return non_text / len(sample) > 0.3


def should_exclude(path: Path) -> bool:
    if path.name in EXCLUDE_FILE_NAMES:
        return True
    for part in path.relative_to(REPO_ROOT).parts:
        if part in EXCLUDE_DIR_NAMES:
            return True
    return False


def iter_files_under(root: Path) -> Iterable[Path]:
    for path in root.rglob("*"):
        if not path.is_file():
            continue
        if should_exclude(path):
            continue
        yield path


def expand_specs(specs: Iterable[str]) -> List[Path]:
    files: Set[Path] = set()
    for spec in specs:
        candidate = (REPO_ROOT / spec).resolve()
        if any(ch in spec for ch in "*?["):
            for match in REPO_ROOT.glob(spec):
                if match.is_file() and not should_exclude(match):
                    files.add(match)
                elif match.is_dir():
                    files.update(iter_files_under(match))
            continue
        if candidate.is_dir():
            files.update(iter_files_under(candidate))
        elif candidate.is_file() and not should_exclude(candidate):
            files.add(candidate)
    return sorted(files, key=lambda path: path.relative_to(REPO_ROOT).as_posix())


def collect_files(args: argparse.Namespace, output_path: Path) -> List[Path]:
    files: Set[Path] = set()

    if args.backend:
        files.update(iter_files_under(REPO_ROOT / "backend"))
        main_py = REPO_ROOT / "main.py"
        if main_py.exists():
            files.add(main_py)
    if args.frontend:
        files.update(iter_files_under(REPO_ROOT / "frontend-next"))
    if args.transcriber:
        files.update(expand_specs(PART_SPECS["transcriber"]))
    if args.editor:
        files.update(expand_specs(PART_SPECS["editor"]))
    if args.clip_creator:
        files.update(expand_specs(PART_SPECS["clip_creator"]))

    if not any((args.backend, args.frontend, args.transcriber, args.editor, args.clip_creator)):
        files.update(iter_files_under(REPO_ROOT))
        main_py = REPO_ROOT / "main.py"
        if main_py.exists():
            files.add(main_py)

    files = {path for path in files if path.resolve() != output_path.resolve()}
    return sorted(files, key=lambda path: path.relative_to(REPO_ROOT).as_posix())


def write_export(output_path: Path, files: List[Path]) -> int:
    output_path.parent.mkdir(parents=True, exist_ok=True)
    total_chars = 0
    with output_path.open("w", encoding="utf-8", newline="\n") as handle:
        def write_chunk(text: str) -> None:
            nonlocal total_chars
            handle.write(text)
            total_chars += len(text)

        for path in files:
            rel_path = path.relative_to(REPO_ROOT).as_posix()
            write_chunk(f"===== FILE: {rel_path} =====\n")
            try:
                data = path.read_bytes()
            except OSError as exc:
                write_chunk(f"[unreadable file: {exc}]\n")
                write_chunk("===== END FILE =====\n\n")
                continue
            if is_binary_bytes(data):
                write_chunk("[binary file omitted]\n")
                write_chunk("===== END FILE =====\n\n")
                continue
            text = data.decode("utf-8", errors="replace")
            write_chunk(text)
            if not text.endswith("\n"):
                write_chunk("\n")
            write_chunk("===== END FILE =====\n\n")
    return total_chars


def build_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(
        description="Export TranscribeAlpha source files into a single plain text file.",
    )
    parser.add_argument(
        "--output",
        default=str(REPO_ROOT / "codebase_export.txt"),
        help="Output file path (default: %(default)s)",
    )
    parser.add_argument("--backend", action="store_true", help="Include backend sources (plus main.py).")
    parser.add_argument("--frontend", action="store_true", help="Include frontend sources.")
    parser.add_argument("--transcriber", action="store_true", help="Include transcriber-related files (backend + frontend).")
    parser.add_argument("--editor", action="store_true", help="Include editor-related files (backend + frontend).")
    parser.add_argument(
        "--clip-creator",
        "--clip_creator",
        dest="clip_creator",
        action="store_true",
        help="Include clip creator-related files (backend + frontend).",
    )
    return parser


def main() -> int:
    parser = build_parser()
    args = parser.parse_args()
    output_path = Path(args.output).expanduser()

    files = collect_files(args, output_path)
    if not files:
        print("No files matched the selected filters.", file=sys.stderr)
        return 1

    total_chars = write_export(output_path, files)
    token_estimate = (total_chars + 3) // 4
    rel_output = output_path
    try:
        rel_output = output_path.relative_to(REPO_ROOT)
    except ValueError:
        pass
    print(f"Wrote {len(files)} files to {rel_output}")
    print(f"Characters: {total_chars:,}")
    print(f"Estimated tokens (4 chars/token): {token_estimate:,}")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
===== END FILE =====

===== FILE: scripts/list_users.sh =====
#!/bin/bash
#
# List all TranscribeAlpha users
# Usage: ./scripts/list_users.sh
#

SECRET_NAME="transcribealpha-users"

# Check if gcloud is available and logged in
if ! gcloud auth print-identity-token &> /dev/null 2>&1; then
    echo "Error: Not logged in to gcloud. Run: gcloud auth login"
    exit 1
fi

echo "TranscribeAlpha Users"
echo "====================="
echo ""

gcloud secrets versions access latest --secret="$SECRET_NAME" 2>/dev/null | python3 -c "
import sys, json
data = json.load(sys.stdin)
users = data.get('users', [])
if not users:
    print('No users found.')
else:
    for u in users:
        role = u.get('role', 'user')
        created = u.get('created_at', 'unknown')[:10]
        print(f\"  {u['username']:20} role: {role:8} created: {created}\")
    print()
    print(f'Total: {len(users)} user(s)')
"
===== END FILE =====

===== FILE: scripts/remove_user.sh =====
#!/bin/bash
#
# Remove a user from TranscribeAlpha
# Usage: ./scripts/remove_user.sh <username>
#
# Note: This removes the user's login but their transcripts remain in storage.
#

set -e

SECRET_NAME="transcribealpha-users"

RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m'

if [ $# -lt 1 ]; then
    echo -e "${RED}Usage: $0 <username>${NC}"
    exit 1
fi

USERNAME="$1"

echo -e "${YELLOW}Removing user: ${USERNAME}${NC}"

# Check gcloud
if ! gcloud auth print-identity-token &> /dev/null 2>&1; then
    echo -e "${RED}Error: Not logged in to gcloud. Run: gcloud auth login${NC}"
    exit 1
fi

# Get current users
CURRENT_USERS=$(gcloud secrets versions access latest --secret="$SECRET_NAME" 2>/dev/null)

# Check if user exists
if ! echo "$CURRENT_USERS" | python3 -c "import sys, json; users = json.load(sys.stdin); exit(0 if any(u['username'] == '$USERNAME' for u in users.get('users', [])) else 1)" 2>/dev/null; then
    echo -e "${RED}Error: User '$USERNAME' not found${NC}"
    exit 1
fi

# Confirm
echo -e "${YELLOW}Are you sure you want to remove '$USERNAME'? (y/N)${NC}"
read -r CONFIRM
if [ "$CONFIRM" != "y" ] && [ "$CONFIRM" != "Y" ]; then
    echo "Cancelled."
    exit 0
fi

# Remove user
NEW_USERS=$(echo "$CURRENT_USERS" | python3 -c "
import sys, json
data = json.load(sys.stdin)
data['users'] = [u for u in data['users'] if u['username'] != '$USERNAME']
print(json.dumps(data, indent=2))
")

# Upload
TEMP_FILE=$(mktemp)
echo "$NEW_USERS" > "$TEMP_FILE"
gcloud secrets versions add "$SECRET_NAME" --data-file="$TEMP_FILE" --quiet
rm -f "$TEMP_FILE"

echo ""
echo -e "${GREEN}User '$USERNAME' removed successfully!${NC}"
echo ""
echo "Note: Their transcripts remain in Cloud Storage."
===== END FILE =====

===== FILE: transcript_template.docx =====
[binary file omitted]
===== END FILE =====

